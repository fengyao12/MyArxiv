<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-21T00:00:00Z">2025-04-21</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">73</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seeing from Another Perspective: Evaluating Multi-View Understanding in
  MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15280v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15280v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chun-Hsiao Yeh, Chenyu Wang, Shengbang Tong, Ta-Ying Cheng, Rouyu Wang, Tianzhe Chu, Yuexiang Zhai, Yubei Chen, Shenghua Gao, Yi Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-view understanding, the ability to reconcile visual information across
diverse viewpoints for effective navigation, manipulation, and 3D scene
comprehension, is a fundamental challenge in Multi-Modal Large Language Models
(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive
advances in high-level reasoning and planning, they frequently fall short when
confronted with multi-view geometric consistency and cross-view correspondence.
To comprehensively evaluate the challenges of MLLMs in multi-view scene
reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human
carefully annotated multi-view question-answer pairs across 90 diverse
real-world scenes. Our six tasks (counting, attribute identification, relative
distance, relative direction, object manipulation, and camera pose estimation)
specifically test model's geometric correspondence and the capacity to align
information consistently across views. Our extensive experiments, benchmark on
27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and
GPT-4o against human evaluators reveals a substantial performance gap,
indicating that current MLLMs remain far from human-level proficiency. Through
in-depth analysis, we show that MLLMs are particularly underperforming under
two aspects: (1) cross-view correspondence for partially occluded views and (2)
establishing the coarse camera poses. These findings highlight the necessity of
domain-specific refinements or modules that embed stronger multi-view
awareness. We believe that our All-Angles Bench offers valuable insights and
contribute to bridging the gap between MLLMs and human-level multi-view
understanding. The project and benchmark are publicly available at
https://danielchyeh.github.io/All-Angles-Bench/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://danielchyeh.github.io/All-Angles-Bench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An LMM for Efficient Video Understanding via Reinforced Compression of
  Video Cubes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji Qi, Yuan Yao, Yushi Bai, Bin Xu, Juanzi Li, Zhiyuan Liu, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Multimodal Models (LMMs) uniformly perceive video frames, creating
computational inefficiency for videos with inherently varying temporal
information density. This paper present \textbf{Quicksviewer}, an LMM with new
perceiving paradigm that partitions a video of nonuniform density into varying
cubes using Gumbel Softmax, followed by a unified resampling for each cube to
achieve efficient video understanding. This simple and intuitive approach
dynamically compress video online based on its temporal density, significantly
reducing spatiotemporal redundancy (overall 45$\times$ compression rate), while
enabling efficient training with large receptive field. We train the model from
a language backbone through three progressive stages, each incorporating
lengthy videos on average of 420s/1fps thanks to the perceiving efficiency.
With only 0.8M total video-text samples for training, our model outperforms the
direct baseline employing a fixed partitioning strategy by a maximum of 8.72 in
accuracy, demonstrating the effectiveness in performance. On Video-MME,
Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\%
of tokens per frame required by baselines. With this paradigm, scaling up the
number of input frames reveals a clear power law of the model capabilities. It
is also empirically verified that the segments generated by the cubing network
can help for analyzing continuous events in videos.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Roll the dice & look before you leap: Going beyond the creative limits
  of next-token prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15266v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15266v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vaishnavh Nagarajan, Chen Henry Wu, Charles Ding, Aditi Raghunathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We design a suite of minimal algorithmic tasks that are a loose abstraction
of open-ended real-world tasks. This allows us to cleanly and controllably
quantify the creative limits of the present-day language model. Much like
real-world tasks that require a creative, far-sighted leap of thought, our
tasks require an implicit, open-ended stochastic planning step that either (a)
discovers new connections in an abstract knowledge graph (like in wordplay,
drawing analogies, or research) or (b) constructs new patterns (like in
designing math problems or new proteins). In these tasks, we empirically and
conceptually argue how next-token learning is myopic and memorizes excessively;
comparatively, multi-token approaches, namely teacherless training and
diffusion models, excel in producing diverse and original output. Secondly, in
our tasks, we find that to elicit randomness from the Transformer without
hurting coherence, it is better to inject noise right at the input layer (via a
method we dub hash-conditioning) rather than defer to temperature sampling from
the output layer. Thus, our work offers a principled, minimal test-bed for
analyzing open-ended creative skills, and offers new arguments for going beyond
next-token learning and softmax-based sampling. We make part of the code
available under https://github.com/chenwu98/algorithmic-creativity
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anirudh Khatry, Robert Zhang, Jia Pan, Ziteng Wang, Qiaochu Chen, Greg Durrett, Isil Dillig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  C-to-Rust transpilation is essential for modernizing legacy C code while
enhancing safety and interoperability with modern Rust ecosystems. However, no
dataset currently exists for evaluating whether a system can transpile C into
safe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset
of 100 C repositories, each paired with manually-written interfaces in safe
Rust as well as test cases that can be used to validate correctness of the
transpilation. By considering entire repositories rather than isolated
functions, CRUST-Bench captures the challenges of translating complex projects
with dependencies across multiple files. The provided Rust interfaces provide
explicit specifications that ensure adherence to idiomatic, memory-safe Rust
patterns, while the accompanying test cases enforce functional correctness. We
evaluate state-of-the-art large language models (LLMs) on this task and find
that safe and idiomatic Rust generation is still a challenging problem for
various state-of-the-art methods and techniques. We also provide insights into
the errors LLMs usually make in transpiling code from C to safe Rust. The best
performing model, OpenAI o1, is able to solve only 15 tasks in a single-shot
setting. Improvements on CRUST-Bench would lead to improved transpilation
systems that can reason about complex scenarios and help in migrating legacy
codebases from C into languages like Rust that ensure memory safety. You can
find the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as
  Test-Time Scaling Evaluators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15253v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15253v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilun Zhou, Austin Xu, Peifeng Wang, Caiming Xiong, Shafiq Joty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling test-time computation, or affording a generator large language model
(LLM) extra compute during inference, typically employs the help of external
non-generative evaluators (i.e., reward models). Concurrently, LLM-judges,
models trained to generate evaluations and critiques (explanations) in natural
language, are becoming increasingly popular in automatic evaluation. Despite
judge empirical successes, their effectiveness as evaluators in test-time
scaling settings is largely unknown. In this paper, we introduce the Judge
Evaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge
performance in three domains (math reasoning, code generation, and instruction
following) under three task settings: response reranking, step-level beam
search, and critique-based response refinement. We evaluate 10 different judge
models (7B-70B parameters) for 8 different base generator models (6.7B-72B
parameters). Our benchmark shows that while judges are competitive with outcome
reward models in reranking, they are consistently worse than process reward
models in beam search procedures. Furthermore, though unique to LLM-judges,
their natural language critiques are currently ineffective in guiding the
generator towards better responses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally. The codebase is at
  https://github.com/SalesforceAIResearch/jetts-benchmark</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MR. Guard: Multilingual Reasoning Guardrail using Curriculum Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15241v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15241v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yahan Yang, Soham Dan, Shuo Li, Dan Roth, Insup Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are susceptible to adversarial attacks such as
jailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability
is exacerbated in multilingual setting, where multilingual safety-aligned data
are often limited. Thus, developing a guardrail capable of detecting and
filtering unsafe content across diverse languages is critical for deploying
LLMs in real-world applications. In this work, we propose an approach to build
a multilingual guardrail with reasoning. Our method consists of: (1) synthetic
multilingual data generation incorporating culturally and linguistically
nuanced variants, (2) supervised fine-tuning, and (3) a curriculum-guided Group
Relative Policy Optimization (GRPO) framework that further improves
performance. Experimental results demonstrate that our multilingual guardrail
consistently outperforms recent baselines across both in-domain and
out-of-domain languages. The multilingual reasoning capability of our guardrail
enables it to generate multilingual explanations, which are particularly useful
for understanding language-specific risks and ambiguities in multilingual
content moderation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Values in the Wild: Discovering and Analyzing Values in Real-World
  Language Model Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15236v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15236v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saffron Huang, Esin Durmus, Miles McCain, Kunal Handa, Alex Tamkin, Jerry Hong, Michael Stern, Arushi Somani, Xiuruo Zhang, Deep Ganguli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI assistants can impart value judgments that shape people's decisions and
worldviews, yet little is known empirically about what values these systems
rely on in practice. To address this, we develop a bottom-up,
privacy-preserving method to extract the values (normative considerations
stated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit
in hundreds of thousands of real-world interactions. We empirically discover
and taxonomize 3,307 AI values and study how they vary by context. We find that
Claude expresses many practical and epistemic values, and typically supports
prosocial human values while resisting values like "moral nihilism". While some
values appear consistently across contexts (e.g. "transparency"), many are more
specialized and context-dependent, reflecting the diversity of human
interlocutors and their varied contexts. For example, "harm prevention" emerges
when Claude resists users, "historical accuracy" when responding to queries
about controversial events, "healthy boundaries" when asked for relationship
advice, and "human agency" in technology ethics discussions. By providing the
first large-scale empirical mapping of AI values in deployment, our work
creates a foundation for more grounded evaluation and design of values in AI
systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>44 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fully Bayesian Approaches to Topics over Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julián Cendrero, Julio Gonzalo, Ivar Zapata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Topics over Time (ToT) model captures thematic changes in timestamped
datasets by explicitly modeling publication dates jointly with word
co-occurrence patterns. However, ToT was not approached in a fully Bayesian
fashion, a flaw that makes it susceptible to stability problems. To address
this issue, we propose a fully Bayesian Topics over Time (BToT) model via the
introduction of a conjugate prior to the Beta distribution. This prior acts as
a regularization that prevents the online version of the algorithm from
unstable updates when a topic is poorly represented in a mini-batch. The
characteristics of this prior to the Beta distribution are studied here for the
first time. Still, this model suffers from a difference in scale between the
single-time observations and the multiplicity of words per document. A
variation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a
solution. In WBToT, publication dates are repeated a certain number of times
per document, which balances the relative influence of words and timestamps
along the inference process. We have tested our models on two datasets: a
collection of over 200 years of US state-of-the-union (SOTU) addresses and a
large-scale COVID-19 Twitter corpus of 10 million tweets. The results show that
WBToT captures events better than Latent Dirichlet Allocation and other SOTA
topic models like BERTopic: the median absolute deviation of the topic presence
over time is reduced by $51\%$ and $34\%$, respectively. Our experiments also
demonstrate the superior coherence of WBToT over BToT, which highlights the
importance of balancing the time and word modalities. Finally, we illustrate
the stability of the online optimization algorithm in WBToT, which allows the
application of WBToT to problems that are intractable for standard ToT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EvalAgent: Discovering Implicit Evaluation Criteria from the Web 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manya Wadhwa, Zayne Sprague, Chaitanya Malaviya, Philippe Laban, Junyi Jessy Li, Greg Durrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluation of language model outputs on structured writing tasks is typically
conducted with a number of desirable criteria presented to human evaluators or
large language models (LLMs). For instance, on a prompt like "Help me draft an
academic talk on coffee intake vs research productivity", a model response may
be evaluated for criteria like accuracy and coherence. However, high-quality
responses should do more than just satisfy basic task requirements. An
effective response to this query should include quintessential features of an
academic talk, such as a compelling opening, clear research questions, and a
takeaway. To help identify these implicit criteria, we introduce EvalAgent, a
novel framework designed to automatically uncover nuanced and task-specific
criteria. EvalAgent first mines expert-authored online guidance. It then uses
this evidence to propose diverse, long-tail evaluation criteria that are
grounded in reliable external sources. Our experiments demonstrate that the
grounded criteria produced by EvalAgent are often implicit (not directly stated
in the user's prompt), yet specific (high degree of lexical precision).
Further, EvalAgent criteria are often not satisfied by initial responses but
they are actionable, such that responses can be refined to satisfy them.
Finally, we show that combining LLM-generated and EvalAgent criteria uncovers
more human-valued criteria than using LLMs alone.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus
  LLM Judges <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nandan Thakur, Ronak Pradeep, Shivani Upadhyay, Daniel Campos, Nick Craswell, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) enables large language models (LLMs) to
generate answers with citations from source documents containing "ground
truth", thereby reducing system hallucinations. A crucial factor in RAG
evaluation is "support", whether the information in the cited documents
supports the answer. To this end, we conducted a large-scale comparative study
of 45 participant submissions on 36 topics to the TREC 2024 RAG Track,
comparing an automatic LLM judge (GPT-4o) against human judges for support
assessment. We considered two conditions: (1) fully manual assessments from
scratch and (2) manual assessments with post-editing of LLM predictions. Our
results indicate that for 56% of the manual from-scratch assessments, human and
GPT-4o predictions match perfectly (on a three-level scale), increasing to 72%
in the manual with post-editing condition. Furthermore, by carefully analyzing
the disagreements in an unbiased study, we found that an independent human
judge correlates better with GPT-4o than a human judge, suggesting that LLM
judges can be a reliable alternative for support assessment. To conclude, we
provide a qualitative analysis of human and GPT-4o errors to help guide future
iterations of support assessment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025 (short)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On true empty category 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15168v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15168v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qilin Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  According to Chomsky (1981, 1986), empty categories consist of PRO, pro,
trace, and variable. However, some empty object positions seem to be
incompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014)
and Li & Wei (2014) raise the true empty category hypothesis, which holds that
true empty category is only an empty position with category and Case features.
As a last resort option, it is used mainly to meet the subcatgorization of a
verb. This assumption is ingenious, and if proved to be true, it will exert a
great impact on the study of UG. In this paper, we evaluate their evidence from
topicalization and demonstrate that it can be accounted for without invoking
true empty category.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Synthetic Imputation Approach: Generating Optimal Synthetic Texts
  For Underrepresented Categories In Supervised Classification Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15160v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15160v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joan C. Timoneda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa,
require that all categories in an annotation task be sufficiently represented
in the training data for optimal performance. However, it is often difficult to
find sufficient examples for all categories in a task when building a
high-quality training set. In this article, I describe this problem and propose
a solution, the synthetic imputation approach. Leveraging a generative LLM
(GPT-4o), this approach generates synthetic texts based on careful prompting
and five original examples drawn randomly with replacement from the sample.
This approach ensures that new synthetic texts are sufficiently different from
the original texts to reduce overfitting, but retain the underlying substantive
meaning of the examples to maximize out-of-sample performance. With 75 original
examples or more, synthetic imputation's performance is on par with a full
sample of original texts, and overfitting remains low, predictable and
correctable with 50 original samples. The synthetic imputation approach
provides a novel role for generative LLMs in research and allows applied
researchers to balance their datasets for best performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juyeon Kim, Geon Lee, Taeuk Kim, Kijung Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity linking (EL) aligns textual mentions with their corresponding entities
in a knowledge base, facilitating various applications such as semantic search
and question answering. Recent advances in multimodal entity linking (MEL) have
shown that combining text and images can reduce ambiguity and improve alignment
accuracy. However, most existing MEL methods overlook the rich structural
information available in the form of knowledge-graph (KG) triples. In this
paper, we propose KGMEL, a novel framework that leverages KG triples to enhance
MEL. Specifically, it operates in three stages: (1) Generation: Produces
high-quality triples for each mention by employing vision-language models based
on its text and images. (2) Retrieval: Learns joint mention-entity
representations, via contrastive learning, that integrate text, images, and
(generated or KG) triples to retrieve candidate entities for each mention. (3)
Reranking: Refines the KG triples of the candidate entities and employs large
language models to identify the best-matching entity for the mention. Extensive
experiments on benchmark datasets demonstrate that KGMEL outperforms existing
methods. Our code and datasets are available at:
https://github.com/juyeonnn/KGMEL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGIR 2025 (Short)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15133v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15133v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziwen Xu, Shuxun Wang, Kewei Xu, Haoming Xu, Mengru Wang, Xinle Deng, Yunzhi Yao, Guozhou Zheng, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce EasyEdit2, a framework designed to enable
plug-and-play adjustability for controlling Large Language Model (LLM)
behaviors. EasyEdit2 supports a wide range of test-time interventions,
including safety, sentiment, personality, reasoning patterns, factuality, and
language features. Unlike its predecessor, EasyEdit2 features a new
architecture specifically designed for seamless model steering. It comprises
key modules such as the steering vector generator and the steering vector
applier, which enable automatic generation and application of steering vectors
to influence the model's behavior without modifying its parameters. One of the
main advantages of EasyEdit2 is its ease of use-users do not need extensive
technical knowledge. With just a single example, they can effectively guide and
adjust the model's responses, making precise control both accessible and
efficient. Empirically, we report model steering performance across different
LLMs, demonstrating the effectiveness of these techniques. We have released the
source code on GitHub at https://github.com/zjunlp/EasyEdit along with a
demonstration notebook. In addition, we provide a demo video at
https://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Demo:
  https://zjunlp.github.io/project/EasyEdit2/video; code:
  https://github.com/zjunlp/EasyEdit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kuwain 1.5B: An Arabic SLM via Language Injection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15120v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15120v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khalil Hennara, Sara Chrouf, Mohamed Motaism Hamed, Zeina Aldallal, Omar Hadid, Safwan AlModhayan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Enhancing existing models with new knowledge is a crucial aspect of AI
development. This paper introduces a novel method for integrating a new
language into a large language model (LLM). Our approach successfully
incorporates a previously unseen target language into an existing LLM without
compromising its prior knowledge. We trained a tiny model with 1.5 billion
parameters named Kuwain by injecting the Arabic language into a small
open-source model mainly trained in English. Our method demonstrates
significant improvements in Arabic language performance, with an average 8%
improvement across various benchmarks, while retaining the model's existing
knowledge with a minimum amount of the original model's data. This offers a
cost-effective alternative to training a comprehensive model in both English
and Arabic. The results highlight the potential for efficient, targeted
language model expansion without extensive retraining or resource-intensive
processes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking the Potential of Multimodality in Collaborative Problem
  Solving Diagnosis with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15093v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15093v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        K. Wong, B. Wu, S. Bulathwela, M. Cukurova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting collaborative and problem-solving behaviours from digital traces to
interpret students' collaborative problem solving (CPS) competency is a
long-term goal in the Artificial Intelligence in Education (AIEd) field.
Although multimodal data and advanced models are argued to have the potential
to detect complex CPS behaviours, empirical evidence on their value remains
limited with some contrasting evidence. In this study, we investigated the
potential of multimodal data to improve model performance in diagnosing 78
secondary school students' CPS subskills and indicators in authentic
educational settings. In particular, text embeddings from verbal data and
acoustic embeddings from audio data were used in a multimodal classification
model for CPS diagnosis. Both unimodal and multimodal transformer-based models
outperformed traditional models in detecting CPS classes. Although the
inclusion of multimodality did not improve the performance of traditional
unimodal models, its integration into transformer-based models demonstrated
improved performance for diagnosing social-cognitive CPS classes compared to
unimodal transformer-based models. Based on the results, the paper argues that
multimodality and the selection of a particular modelling technique should not
be taken for granted to achieve the best performance in the automated detection
of every CPS subskill and indicator. Rather, their value is limited to certain
types of CPS indicators, affected by the complexity of the labels, and
dependent on the composition of indicators in the dataset. We conclude the
paper by discussing the required nuance when considering the value of LLMs and
multimodality in automated CPS diagnosis, highlighting the need for human-AI
complementarity, and proposing the exploration of relevant model architectures
and techniques to improve CPS diagnosis in authentic educational contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for 26th International Conference on Artificial Intelligence
  in Education (AIED 2025), 22 - 26 July 2025, Palermo, Italy. 17 pages, 1
  figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulong Li, Zhixiang Lu, Feilong Tang, Simin Lai, Ming Hu, Yuxuan Zhang, Haochen Xue, Zhaodong Wu, Imran Razzak, Qingxia Li, Jionglong Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of social media has significantly reshaped the dynamics
of public opinion, resulting in complex interactions that traditional models
fail to effectively capture. To address this challenge, we propose an
innovative approach that integrates multi-dimensional Hawkes processes with
Graph Neural Network, modeling opinion propagation dynamics among nodes in a
social network while considering the intricate hierarchical relationships
between comments. The extended multi-dimensional Hawkes process captures the
hierarchical structure, multi-dimensional interactions, and mutual influences
across different topics, forming a complex propagation network. Moreover,
recognizing the lack of high-quality datasets capable of comprehensively
capturing the evolution of public opinion dynamics, we introduce a new dataset,
VISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015
second-level comments, and 29,578 third-level comments, covering diverse
domains such as politics, entertainment, sports, health, and medicine. The
dataset is annotated with detailed sentiment labels across 11 categories and
clearly defined hierarchical relationships. When combined with our method, it
offers strong interpretability by linking sentiment propagation to the comment
hierarchy and temporal evolution. Our approach provides a robust baseline for
future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation
  with Large Language Models <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15068v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15068v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronak Pradeep, Nandan Thakur, Shivani Upadhyay, Daniel Campos, Nick Craswell, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have significantly enhanced the capabilities of
information access systems, especially with retrieval-augmented generation
(RAG). Nevertheless, the evaluation of RAG systems remains a barrier to
continued progress, a challenge we tackle in this work by proposing an
automatic evaluation framework that is validated against human annotations. We
believe that the nugget evaluation methodology provides a solid foundation for
evaluating RAG systems. This approach, originally developed for the TREC
Question Answering (QA) Track in 2003, evaluates systems based on atomic facts
that should be present in good answers. Our efforts focus on "refactoring" this
methodology, where we describe the AutoNuggetizer framework that specifically
applies LLMs to both automatically create nuggets and automatically assign
nuggets to system answers. In the context of the TREC 2024 RAG Track, we
calibrate a fully automatic approach against strategies where nuggets are
created manually or semi-manually by human assessors and then assigned manually
to system answers. Based on results from a community-wide evaluation, we
observe strong agreement at the run level between scores derived from fully
automatic nugget evaluation and human-based variants. The agreement is stronger
when individual framework components such as nugget assignment are automated
independently. This suggests that our evaluation framework provides tradeoffs
between effort and quality that can be used to guide the development of future
RAG systems. However, further research is necessary to refine our approach,
particularly in establishing robust per-topic agreement to diagnose system
failures effectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in SIGIR 2025. Significant updates and revisions to
  arXiv:2411.09607</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Testing LLMs' Capabilities in Annotating Translations Based on an Error
  Typology Designed for LSP Translation: First Experiments with Chat<span class="highlight-title">GPT</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15052v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15052v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joachim Minder, Guillaume Wisniewski, Natalie Kübler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study investigates the capabilities of large language models (LLMs),
specifically ChatGPT, in annotating MT outputs based on an error typology. In
contrast to previous work focusing mainly on general language, we explore
ChatGPT's ability to identify and categorise errors in specialised
translations. By testing two different prompts and based on a customised error
typology, we compare ChatGPT annotations with human expert evaluations of
translations produced by DeepL and ChatGPT itself. The results show that, for
translations generated by DeepL, recall and precision are quite high. However,
the degree of accuracy in error categorisation depends on the prompt's specific
features and its level of detail, ChatGPT performing very well with a detailed
prompt. When evaluating its own translations, ChatGPT achieves significantly
poorer results, revealing limitations with self-assessment. These results
highlight both the potential and the limitations of LLMs for translation
evaluation, particularly in specialised domains. Our experiments pave the way
for future research on open-source LLMs, which could produce annotations of
comparable or even higher quality. In the future, we also aim to test the
practical effectiveness of this automated evaluation in the context of
translation training, particularly by optimising the process of human
evaluation by teachers and by exploring the impact of annotations by LLMs on
students' post-editing and translation learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in the proceedings of MT Summit 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RainbowPlus: Enhancing Adversarial <span class="highlight-title">Prompt</span> Generation via Evolutionary
  Quality-Diversity Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15047v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15047v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quy-Anh Dang, Chris Ngo, Truong-Son Hy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) exhibit remarkable capabilities but are
susceptible to adversarial prompts that exploit vulnerabilities to produce
unsafe or biased outputs. Existing red-teaming methods often face scalability
challenges, resource-intensive requirements, or limited diversity in attack
strategies. We propose RainbowPlus, a novel red-teaming framework rooted in
evolutionary computation, enhancing adversarial prompt generation through an
adaptive quality-diversity (QD) search that extends classical evolutionary
algorithms like MAP-Elites with innovations tailored for language models. By
employing a multi-element archive to store diverse high-quality prompts and a
comprehensive fitness function to evaluate multiple prompts concurrently,
RainbowPlus overcomes the constraints of single-prompt archives and pairwise
comparisons in prior QD methods like Rainbow Teaming. Experiments comparing
RainbowPlus to QD methods across six benchmark datasets and four open-source
LLMs demonstrate superior attack success rate (ASR) and diversity
(Diverse-Score $\approx 0.84$), generating up to 100 times more unique prompts
(e.g., 10,418 vs. 100 for Ministral-8B-Instruct-2410). Against nine
state-of-the-art methods on the HarmBench dataset with twelve LLMs (ten
open-source, two closed-source), RainbowPlus achieves an average ASR of 81.1%,
surpassing AutoDAN-Turbo by 3.9%, and is 9 times faster (1.45 vs. 13.50 hours).
Our open-source implementation fosters further advancements in LLM safety,
offering a scalable tool for vulnerability assessment. Code and resources are
publicly available at https://github.com/knoveleng/rainbowplus, supporting
reproducibility and future research in LLM red-teaming.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DistilQwen2.5: Industrial Practices of Training Distilled Open
  Lightweight Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15027v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15027v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengyu Wang, Junbing Yan, Yuanhao Yue, Jun Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Enhancing computational efficiency and reducing deployment costs for large
language models (LLMs) have become critical challenges in various
resource-constrained scenarios. In this work, we present DistilQwen2.5, a
family of distilled, lightweight LLMs derived from the public Qwen2.5 models.
These distilled models exhibit enhanced instruction-following capabilities
compared to the original models based on a series of distillation techniques
that incorporate knowledge from much larger LLMs. In our industrial practice,
we first leverage powerful proprietary LLMs with varying capacities as
multi-agent teachers to select, rewrite, and refine instruction-response pairs
that are more suitable for student LLMs to learn. After standard fine-tuning,
we further leverage a computationally efficient model fusion approach that
enables student models to progressively integrate fine-grained hidden knowledge
from their teachers. Experimental evaluations demonstrate that the distilled
models possess significantly stronger capabilities than their original
checkpoints. Additionally, we present use cases to illustrate the applications
of our framework in real-world scenarios. To facilitate practical use, we have
released all the DistilQwen2.5 models to the open-source community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMs as Data Annotators: How Close Are We to Human Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15022v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15022v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Uzair Ul Haq, Davide Rigoni, Alessandro Sperduti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In NLP, fine-tuning LLMs is effective for various applications but requires
high-quality annotated data. However, manual annotation of data is
labor-intensive, time-consuming, and costly. Therefore, LLMs are increasingly
used to automate the process, often employing in-context learning (ICL) in
which some examples related to the task are given in the prompt for better
performance. However, manually selecting context examples can lead to
inefficiencies and suboptimal model performance. This paper presents
comprehensive experiments comparing several LLMs, considering different
embedding models, across various datasets for the Named Entity Recognition
(NER) task. The evaluation encompasses models with approximately $7$B and $70$B
parameters, including both proprietary and non-proprietary models. Furthermore,
leveraging the success of Retrieval-Augmented Generation (RAG), it also
considers a method that addresses the limitations of ICL by automatically
retrieving contextual examples, thereby enhancing performance. The results
highlight the importance of selecting the appropriate LLM and embedding model,
understanding the trade-offs between LLM sizes and desired performance, and the
necessity to direct research efforts towards more challenging datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stay Hungry, Stay Foolish: On the Extended Reading Articles Generation
  with LLMs <span class="chip">AAAI2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yow-Fu Liou, Yu-Chien Tang, An-Zi Yen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The process of creating educational materials is both time-consuming and
demanding for educators. This research explores the potential of Large Language
Models (LLMs) to streamline this task by automating the generation of extended
reading materials and relevant course suggestions. Using the TED-Ed Dig Deeper
sections as an initial exploration, we investigate how supplementary articles
can be enriched with contextual knowledge and connected to additional learning
resources. Our method begins by generating extended articles from video
transcripts, leveraging LLMs to include historical insights, cultural examples,
and illustrative anecdotes. A recommendation system employing semantic
similarity ranking identifies related courses, followed by an LLM-based
refinement process to enhance relevance. The final articles are tailored to
seamlessly integrate these recommendations, ensuring they remain cohesive and
informative. Experimental evaluations demonstrate that our model produces
high-quality content and accurate course suggestions, assessed through metrics
such as Hit Rate, semantic similarity, and coherence. Our experimental analysis
highlight the nuanced differences between the generated and existing materials,
underscoring the model's capacity to offer more engaging and accessible
learning experiences. This study showcases how LLMs can bridge the gap between
core content and supplementary learning, providing students with additional
recommended resources while also assisting teachers in designing educational
materials.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by iRAISE@AAAI2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient <span class="highlight-title">Pretrain</span>ing Length Scaling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14992v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14992v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bohong Wu, Shen Yan, Sijun Zhang, Jianqiao Lu, Yutao Zeng, Ya Wang, Xun Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models have demonstrated the effectiveness
of length scaling during post-training, yet its potential in pre-training
remains underexplored. We present the Parallel Hidden Decoding Transformer
(\textit{PHD}-Transformer), a novel framework that enables efficient length
scaling during pre-training while maintaining inference efficiency.
\textit{PHD}-Transformer achieves this through an innovative KV cache
management strategy that distinguishes between original tokens and hidden
decoding tokens. By retaining only the KV cache of original tokens for
long-range dependencies while immediately discarding hidden decoding tokens
after use, our approach maintains the same KV cache size as the vanilla
transformer while enabling effective length scaling. To further enhance
performance, we introduce two optimized variants: \textit{PHD-SWA} employs
sliding window attention to preserve local dependencies, while
\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate
linear growth in pre-filling time. Extensive experiments demonstrate consistent
improvements across multiple benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating LLMs on Chinese Topic Constructions: A Research Proposal
  Inspired by Tian et al. (2024) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14969v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14969v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodong Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a framework for evaluating large language models (LLMs)
on Chinese topic constructions, focusing on their sensitivity to island
constraints. Drawing inspiration from Tian et al. (2024), we outline an
experimental design for testing LLMs' grammatical knowledge of Mandarin syntax.
While no experiments have been conducted yet, this proposal aims to provide a
foundation for future studies and invites feedback on the methodology.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in
  Multiparty Dialogues 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14963v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14963v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Ribeiro, Luísa Coheur, Joao P. Carvalho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speaker identification using voice recordings leverages unique acoustic
features, but this approach fails when only textual data is available. Few
approaches have attempted to tackle the problem of identifying speakers solely
from text, and the existing ones have primarily relied on traditional methods.
In this work, we explore the use of fuzzy fingerprints from large pre-trained
models to improve text-based speaker identification. We integrate
speaker-specific tokens and context-aware modeling, demonstrating that
conversational context significantly boosts accuracy, reaching 70.6% on the
Friends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show
that fuzzy fingerprints can approximate full fine-tuning performance with fewer
hidden units, offering improved interpretability. Finally, we analyze ambiguous
utterances and propose a mechanism to detect speaker-agnostic lines. Our
findings highlight key challenges and provide insights for future improvements
in text-based speaker identification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted at the FUZZY IEEE 2025 conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Reason under Off-Policy Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14945v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14945v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianhao Yan, Yafu Li, Zican Hu, Zhi Wang, Ganqu Cui, Xiaoye Qu, Yu Cheng, Yue Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large reasoning models (LRMs) demonstrate that
sophisticated behaviors such as multi-step reasoning and self-reflection can
emerge via reinforcement learning (RL) with simple rule-based rewards. However,
existing zero-RL approaches are inherently ``on-policy'', limiting learning to
a model's own outputs and failing to acquire reasoning abilities beyond its
initial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY
guidance), a framework that augments zero-RL with off-policy reasoning traces.
LUFFY dynamically balances imitation and exploration by combining off-policy
demonstrations with on-policy rollouts during training. Notably, we propose
policy shaping via regularized importance sampling to avoid superficial and
rigid imitation during mixed-policy training. Remarkably, LUFFY achieves an
over +7.0 average gain across six math benchmarks and an advantage of over +6.2
points in out-of-distribution tasks. It also substantially surpasses
imitation-based supervised fine-tuning (SFT), particularly in generalization.
Analysis shows LUFFY not only imitates effectively but also explores beyond
demonstrations, offering a scalable path to train generalizable reasoning
models with off-policy guidance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent
  Dialogue Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yao Shi, Rongkeng Liang, Yong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) increasingly serve as educational tools, yet
evaluating their teaching capabilities remains challenging due to the
resource-intensive, context-dependent, and methodologically complex nature of
teacher-student interactions. We introduce EducationQ, a multi-agent dialogue
framework that efficiently assesses teaching capabilities through simulated
dynamic educational scenarios, featuring specialized agents for teaching,
learning, and evaluation. Testing 14 LLMs across major AI Organizations
(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13
disciplines and 10 difficulty levels reveals that teaching effectiveness does
not correlate linearly with model scale or general reasoning capabilities -
with some smaller open-source models outperforming larger commercial
counterparts in teaching contexts. This finding highlights a critical gap in
current evaluations that prioritize knowledge recall over interactive pedagogy.
Our mixed-methods evaluation, combining quantitative metrics with qualitative
analysis and expert case studies, identifies distinct pedagogical strengths
employed by top-performing models (e.g., sophisticated questioning strategies,
adaptive feedback mechanisms). Human expert evaluations show 78% agreement with
our automated qualitative analysis of effective teaching behaviors, validating
our methodology. EducationQ demonstrates that LLMs-as-teachers require
specialized optimization beyond simple scaling, suggesting next-generation
educational AI prioritize targeted enhancement of specific pedagogical
effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CRAVE: A Conflicting Reasoning Approach for Explainable Claim
  Verification Using LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14905v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14905v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingming Zheng, Xiaoliang Liu, Peng Wu, Li Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid spread of misinformation, driven by digital media and AI-generated
content, has made automatic claim verification essential. Traditional methods,
which depend on expert-annotated evidence, are labor-intensive and not
scalable. Although recent automated systems have improved, they still struggle
with complex claims that require nuanced reasoning. To address this, we propose
CRAVE, a Conflicting Reasoning Approach for explainable claim VErification,
that verify the complex claims based on the conflicting rationales reasoned by
large language models (LLMs). Specifically, CRAVE introduces a three-module
framework. Ambiguity Elimination enchanced Evidence Retrieval module performs
ambiguity elimination and entity-based search to gather relevant evidence
related to claim verification from external sources like Wikipedia. Conflicting
Perspective Reasoning and Preliminary Judgment module with LLMs adopts LLMs to
reason rationales with conflicting stances about claim verification from
retrieved evidence across four dimensions, i.e., direct evidence, semantic
relationships, linguistic patterns, and logical reasoning and make a
preliminary judgment. Finally, Small Language Model (SLM) based Judge module is
fine-tuned to make use of preliminary judgment from LLMs to assess the
confidence of the conflicting rationales and make a final authenticity
judgment. This methodology allows CRAVE to capture subtle inconsistencies in
complex claims, improving both the accuracy and transparency of claim
verification. Extensive experiments on two public claim verification datasets
demonstrate that our CRAVE model achieves much better performance than
state-of-the-art methods and exhibits a superior capacity for finding relevant
evidence and explaining the model predictions. The code is provided at
https://github.com/8zym/CRAVE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VLM as Policy: Common-Law Content Moderation Framework for Short Video
  Platform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Lu, Tianke Zhang, Chang Meng, Xiaobei Wang, Jinpeng Wang, YiFan Zhang, Shisong Tang, Changyi Liu, Haojie Ding, Kaiyu Jiang, Kaiyu Tang, Bin Wen, Hai-Tao Zheng, Fan Yang, Tingting Gao, Di Zhang, Kun Gai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exponentially growing short video platforms (SVPs) face significant
challenges in moderating content detrimental to users' mental health,
particularly for minors. The dissemination of such content on SVPs can lead to
catastrophic societal consequences. Although substantial efforts have been
dedicated to moderating such content, existing methods suffer from critical
limitations: (1) Manual review is prone to human bias and incurs high
operational costs. (2) Automated methods, though efficient, lack nuanced
content understanding, resulting in lower accuracy. (3) Industrial moderation
regulations struggle to adapt to rapidly evolving trends due to long update
cycles. In this paper, we annotate the first SVP content moderation benchmark
with authentic user/reviewer feedback to fill the absence of benchmark in this
field. Then we evaluate various methods on the benchmark to verify the
existence of the aforementioned limitations. We further propose our common-law
content moderation framework named KuaiMod to address these challenges. KuaiMod
consists of three components: training data construction, offline adaptation,
and online deployment & refinement. Leveraging large vision language model
(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video
toxicity based on sparse user feedback and fosters dynamic moderation policy
with rapid update speed and high accuracy. Offline experiments and large-scale
online A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the
best moderation performance on our benchmark. The deployment of KuaiMod reduces
the user reporting rate by 20% and its application in video recommendation
increases both Daily Active User (DAU) and APP Usage Time (AUT) on several
Kuaishou scenarios. We have open-sourced our benchmark at
https://kuaimod.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval Augmented Generation Evaluation in the Era of Large Language
  Models: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14891v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14891v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aoran Gan, Hao Yu, Kai Zhang, Qi Liu, Wenyu Yan, Zhenya Huang, Shiwei Tong, Guoping Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Retrieval-Augmented Generation (RAG) have
revolutionized natural language processing by integrating Large Language Models
(LLMs) with external information retrieval, enabling accurate, up-to-date, and
verifiable text generation across diverse applications. However, evaluating RAG
systems presents unique challenges due to their hybrid architecture that
combines retrieval and generation components, as well as their dependence on
dynamic knowledge sources in the LLM era. In response, this paper provides a
comprehensive survey of RAG evaluation methods and frameworks, systematically
reviewing traditional and emerging evaluation approaches, for system
performance, factual accuracy, safety, and computational efficiency in the LLM
era. We also compile and categorize the RAG-specific datasets and evaluation
frameworks, conducting a meta-analysis of evaluation practices in high-impact
RAG research. To the best of our knowledge, this work represents the most
comprehensive survey for RAG evaluation, bridging traditional and LLM-driven
methods, and serves as a critical resource for advancing RAG development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Natural Fingerprints of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14871v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14871v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teppei Suzuki, Ryokan Ri, Sho Takase
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often exhibit biases -- systematic deviations
from expected norms -- in their outputs. These range from overt issues, such as
unfair responses, to subtler patterns that can reveal which model produced
them. We investigate the factors that give rise to identifiable characteristics
in LLMs. Since LLMs model training data distribution, it is reasonable that
differences in training data naturally lead to the characteristics. However,
our findings reveal that even when LLMs are trained on the exact same data, it
is still possible to distinguish the source model based on its generated text.
We refer to these unintended, distinctive characteristics as natural
fingerprints. By systematically controlling training conditions, we show that
the natural fingerprints can emerge from subtle differences in the training
process, such as parameter sizes, optimization settings, and even random seeds.
We believe that understanding natural fingerprints offers new insights into the
origins of unintended bias and ways for improving control over LLM behavior.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OTC: Optimal Tool Calls via Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14870v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14870v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongru Wang, Cheng Qian, Wanjun Zhong, Xiusi Chen, Jiahao Qiu, Shijue Huang, Bowen Jin, Mengdi Wang, Kam-Fai Wong, Heng Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tool-integrated reasoning (TIR) augments large language models (LLMs) with
the ability to invoke external tools, such as search engines and code
interpreters, to solve tasks beyond the capabilities of language-only
reasoning. While reinforcement learning (RL) has shown promise in improving TIR
by optimizing final answer correctness, existing approaches often overlook the
efficiency and cost associated with tool usage. This can lead to suboptimal
behavior, including excessive tool calls that increase computational and
financial overhead, or insufficient tool use that compromises answer quality.
In this work, we propose Optimal Tool Call-controlled Policy Optimization
(OTC-PO), a simple yet effective RL-based framework that encourages models to
produce accurate answers with minimal tool calls. Our method introduces a
tool-integrated reward that jointly considers correctness and tool efficiency,
promoting high tool productivity. We instantiate this framework within both
Proximal Policy Optimization (PPO) and Group Relative Preference Optimization
(GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and
Qwen-Math across multiple QA benchmarks show that our approach reduces tool
calls by up to 73.1\% and improves tool productivity by up to 229.4\%, while
maintaining comparable answer accuracy. To the best of our knowledge, this is
the first RL-based framework that explicitly optimizes tool-use efficiency in
TIR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AlignRAG: An Adaptable Framework for Resolving Misalignments in
  Retrieval-Aware Reasoning of RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14858v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14858v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has emerged as a foundational paradigm
for knowledge-grounded text generation. However, existing RAG pipelines often
fail to ensure that the reasoning trajectories align with the evidential
constraints imposed by retrieved content. In this paper, we reframe RAG as a
problem of retrieval-aware reasoning and identify a core challenge: reasoning
misalignment-the mismatch between a model's reasoning trajectory and the
retrieved evidence. To address this challenge, we propose AlignRAG, a novel
test-time framework that mitigates reasoning misalignment through iterative
Critique-Driven Alignment (CDA) steps. In contrast to prior approaches that
rely on static training or post-hoc selection, AlignRAG actively refines
reasoning trajectories during inference by enforcing fine-grained alignment
with evidence. Our framework introduces a new paradigm for retrieval-aware
reasoning by: (1) constructing context-rich training corpora; (2) generating
contrastive critiques from preference-aware reasoning trajectories; (3)
training a dedicated \textit{Critic Language Model (CLM)} to identify reasoning
misalignments; and (4) applying CDA steps to optimize reasoning trajectories
iteratively. Empirical results demonstrate that AlignRAG consistently
outperforms all baselines and could integrate as a plug-and-play module into
existing RAG pipelines without further changes. By reconceptualizing RAG as a
structured reasoning trajectory and establishing the test-time framework for
correcting reasoning misalignments in RAG, AlignRAG provides practical
advancements for retrieval-aware generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transparentize the Internal and External Knowledge Utilization in LLMs
  with Trustworthy Citation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14856v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14856v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajun Shen, Tong Zhou, Yubo Chen, Delai Qiu, Shengping Liu, Kang Liu, Jun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While hallucinations of large language models could been alleviated through
retrieval-augmented generation and citation generation, how the model utilizes
internal knowledge is still opaque, and the trustworthiness of its generated
answers remains questionable. In this work, we introduce Context-Prior
Augmented Citation Generation task, requiring models to generate citations
considering both external and internal knowledge while providing trustworthy
references, with 5 evaluation metrics focusing on 3 aspects: answer
helpfulness, citation faithfulness, and trustworthiness. We introduce RAEL, the
paradigm for our task, and also design INTRALIGN, an integrated method
containing customary data generation and an alignment algorithm. Our
experimental results show that our method achieves a better cross-scenario
performance with regard to other baselines. Our extended experiments further
reveal that retrieval quality, question types, and model knowledge have
considerable influence on the trustworthiness in citation generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Completing A Systematic <span class="highlight-title">Review</span> in Hours instead of Months with
  Interactive AI Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14822v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14822v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Qiu, Shijie Chen, Yu Su, Po-Yin Yen, Han-Wei Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Systematic reviews (SRs) are vital for evidence-based practice in high stakes
disciplines, such as healthcare, but are often impeded by intensive labors and
lengthy processes that can take months to complete. Due to the high demand for
domain expertise, existing automatic summarization methods fail to accurately
identify relevant studies and generate high-quality summaries. To that end, we
introduce InsightAgent, a human-centered interactive AI agent powered by large
language models that revolutionize this workflow. InsightAgent partitions a
large literature corpus based on semantics and employs a multi-agent design for
more focused processing of literature, leading to significant improvement in
the quality of generated SRs. InsightAgent also provides intuitive
visualizations of the corpus and agent trajectories, allowing users to
effortlessly monitor the actions of the agent and provide real-time feedback
based on their expertise. Our user studies with 9 medical professionals
demonstrate that the visualization and interaction mechanisms can effectively
improve the quality of synthesized SRs by 27.2%, reaching 79.7% of
human-written quality. At the same time, user satisfaction is improved by
34.4%. With InsightAgent, it only takes a clinician about 1.5 hours, rather
than months, to complete a high-quality systematic review.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Self-improving Token Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14808v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14808v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mario M. Kubek, Shiraj Pokharel, Thomas Böhme, Emma L. McDaniel, Herwig Unger, Armin R. Mikler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article introduces a novel and fast method for refining pre-trained
static word or, more generally, token embeddings. By incorporating the
embeddings of neighboring tokens in text corpora, it continuously updates the
representation of each token, including those without pre-assigned embeddings.
This approach effectively addresses the out-of-vocabulary problem, too.
Operating independently of large language models and shallow neural networks,
it enables versatile applications such as corpus exploration, conceptual
search, and word sense disambiguation. The method is designed to enhance token
representations within topically homogeneous corpora, where the vocabulary is
restricted to a specific domain, resulting in more meaningful embeddings
compared to general-purpose pre-trained vectors. As an example, the methodology
is applied to explore storm events and their impacts on infrastructure and
communities using narratives from a subset of the NOAA Storm Events database.
The article also demonstrates how the approach improves the representation of
storm-related terms over time, providing valuable insights into the evolving
nature of disaster narratives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 4 figures, 3 tables, accepted at the 2025 25th
  International Conference on Innovations for Community Services (I4CS), June
  11 - 13, Munich, Germany, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automatic Evaluation Metrics for Document-level Translation: <span class="highlight-title">Overview</span>,
  Challenges and Trends 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14804v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14804v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxin GUO, Xiaoyu Chen, Zhiqiang Rao, Jinlong Yang, Zongyao Li, Hengchao Shang, Daimeng Wei, Hao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of deep learning technologies, the field of
machine translation has witnessed significant progress, especially with the
advent of large language models (LLMs) that have greatly propelled the
advancement of document-level translation. However, accurately evaluating the
quality of document-level translation remains an urgent issue. This paper first
introduces the development status of document-level translation and the
importance of evaluation, highlighting the crucial role of automatic evaluation
metrics in reflecting translation quality and guiding the improvement of
translation systems. It then provides a detailed analysis of the current state
of automatic evaluation schemes and metrics, including evaluation methods with
and without reference texts, as well as traditional metrics, Model-based
metrics and LLM-based metrics. Subsequently, the paper explores the challenges
faced by current evaluation methods, such as the lack of reference diversity,
dependence on sentence-level alignment information, and the bias, inaccuracy,
and lack of interpretability of the LLM-as-a-judge method. Finally, the paper
looks ahead to the future trends in evaluation methods, including the
development of more user-friendly document-level evaluation methods and more
robust LLM-as-a-judge methods, and proposes possible research directions, such
as reducing the dependency on sentence-level information, introducing
multi-level and multi-granular evaluation approaches, and training models
specifically for machine translation evaluation. This study aims to provide a
comprehensive analysis of automatic evaluation for document-level translation
and offer insights into future developments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14773v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14773v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoming Li, Zhaoliang Chen, Jonathan Zhang, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Planning is central to agents and agentic AI. The ability to plan, e.g.,
creating travel itineraries within a budget, holds immense potential in both
scientific and commercial contexts. Moreover, optimal plans tend to require
fewer resources compared to ad-hoc methods. To date, a comprehensive
understanding of existing planning benchmarks appears to be lacking. Without
it, comparing planning algorithms' performance across domains or selecting
suitable algorithms for new scenarios remains challenging. In this paper, we
examine a range of planning benchmarks to identify commonly used testbeds for
algorithm development and highlight potential gaps. These benchmarks are
categorized into embodied environments, web navigation, scheduling, games and
puzzles, and everyday task automation. Our study recommends the most
appropriate benchmarks for various algorithms and offers insights to guide
future benchmark development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DataComp-LM: In search of the next generation of training sets for
  language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11794v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11794v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muennighoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldaini, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, Vaishaal Shankar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce DataComp for Language Models (DCLM), a testbed for controlled
dataset experiments with the goal of improving language models. As part of
DCLM, we provide a standardized corpus of 240T tokens extracted from Common
Crawl, effective pretraining recipes based on the OpenLM framework, and a broad
suite of 53 downstream evaluations. Participants in the DCLM benchmark can
experiment with data curation strategies such as deduplication, filtering, and
data mixing at model scales ranging from 412M to 7B parameters. As a baseline
for DCLM, we conduct extensive experiments and find that model-based filtering
is key to assembling a high-quality training set. The resulting dataset,
DCLM-Baseline enables training a 7B parameter language model from scratch to
64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the
previous state-of-the-art in open-data language models, DCLM-Baseline
represents a 6.6 percentage point improvement on MMLU while being trained with
40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and
Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53
natural language understanding tasks while being trained with 6.6x less compute
than Llama 3 8B. Our results highlight the importance of dataset design for
training language models and offer a starting point for further research on
data curation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://www.datacomp.ai/dclm/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can LLMs Rank the Harmfulness of Smaller LLMs? We are Not There Yet 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05291v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05291v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Berk Atil, Vipul Gupta, Sarkar Snigdha Sarathi Das, Rebecca J. Passonneau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become ubiquitous, thus it is important to
understand their risks and limitations. Smaller LLMs can be deployed where
compute resources are constrained, such as edge devices, but with different
propensity to generate harmful output. Mitigation of LLM harm typically depends
on annotating the harmfulness of LLM output, which is expensive to collect from
humans. This work studies two questions: How do smaller LLMs rank regarding
generation of harmful content? How well can larger LLMs annotate harmfulness?
We prompt three small LLMs to elicit harmful content of various types, such as
discriminatory language, offensive content, privacy invasion, or negative
influence, and collect human rankings of their outputs. Then, we evaluate three
state-of-the-art large LLMs on their ability to annotate the harmfulness of
these responses. We find that the smaller models differ with respect to
harmfulness. We also find that large LLMs show low to moderate agreement with
humans. These findings underline the need for further work on harm mitigation
in LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training on the Test Task Confounds Evaluation and Emergence <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07890v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07890v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a fundamental problem in the evaluation of large language models
that we call training on the test task. Unlike wrongful practices like training
on the test data, leakage, or data contamination, training on the test task is
not a malpractice. Rather, the term describes a growing set of practices that
utilize knowledge about evaluation tasks at training time. We demonstrate that
training on the test task confounds both relative model evaluations and claims
about emergent capabilities. We argue that the seeming superiority of one model
family over another may be explained by a different degree of training on the
test task. To this end, we propose an effective method to adjust for the effect
of training on the test task on benchmark evaluations. Put simply, to fine-tune
each model under comparison on the same task-relevant data prior to evaluation.
We then show that instances of emergent behavior disappear gradually as models
train on the test task. Our work promotes a new perspective on the evaluation
of large language models, with broad implications for benchmarking and the
study of emergent capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language
  Models via Monitoring Hidden States 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14744v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14744v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilei Jiang, Xinyan Gao, Tianshuo Peng, Yingshui Tan, Xiaoyong Zhu, Bo Zheng, Xiangyu Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of additional modalities increases the susceptibility of
large vision-language models (LVLMs) to safety risks, such as jailbreak
attacks, compared to their language-only counterparts. While existing research
primarily focuses on post-hoc alignment techniques, the underlying safety
mechanisms within LVLMs remain largely unexplored. In this work , we
investigate whether LVLMs inherently encode safety-relevant signals within
their internal activations during inference. Our findings reveal that LVLMs
exhibit distinct activation patterns when processing unsafe prompts, which can
be leveraged to detect and mitigate adversarial inputs without requiring
extensive fine-tuning. Building on this insight, we introduce HiddenDetect, a
novel tuning-free framework that harnesses internal model activations to
enhance safety. Experimental results show that {HiddenDetect} surpasses
state-of-the-art methods in detecting jailbreak attacks against LVLMs. By
utilizing intrinsic safety-aware patterns, our method provides an efficient and
scalable solution for strengthening LVLM robustness against multimodal threats.
Our code will be released publicly at
https://github.com/leigest519/HiddenDetect.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Embedding Ontologies via Incorporating Extensional and Intensional
  Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01677v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01677v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keyu Wang, Guilin Qi, Jiaoyan Chen, Yi Huang, Tianxing Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ontologies contain rich knowledge within domain, which can be divided into
two categories, namely extensional knowledge and intensional knowledge.
Extensional knowledge provides information about the concrete instances that
belong to specific concepts in the ontology, while intensional knowledge
details inherent properties, characteristics, and semantic associations among
concepts. However, existing ontology embedding approaches fail to take both
extensional knowledge and intensional knowledge into fine consideration
simultaneously. In this paper, we propose a novel ontology embedding approach
named EIKE (Extensional and Intensional Knowledge Embedding) by representing
ontologies in two spaces, called extensional space and intensional space. EIKE
presents a unified framework for embedding instances, concepts and their
relations in an ontology, applying a geometry-based method to model extensional
knowledge and a pretrained language model to model intensional knowledge, which
can capture both structure information and textual information. Experimental
results show that EIKE significantly outperforms state-of-the-art methods in
three datasets for both triple classification and link prediction, indicating
that EIKE provides a more comprehensive and representative perspective of the
domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inverse Constitutional AI: Compressing Preferences into Principles <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arduin Findeis, Timo Kaufmann, Eyke Hüllermeier, Samuel Albanie, Robert Mullins
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Feedback data is widely used for fine-tuning and evaluating state-of-the-art
AI models. Pairwise text preferences, where human or AI annotators select the
"better" of two options, are particularly common. Such preferences are used to
train (reward) models or to rank models with aggregate statistics. For many
applications it is desirable to understand annotator preferences in addition to
modelling them - not least because extensive prior work has shown various
unintended biases in preference datasets. Yet, preference datasets remain
challenging to interpret. Neither black-box reward models nor statistics can
answer why one text is preferred over another. Manual interpretation of the
numerous (long) response pairs is usually equally infeasible. In this paper, we
introduce the Inverse Constitutional AI (ICAI) problem, formulating the
interpretation of pairwise text preference data as a compression task. In
constitutional AI, a set of principles (a constitution) is used to provide
feedback and fine-tune AI models. ICAI inverts this process: given a feedback
dataset, we aim to extract a constitution that best enables a large language
model (LLM) to reconstruct the original annotations. We propose a corresponding
ICAI algorithm and validate its generated constitutions quantitatively based on
annotation reconstruction accuracy on several datasets: (a) synthetic feedback
data with known principles; (b) AlpacaEval cross-annotated human feedback data;
(c) crowdsourced Chatbot Arena data; and (d) PRISM data from diverse
demographic groups. As a short and interpretable representation of the original
dataset, generated constitutions have many potential use cases: help identify
undesirable annotator biases, understand model performance better, scale
feedback to unseen data, or adapt models to individual user or group
preferences. We release the source code at https://github.com/rdnfn/icai.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025, v2 is camera-ready version; Main changes from
  v1: extended experiments, additional baselines</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LServe: Efficient Long-sequence LLM Serving with Unified Sparse
  Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14866v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14866v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shang Yang, Junxian Guo, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable potential in processing
long sequences and complex reasoning tasks, yet efficiently serving these
models remains challenging due to the quadratic computational complexity of
attention in the prefilling stage and the large memory footprint of the KV
cache in the decoding stage. To address these issues, we introduce LServe, an
efficient system that accelerates long-sequence LLM serving via hybrid sparse
attention. This method unifies different hardware-friendly, structured sparsity
patterns for both prefilling and decoding attention into a single framework,
where computations on less important tokens are skipped block-wise. LServe
demonstrates the compatibility of static and dynamic sparsity in long-context
LLM attention. This design enables multiplicative speedups by combining these
optimizations. Specifically, we convert half of the attention heads to nearly
free streaming heads in both the prefilling and decoding stages. Additionally,
we find that only a constant number of KV pages is required to preserve
long-context and reasoning capabilities, irrespective of context length. We
then design a hierarchical KV page selection policy that dynamically prunes KV
pages based on query-centric similarity. On average, LServe accelerates LLM
prefilling by up to 2.9x and decoding by 1.3-2.1x over vLLM, maintaining
long-context accuracy. Code is released at
https://github.com/mit-han-lab/omniserve.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MLSys 2025. Code available at:
  https://github.com/mit-han-lab/omniserve</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Video-Language Models to 10K Frames via Hierarchical
  Differential Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.02438v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.02438v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-form video processing fundamentally challenges vision-language models
(VLMs) due to the high computational costs of handling extended temporal
sequences. Existing token pruning and feature merging methods often sacrifice
critical temporal dependencies or dilute semantic information. We introduce
differential distillation, a principled approach that systematically preserves
task-relevant information while suppressing redundancy. Based on this
principle, we develop ViLaMP, a hierarchical video-language model that
processes hour-long videos at ``mixed precision'' through two key mechanisms:
(1) differential keyframe selection that maximizes query relevance while
maintaining temporal distinctiveness at the frame level and (2) differential
feature merging that preserves query-salient features in non-keyframes at the
patch level. Hence, ViLaMP retains full information in keyframes while reducing
non-keyframes to their most salient features, resembling mixed-precision
training. Extensive experiments demonstrate ViLaMP's superior performance
across four video understanding benchmarks, particularly on long-form content.
Notably, ViLaMP can process ultra-long videos (up to 10K frames) on a single
NVIDIA A100 GPU, achieving substantial computational efficiency while
maintaining state-of-the-art performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LongProc: Benchmarking Long-Context Language Models on Long Procedural
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05414v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05414v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for evaluating long-context language models (LCLMs)
primarily focus on long-context recall, requiring models to produce short
responses based on a few critical snippets while processing thousands of
irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new
benchmark that requires both the integration of highly dispersed information
and long-form generation. LongProc consists of six diverse procedural
generation tasks, such as extracting structured information from HTML pages
into a TSV format and executing complex search procedures to create travel
plans. These tasks challenge LCLMs by testing their ability to follow detailed
procedural instructions, synthesize and reason over dispersed information, and
generate structured, long-form outputs (up to 8K tokens). Furthermore, as these
tasks adhere to deterministic procedures and yield structured outputs, they
enable reliable rule-based evaluation. We evaluated 23 LCLMs, including
instruction-tuned models and recent reasoning models, on LongProc at three
difficulty levels, with the maximum number of output tokens set at 500, 2K, and
8K. Notably, while all tested models claim a context window size above 32K
tokens, open-weight models typically falter on 2K-token tasks, and
closed-source models like GPT-4o show significant degradation on 8K-token
tasks. Reasoning models achieve stronger overall performance in long-form
generation, benefiting from long CoT training. Further analysis reveals that
LCLMs struggle to maintain long-range coherence in long-form generations. These
findings highlight critical limitations in current LCLMs and suggest
substantial room for improvement. Data and code available at:
https://princeton-pli.github.io/LongProc.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic Wave Functions: Exploring Meaning in Large Language Models
  Through Quantum Formalism 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10664v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10664v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timo Aukusti Laine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) encode semantic relationships in
high-dimensional vector embeddings. This paper explores the analogy between LLM
embedding spaces and quantum mechanics, positing that LLMs operate within a
quantized semantic space where words and phrases behave as quantum states. To
capture nuanced semantic interference effects, we extend the standard
real-valued embedding space to the complex domain, drawing parallels to the
double-slit experiment. We introduce a "semantic wave function" to formalize
this quantum-derived representation and utilize potential landscapes, such as
the double-well potential, to model semantic ambiguity. Furthermore, we propose
a complex-valued similarity measure that incorporates both magnitude and phase
information, enabling a more sensitive comparison of semantic representations.
We develop a path integral formalism, based on a nonlinear Schr\"odinger
equation with a gauge field and Mexican hat potential, to model the dynamic
evolution of LLM behavior. This interdisciplinary approach offers a new
theoretical framework for understanding and potentially manipulating LLMs, with
the goal of advancing both artificial and natural language understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 4 figures. Some corrections added</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Translation All You Need? A Study on Solving Multilingual Tasks with
  Large Language Models <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10258v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10258v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaoqun Liu, Wenxuan Zhang, Yiran Zhao, Anh Tuan Luu, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated multilingual capabilities, yet
they are mostly English-centric due to the imbalanced training corpora. While
prior works have leveraged this bias to enhance multilingual performance
through translation, they have been largely limited to natural language
processing (NLP) tasks. In this work, we extend the evaluation to real-world
user queries and non-English-centric LLMs, offering a broader examination of
multilingual performance. Our key contribution lies in demonstrating that while
translation into English can boost the performance of English-centric LLMs on
NLP tasks, it is not universally optimal. For culture-related tasks that need
deep language understanding, prompting in the native language proves more
effective as it better captures the nuances of culture and language. Our
experiments expose varied behaviors across LLMs and tasks in the multilingual
context, underscoring the need for a more comprehensive approach to
multilingual evaluation. Therefore, we call for greater efforts in developing
and evaluating LLMs that go beyond English-centric paradigms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative AI Act II: Test Time Scaling Drives Cognition Engineering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13828v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13828v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijie Xia, Yiwei Qin, Xuefeng Li, Yan Ma, Run-Ze Fan, Steffi Chern, Haoyang Zou, Fan Zhou, Xiangkun Hu, Jiahe Jin, Yanheng He, Yixin Ye, Yixiu Liu, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The first generation of Large Language Models - what might be called "Act I"
of generative AI (2020-2023) - achieved remarkable success through massive
parameter and data scaling, yet exhibited fundamental limitations such as
knowledge latency, shallow reasoning, and constrained cognitive processes.
During this era, prompt engineering emerged as our primary interface with AI,
enabling dialogue-level communication through natural language. We now witness
the emergence of "Act II" (2024-present), where models are transitioning from
knowledge-retrieval systems (in latent space) to thought-construction engines
through test-time scaling techniques. This new paradigm establishes a
mind-level connection with AI through language-based thoughts. In this paper,
we clarify the conceptual foundations of cognition engineering and explain why
this moment is critical for its development. We systematically break down these
advanced approaches through comprehensive tutorials and optimized
implementations, democratizing access to cognition engineering and enabling
every practitioner to participate in AI's second act. We provide a regularly
updated collection of papers on test-time scaling in the GitHub Repository:
https://github.com/GAIR-NLP/cognition-engineering
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Context-Parametric Inversion: Why Instruction Finetuning Can Worsen
  Context Reliance <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10796v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10796v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A standard practice when using large language models is for users to
supplement their instruction with an input context containing new information
for the model to process. However, models struggle to reliably follow the input
context, especially when it conflicts with their parametric knowledge from
pretraining. In-principle, one would expect models to adapt to the user context
better after instruction finetuning, particularly when handling knowledge
conflicts. However, we observe a surprising failure mode: during instruction
tuning, the context reliance under knowledge conflicts initially increases as
expected, but then gradually decreases as instruction finetuning progresses.
This happens while the performance on standard benchmarks keeps on increasing
far after this drop. We call this phenomenon context-parametric inversion and
observe it across multiple general purpose instruction tuning datasets such as
TULU, Alpaca and Ultrachat, across different model families like Llama,
Mistral, and Pythia. We perform various controlled studies and theoretical
analysis to show that context-parametric inversion occurs due to examples in
the instruction finetuning data where the input context provides information
that aligns with model's parametric knowledge. Our analysis suggests some
natural mitigation strategies with limited but insightful gains, and serves as
a useful starting point in addressing this deficiency in instruction
finetuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06635v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06635v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancements in large language models (LLMs) have significantly
enhanced natural language processing capabilities, facilitating the development
of AudioLLMs that process and understand speech and audio inputs alongside
text. Existing AudioLLMs typically combine a pre-trained audio encoder with a
pre-trained LLM, which are subsequently finetuned on specific audio tasks.
However, the pre-trained audio encoder has constrained capacity to capture
features for new tasks and datasets. To address this, we propose to incorporate
mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE
supplements a base encoder with a pool of relatively light weight encoders,
selectively activated based on the audio input to enhance feature extraction
without significantly increasing model size. Our empirical results demonstrate
that MoWE effectively improves multi-task performance, broadening the
applicability of AudioLLMs to more diverse audio tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Strategic Coordination Framework of Small LLMs Matches Large LLMs in
  Data Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12322v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12322v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, Honglin Lin, Jiang Wu, Lijun Wu, Conghui He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While data synthesis and distillation are promising strategies to enhance
small language models, current approaches heavily rely on Large Language Models
(LLMs), which suffer from high computational costs, environmental inefficiency,
and potential biases inherited from monolithic architectures. In contrast,
smaller LLMs are more accessible and sustainable, but their individual
capabilities often fall short in generating high-quality, diverse, and reliable
data. Inspired by collaborative human processes (e.g., peer review), we propose
a multiple small LLMs involved framework, GRA, that aggregates specialized
roles across small LLMs to iterative refinement and quality control typically
achieved by a single large LLM. In this collaborative framework, multiple small
LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a
peer-review-inspired data synthesis pipeline. The Generator proposes initial
data samples, the Reviewer critiques their quality and diversity, and the
Adjudicator resolves conflicts to finalize the output. By decomposing the
synthesis process into specialized sub-tasks, collaborative small LLMs can
achieve data-level parity with large LLM-based distillation. Through
experiments across multiple benchmarks, we demonstrate that GRA-produced data
matches or exceeds the quality of single large LLM outputs, e.g.,
Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large
models for high-quality data synthesis, advocating instead for strategic
coordination of smaller agents. Our datasets, models, and code are publicly
available at https://github.com/GX-XinGao/GRA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-tuning a Large Language Model for Automating Computational Fluid
  Dynamics Simulations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09602v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09602v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhehao Dong, Zhen Lu, Yue Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Configuring computational fluid dynamics (CFD) simulations typically demands
extensive domain expertise, limiting broader access. Although large language
models (LLMs) have advanced scientific computing, their use in automating CFD
workflows is underdeveloped. We introduce a novel approach centered on
domain-specific LLM adaptation. By fine-tuning Qwen2.5-7B-Instruct on NL2FOAM,
our custom dataset of 28716 natural language-to-OpenFOAM configuration pairs
with chain-of-thought (CoT) annotations, we enable direct translation from
natural language descriptions to executable CFD setups. A multi-agent framework
orchestrates the process, autonomously verifying inputs, generating
configurations, running simulations, and correcting errors. Evaluation on a
benchmark of 21 diverse flow cases demonstrates state-of-the-art performance,
achieving 88.7% solution accuracy and 82.6% first-attempt success rate. This
significantly outperforms larger general-purpose models like
Qwen2.5-72B-Instruct, DeepSeek-R1, and Llama3.3-70B-Instruct, while also
requiring fewer correction iterations and maintaining high computational
efficiency. The results highlight the critical role of domain-specific
adaptation in deploying LLM assistants for complex engineering workflows. Our
code and fine-tuned model have been deposited at
https://github.com/YYgroup/AutoCFD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SCORE: Story Coherence and Retrieval Enhancement for AI Narratives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.23512v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.23512v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiang Yi, Yangfan He, Jianhui Wang, Xinyuan Song, Shiyao Qian, Xinhang Yuan, Miao Zhang, Li Sun, Keqin Li, Kuan Lu, Menghao Huo, Jiaqi Chen, Tianyu Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) can generate creative and engaging narratives
from user-specified input, but maintaining coherence and emotional depth
throughout these AI-generated stories remains a challenge. In this work, we
propose SCORE, a framework for Story Coherence and Retrieval Enhancement,
designed to detect and resolve narrative inconsistencies. By tracking key item
statuses and generating episode summaries, SCORE uses a Retrieval-Augmented
Generation (RAG) approach, incorporating TF-IDF and cosine similarity to
identify related episodes and enhance the overall story structure. Results from
testing multiple LLM-generated stories demonstrate that SCORE significantly
improves the consistency and stability of narrative coherence compared to
baseline GPT models, providing a more robust method for evaluating and refining
AI-generated narratives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adapting Multilingual LLMs to Low-Resource Languages using Continued
  <span class="highlight-title">Pre-train</span>ing and Synthetic Corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14815v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14815v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raviraj Joshi, Kanishk Singla, Anusha Kamath, Raunak Kalani, Rakesh Paul, Utkarsh Vaidya, Sanjay Singh Chauhan, Niranjan Wartikar, Eileen Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilingual LLMs support a variety of languages; however, their performance
is suboptimal for low-resource languages. In this work, we emphasize the
importance of continued pre-training of multilingual LLMs and the use of
translation-based synthetic pre-training corpora for improving LLMs in
low-resource languages. We conduct our study in the context of the low-resource
Indic language Hindi. We introduce Nemotron-Mini-Hindi 4B, a bilingual SLM
supporting both Hindi and English, based on Nemotron-Mini 4B. The model is
trained using a mix of real and synthetic Hindi + English tokens, with
continuous pre-training performed on 400B tokens. We demonstrate that both the
base and instruct models achieve state-of-the-art results on Hindi benchmarks
while remaining competitive on English tasks. Additionally, we observe that the
continued pre-training approach enhances the model's overall factual accuracy.
We perform an ablation study to highlight the impact of Hindi pre-training,
showing significant improvements in Hindi chat capabilities and factual
accuracy, which cannot be achieved through Hindi alignment alone.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UXAgent: A System for Simulating Usability Testing of Web Design with
  LLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09407v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09407v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Lu, Bingsheng Yao, Hansu Gu, Jing Huang, Jessie Wang, Yang Li, Jiri Gesi, Qi He, Toby Jia-Jun Li, Dakuo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Usability testing is a fundamental research method that user experience (UX)
researchers use to evaluate and iterate a web design, but\textbf{ how to
evaluate and iterate the usability testing study design } itself? Recent
advances in Large Language Model-simulated Agent (\textbf{LLM Agent}) research
inspired us to design \textbf{UXAgent} to support UX researchers in evaluating
and reiterating their usability testing study design before they conduct the
real human-subject study. Our system features a Persona Generator module, an
LLM Agent module, and a Universal Browser Connector module to automatically
generate thousands of simulated users to interactively test the target website.
The system also provides an Agent Interview Interface and a Video Replay
Interface so that the UX researchers can easily review and analyze the
generated qualitative and quantitative log data. Through a heuristic
evaluation, five UX researcher participants praised the innovation of our
system but also expressed concerns about the future of LLM Agent usage in UX
studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM Agents That Act Like Us: Accurate Human Behavior Simulation with
  Real-World Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.20749v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.20749v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Lu, Jing Huang, Yan Han, Bennet Bei, Yaochen Xie, Dakuo Wang, Jessie Wang, Qi He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research shows that LLMs can simulate ``believable'' human behaviors
to power LLM agents via prompt-only methods. In this work, we focus on
evaluating and improving LLM's objective ``accuracy'' rather than the
subjective ``believability'' in the web action generation task, leveraging a
large-scale, real-world dataset collected from online shopping human actions.
We present the first comprehensive quantitative evaluation of state-of-the-art
LLMs (e.g., DeepSeek-R1, Llama, and Claude) on the task of web action
generation. Our results show that fine-tuning LLMs on real-world behavioral
data substantially improves their ability to generate actions compared to
prompt-only methods. Furthermore, incorporating synthesized reasoning traces
into model training leads to additional performance gains, demonstrating the
value of explicit rationale in behavior modeling. This work establishes a new
benchmark for evaluating LLMs in behavior simulation and offers actionable
insights into how real-world action data and reasoning augmentation can enhance
the fidelity of LLM agents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Characterizing Knowledge Manipulation in a Russian Wikipedia Fork 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mykola Trokhymovych, Oleksandr Kosovan, Nathan Forrester, Pablo Aragón, Diego Saez-Trumper, Ricardo Baeza-Yates
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Wikipedia is powered by MediaWiki, a free and open-source software that is
also the infrastructure for many other wiki-based online encyclopedias. These
include the recently launched website Ruwiki, which has copied and modified the
original Russian Wikipedia content to conform to Russian law. To identify
practices and narratives that could be associated with different forms of
knowledge manipulation, this article presents an in-depth analysis of this
Russian Wikipedia fork. We propose a methodology to characterize the main
changes with respect to the original version. The foundation of this study is a
comprehensive comparative analysis of more than 1.9M articles from Russian
Wikipedia and its fork. Using meta-information and geographical, temporal,
categorical, and textual features, we explore the changes made by Ruwiki
editors. Furthermore, we present a classification of the main topics of
knowledge manipulation in this fork, including a numerical estimation of their
scope. This research not only sheds light on significant changes within Ruwiki,
but also provides a methodology that could be applied to analyze other
Wikipedia forks and similar collaborative projects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unanswerability Evaluation for Retrieval Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.12300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.12300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Peng, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing evaluation frameworks for retrieval-augmented generation (RAG)
systems focus on answerable queries, but they overlook the importance of
appropriately rejecting unanswerable requests. In this paper, we introduce
UAEval4RAG, a framework designed to evaluate whether RAG systems can handle
unanswerable queries effectively. We define a taxonomy with six unanswerable
categories, and UAEval4RAG automatically synthesizes diverse and challenging
queries for any given knowledge base with unanswered ratio and acceptable ratio
metrics. We conduct experiments with various RAG components, including
retrieval models, rewriting methods, rerankers, language models, and prompting
strategies, and reveal hidden trade-offs in performance of RAG systems. Our
findings highlight the critical role of component selection and prompt design
in optimizing RAG systems to balance the accuracy of answerable queries with
high rejection rates of unanswerable ones. UAEval4RAG provides valuable
insights and tools for developing more robust and reliable RAG systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Boundaries: Learning a Universal Entity Taxonomy across <span class="highlight-title">Dataset</span>s
  and Languages for Open Named Entity Recognition <span class="chip">COLING 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11192v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11192v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuming Yang, Wantong Zhao, Caishuang Huang, Junjie Ye, Xiao Wang, Huiyuan Zheng, Yang Nan, Yuran Wang, Xueying Xu, Kaixin Huang, Yunke Zhang, Tao Gui, Qi Zhang, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open Named Entity Recognition (NER), which involves identifying arbitrary
types of entities from arbitrary domains, remains challenging for Large
Language Models (LLMs). Recent studies suggest that fine-tuning LLMs on
extensive NER data can boost their performance. However, training directly on
existing datasets neglects their inconsistent entity definitions and redundant
data, limiting LLMs to dataset-specific learning and hindering out-of-domain
adaptation. To address this, we present B2NERD, a compact dataset designed to
guide LLMs' generalization in Open NER under a universal entity taxonomy.
B2NERD is refined from 54 existing English and Chinese datasets using a
two-step process. First, we detect inconsistent entity definitions across
datasets and clarify them by distinguishable label names to construct a
universal taxonomy of 400+ entity types. Second, we address redundancy using a
data pruning strategy that selects fewer samples with greater category and
semantic diversity. Comprehensive evaluation shows that B2NERD significantly
enhances LLMs' Open NER capabilities. Our B2NER models, trained on B2NERD,
outperform GPT-4 by 6.8-12.0 F1 points and surpass previous methods in 3
out-of-domain benchmarks across 15 datasets and 6 languages. The data, models,
and code are publicly available at https://github.com/UmeanNever/B2NER.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at COLING 2025. Camera-ready version updated. Project page:
  https://github.com/UmeanNever/B2NER</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NAACL2025 Tutorial: Adaptation of Large Language Models <span class="chip">NAACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.03931v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.03931v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixuan Ke, Yifei Ming, Shafiq Joty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This tutorial on adaptation of LLMs is designed to address the growing demand
for models that go beyond the static capabilities of generic LLMs by providing
an overview of dynamic, domain-specific, and task-adaptive LLM adaptation
techniques. While general LLMs have demonstrated strong generalization across a
variety of tasks, they often struggle to perform well in specialized domains
such as finance, healthcare, and code generation for underrepresented
languages. Additionally, their static nature limits their ability to evolve
with the changing world, and they are often extremely large in size, making
them impractical and costly to deploy at scale. As a result, the adaptation of
LLMs has drawn much attention since the birth of LLMs and is of core
importance, both for industry, which focuses on serving its targeted users, and
academia, which can greatly benefit from small but powerful LLMs. To address
this gap, this tutorial aims to provide an overview of the LLM adaptation
techniques. We start with an introduction to LLM adaptation, from both the data
perspective and the model perspective. We then emphasize how the evaluation
metrics and benchmarks are different from other techniques. After establishing
the problems, we explore various adaptation techniques. We categorize
adaptation techniques into two main families. The first is parametric knowledge
adaptation, which focuses on updating the parametric knowledge within LLMs.
Additionally, we will discuss real-time adaptation techniques, including model
editing, which allows LLMs to be updated dynamically in production
environments. The second kind of adaptation is semi-parametric knowledge
adaptation, where the goal is to update LLM parameters to better leverage
external knowledge or tools through techniques like retrieval-augmented
generation (RAG) and agent-based systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL2025 Tutorial</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in
  Vision-Language Alignment <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14148v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14148v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent advancements in large language models (LLMs) and pre-trained
vision models have accelerated the development of vision-language large models
(VLLMs), enhancing the interaction between visual and linguistic modalities.
Despite their notable success across various domains, VLLMs face challenges in
modality alignment, which can lead to issues like hallucinations and unsafe
content generation. Current alignment techniques often rely on coarse feedback
and external datasets, limiting scalability and performance. In this paper, we
propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel
self-alignment method that utilizes the model's own visual encoder as a
fine-grained verifier to improve vision-language alignment without the need for
additional data. By leveraging token-level feedback from the vision encoder,
FiSAO significantly improves vision-language alignment, even surpassing
traditional preference tuning methods that require additional data. Through
both theoretical analysis and experimental validation, we demonstrate that
FiSAO effectively addresses the misalignment problem in VLLMs, marking the
first instance of token-level rewards being applied to such models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages; Published as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task-Specific Directions: Definition, Exploration, and Utilization in
  Parameter Efficient Fine-Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01035v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01035v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chongjie Si, Zhiyi Shi, Shifan Zhang, Xiaokang Yang, Hanspeter Pfister, Wei Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models demonstrate impressive performance on downstream tasks,
yet they require extensive resource consumption when fully fine-tuning all
parameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT)
strategies, such as LoRA, have been developed. In this paper, we delve into the
concept of task-specific directions (TSDs), which are critical for
transitioning large models from pretrained states to task-specific enhancements
in PEFT. We propose a framework to clearly define these directions and explore
their properties and practical utilization challenges. We then introduce a
novel approach, LoRA-Dash, which aims to maximize the impact of TSDs during the
fine-tuning process, thereby enhancing model performance on targeted tasks.
Additionally, based on our exploration of TSD, we focus on an important issue
in PEFT: the initialization of LoRA. While some works have pointed out the
significance of initialization for LoRA's performance and proposed various
strategies, these methods are often empirical and not task-specific. To address
this issue, we propose LoRA-Init. Starting from TSD, we identify the directions
that require the most adjustment during fine-tuning for downstream tasks. By
initializing the matrices in LoRA with these directions, LoRA-Init
significantly enhances LoRA's performance. Moreover, we can combine LoRA-Dash
and LoRA-Init to create the final version of LoRA based on TSDs, which we refer
to as LoRA-TSD. Extensive experiments have conclusively demonstrated the
effectiveness of these methods, and in-depth analyses further reveal the
underlying mechanisms behind their success.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes in https://github.com/Chongjie-Si/Subspace-Tuning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aioli: A Unified Optimization Framework for Language Model Data Mixing <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.05735v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.05735v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mayee F. Chen, Michael Y. Hu, Nicholas Lourie, Kyunghyun Cho, Christopher Ré
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model performance depends on identifying the optimal mixture of data
groups to train on (e.g., law, code, math). Prior work has proposed a diverse
set of methods to efficiently learn mixture proportions, ranging from fitting
regression models over training runs to dynamically updating proportions
throughout training. Surprisingly, we find that no existing method consistently
outperforms a simple stratified sampling baseline in terms of average test
perplexity. To understand this inconsistency, we unify existing methods into a
standard framework, showing they are equivalent to solving a common
optimization problem: minimize average loss subject to a method-specific mixing
law -- an implicit assumption on the relationship between loss and mixture
proportions. This framework suggests that measuring the fidelity of a method's
mixing law can offer insights into its performance. Empirically, we find that
existing methods set their mixing law parameters inaccurately, resulting in the
inconsistent mixing performance we observe. Using this insight, we derive a new
online method named Aioli, which directly estimates the mixing law parameters
throughout training and uses them to dynamically adjust proportions. Aioli
outperforms stratified sampling on 6 out of 6 datasets by an average of 0.27
test perplexity points, whereas existing methods fail to consistently beat
stratified sampling, doing up to 6.9 points worse. Moreover, in a practical
setting where proportions are learned on shorter runs due to computational
constraints, Aioli can dynamically adjust these proportions over the full
training run, consistently improving performance over existing methods by up to
12.012 test perplexity points.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Camera Ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Generalization in Intent Detection: GRPO with Reward-Based
  Curriculum Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Feng, Xiaoxue Wang, Ziwei Bai, Donghang Su, Bowen Wu, Qun Yu, Baoxun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intent detection, a critical component in task-oriented dialogue (TOD)
systems, faces significant challenges in adapting to the rapid influx of
integrable tools with complex interrelationships. Existing approaches, such as
zero-shot reformulations and LLM-based dynamic recognition, struggle with
performance degradation when encountering unseen intents, leading to erroneous
task routing. To enhance the model's generalization performance on unseen
tasks, we employ Reinforcement Learning (RL) combined with a Reward-based
Curriculum Sampling (RCS) during Group Relative Policy Optimization (GRPO)
training in intent detection tasks. Experiments demonstrate that RL-trained
models substantially outperform supervised fine-tuning (SFT) baselines in
generalization. Besides, the introduction of the RCS, significantly bolsters
the effectiveness of RL in intent detection by focusing the model on
challenging cases during training. Moreover, incorporating Chain-of-Thought
(COT) processes in RL notably improves generalization in complex intent
detection tasks, underscoring the importance of thought in challenging
scenarios. This work advances the generalization of intent detection tasks,
offering practical insights for deploying adaptable dialogue systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of
  Black-box Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13775v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13775v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengxian Wu, Juan Wen, Wanli Peng, Ziwei Zhang, Yinghan Zhou, Yiming Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous insertion-based and paraphrase-based backdoors have achieved great
success in attack efficacy, but they ignore the text quality and semantic
consistency between poisoned and clean texts. Although recent studies introduce
LLMs to generate poisoned texts and improve the stealthiness, semantic
consistency, and text quality, their hand-crafted prompts rely on expert
experiences, facing significant challenges in prompt adaptability and attack
performance after defenses. In this paper, we propose a novel backdoor attack
based on adaptive optimization mechanism of black-box large language models
(BadApex), which leverages a black-box LLM to generate poisoned text through a
refined prompt. Specifically, an Adaptive Optimization Mechanism is designed to
refine an initial prompt iteratively using the generation and modification
agents. The generation agent generates the poisoned text based on the initial
prompt. Then the modification agent evaluates the quality of the poisoned text
and refines a new prompt. After several iterations of the above process, the
refined prompt is used to generate poisoned texts through LLMs. We conduct
extensive experiments on three dataset with six backdoor attacks and two
defenses. Extensive experimental results demonstrate that BadApex significantly
outperforms state-of-the-art attacks. It improves prompt adaptability, semantic
consistency, and text quality. Furthermore, when two defense methods are
applied, the average attack success rate (ASR) still up to 96.75%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Temporal Knowledge Graph Question Answering: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14191v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14191v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miao Su, Zixuan Li, Zhuo Chen, Long Bai, Xiaolong Jin, Jiafeng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Base Question Answering (KBQA) has been a long-standing field to
answer questions based on knowledge bases. Recently, the evolving dynamics of
knowledge have attracted a growing interest in Temporal Knowledge Graph
Question Answering (TKGQA), an emerging task to answer temporal questions.
However, this field grapples with ambiguities in defining temporal questions
and lacks a systematic categorization of existing methods for TKGQA. In
response, this paper provides a thorough survey from two perspectives: the
taxonomy of temporal questions and the methodological categorization for TKGQA.
Specifically, we first establish a detailed taxonomy of temporal questions
engaged in prior studies. Subsequently, we provide a comprehensive review of
TKGQA techniques of two categories: semantic parsing-based and TKG
embedding-based. Building on this review, the paper outlines potential research
directions aimed at advancing the field of TKGQA. This work aims to serve as a
comprehensive reference for TKGQA and to stimulate further research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures. This work has been submitted to the IEEE for
  possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LongStory: Coherent, Complete and Length Controlled Long story
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.15208v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.15208v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyeongman Park, Nakyeong Yang, Kyomin Jung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A human author can write any length of story without losing coherence. Also,
they always bring the story to a proper ending, an ability that current
language models lack. In this work, we present the LongStory for coherent,
complete, and length-controlled long story generation. LongStory introduces two
novel methodologies: (1) the long and short-term contexts weight calibrator
(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights
for long-term context Memory and short-term context Cheating, acknowledging
their distinct roles. The LSP employs discourse tokens to convey the structural
positions of a long story. Trained on three datasets with varied average story
lengths, LongStory outperforms other baselines, including the strong story
generator Plotmachine, in coherence, completeness, relevance, and
repetitiveness. We also perform zero-shot tests on each dataset to assess the
model's ability to predict outcomes beyond its training data and validate our
methodology by comparing its performance with variants of our model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Training Data of Large Language Models via Expectation
  Maximization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07582v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07582v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gyuwan Kim, Yang Li, Evangelia Spiliopoulou, Jie Ma, Miguel Ballesteros, William Yang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancement of large language models has grown parallel to the opacity of
their training data. Membership inference attacks (MIAs) aim to determine
whether specific data was used to train a model. They offer valuable insights
into detecting data contamination and ensuring compliance with privacy and
copyright standards. However, MIA for LLMs is challenging due to the massive
scale of training data and the inherent ambiguity of membership in texts.
Moreover, creating realistic MIA evaluation benchmarks is difficult as training
and test data distributions are often unknown. We introduce EM-MIA, a novel
membership inference method that iteratively refines membership scores and
prefix scores via an expectation-maximization algorithm. Our approach leverages
the observation that these scores can improve each other: membership scores
help identify effective prefixes for detecting training data, while prefix
scores help determine membership. As a result, EM-MIA achieves state-of-the-art
results on WikiMIA. To enable comprehensive evaluation, we introduce OLMoMIA, a
benchmark built from OLMo resources, which allows controlling task difficulty
through varying degrees of overlap between training and test data
distributions. Our experiments demonstrate EM-MIA is robust across different
scenarios while also revealing fundamental limitations of current MIA
approaches when member and non-member distributions are nearly identical.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LangCoop: Collaborative Driving with Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13406v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13406v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangbo Gao, Yuheng Wu, Rujia Wang, Chenxi Liu, Yang Zhou, Zhengzhong Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-agent collaboration holds great promise for enhancing the safety,
reliability, and mobility of autonomous driving systems by enabling information
sharing among multiple connected agents. However, existing multi-agent
communication approaches are hindered by limitations of existing communication
media, including high bandwidth demands, agent heterogeneity, and information
loss. To address these challenges, we introduce LangCoop, a new paradigm for
collaborative autonomous driving that leverages natural language as a compact
yet expressive medium for inter-agent communication. LangCoop features two key
innovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured
zero-shot vision-language reasoning and Natural Language Information Packaging
(LangPack) for efficiently packaging information into concise, language-based
messages. Through extensive experiments conducted in the CARLA simulations, we
demonstrate that LangCoop achieves a remarkable 96\% reduction in communication
bandwidth (< 2KB per message) compared to image-based communication, while
maintaining competitive driving performance in the closed-loop evaluation. Our
project page and code are at https://xiangbogaobarry.github.io/LangCoop/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs
  on the Edge <span class="chip">AAAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.05693v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.05693v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuan Shen, Peiyan Dong, Lei Lu, Zhenglun Kong, Zhengang Li, Ming Lin, Chao Wu, Yanzhi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) stand out for their impressive performance in
intricate language modeling tasks. However, their demanding computational and
memory needs pose obstacles for broad use on edge devices. Quantization is then
introduced to boost LLMs' on-device efficiency. Recent works show that 8-bit or
lower weight quantization is feasible with minimal impact on end-to-end task
performance, while the activation is still not quantized. On the other hand,
mainstream commodity edge devices still struggle to execute these sub-8-bit
quantized networks effectively. In this paper, we propose Agile-Quant, an
activation-guided quantization framework for popular Large Language Models
(LLMs), and implement an end-to-end accelerator on multiple edge devices for
faster inference. Considering the hardware profiling and activation analysis,
we first introduce a basic activation quantization strategy to balance the
trade-off of task performance and real inference speed. Then we leverage the
activation-aware token pruning technique to reduce the outliers and the adverse
impact on attentivity. Ultimately, we utilize the SIMD-based 4-bit multiplier
and our efficient TRIP matrix multiplication to implement the accelerator for
LLMs on the edge. We apply our framework on different scales of LLMs including
LLaMA, OPT, and BLOOM with 4-bit or 8-bit for the activation and 4-bit for the
weight quantization. Experiments show that Agile-Quant achieves simultaneous
quantization of model weights and activations while maintaining task
performance comparable to existing weight-only quantization methods. Moreover,
in the 8- and 4-bit scenario, Agile-Quant achieves an on-device speedup of up
to 2.55x compared to its FP16 counterparts across multiple edge devices,
marking a pioneering advancement in this domain. Code:
https://github.com/shawnricecake/agile-quant
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">124</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on
  3D Gaussians 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15281v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15281v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cailin Zhuang, Yaoqi Hu, Xuanyang Zhang, Wei Cheng, Jiacheng Bao, Shengqi Liu, Yiying Yang, Xianfang Zeng, Gang Yu, Ming Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction
but struggles with stylized scenarios (e.g., cartoons, games) due to fragmented
textures, semantic misalignment, and limited adaptability to abstract
aesthetics. We propose StyleMe3D, a holistic framework for 3D GS style transfer
that integrates multi-modal style conditioning, multi-level semantic alignment,
and perceptual quality enhancement. Our key insights include: (1) optimizing
only RGB attributes preserves geometric integrity during stylization; (2)
disentangling low-, medium-, and high-level semantics is critical for coherent
style transfer; (3) scalability across isolated objects and complex scenes is
essential for practical deployment. StyleMe3D introduces four novel components:
Dynamic Style Score Distillation (DSSD), leveraging Stable Diffusion's latent
space for semantic alignment; Contrastive Style Descriptor (CSD) for localized,
content-aware texture transfer; Simultaneously Optimized Scale (SOS) to
decouple style details and structural coherence; and 3D Gaussian Quality
Assessment (3DG-QA), a differentiable aesthetic prior trained on human-rated
data to suppress artifacts and enhance visual harmony. Evaluated on NeRF
synthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D
outperforms state-of-the-art methods in preserving geometric details (e.g.,
carvings on sculptures) and ensuring stylistic consistency across scenes (e.g.,
coherent lighting in landscapes), while maintaining real-time rendering. This
work bridges photorealistic 3D GS and artistic stylization, unlocking
applications in gaming, virtual worlds, and digital art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages; Project page: https://styleme3d.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiye Xu, Jiahao Wang, Weiyun Wang, Zhe Chen, Wengang Zhou, Aijun Yang, Lewei Lu, Houqiang Li, Xiaohua Wang, Xizhou Zhu, Wenhai Wang, Jifeng Dai, Jinguo Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual reasoning is a core component of human intelligence and a critical
capability for advanced multimodal models. Yet current reasoning evaluations of
multimodal large language models (MLLMs) often rely on text descriptions and
allow language-based reasoning shortcuts, failing to measure genuine
vision-centric reasoning. To address this, we introduce VisuLogic: a benchmark
of 1,000 human-verified problems across six categories (e.g., quantitative
shifts, spatial relations, attribute comparisons). These various types of
questions can be evaluated to assess the visual reasoning capabilities of MLLMs
from multiple perspectives. We evaluate leading MLLMs on this benchmark and
analyze their results to identify common failure modes. Most models score below
30% accuracy-only slightly above the 25% random baseline and far below the
51.4% achieved by humans-revealing significant gaps in visual reasoning.
Furthermore, we provide a supplementary training dataset and a
reinforcement-learning baseline to support further progress.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code, data, and baselines are available at
  https://visulogic-benchmark.github.io/VisuLogic</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seeing from Another Perspective: Evaluating Multi-View Understanding in
  MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15280v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15280v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chun-Hsiao Yeh, Chenyu Wang, Shengbang Tong, Ta-Ying Cheng, Rouyu Wang, Tianzhe Chu, Yuexiang Zhai, Yubei Chen, Shenghua Gao, Yi Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-view understanding, the ability to reconcile visual information across
diverse viewpoints for effective navigation, manipulation, and 3D scene
comprehension, is a fundamental challenge in Multi-Modal Large Language Models
(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive
advances in high-level reasoning and planning, they frequently fall short when
confronted with multi-view geometric consistency and cross-view correspondence.
To comprehensively evaluate the challenges of MLLMs in multi-view scene
reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human
carefully annotated multi-view question-answer pairs across 90 diverse
real-world scenes. Our six tasks (counting, attribute identification, relative
distance, relative direction, object manipulation, and camera pose estimation)
specifically test model's geometric correspondence and the capacity to align
information consistently across views. Our extensive experiments, benchmark on
27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and
GPT-4o against human evaluators reveals a substantial performance gap,
indicating that current MLLMs remain far from human-level proficiency. Through
in-depth analysis, we show that MLLMs are particularly underperforming under
two aspects: (1) cross-view correspondence for partially occluded views and (2)
establishing the coarse camera poses. These findings highlight the necessity of
domain-specific refinements or modules that embed stronger multi-view
awareness. We believe that our All-Angles Bench offers valuable insights and
contribute to bridging the gap between MLLMs and human-level multi-view
understanding. The project and benchmark are publicly available at
https://danielchyeh.github.io/All-Angles-Bench/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://danielchyeh.github.io/All-Angles-Bench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DRAWER: Digital Reconstruction and Articulation With Environment Realism 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongchi Xia, Entong Su, Marius Memmel, Arhan Jain, Raymond Yu, Numfor Mbiziwo-Tiapo, Ali Farhadi, Abhishek Gupta, Shenlong Wang, Wei-Chiu Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Creating virtual digital replicas from real-world data unlocks significant
potential across domains like gaming and robotics. In this paper, we present
DRAWER, a novel framework that converts a video of a static indoor scene into a
photorealistic and interactive digital environment. Our approach centers on two
main contributions: (i) a reconstruction module based on a dual scene
representation that reconstructs the scene with fine-grained geometric details,
and (ii) an articulation module that identifies articulation types and hinge
positions, reconstructs simulatable shapes and appearances and integrates them
into the scene. The resulting virtual environment is photorealistic,
interactive, and runs in real time, with compatibility for game engines and
robotic simulation platforms. We demonstrate the potential of DRAWER by using
it to automatically create an interactive game in Unreal Engine and to enable
real-to-sim-to-real transfer for robotics applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://drawer-art.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Eagle 2.5: Boosting Long-Context Post-Training for Frontier
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guo Chen, Zhiqi Li, Shihao Wang, Jindong Jiang, Yicheng Liu, Lidong Lu, De-An Huang, Wonmin Byeon, Matthieu Le, Tuomas Rintamaki, Tyler Poon, Max Ehrlich, Tuomas Rintamaki, Tyler Poon, Tong Lu, Limin Wang, Bryan Catanzaro, Jan Kautz, Andrew Tao, Zhiding Yu, Guilin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Eagle 2.5, a family of frontier vision-language models (VLMs)
for long-context multimodal learning. Our work addresses the challenges in long
video comprehension and high-resolution image understanding, introducing a
generalist framework for both tasks. The proposed training framework
incorporates Automatic Degrade Sampling and Image Area Preservation, two
techniques that preserve contextual integrity and visual details. The framework
also includes numerous efficiency optimizations in the pipeline for
long-context data training. Finally, we propose Eagle-Video-110K, a novel
dataset that integrates both story-level and clip-level annotations,
facilitating long-video understanding. Eagle 2.5 demonstrates substantial
improvements on long-context multimodal benchmarks, providing a robust solution
to the limitations of existing VLMs. Notably, our best model Eagle 2.5-8B
achieves 72.4% on Video-MME with 512 input frames, matching the results of
top-tier commercial model such as GPT-4o and large-scale open-source models
like Qwen2.5-VL-72B and InternVL2.5-78B.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An LMM for Efficient Video Understanding via Reinforced Compression of
  Video Cubes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji Qi, Yuan Yao, Yushi Bai, Bin Xu, Juanzi Li, Zhiyuan Liu, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Multimodal Models (LMMs) uniformly perceive video frames, creating
computational inefficiency for videos with inherently varying temporal
information density. This paper present \textbf{Quicksviewer}, an LMM with new
perceiving paradigm that partitions a video of nonuniform density into varying
cubes using Gumbel Softmax, followed by a unified resampling for each cube to
achieve efficient video understanding. This simple and intuitive approach
dynamically compress video online based on its temporal density, significantly
reducing spatiotemporal redundancy (overall 45$\times$ compression rate), while
enabling efficient training with large receptive field. We train the model from
a language backbone through three progressive stages, each incorporating
lengthy videos on average of 420s/1fps thanks to the perceiving efficiency.
With only 0.8M total video-text samples for training, our model outperforms the
direct baseline employing a fixed partitioning strategy by a maximum of 8.72 in
accuracy, demonstrating the effectiveness in performance. On Video-MME,
Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\%
of tokens per frame required by baselines. With this paradigm, scaling up the
number of input frames reveals a clear power law of the model capabilities. It
is also empirically verified that the segments generated by the cubing network
can help for analyzing continuous events in videos.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diffusion Bridge Models for 3D Medical Image Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15267v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15267v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaorong Zhang, Tamoghna Chattopadhyay, Sophia I. Thomopoulos, Jose-Luis Ambite, Paul M. Thompson, Greg Ver Steeg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion tensor imaging (DTI) provides crucial insights into the
microstructure of the human brain, but it can be time-consuming to acquire
compared to more readily available T1-weighted (T1w) magnetic resonance imaging
(MRI). To address this challenge, we propose a diffusion bridge model for 3D
brain image translation between T1w MRI and DTI modalities. Our model learns to
generate high-quality DTI fractional anisotropy (FA) images from T1w images and
vice versa, enabling cross-modality data augmentation and reducing the need for
extensive DTI acquisition. We evaluate our approach using perceptual
similarity, pixel-level agreement, and distributional consistency metrics,
demonstrating strong performance in capturing anatomical structures and
preserving information on white matter integrity. The practical utility of the
synthetic data is validated through sex classification and Alzheimer's disease
classification tasks, where the generated images achieve comparable performance
to real data. Our diffusion bridge model offers a promising solution for
improving neuroimaging datasets and supporting clinical decision-making, with
the potential to significantly impact neuroimaging research and clinical
practice.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revealing the 3D Cosmic Web through Gravitationally Constrained Neural
  Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15262v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15262v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brandon Zhao, Aviad Levis, Liam Connor, Pratul P. Srinivasan, Katherine L. Bouman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weak gravitational lensing is the slight distortion of galaxy shapes caused
primarily by the gravitational effects of dark matter in the universe. In our
work, we seek to invert the weak lensing signal from 2D telescope images to
reconstruct a 3D map of the universe's dark matter field. While inversion
typically yields a 2D projection of the dark matter field, accurate 3D maps of
the dark matter distribution are essential for localizing structures of
interest and testing theories of our universe. However, 3D inversion poses
significant challenges. First, unlike standard 3D reconstruction that relies on
multiple viewpoints, in this case, images are only observed from a single
viewpoint. This challenge can be partially addressed by observing how galaxy
emitters throughout the volume are lensed. However, this leads to the second
challenge: the shapes and exact locations of unlensed galaxies are unknown, and
can only be estimated with a very large degree of uncertainty. This introduces
an overwhelming amount of noise which nearly drowns out the lensing signal
completely. Previous approaches tackle this by imposing strong assumptions
about the structures in the volume. We instead propose a methodology using a
gravitationally-constrained neural field to flexibly model the continuous
matter distribution. We take an analysis-by-synthesis approach, optimizing the
weights of the neural network through a fully differentiable physical forward
model to reproduce the lensing signal present in image measurements. We
showcase our method on simulations, including realistic simulated measurements
of dark matter distributions that mimic data from upcoming telescope surveys.
Our results show that our method can not only outperform previous methods, but
importantly is also able to recover potentially surprising dark matter
structures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15259v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15259v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunxuan Cai, Sitao Xiang, Zongjian Li, Haiwei Chen, Yajie Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Digital modeling and reconstruction of human faces serve various
applications. However, its availability is often hindered by the requirements
of data capturing devices, manual labor, and suitable actors. This situation
restricts the diversity, expressiveness, and control over the resulting models.
This work aims to demonstrate that a semantically controllable generative
network can provide enhanced control over the digital face modeling process. To
enhance diversity beyond the limited human faces scanned in a controlled
setting, we introduce a novel data generation pipeline that creates a
high-quality 3D face database using a pre-trained diffusion model. Our proposed
normalization module converts synthesized data from the diffusion model into
high-quality scanned data. Using the 44,000 face models we obtained, we further
developed an efficient GAN-based generator. This generator accepts semantic
attributes as input, and generates geometry and albedo. It also allows
continuous post-editing of attributes in the latent space. Our asset refinement
component subsequently creates physically-based facial assets. We introduce a
comprehensive system designed for creating and editing high-quality face
assets. Our proposed model has undergone extensive experiment, comparison and
evaluation. We also integrate everything into a web-based interactive tool. We
aim to make this tool publicly available with the release of the paper.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SuoiAI: Building a <span class="highlight-title">Dataset</span> for Aquatic Invertebrates in Vietnam <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tue Vo, Lakshay Sharma, Tuan Dinh, Khuong Dinh, Trang Nguyen, Trung Phan, Minh Do, Duong Vu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and monitoring aquatic biodiversity is critical for ecological
health and conservation efforts. This paper proposes SuoiAI, an end-to-end
pipeline for building a dataset of aquatic invertebrates in Vietnam and
employing machine learning (ML) techniques for species classification. We
outline the methods for data collection, annotation, and model training,
focusing on reducing annotation effort through semi-supervised learning and
leveraging state-of-the-art object detection and classification models. Our
approach aims to overcome challenges such as data scarcity, fine-grained
classification, and deployment in diverse environmental conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a workshop paper at "Tackling Climate Change with
  Machine Learning", ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shape-Guided Clothing Warping for Virtual Try-On <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15232v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15232v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Han, Shunyuan Zheng, Zonglin Li, Chenyang Wang, Xin Sun, Quanling Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image-based virtual try-on aims to seamlessly fit in-shop clothing to a
person image while maintaining pose consistency. Existing methods commonly
employ the thin plate spline (TPS) transformation or appearance flow to deform
in-shop clothing for aligning with the person's body. Despite their promising
performance, these methods often lack precise control over fine details,
leading to inconsistencies in shape between clothing and the person's body as
well as distortions in exposed limb regions. To tackle these challenges, we
propose a novel shape-guided clothing warping method for virtual try-on, dubbed
SCW-VTON, which incorporates global shape constraints and additional limb
textures to enhance the realism and consistency of the warped clothing and
try-on results. To integrate global shape constraints for clothing warping, we
devise a dual-path clothing warping module comprising a shape path and a flow
path. The former path captures the clothing shape aligned with the person's
body, while the latter path leverages the mapping between the pre- and
post-deformation of the clothing shape to guide the estimation of appearance
flow. Furthermore, to alleviate distortions in limb regions of try-on results,
we integrate detailed limb guidance by developing a limb reconstruction network
based on masked image modeling. Through the utilization of SCW-VTON, we are
able to generate try-on results with enhanced clothing shape consistency and
precise control over details. Extensive experiments demonstrate the superiority
of our approach over state-of-the-art methods both qualitatively and
quantitatively. The code is available at https://github.com/xyhanHIT/SCW-VTON.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM MM 2024. The code is available at
  https://github.com/xyhanHIT/SCW-VTON</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's
  LLM-CLIP Framework for Image Captioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15199v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15199v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yassir Benhammou, Alessandro Tiberio, Gabriel Trautmann, Suman Kalyan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MILS (Multimodal Iterative LLM Solver) is a recently published framework that
claims "LLMs can see and hear without any training" by leveraging an iterative,
LLM-CLIP based approach for zero-shot image captioning. While this MILS
approach demonstrates good performance, our investigation reveals that this
success comes at a hidden, substantial computational cost due to its expensive
multi-step refinement process. In contrast, alternative models such as BLIP-2
and GPT-4V achieve competitive results through a streamlined, single-pass
approach. We hypothesize that the significant overhead inherent in MILS's
iterative process may undermine its practical benefits, thereby challenging the
narrative that zero-shot performance can be attained without incurring heavy
resource demands. This work is the first to expose and quantify the trade-offs
between output quality and computational cost in MILS, providing critical
insights for the design of more efficient multimodal models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 tables, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Measurement of Eczema Severity with <span class="highlight-title">Self-Supervised</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neelesh Kumar, Oya Aran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated diagnosis of eczema using images acquired from digital camera can
enable individuals to self-monitor their recovery. The process entails first
segmenting out the eczema region from the image and then measuring the severity
of eczema in the segmented region. The state-of-the-art methods for automated
eczema diagnosis rely on deep neural networks such as convolutional neural
network (CNN) and have shown impressive performance in accurately measuring the
severity of eczema. However, these methods require massive volume of annotated
data to train which can be hard to obtain. In this paper, we propose a
self-supervised learning framework for automated eczema diagnosis under limited
training data regime. Our framework consists of two stages: i) Segmentation,
where we use an in-context learning based algorithm called SegGPT for few-shot
segmentation of eczema region from the image; ii) Feature extraction and
classification, where we extract DINO features from the segmented regions and
feed it to a multi-layered perceptron (MLP) for 4-class classification of
eczema severity. When evaluated on a dataset of annotated "in-the-wild" eczema
images, we show that our method outperforms (Weighted F1: 0.67 $\pm$ 0.01) the
state-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted
F1: 0.44 $\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\pm$ 0.22). Our
results show that self-supervised learning can be a viable solution for
automated skin diagnosis where labeled data is scarce.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Breast density in MRI: an AI-based quantification and relationship to
  assessment in mammography 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15192v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15192v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaqian Chen, Lin Li, Hanxue Gu, Haoyu Dong, Derek L. Nguyen, Allan D. Kirk, Maciej A. Mazurowski, E. Shelley Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mammographic breast density is a well-established risk factor for breast
cancer. Recently there has been interest in breast MRI as an adjunct to
mammography, as this modality provides an orthogonal and highly quantitative
assessment of breast tissue. However, its 3D nature poses analytic challenges
related to delineating and aggregating complex structures across slices. Here,
we applied an in-house machine-learning algorithm to assess breast density on
normal breasts in three MRI datasets. Breast density was consistent across
different datasets (0.104 - 0.114). Analysis across different age groups also
demonstrated strong consistency across datasets and confirmed a trend of
decreasing density with age as reported in previous studies. MR breast density
was correlated with mammographic breast density, although some notable
differences suggest that certain breast density components are captured only on
MRI. Future work will determine how to integrate MR breast density with current
tools to improve future breast cancer risk prediction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tiger200K: Manually Curated High Visual Quality Video <span class="highlight-title">Dataset</span> from UGC
  Platform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15182v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15182v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xianpan Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent surge in open-source text-to-video generation models has
significantly energized the research community, yet their dependence on
proprietary training datasets remains a key constraint. While existing open
datasets like Koala-36M employ algorithmic filtering of web-scraped videos from
early platforms, they still lack the quality required for fine-tuning advanced
video generation models. We present Tiger200K, a manually curated high visual
quality video dataset sourced from User-Generated Content (UGC) platforms. By
prioritizing visual fidelity and aesthetic quality, Tiger200K underscores the
critical role of human expertise in data curation, and providing high-quality,
temporally consistent video-text pairs for fine-tuning and optimizing video
generation architectures through a simple but effective pipeline including shot
boundary detection, OCR, border detecting, motion filter and fine bilingual
caption. The dataset will undergo ongoing expansion and be released as an
open-source initiative to advance research and applications in video generative
models. Project page: https://tinytigerpan.github.io/tiger200k/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://tinytigerpan.github.io/tiger200k/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FaceCraft4D: Animated 3D Facial Avatar Generation from a Single Image 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Yin, Mallikarjun B R, Chun-Han Yao, Rafał Mantiuk, Varun Jampani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel framework for generating high-quality, animatable 4D
avatar from a single image. While recent advances have shown promising results
in 4D avatar creation, existing methods either require extensive multiview data
or struggle with shape accuracy and identity consistency. To address these
limitations, we propose a comprehensive system that leverages shape, image, and
video priors to create full-view, animatable avatars. Our approach first
obtains initial coarse shape through 3D-GAN inversion. Then, it enhances
multiview textures using depth-guided warping signals for cross-view
consistency with the help of the image diffusion model. To handle expression
animation, we incorporate a video prior with synchronized driving signals
across viewpoints. We further introduce a Consistent-Inconsistent training to
effectively handle data inconsistencies during 4D reconstruction. Experimental
results demonstrate that our method achieves superior quality compared to the
prior art, while maintaining consistency across different viewpoints and
expressions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DSPO: Direct Semantic Preference Optimization for Real-World Image
  Super-Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15176v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15176v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miaomiao Cai, Simiao Li, Wei Li, Xudong Huang, Hanting Chen, Jie Hu, Yunhe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in diffusion models have improved Real-World Image
Super-Resolution (Real-ISR), but existing methods lack human feedback
integration, risking misalignment with human preference and may leading to
artifacts, hallucinations and harmful content generation. To this end, we are
the first to introduce human preference alignment into Real-ISR, a technique
that has been successfully applied in Large Language Models and Text-to-Image
tasks to effectively enhance the alignment of generated outputs with human
preferences. Specifically, we introduce Direct Preference Optimization (DPO)
into Real-ISR to achieve alignment, where DPO serves as a general alignment
technique that directly learns from the human preference dataset. Nevertheless,
unlike high-level tasks, the pixel-level reconstruction objectives of Real-ISR
are difficult to reconcile with the image-level preferences of DPO, which can
lead to the DPO being overly sensitive to local anomalies, leading to reduced
generation quality. To resolve this dichotomy, we propose Direct Semantic
Preference Optimization (DSPO) to align instance-level human preferences by
incorporating semantic guidance, which is through two strategies: (a) semantic
instance alignment strategy, implementing instance-level alignment to ensure
fine-grained perceptual consistency, and (b) user description feedback
strategy, mitigating hallucinations through semantic textual feedback on
instance-level images. As a plug-and-play solution, DSPO proves highly
effective in both one-step and multi-step SR frameworks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HSANET: A Hybrid Self-Cross Attention Network For Remote Sensing Change
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengxi Han, Xiaoyu Su, Zhiqiang Wei, Meiqi Hu, Yichu Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remote sensing image change detection task is an essential method for
large-scale monitoring. We propose HSANet, a network that uses hierarchical
convolution to extract multi-scale features. It incorporates hybrid
self-attention and cross-attention mechanisms to learn and fuse global and
cross-scale information. This enables HSANet to capture global context at
different scales and integrate cross-scale features, refining edge details and
improving detection performance. We will also open-source our model code:
https://github.com/ChengxiHAN/HSANet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Efficient Aerial Image Detection with Variable Receptive Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15165v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15165v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liu Wenbin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aerial object detection using unmanned aerial vehicles (UAVs) faces critical
challenges including sub-10px targets, dense occlusions, and stringent
computational constraints. Existing detectors struggle to balance accuracy and
efficiency due to rigid receptive fields and redundant architectures. To
address these limitations, we propose Variable Receptive Field DETR (VRF-DETR),
a transformer-based detector incorporating three key components: 1) Multi-Scale
Context Fusion (MSCF) module that dynamically recalibrates features through
adaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution
(GConv) layer enabling parameter-efficient local-context modeling via depthwise
separable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)
Bottleneck that hierarchically disentangles occluded objects through cascaded
global-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR
achieves 51.4\% mAP\textsubscript{50} and 31.8\% mAP\textsubscript{50:95} with
only 13.5M parameters. This work establishes a new efficiency-accuracy Pareto
frontier for UAV-based detection tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Acquire and then Adapt: Squeezing out Text-to-Image Model for Image
  Restoration <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyuan Deng, Xinyi Wu, Yongxing Yang, Congchao Zhu, Song Wang, Zhenyao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, pre-trained text-to-image (T2I) models have been extensively
adopted for real-world image restoration because of their powerful generative
prior. However, controlling these large models for image restoration usually
requires a large number of high-quality images and immense computational
resources for training, which is costly and not privacy-friendly. In this
paper, we find that the well-trained large T2I model (i.e., Flux) is able to
produce a variety of high-quality images aligned with real-world distributions,
offering an unlimited supply of training samples to mitigate the above issue.
Specifically, we proposed a training data construction pipeline for image
restoration, namely FluxGen, which includes unconditional image generation,
image selection, and degraded image simulation. A novel light-weighted adapter
(FluxIR) with squeeze-and-excitation layers is also carefully designed to
control the large Diffusion Transformer (DiT)-based T2I model so that
reasonable details can be restored. Experiments demonstrate that our proposed
method enables the Flux model to adapt effectively to real-world image
restoration tasks, achieving superior scores and visual quality on both
synthetic and real-world degradation datasets - at only about 8.5\% of the
training cost compared to current approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic 3D KAN Convolution with Adaptive Grid Optimization for
  Hyperspectral Image Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15155v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15155v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guandong Li, Mengxia Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks face several challenges in hyperspectral image
classification, including high-dimensional data, sparse distribution of ground
objects, and spectral redundancy, which often lead to classification
overfitting and limited generalization capability. To more efficiently adapt to
ground object distributions while extracting image features without introducing
excessive parameters and skipping redundant information, this paper proposes
KANet based on an improved 3D-DenseNet model, consisting of 3D KAN Conv and an
adaptive grid update mechanism. By introducing learnable univariate B-spline
functions on network edges, specifically by flattening three-dimensional
neighborhoods into vectors and applying B-spline-parameterized nonlinear
activation functions to replace the fixed linear weights of traditional 3D
convolutional kernels, we precisely capture complex spectral-spatial nonlinear
relationships in hyperspectral data. Simultaneously, through a dynamic grid
adjustment mechanism, we adaptively update the grid point positions of
B-splines based on the statistical characteristics of input data, optimizing
the resolution of spline functions to match the non-uniform distribution of
spectral features, significantly improving the model's accuracy in
high-dimensional data modeling and parameter efficiency, effectively
alleviating the curse of dimensionality. This characteristic demonstrates
superior neural scaling laws compared to traditional convolutional neural
networks and reduces overfitting risks in small-sample and high-noise
scenarios. KANet enhances model representation capability through a 3D dynamic
expert convolution system without increasing network depth or width. The
proposed method demonstrates superior performance on IN, UP, and KSC datasets,
outperforming mainstream hyperspectral image classification approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Landmark-Free Preoperative-to-Intraoperative Registration in
  Laparoscopic Liver Resection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15152v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15152v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Zhou, Bingchen Gao, Kai Wang, Jialun Pei, Pheng-Ann Heng, Jing Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Liver registration by overlaying preoperative 3D models onto intraoperative
2D frames can assist surgeons in perceiving the spatial anatomy of the liver
clearly for a higher surgical success rate. Existing registration methods rely
heavily on anatomical landmark-based workflows, which encounter two major
limitations: 1) ambiguous landmark definitions fail to provide efficient
markers for registration; 2) insufficient integration of intraoperative liver
visual information in shape deformation modeling. To address these challenges,
in this paper, we propose a landmark-free preoperative-to-intraoperative
registration framework utilizing effective self-supervised learning, termed
\ourmodel. This framework transforms the conventional 3D-2D workflow into a
3D-3D registration pipeline, which is then decoupled into rigid and non-rigid
registration subtasks. \ourmodel~first introduces a feature-disentangled
transformer to learn robust correspondences for recovering rigid
transformations. Further, a structure-regularized deformation network is
designed to adjust the preoperative model to align with the intraoperative
liver surface. This network captures structural correlations through geometry
similarity modeling in a low-rank transformer network. To facilitate the
validation of the registration performance, we also construct an in-vivo
registration dataset containing liver resection videos of 21 patients, called
\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the
liver together with liver mask annotations and calibrated camera intrinsic
parameters. Extensive experiments and user studies on both synthetic and
in-vivo datasets demonstrate the superiority and potential clinical
applicability of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>TMI under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ "I Know It When I See It": Mood Spaces for Connecting and Expressing
  Visual Concepts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15145v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15145v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huzheng Yang, Katherine Xu, Michael D. Grossberg, Yutong Bai, Jianbo Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expressing complex concepts is easy when they can be labeled or quantified,
but many ideas are hard to define yet instantly recognizable. We propose a Mood
Board, where users convey abstract concepts with examples that hint at the
intended direction of attribute changes. We compute an underlying Mood Space
that 1) factors out irrelevant features and 2) finds the connections between
images, thus bringing relevant concepts closer. We invent a fibration
computation to compress/decompress pre-trained features into/from a compact
space, 50-100x smaller. The main innovation is learning to mimic the pairwise
affinity relationship of the image tokens across exemplars. To focus on the
coarse-to-fine hierarchical structures in the Mood Space, we compute the top
eigenvector structure from the affinity matrix and define a loss in the
eigenvector space. The resulting Mood Space is locally linear and compact,
allowing image-level operations, such as object averaging, visual analogy, and
pose transfer, to be performed as a simple vector operation in Mood Space. Our
learning is efficient in computation without any fine-tuning, needs only a few
(2-20) exemplars, and takes less than a minute to learn.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://huzeyann.github.io/mspace/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instance-Adaptive Keypoint Learning with Local-to-Global Geometric
  Aggregation for Category-Level Object Pose Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15134v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15134v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Zhang, Lu Zou, Tao Lu, Yuan Yao, Zhangjin Huang, Guoping Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Category-level object pose estimation aims to predict the 6D pose and size of
previously unseen instances from predefined categories, requiring strong
generalization across diverse object instances. Although many previous methods
attempt to mitigate intra-class variations, they often struggle with instances
exhibiting complex geometries or significant deviations from canonical shapes.
To address this challenge, we propose INKL-Pose, a novel category-level object
pose estimation framework that enables INstance-adaptive Keypoint Learning with
local-to-global geometric aggregation. Specifically, our approach first
predicts semantically consistent and geometric informative keypoints through an
Instance-Adaptive Keypoint Generator, then refines them with: (1) a Local
Keypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global
Keypoint Feature Aggregator using bidirectional Mamba for structural
consistency. To enable bidirectional modeling in Mamba, we introduce a Feature
Sequence Flipping strategy that preserves spatial coherence while constructing
backward feature sequences. Additionally, we design a surface loss and a
separation loss to enforce uniform coverage and spatial diversity in keypoint
distribution. The generated keypoints are finally mapped to a canonical space
for regressing the object's 6D pose and size. Extensive experiments on
CAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves
state-of-the-art performance and significantly outperforms existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15133v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15133v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziwen Xu, Shuxun Wang, Kewei Xu, Haoming Xu, Mengru Wang, Xinle Deng, Yunzhi Yao, Guozhou Zheng, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce EasyEdit2, a framework designed to enable
plug-and-play adjustability for controlling Large Language Model (LLM)
behaviors. EasyEdit2 supports a wide range of test-time interventions,
including safety, sentiment, personality, reasoning patterns, factuality, and
language features. Unlike its predecessor, EasyEdit2 features a new
architecture specifically designed for seamless model steering. It comprises
key modules such as the steering vector generator and the steering vector
applier, which enable automatic generation and application of steering vectors
to influence the model's behavior without modifying its parameters. One of the
main advantages of EasyEdit2 is its ease of use-users do not need extensive
technical knowledge. With just a single example, they can effectively guide and
adjust the model's responses, making precise control both accessible and
efficient. Empirically, we report model steering performance across different
LLMs, demonstrating the effectiveness of these techniques. We have released the
source code on GitHub at https://github.com/zjunlp/EasyEdit along with a
demonstration notebook. In addition, we provide a demo video at
https://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Demo:
  https://zjunlp.github.io/project/EasyEdit2/video; code:
  https://github.com/zjunlp/EasyEdit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A General Infrastructure and Workflow for Quadrotor Deep Reinforcement
  Learning and Reality Deployment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangyao Huang, Hao Wang, Yu Luo, Jingyu Chen, Jintao Chen, Xiangkui Zhang, Xiangyang Ji, Huaping Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deploying robot learning methods to a quadrotor in unstructured outdoor
environments is an exciting task. Quadrotors operating in real-world
environments by learning-based methods encounter several challenges: a large
amount of simulator generated data required for training, strict demands for
real-time processing onboard, and the sim-to-real gap caused by dynamic and
noisy conditions. Current works have made a great breakthrough in applying
learning-based methods to end-to-end control of quadrotors, but rarely mention
the infrastructure system training from scratch and deploying to reality, which
makes it difficult to reproduce methods and applications. To bridge this gap,
we propose a platform that enables the seamless transfer of end-to-end deep
reinforcement learning (DRL) policies. We integrate the training environment,
flight dynamics control, DRL algorithms, the MAVROS middleware stack, and
hardware into a comprehensive workflow and architecture that enables
quadrotors' policies to be trained from scratch to real-world deployment in
several minutes. Our platform provides rich types of environments including
hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and
planning in unknown environments, as a physical experiment benchmark. Through
extensive empirical validation, we demonstrate the efficiency of proposed
sim-to-real platform, and robust outdoor flight performance under real-world
perturbations. Details can be found from our website
https://emnavi.tech/AirGym/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry
  Monocular Video 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15122v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15122v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minh-Quan Viet Bui, Jongmin Park, Juan Luis Gonzalez Bello, Jaeho Moon, Jihyong Oh, Munchurl Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS)
framework capable of reconstructing sharp and high-quality novel
spatio-temporal views from blurry monocular videos in an end-to-end manner.
Existing dynamic novel view synthesis (NVS) methods are highly sensitive to
motion blur in casually captured videos, resulting in significant degradation
of rendering quality. While recent approaches address motion-blurred inputs for
NVS, they primarily focus on static scene reconstruction and lack dedicated
motion modeling for dynamic objects. To overcome these limitations, our MoBGS
introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for
effective latent camera trajectory estimation, improving global camera motion
deblurring. In addition, we propose a physically-inspired Latent Camera-induced
Exposure Estimation (LCEE) method to ensure consistent deblurring of both
global camera and local object motion. Our MoBGS framework ensures the temporal
consistency of unseen latent timestamps and robust motion decomposition of
static and dynamic regions. Extensive experiments on the Stereo Blur dataset
and real-world blurry videos show that our MoBGS significantly outperforms the
very recent advanced methods (DyBluRF and Deblur4DGS), achieving
state-of-the-art performance for dynamic NVS under motion blur.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally to this work (equal
  contribution). The last two authors advised equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust and Real-time Surface Normal Estimation from Stereo Disparities
  using Affine Transformations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15121v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15121v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Csongor Csanad Kariko, Muhammad Rafi Faisal, Levente Hajder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work introduces a novel method for surface normal estimation from
rectified stereo image pairs, leveraging affine transformations derived from
disparity values to achieve fast and accurate results. We demonstrate how the
rectification of stereo image pairs simplifies the process of surface normal
estimation by reducing computational complexity. To address noise reduction, we
develop a custom algorithm inspired by convolutional operations, tailored to
process disparity data efficiently. We also introduce adaptive heuristic
techniques for efficiently detecting connected surface components within the
images, further improving the robustness of the method. By integrating these
methods, we construct a surface normal estimator that is both fast and
accurate, producing a dense, oriented point cloud as the final output. Our
method is validated using both simulated environments and real-world stereo
images from the Middlebury and Cityscapes datasets, demonstrating significant
improvements in real-time performance and accuracy when implemented on a GPU.
Upon acceptance, the shader source code will be made publicly available to
facilitate further research and reproducibility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Sound Source Localization with Joint Slot Attention on Image
  and Audio <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15118v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15118v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Inho Kim, Youngkil Song, Jicheol Park, Won Hwa Kim, Suha Kwak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sound source localization (SSL) is the task of locating the source of sound
within an image. Due to the lack of localization labels, the de facto standard
in SSL has been to represent an image and audio as a single embedding vector
each, and use them to learn SSL via contrastive learning. To this end, previous
work samples one of local image features as the image embedding and aggregates
all local audio features to obtain the audio embedding, which is far from
optimal due to the presence of noise and background irrelevant to the actual
target in the input. We present a novel SSL method that addresses this chronic
issue by joint slot attention on image and audio. To be specific, two slots
competitively attend image and audio features to decompose them into target and
off-target representations, and only target representations of image and audio
are used for contrastive learning. Also, we introduce cross-modal attention
matching to further align local features of image and audio. Our method
achieved the best in almost all settings on three public benchmarks for SSL,
and substantially outperformed all the prior work in cross-modal retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unwarping Screen Content Images via Structure-texture Enhancement
  Network and Transformation Self-estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15108v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15108v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenzhen Xiao, Heng Liu, Bingwen Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While existing implicit neural network-based image unwarping methods perform
well on natural images, they struggle to handle screen content images (SCIs),
which often contain large geometric distortions, text, symbols, and sharp
edges. To address this, we propose a structure-texture enhancement network
(STEN) with transformation self-estimation for SCI warping. STEN integrates a
B-spline implicit neural representation module and a transformation error
estimation and self-correction algorithm. It comprises two branches: the
structure estimation branch (SEB), which enhances local aggregation and global
dependency modeling, and the texture estimation branch (TEB), which improves
texture detail synthesis using B-spline implicit neural representation.
Additionally, the transformation self-estimation module autonomously estimates
the transformation error and corrects the coordinate transformation matrix,
effectively handling real-world image distortions. Extensive experiments on
public SCI datasets demonstrate that our approach significantly outperforms
state-of-the-art methods. Comparisons on well-known natural image datasets also
show the potential of our approach for natural image distortion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A triple-branch network for latent fingerprint enhancement guided by
  orientation fields and minutiae 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15105v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15105v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yurun Wang, Zerong Qi, Shujun Fu, Mingzheng Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Latent fingerprint enhancement is a critical step in the process of latent
fingerprint identification. Existing deep learning-based enhancement methods
still fall short of practical application requirements, particularly in
restoring low-quality fingerprint regions. Recognizing that different regions
of latent fingerprints require distinct enhancement strategies, we propose a
Triple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances
different regions of the image using tailored strategies. Furthermore, to
improve the generalization capability of the network, we integrate orientation
field and minutiae-related modules into TBSFNet and introduce a Multi-Level
Feature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST
datasets demonstrate that MLFGNet outperforms existing enhancement algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced
  Long-Range Depth Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingxia Zhan, Li Zhang, XiaoMeng Chu, Beibei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monocular depth estimation (MDE) aims to predict per-pixel depth values from
a single RGB image. Recent advancements have positioned diffusion models as
effective MDE tools by framing the challenge as a conditional image generation
task. Despite their progress, these methods often struggle with accurately
reconstructing distant depths, due largely to the imbalanced distribution of
depth values and an over-reliance on spatial-domain features. To overcome these
limitations, we introduce VistaDepth, a novel framework that integrates
adaptive frequency-domain feature enhancements with an adaptive
weight-balancing mechanism into the diffusion process. Central to our approach
is the Latent Frequency Modulation (LFM) module, which dynamically refines
spectral responses in the latent feature space, thereby improving the
preservation of structural details and reducing noisy artifacts. Furthermore,
we implement an adaptive weighting strategy that modulates the diffusion loss
in real-time, enhancing the model's sensitivity towards distant depth
reconstruction. These innovations collectively result in superior depth
perception performance across both distance and detail. Experimental
evaluations confirm that VistaDepth achieves state-of-the-art performance among
diffusion-based MDE techniques, particularly excelling in the accurate
reconstruction of distant regions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hierarchical Attention Fusion of Visual and Textual Representations for
  Cross-Domain Sequential Recommendation <span class="chip">SC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15085v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15085v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wangyu Wu, Zhenhong Chen, Siqi Song, Xianglin Qiua, Xiaowei Huang, Fei Ma, Jimin Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by
leveraging historical interactions across multiple domains, focusing on
modeling cross-domain preferences through intra- and inter-sequence item
relationships. Inspired by human cognitive processes, we propose Hierarchical
Attention Fusion of Visual and Textual Representations (HAF-VT), a novel
approach integrating visual and textual data to enhance cognitive modeling.
Using the frozen CLIP model, we generate image and text embeddings, enriching
item representations with multimodal data. A hierarchical attention mechanism
jointly learns single-domain and cross-domain preferences, mimicking human
information integration. Evaluated on four e-commerce datasets, HAF-VT
outperforms existing methods in capturing cross-domain user interests, bridging
cognitive principles with computational models and highlighting the role of
multimodal data in sequential decision-making.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CogSCI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structure-guided Diffusion <span class="highlight-title">Transformer</span> for Low-Light Image Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15054v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15054v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangchen Yin, Zhenda Yu, Longtao Jiang, Xin Gao, Xiao Sun, Zhi Liu, Xun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While the diffusion transformer (DiT) has become a focal point of interest in
recent years, its application in low-light image enhancement remains a blank
area for exploration. Current methods recover the details from low-light images
while inevitably amplifying the noise in images, resulting in poor visual
quality. In this paper, we firstly introduce DiT into the low-light enhancement
task and design a novel Structure-guided Diffusion Transformer based Low-light
image enhancement (SDTL) framework. We compress the feature through wavelet
transform to improve the inference efficiency of the model and capture the
multi-directional frequency band. Then we propose a Structure Enhancement
Module (SEM) that uses structural prior to enhance the texture and leverages an
adaptive fusion strategy to achieve more accurate enhancement effect. In
Addition, we propose a Structure-guided Attention Block (SAB) to pay more
attention to texture-riched tokens and avoid interference from noisy areas in
noise prediction. Extensive qualitative and quantitative experiments
demonstrate that our method achieves SOTA performance on several popular
datasets, validating the effectiveness of SDTL in improving image quality and
the potential of DiT in low-light enhancement tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Multimedia (TMM)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VeLU: Variance-enhanced Learning Unit for Deep Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo Nicolè, Stefano Ghidoni, Nassir Navab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Activation functions are fundamental in deep neural networks and directly
impact gradient flow, optimization stability, and generalization. Although ReLU
remains standard because of its simplicity, it suffers from vanishing gradients
and lacks adaptability. Alternatives like Swish and GELU introduce smooth
transitions, but fail to dynamically adjust to input statistics. We propose
VeLU, a Variance-enhanced Learning Unit as an activation function that
dynamically scales based on input variance by integrating ArcTan-Sin
transformations and Wasserstein-2 regularization, effectively mitigating
covariate shifts and stabilizing optimization. Extensive experiments on
ViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm
VeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.
The codes of VeLU are publicly available on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ScanEdit: Hierarchically-Guided Functional 3D Scan Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15049v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15049v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed el amine Boudjoghra, Ivan Laptev, Angela Dai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the fast pace of 3D capture technology and resulting abundance of 3D
data, effective 3D scene editing becomes essential for a variety of graphics
applications. In this work we present ScanEdit, an instruction-driven method
for functional editing of complex, real-world 3D scans. To model large and
interdependent sets of ob- jectswe propose a hierarchically-guided approach.
Given a 3D scan decomposed into its object instances, we first construct a
hierarchical scene graph representation to enable effective, tractable editing.
We then leverage reason- ing capabilities of Large Language Models (LLMs) and
translate high-level language instructions into actionable commands applied
hierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based
guidance with ex- plicit physical constraints and generates realistic scenes
where object arrangements obey both physics and common sense. In our extensive
experimental evaluation ScanEdit outperforms state of the art and demonstrates
excellent re- sults for a variety of real-world scenes and input instruc-
tions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project webpage: https://aminebdj.github.io/scanedit/ Video:
  https://www.youtube.com/watch?v=Dfmu2g6pVlg</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong
  Person Re-identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15041v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15041v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiben Liu, Huijie Fan, Qiang Wang, Baojie Fan, Yandong Tang, Liangqiong Qu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lifelong Person Re-identification (LReID) suffers from a key challenge in
preserving old knowledge while adapting to new information. The existing
solutions include rehearsal-based and rehearsal-free methods to address this
challenge. Rehearsal-based approaches rely on knowledge distillation,
continuously accumulating forgetting during the distillation process.
Rehearsal-free methods insufficiently learn the distribution of each domain,
leading to forgetfulness over time. To solve these issues, we propose a novel
Distribution-aware Forgetting Compensation (DAFC) model that explores
cross-domain shared representation learning and domain-specific distribution
integration without using old exemplars or knowledge distillation. We propose a
Text-driven Prompt Aggregation (TPA) that utilizes text features to enrich
prompt elements and guide the prompt model to learn fine-grained
representations for each instance. This can enhance the differentiation of
identity information and establish the foundation for domain distribution
awareness. Then, Distribution-based Awareness and Integration (DAI) is designed
to capture each domain-specific distribution by a dedicated expert network and
adaptively consolidate them into a shared region in high-dimensional space. In
this manner, DAI can consolidate and enhance cross-domain shared representation
learning while alleviating catastrophic forgetting. Furthermore, we develop a
Knowledge Consolidation Mechanism (KCM) that comprises instance-level
discrimination and cross-domain consistency alignment strategies to facilitate
model adaptive learning of new knowledge from the current domain and promote
knowledge consolidation learning between acquired domain-specific
distributions, respectively. Experimental results show that our DAFC outperform
state-of-the-art methods by at least 9.8\%/6.6\% and 6.4\%/6.2\% of average
mAP/R@1 on two training orders.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DyST-XL: Dynamic Layout Planning and Content Control for Compositional
  Text-to-Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15032v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15032v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weijie He, Mushui Liu, Yunlong Yu, Zhao Wang, Chao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositional text-to-video generation, which requires synthesizing dynamic
scenes with multiple interacting entities and precise spatial-temporal
relationships, remains a critical challenge for diffusion-based models.
Existing methods struggle with layout discontinuity, entity identity drift, and
implausible interaction dynamics due to unconstrained cross-attention
mechanisms and inadequate physics-aware reasoning. To address these
limitations, we propose DyST-XL, a \textbf{training-free} framework that
enhances off-the-shelf text-to-video models (e.g., CogVideoX-5B) through
frame-aware control. DyST-XL integrates three key innovations: (1) A Dynamic
Layout Planner that leverages large language models (LLMs) to parse input
prompts into entity-attribute graphs and generates physics-aware keyframe
layouts, with intermediate frames interpolated via trajectory optimization; (2)
A Dual-Prompt Controlled Attention Mechanism that enforces localized text-video
alignment through frame-aware attention masking, achieving the precise control
over individual entities; and (3) An Entity-Consistency Constraint strategy
that propagates first-frame feature embeddings to subsequent frames during
denoising, preserving object identity without manual annotation. Experiments
demonstrate that DyST-XL excels in compositional text-to-video generation,
significantly improving performance on complex prompts and bridging a crucial
gap in training-free video synthesis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Controllable Appearance Representation for Flexible Transfer and
  Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15028v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15028v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santiago Jimenez-Navarro, Julia Guerrero-Viu, Belen Masia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a method that computes an interpretable representation of material
appearance within a highly compact, disentangled latent space. This
representation is learned in a self-supervised fashion using an adapted
FactorVAE. We train our model with a carefully designed unlabeled dataset,
avoiding possible biases induced by human-generated labels. Our model
demonstrates strong disentanglement and interpretability by effectively
encoding material appearance and illumination, despite the absence of explicit
supervision. Then, we use our representation as guidance for training a
lightweight IP-Adapter to condition a diffusion pipeline that transfers the
appearance of one or more images onto a target geometry, and allows the user to
further edit the resulting appearance. Our approach offers fine-grained control
over the generated results: thanks to the well-structured compact latent space,
users can intuitively manipulate attributes such as hue or glossiness in image
space to achieve the desired final appearance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Gaussian Shading++: Rethinking the Realistic Deployment Challenge of
  Performance-Lossless Image Watermark for Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15026v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15026v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zijin Yang, Xin Zhang, Kejiang Chen, Kai Zeng, Qiyi Yao, Han Fang, Weiming Zhang, Nenghai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ethical concerns surrounding copyright protection and inappropriate content
generation pose challenges for the practical implementation of diffusion
models. One effective solution involves watermarking the generated images.
Existing methods primarily focus on ensuring that watermark embedding does not
degrade the model performance. However, they often overlook critical challenges
in real-world deployment scenarios, such as the complexity of watermark key
management, user-defined generation parameters, and the difficulty of
verification by arbitrary third parties. To address this issue, we propose
Gaussian Shading++, a diffusion model watermarking method tailored for
real-world deployment. We propose a double-channel design that leverages
pseudorandom error-correcting codes to encode the random seed required for
watermark pseudorandomization, achieving performance-lossless watermarking
under a fixed watermark key and overcoming key management challenges.
Additionally, we model the distortions introduced during generation and
inversion as an additive white Gaussian noise channel and employ a novel soft
decision decoding strategy during extraction, ensuring strong robustness even
when generation parameters vary. To enable third-party verification, we
incorporate public key signatures, which provide a certain level of resistance
against forgery attacks even when model inversion capabilities are fully
disclosed. Extensive experiments demonstrate that Gaussian Shading++ not only
maintains performance losslessness but also outperforms existing methods in
terms of robustness, making it a more practical solution for real-world
deployment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Insert Anything: Image Insertion via In-Context Editing in DiT 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15009v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15009v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wensong Song, Hong Jiang, Zongxing Yang, Ruijie Quan, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents Insert Anything, a unified framework for reference-based
image insertion that seamlessly integrates objects from reference images into
target scenes under flexible, user-specified control guidance. Instead of
training separate models for individual tasks, our approach is trained once on
our new AnyInsertion dataset--comprising 120K prompt-image pairs covering
diverse tasks such as person, object, and garment insertion--and effortlessly
generalizes to a wide range of insertion scenarios. Such a challenging setting
requires capturing both identity features and fine-grained details, while
allowing versatile local adaptations in style, color, and texture. To this end,
we propose to leverage the multimodal attention of the Diffusion Transformer
(DiT) to support both mask- and text-guided editing. Furthermore, we introduce
an in-context editing mechanism that treats the reference image as contextual
information, employing two prompting strategies to harmonize the inserted
elements with the target scene while faithfully preserving their distinctive
features. Extensive experiments on AnyInsertion, DreamBooth, and VTON-HD
benchmarks demonstrate that our method consistently outperforms existing
alternatives, underscoring its great potential in real-world applications such
as creative content generation, virtual try-on, and scene composition.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical
  Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15007v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15007v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David C Wong, Bin Wang, Gorkem Durak, Marouane Tliba, Mohamed Amine Kerkouri, Aladine Chetouani, Ahmet Enis Cetin, Cagdas Topel, Nicolo Gennaro, Camila Vendrami, Tugce Agirlar Trabzonlu, Amir Ali Rahsepar, Laetitia Perronne, Matthew Antalek, Onural Ozturk, Gokcan Okur, Andrew C. Gordon, Ayis Pyrros, Frank H Miller, Amir A Borhani, Hatice Savas, Eric M. Hart
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Eye-tracking analysis plays a vital role in medical imaging, providing key
insights into how radiologists visually interpret and diagnose clinical cases.
In this work, we first analyze radiologists' attention and agreement by
measuring the distribution of various eye-movement patterns, including saccades
direction, amplitude, and their joint distribution. These metrics help uncover
patterns in attention allocation and diagnostic strategies. Furthermore, we
investigate whether and how doctors' gaze behavior shifts when viewing
authentic (Real) versus deep-learning-generated (Fake) images. To achieve this,
we examine fixation bias maps, focusing on first, last, short, and longest
fixations independently, along with detailed saccades patterns, to quantify
differences in gaze distribution and visual saliency between authentic and
synthetic images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper was accepted at ETRA 2025 Japan</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and
  Enhancement: KwaiSR <span class="highlight-title">Dataset</span> and Study <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15003v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15003v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Li, Xijun Wang, Bingchen Li, Kun Yuan, Yizhen Shao, Suhang Yao, Ming Sun, Chao Zhou, Radu Timofte, Zhibo Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we build the first benchmark dataset for short-form UGC Image
Super-resolution in the wild, termed KwaiSR, intending to advance the research
on developing image super-resolution algorithms for short-form UGC platforms.
This dataset is collected from the Kwai Platform, which is composed of two
parts, i.e., synthetic and wild parts. Among them, the synthetic dataset,
including 1,900 image pairs, is produced by simulating the degradation
following the distribution of real-world low-quality short-form UGC images,
aiming to provide the ground truth for training and objective comparison in the
validation/testing. The wild dataset contains low-quality images collected
directly from the Kwai Platform, which are filtered using the quality
assessment method KVQ from the Kwai Platform. As a result, the KwaiSR dataset
contains 1800 synthetic image pairs and 1900 wild images, which are divided
into training, validation, and testing parts with a ratio of 8:1:1. Based on
the KwaiSR dataset, we organize the NTIRE 2025 challenge on a second short-form
UGC Video quality assessment and enhancement, which attracts lots of
researchers to develop the algorithm for it. The results of this competition
have revealed that our KwaiSR dataset is pretty challenging for existing Image
SR methods, which is expected to lead to a new direction in the image
super-resolution field. The dataset can be found from
https://lixinustc.github.io/NTIRE2025-KVQE-KwaSR-KVQ.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KwaiSR dataset, a new dataset for image super-resolution, used for
  CVPR NTIRE 2025 Challenge; CVPR 2025 workshop paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A
  Comprehensive Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14988v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14988v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong-Tao Yu, Xiu-Shen Wei, Yuxin Peng, Serge Belongie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
remarkable multimodal perception capabilities, garnering significant attention.
While numerous evaluation studies have emerged, assessing LVLMs both
holistically and on specialized tasks, fine-grained image tasks-fundamental to
computer vision-remain largely unexplored. To fill this gap, we introduce a
comprehensive fine-grained evaluation benchmark, i.e., FG-BMK, comprising 3.49
million questions and 3.32 million images. Our evaluation systematically
examines LVLMs from both human-oriented and machine-oriented perspectives,
focusing on their semantic recognition and fine-grained feature representation
capabilities. Through extensive experiments on eight representative LVLMs/VLMs,
we uncover key findings regarding the influence of training paradigms, modality
alignment, perturbation susceptibility, and fine-grained category reasoning on
task performance. This work provides critical insights into the limitations of
current LVLMs and offers guidance for future data construction and model design
in the development of more advanced LVLMs. Our code is open-source and
available at https://github.com/SEU-VIPGroup/FG-BMK.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RealisDance-DiT: Simple yet Strong Baseline towards Controllable
  Character Animation in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14977v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14977v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingkai Zhou, Yifan Wu, Shikai Li, Min Wei, Chao Fan, Weihua Chen, Wei Jiang, Fan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable character animation remains a challenging problem, particularly
in handling rare poses, stylized characters, character-object interactions,
complex illumination, and dynamic scenes. To tackle these issues, prior work
has largely focused on injecting pose and appearance guidance via elaborate
bypass networks, but often struggles to generalize to open-world scenarios. In
this paper, we propose a new perspective that, as long as the foundation model
is powerful enough, straightforward model modifications with flexible
fine-tuning strategies can largely address the above challenges, taking a step
towards controllable character animation in the wild. Specifically, we
introduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Our
sufficient analysis reveals that the widely adopted Reference Net design is
suboptimal for large-scale DiT models. Instead, we demonstrate that minimal
modifications to the foundation model architecture yield a surprisingly strong
baseline. We further propose the low-noise warmup and "large batches and small
iterations" strategies to accelerate model convergence during fine-tuning while
maximally preserving the priors of the foundation model. In addition, we
introduce a new test dataset that captures diverse real-world challenges,
complementing existing benchmarks such as TikTok dataset and UBC fashion video
dataset, to comprehensively evaluate the proposed method. Extensive experiments
show that RealisDance-DiT outperforms existing methods by a large margin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page:
  https://thefoxofsky.github.io/project_pages_new/RealisDance-DiT/index</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cyc3D: Fine-grained Controllable 3D Generation via Cycle Consistency
  Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14975v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14975v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongbin Xu, Chaohui Yu, Feng Xiao, Jiazheng Xing, Hai Ci, Weitao Chen, Ming Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable progress of 3D generation, achieving controllability,
i.e., ensuring consistency between generated 3D content and input conditions
like edge and depth, remains a significant challenge. Existing methods often
struggle to maintain accurate alignment, leading to noticeable discrepancies.
To address this issue, we propose \name{}, a new framework that enhances
controllable 3D generation by explicitly encouraging cyclic consistency between
the second-order 3D content, generated based on extracted signals from the
first-order generation, and its original input controls. Specifically, we
employ an efficient feed-forward backbone that can generate a 3D object from an
input condition and a text prompt. Given an initial viewpoint and a control
signal, a novel view is rendered from the generated 3D content, from which the
extracted condition is used to regenerate the 3D content. This re-generated
output is then rendered back to the initial viewpoint, followed by another
round of control signal extraction, forming a cyclic process with two
consistency constraints. \emph{View consistency} ensures coherence between the
two generated 3D objects, measured by semantic similarity to accommodate
generative diversity. \emph{Condition consistency} aligns the final extracted
signal with the original input control, preserving structural or geometric
details throughout the process. Extensive experiments on popular benchmarks
demonstrate that \name{} significantly improves controllability, especially for
fine-grained details, outperforming existing methods across various conditions
(e.g., +14.17\% PSNR for edge, +6.26\% PSNR for sketch).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint version. The code will be open after finishing the reviewing
  process</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 3D Gaussian Head Avatars with Expressive Dynamic Appearances by Compact
  Tensorial Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14967v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14967v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yating Wang, Xuan Wang, Ran Yi, Yanbo Fan, Jichen Hu, Jingcheng Zhu, Lizhuang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have combined 3D Gaussian and 3D Morphable Models (3DMM) to
construct high-quality 3D head avatars. In this line of research, existing
methods either fail to capture the dynamic textures or incur significant
overhead in terms of runtime speed or storage space. To this end, we propose a
novel method that addresses all the aforementioned demands. In specific, we
introduce an expressive and compact representation that encodes texture-related
attributes of the 3D Gaussians in the tensorial format. We store appearance of
neutral expression in static tri-planes, and represents dynamic texture details
for different expressions using lightweight 1D feature lines, which are then
decoded into opacity offset relative to the neutral face. We further propose
adaptive truncated opacity penalty and class-balanced sampling to improve
generalization across different expressions. Experiments show this design
enables accurate face dynamic details capturing while maintains real-time
rendering and significantly reduces storage costs, thus broadening the
applicability to more scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for
  PIV 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14952v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14952v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianyu Zhu, Junjie Wang, Jeremiah Hu, Jia Ai, Yong Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning algorithms have significantly reduced the computational time
and improved the spatial resolution of particle image velocimetry~(PIV).
However, the models trained on synthetic datasets might have a degraded
performance on practical particle images due to domain gaps. As a result,
special residual patterns are often observed for the vector fields of deep
learning-based estimators. To reduce the special noise step-by-step, we employ
a denoising diffusion model~(FlowDiffuser) for PIV analysis. And the
data-hungry iterative denoising diffusion model is trained via a transfer
learning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)
pre-training a FlowDiffuser model with multiple optical flow datasets of the
computer vision community, such as Sintel, KITTI, etc; (2) fine-tuning the
pre-trained model on synthetic PIV datasets. Note that the PIV images are
upsampled by a factor of two to resolve the small-scale turbulent flow
structures. The visualized results indicate that our PIV-FlowDiffuser
effectively suppresses the noise patterns. Therefore, the denoising diffusion
model reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIV
baseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibits
enhanced generalization performance on unseen particle images due to transfer
learning. Overall, this study highlights the transfer-learning-based denoising
diffusion models for PIV. And a detailed implementation is recommended for
interested readers in the repository
https://github.com/Zhu-Qianyu/PIV-FlowDiffuser.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14933v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14933v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mazharul Islam Rakib, Showrin Rahman, Joyanta Jyoti Mondal, Xi Xiao, David Lewis, Alessandra Mileo, Meem Arafat Manab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In today's age of social media and marketing, copyright issues can be a major
roadblock to the free sharing of images. Generative AI models have made it
possible to create high-quality images, but concerns about copyright
infringement are a hindrance to their abundant use. As these models use data
from training images to generate new ones, it is often a daunting task to
ensure they do not violate intellectual property rights. Some AI models have
even been noted to directly copy copyrighted images, a problem often referred
to as source copying. Traditional copyright protection measures such as
watermarks and metadata have also proven to be futile in this regard. To
address this issue, we propose a novel two-step image generation model inspired
by the conditional diffusion model. The first step involves creating an image
segmentation mask for some prompt-based generated images. This mask embodies
the shape of the image. Thereafter, the diffusion model is asked to generate
the image anew while avoiding the shape in question. This approach shows a
decrease in structural similarity from the training image, i.e. we are able to
avoid the source copying problem using this approach without expensive
retraining of the model or user-centered prompt generation techniques. This
makes our approach the most computationally inexpensive approach to avoiding
both copyright infringement and source copying for diffusion model-based image
generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 9 figures, preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast Adversarial Training with Weak-to-Strong Spatial-Temporal
  Consistency in the Frequency Domain on Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14921v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14921v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songping Wang, Hanqing Liu, Yueming Lyu, Xiantao Hu, Ziwen He, Wei Wang, Caifeng Shan, Liang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial Training (AT) has been shown to significantly enhance adversarial
robustness via a min-max optimization approach. However, its effectiveness in
video recognition tasks is hampered by two main challenges. First, fast
adversarial training for video models remains largely unexplored, which
severely impedes its practical applications. Specifically, most video
adversarial training methods are computationally costly, with long training
times and high expenses. Second, existing methods struggle with the trade-off
between clean accuracy and adversarial robustness. To address these challenges,
we introduce Video Fast Adversarial Training with Weak-to-Strong consistency
(VFAT-WS), the first fast adversarial training method for video data.
Specifically, VFAT-WS incorporates the following key designs: First, it
integrates a straightforward yet effective temporal frequency augmentation
(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a
single-step PGD attack to boost training efficiency and robustness. Second, it
devises a weak-to-strong spatial-temporal consistency regularization, which
seamlessly integrates the simpler TF-AUG and the more complex STF-AUG.
Leveraging the consistency regularization, it steers the learning process from
simple to complex augmentations. Both of them work together to achieve a better
trade-off between clean accuracy and robustness. Extensive experiments on
UCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that
VFAT-WS achieves great improvements in adversarial robustness and corruption
robustness, while accelerating training by nearly 490%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in
  Fine-Grained Visual Understanding <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14920v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14920v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Geng Li, Jinglin Xu, Yunzhen Zhao, Yuxin Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans can effortlessly locate desired objects in cluttered environments,
relying on a cognitive mechanism known as visual search to efficiently filter
out irrelevant information and focus on task-related regions. Inspired by this
process, we propose Dyfo (Dynamic Focus), a training-free dynamic focusing
visual search method that enhances fine-grained visual understanding in large
multimodal models (LMMs). Unlike existing approaches which require additional
modules or data collection, Dyfo leverages a bidirectional interaction between
LMMs and visual experts, using a Monte Carlo Tree Search (MCTS) algorithm to
simulate human-like focus adjustments. This enables LMMs to focus on key visual
regions while filtering out irrelevant content, without introducing additional
training caused by vocabulary expansion or the integration of specialized
localization modules. Experimental results demonstrate that Dyfo significantly
improves fine-grained visual understanding and reduces hallucination issues in
LMMs, achieving superior performance across both fixed and dynamic resolution
models. The code is available at https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025 (Hightlight). Project page with code:
  https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GenCLIP: Generalizing CLIP <span class="highlight-title">Prompt</span>s for Zero-shot Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14919v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14919v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donghyeong Kim, Chaewon Park, Suhwan Cho, Hyeonjeong Lim, Minseok Kang, Jungho Lee, Sangyoun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot anomaly detection (ZSAD) aims to identify anomalies in unseen
categories by leveraging CLIP's zero-shot capabilities to match text prompts
with visual features. A key challenge in ZSAD is learning general prompts
stably and utilizing them effectively, while maintaining both generalizability
and category specificity. Although general prompts have been explored in prior
works, achieving their stable optimization and effective deployment remains a
significant challenge. In this work, we propose GenCLIP, a novel framework that
learns and leverages general prompts more effectively through multi-layer
prompting and dual-branch inference. Multi-layer prompting integrates
category-specific visual cues from different CLIP layers, enriching general
prompts with more comprehensive and robust feature representations. By
combining general prompts with multi-layer visual features, our method further
enhances its generalization capability. To balance specificity and
generalization, we introduce a dual-branch inference strategy, where a
vision-enhanced branch captures fine-grained category-specific features, while
a query-only branch prioritizes generalization. The complementary outputs from
both branches improve the stability and reliability of anomaly detection across
unseen categories. Additionally, we propose an adaptive text prompt filtering
mechanism, which removes irrelevant or atypical class names not encountered
during CLIP's training, ensuring that only meaningful textual inputs contribute
to the final vision-language alignment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Guidelines for External Disturbance Factors in the Use of OCR in
  Real-World Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14913v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14913v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kenji Iwata, Eiki Ishidera, Toshifumi Yamaai, Yutaka Satoh, Hiroshi Tanaka, Katsuhiko Takahashi, Akio Furuhata, Yoshihisa Tanabe, Hiroshi Matsumura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The performance of OCR has improved with the evolution of AI technology. As
OCR continues to broaden its range of applications, the increased likelihood of
interference introduced by various usage environments can prevent it from
achieving its inherent performance. This results in reduced recognition
accuracy under certain conditions, and makes the quality control of recognition
devices more challenging. Therefore, to ensure that users can properly utilize
OCR, we compiled the real-world external disturbance factors that cause
performance degradation, along with the resulting image degradation phenomena,
into an external disturbance factor table and, by also indicating how to make
use of it, organized them into guidelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmniAudio: Generating Spatial Audio from 360-Degree Video 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14906v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14906v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huadai Liu, Tianyi Luo, Qikai Jiang, Kaicheng Luo, Peiwen Sun, Jialei Wan, Rongjie Huang, Qian Chen, Wen Wang, Xiangtai Li, Shiliang Zhang, Zhijie Yan, Zhou Zhao, Wei Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional video-to-audio generation techniques primarily focus on
field-of-view (FoV) video and non-spatial audio, often missing the spatial cues
necessary for accurately representing sound sources in 3D environments. To
address this limitation, we introduce a novel task, 360V2SA, to generate
spatial audio from 360-degree videos, specifically producing First-order
Ambisonics (FOA) audio - a standard format for representing 3D spatial audio
that captures sound directionality and enables realistic 3D audio reproduction.
We first create Sphere360, a novel dataset tailored for this task that is
curated from real-world data. We also design an efficient semi-automated
pipeline for collecting and cleaning paired video-audio data. To generate
spatial audio from 360-degree video, we propose a novel framework OmniAudio,
which leverages self-supervised pre-training using both spatial audio data (in
FOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a
dual-branch framework that utilizes both panoramic and FoV video inputs to
capture comprehensive local and global information from 360-degree videos.
Experimental results demonstrate that OmniAudio achieves state-of-the-art
performance across both objective and subjective metrics on Sphere360. Code and
datasets will be released at https://github.com/liuhuadai/OmniAudio. The demo
page is available at https://OmniAudio-360V2SA.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls
  for Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14899v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14899v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenjie Cao, Jingkai Zhou, Shikai Li, Jingyun Liang, Chaohui Yu, Fan Wang, Xiangyang Xue, Yanwei Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Camera and human motion controls have been extensively studied for video
generation, but existing approaches typically address them separately,
suffering from limited data with high-quality annotations for both aspects. To
overcome this, we present Uni3C, a unified 3D-enhanced framework for precise
control of both camera and human motion in video generation. Uni3C includes two
key contributions. First, we propose a plug-and-play control module trained
with a frozen video generative backbone, PCDController, which utilizes
unprojected point clouds from monocular depth to achieve accurate camera
control. By leveraging the strong 3D priors of point clouds and the powerful
capacities of video foundational models, PCDController shows impressive
generalization, performing well regardless of whether the inference backbone is
frozen or fine-tuned. This flexibility enables different modules of Uni3C to be
trained in specific domains, i.e., either camera control or human motion
control, reducing the dependency on jointly annotated data. Second, we propose
a jointly aligned 3D world guidance for the inference phase that seamlessly
integrates both scenic point clouds and SMPL-X characters to unify the control
signals for camera and human motion, respectively. Extensive experiments
confirm that PCDController enjoys strong robustness in driving camera motion
for fine-tuned backbones of video generation. Uni3C substantially outperforms
competitors in both camera controllability and human motion quality.
Additionally, we collect tailored validation sets featuring challenging camera
movements and human actions to validate the effectiveness of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://github.com/ewrfcas/Uni3C</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WMKA-Net: A Weighted Multi-Kernel Attention NetworkMethod for Retinal
  Vessel Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14888v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14888v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinran Xu, Yuliang Ma, Sifu Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel retinal vessel segmentation network, the Weighted
Multi-Kernel Attention Network (WMKA-Net), which aims to address the issues of
insufficient multiscale feature capture, loss of contextual information, and
noise sensitivity in retinal vessel segmentation. WMKA-Net significantly
improves the segmentation performance of small vessels and low-contrast regions
by integrating several innovative components, including the MultiKernelFeature
Fusion Module (MKDC), the Progressive Feature Weighting Fusion Strategy (UDFF),
and the Attention Mechanism Module (AttentionBlock). The MKDC module employs
multiscale parallel convolutional kernels to extract vessel characteristics,
thereby enhancing the ability to capture complex vascular structures. The UDFF
strategy optimizes the transmission of feature information by weighted fusion
of high- and low-level features. The AttentionBlock highlights key regions and
suppresses noise interference through the attention mechanism. Experimental
results demonstrate that WMKA-Net achieves excellent segmentation performance
in multiple public datasets, particularly in segmentation of small vessels and
processing of pathological regions. This work provides a robust and efficient
new method for segmentation of the retinal vessel.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Memory-Augmented Dual-Decoder Networks for Multi-Class Unsupervised
  Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14884v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14884v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyu Xing, Chenwei Tang, Tao Wang, Rong Xiao, Wei Ju, Ji-Zhe Zhou, Liangli Zhen, Jiancheng Lv
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in unsupervised anomaly detection (UAD) have shifted from
single-class to multi-class scenarios. In such complex contexts, the increasing
pattern diversity has brought two challenges to reconstruction-based
approaches: (1) over-generalization: anomalies that are subtle or share
compositional similarities with normal patterns may be reconstructed with high
fidelity, making them difficult to distinguish from normal instances; and (2)
insufficient normality reconstruction: complex normal features, such as
intricate textures or fine-grained structures, may not be faithfully
reconstructed due to the model's limited representational capacity, resulting
in false positives. Existing methods typically focus on addressing the former,
which unintentionally exacerbate the latter, resulting in inadequate
representation of intricate normal patterns. To concurrently address these two
challenges, we propose a Memory-augmented Dual-Decoder Networks (MDD-Net). This
network includes two critical components: a Dual-Decoder Reverse Distillation
Network (DRD-Net) and a Class-aware Memory Module (CMM). Specifically, the
DRD-Net incorporates a restoration decoder designed to recover normal features
from synthetic abnormal inputs and an identity decoder to reconstruct features
that maintain the anomalous semantics. By exploiting the discrepancy between
features produced by two decoders, our approach refines anomaly scores beyond
the conventional encoder-decoder comparison paradigm, effectively reducing
false positives and enhancing localization accuracy. Furthermore, the CMM
explicitly encodes and preserves class-specific normal prototypes, actively
steering the network away from anomaly reconstruction. Comprehensive
experimental results across several benchmarks demonstrate the superior
performance of our MDD-Net framework over current SoTA approaches in
multi-class UAD tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Some Optimizers are More Equal: Understanding the Role of Optimizers in
  Group Fairness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14882v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14882v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mojtaba Kolahdouzi, Hatice Gunes, Ali Etemad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study whether and how the choice of optimization algorithm can impact
group fairness in deep neural networks. Through stochastic differential
equation analysis of optimization dynamics in an analytically tractable setup,
we demonstrate that the choice of optimization algorithm indeed influences
fairness outcomes, particularly under severe imbalance. Furthermore, we show
that when comparing two categories of optimizers, adaptive methods and
stochastic methods, RMSProp (from the adaptive category) has a higher
likelihood of converging to fairer minima than SGD (from the stochastic
category). Building on this insight, we derive two new theoretical guarantees
showing that, under appropriate conditions, RMSProp exhibits fairer parameter
updates and improved fairness in a single optimization step compared to SGD. We
then validate these findings through extensive experiments on three publicly
available datasets, namely CelebA, FairFace, and MS-COCO, across different
tasks as facial expression recognition, gender classification, and multi-label
classification, using various backbones. Considering multiple fairness
definitions including equalized odds, equal opportunity, and demographic
parity, adaptive optimizers like RMSProp and Adam consistently outperform SGD
in terms of group fairness, while maintaining comparable predictive accuracy.
Our results highlight the role of adaptive updates as a crucial yet overlooked
mechanism for promoting fair outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle
  Re-identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14877v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14877v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aihua Zheng, Yongqi Sun, Zi Wang, Chenglong Li, Jin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The performance of multi-spectral vehicle Re-identification (ReID) is
significantly degraded when some important discriminative cues in visible, near
infrared and thermal infrared spectra are lost. Existing methods generate or
enhance missing details in low-quality spectra data using the high-quality one,
generally called the primary spectrum, but how to justify the primary spectrum
is a challenging problem. In addition, when the quality of the primary spectrum
is low, the enhancement effect would be greatly degraded, thus limiting the
performance of multi-spectral vehicle ReID. To address these problems, we
propose the Collaborative Enhancement Network (CoEN), which generates a
high-quality proxy from all spectra data and leverages it to supervise the
selection of primary spectrum and enhance all spectra features in a
collaborative manner, for robust multi-spectral vehicle ReID. First, to
integrate the rich cues from all spectra data, we design the Proxy Generator
(PG) to progressively aggregate multi-spectral features. Second, we design the
Dynamic Quality Sort Module (DQSM), which sorts all spectra data by measuring
their correlations with the proxy, to accurately select the primary spectra
with the highest correlation. Finally, we design the Collaborative Enhancement
Module (CEM) to effectively compensate for missing contents of all spectra by
collaborating the primary spectra and the proxy, thereby mitigating the impact
of low-quality primary spectra. Extensive experiments on three benchmark
datasets are conducted to validate the efficacy of the proposed approach
against other multi-spectral vehicle ReID methods. The codes will be released
at https://github.com/yongqisun/CoEN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReSpec: Relevance and Specificity Grounded Online Filtering for Learning
  on Video-Text Data Streams <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14875v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14875v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chris Dongjoo Kim, Jihwan Moon, Sangwoo Moon, Heeseung Yun, Sihaeng Lee, Aniruddha Kembhavi, Soonyoung Lee, Gunhee Kim, Sangho Lee, Christopher Clark
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid growth of video-text data presents challenges in storage and
computation during training. Online learning, which processes streaming data in
real-time, offers a promising solution to these issues while also allowing
swift adaptations in scenarios demanding real-time responsiveness. One strategy
to enhance the efficiency and effectiveness of learning involves identifying
and prioritizing data that enhances performance on target downstream tasks. We
propose Relevance and Specificity-based online filtering framework (ReSpec)
that selects data based on four criteria: (i) modality alignment for clean
data, (ii) task relevance for target focused data, (iii) specificity for
informative and detailed data, and (iv) efficiency for low-latency processing.
Relevance is determined by the probabilistic alignment of incoming data with
downstream tasks, while specificity employs the distance to a root embedding
representing the least specific data as an efficient proxy for informativeness.
By establishing reference points from target task data, ReSpec filters incoming
data in real-time, eliminating the need for extensive storage and compute.
Evaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains
state-of-the-art performance on five zeroshot video retrieval tasks, using as
little as 5% of the data while incurring minimal compute. The source code is
available at https://github.com/cdjkim/ReSpec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025 (main conference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Twin Co-Adaptive Dialogue for Progressive Image Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14868v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14868v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianhui Wang, Yangfan He, Yan Zhong, Xinyuan Song, Jiayi Su, Yuheng Feng, Hongyang He, Wenyu Zhu, Xinhang Yuan, Kuan Lu, Menghao Huo, Miao Zhang, Keqin Li, Jiaqi Chen, Tianyu Shi, Xueqian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern text-to-image generation systems have enabled the creation of
remarkably realistic and high-quality visuals, yet they often falter when
handling the inherent ambiguities in user prompts. In this work, we present
Twin-Co, a framework that leverages synchronized, co-adaptive dialogue to
progressively refine image generation. Instead of a static generation process,
Twin-Co employs a dynamic, iterative workflow where an intelligent dialogue
agent continuously interacts with the user. Initially, a base image is
generated from the user's prompt. Then, through a series of synchronized
dialogue exchanges, the system adapts and optimizes the image according to
evolving user feedback. The co-adaptive process allows the system to
progressively narrow down ambiguities and better align with user intent.
Experiments demonstrate that Twin-Co not only enhances user experience by
reducing trial-and-error iterations but also improves the quality of the
generated images, streamlining the creative process across various
applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridge the Gap: From Weak to Full Supervision for Temporal Action
  Localization with PseudoFormer <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14860v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14860v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyi Liu, Yangcen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly-supervised Temporal Action Localization (WTAL) has achieved notable
success but still suffers from a lack of temporal annotations, leading to a
performance and framework gap compared with fully-supervised methods. While
recent approaches employ pseudo labels for training, three key challenges:
generating high-quality pseudo labels, making full use of different priors, and
optimizing training methods with noisy labels remain unresolved. Due to these
perspectives, we propose PseudoFormer, a novel two-branch framework that
bridges the gap between weakly and fully-supervised Temporal Action
Localization (TAL). We first introduce RickerFusion, which maps all predicted
action proposals to a global shared space to generate pseudo labels with better
quality. Subsequently, we leverage both snippet-level and proposal-level labels
with different priors from the weak branch to train the regression-based model
in the full branch. Finally, the uncertainty mask and iterative refinement
mechanism are applied for training with noisy pseudo labels. PseudoFormer
achieves state-of-the-art WTAL results on the two commonly used benchmarks,
THUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate
the contribution of each component of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025: IEEE Conference on Computer Vision and Pattern Recognition</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Object-Level Verbalized Confidence Calibration in Vision-Language Models
  via Semantic Perturbation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14848v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14848v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpu Zhao, Rui Zhang, Junbin Xiao, Ruibo Hou, Jiaming Guo, Zihao Zhang, Yifan Hao, Yunji Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) excel in various multimodal tasks but
frequently suffer from poor calibration, resulting in misalignment between
their verbalized confidence and response correctness. This miscalibration
undermines user trust, especially when models confidently provide incorrect or
fabricated information. In this work, we propose a novel Confidence Calibration
through Semantic Perturbation (CSP) framework to improve the calibration of
verbalized confidence for VLMs in response to object-centric queries. We first
introduce a perturbed dataset where Gaussian noise is applied to the key object
regions to simulate visual uncertainty at different confidence levels,
establishing an explicit mapping between visual ambiguity and confidence
levels. We further enhance calibration through a two-stage training process
combining supervised fine-tuning on the perturbed dataset with subsequent
preference optimization. Extensive experiments on popular benchmarks
demonstrate that our method significantly improves the alignment between
verbalized confidence and response correctness while maintaining or enhancing
overall task performance. These results highlight the potential of semantic
perturbation as a practical tool for improving the reliability and
interpretability of VLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reliable Multi-Modal Object Re-Identification via Modality-Aware Graph
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14847v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14847v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xixi Wan, Aihua Zheng, Zi Wang, Bo Jiang, Jin Tang, Jixin Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal data provides abundant and diverse object information, crucial
for effective modal interactions in Re-Identification (ReID) tasks. However,
existing approaches often overlook the quality variations in local features and
fail to fully leverage the complementary information across modalities,
particularly in the case of low-quality features. In this paper, we propose to
address this issue by leveraging a novel graph reasoning model, termed the
Modality-aware Graph Reasoning Network (MGRNet). Specifically, we first
construct modality-aware graphs to enhance the extraction of fine-grained local
details by effectively capturing and modeling the relationships between
patches. Subsequently, the selective graph nodes swap operation is employed to
alleviate the adverse effects of low-quality local features by considering both
local and global information, enhancing the representation of discriminative
information. Finally, the swapped modality-aware graphs are fed into the
local-aware graph reasoning module, which propagates multi-modal information to
yield a reliable feature representation. Another advantage of the proposed
graph reasoning approach is its ability to reconstruct missing modal
information by exploiting inherent structural relationships, thereby minimizing
disparities between different modalities. Experimental results on four
benchmarks (RGBNT201, Market1501-MM, RGBNT100, MSVR310) indicate that the
proposed method achieves state-of-the-art performance in multi-modal object
ReID. The code for our method will be available upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distribution-aware <span class="highlight-title">Dataset</span> Distillation for Efficient Image Restoration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuoran Zheng, Xin Su, Chen Wu, Xiuyi Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the exponential increase in image data, training an image restoration
model is laborious. Dataset distillation is a potential solution to this
problem, yet current distillation techniques are a blank canvas in the field of
image restoration. To fill this gap, we propose the Distribution-aware Dataset
Distillation method (TripleD), a new framework that extends the principles of
dataset distillation to image restoration. Specifically, TripleD uses a
pre-trained vision Transformer to extract features from images for complexity
evaluation, and the subset (the number of samples is much smaller than the
original training set) is selected based on complexity. The selected subset is
then fed through a lightweight CNN that fine-tunes the image distribution to
align with the distribution of the original dataset at the feature level. To
efficiently condense knowledge, the training is divided into two stages. Early
stages focus on simpler, low-complexity samples to build foundational
knowledge, while later stages select more complex and uncertain samples as the
model matures. Our method achieves promising performance on multiple image
restoration tasks, including multi-task image restoration, all-in-one image
restoration, and ultra-high-definition image restoration tasks. Note that we
can train a state-of-the-art image restoration model on an
ultra-high-definition (4K resolution) dataset using only one consumer-grade GPU
in less than 8 hours (500 savings in computing resources and immeasurable
training time).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ECViT: Efficient Convolutional Vision <span class="highlight-title">Transformer</span> with Local-Attention
  and Multi-scale Stages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhoujie Qian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Transformers (ViTs) have revolutionized computer vision by leveraging
self-attention to model long-range dependencies. However, ViTs face challenges
such as high computational costs due to the quadratic scaling of self-attention
and the requirement of a large amount of training data. To address these
limitations, we propose the Efficient Convolutional Vision Transformer (ECViT),
a hybrid architecture that effectively combines the strengths of CNNs and
Transformers. ECViT introduces inductive biases such as locality and
translation invariance, inherent to Convolutional Neural Networks (CNNs) into
the Transformer framework by extracting patches from low-level features and
enhancing the encoder with convolutional operations. Additionally, it
incorporates local-attention and a pyramid structure to enable efficient
multi-scale feature extraction and representation. Experimental results
demonstrate that ECViT achieves an optimal balance between performance and
efficiency, outperforming state-of-the-art models on various image
classification tasks while maintaining low computational and storage
requirements. ECViT offers an ideal solution for applications that prioritize
high efficiency without compromising performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14815v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14815v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyong Yuan, Xiaolong Ma, Linke Guo, Lan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models (DMs) have revolutionized text-to-image generation, enabling
the creation of highly realistic and customized images from text prompts. With
the rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users
can now customize powerful pre-trained models using minimal computational
resources. However, the widespread sharing of fine-tuned DMs on open platforms
raises growing ethical and legal concerns, as these models may inadvertently or
deliberately generate sensitive or unauthorized content, such as copyrighted
material, private individuals, or harmful content. Despite the increasing
regulatory attention on generative AI, there are currently no practical tools
for systematically auditing these models before deployment. In this paper, we
address the problem of concept auditing: determining whether a fine-tuned DM
has learned to generate a specific target concept. Existing approaches
typically rely on prompt-based input crafting and output-based image
classification but suffer from critical limitations, including prompt
uncertainty, concept drift, and poor scalability. To overcome these challenges,
we introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric
concept auditing framework. By treating the DM as the object of inspection,
PAIA enables direct analysis of internal model behavior, bypassing the need for
optimized prompts or generated images. We evaluate PAIA on 320 controlled model
and 690 real-world community models sourced from a public DM sharing platform.
PAIA achieves over 90% detection accuracy while reducing auditing time by
18-40x compared to existing baselines. To our knowledge, PAIA is the first
scalable and practical solution for pre-deployment concept auditing of
diffusion models, providing a practical foundation for safer and more
transparent diffusion model sharing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Sleepiness Detection for Driver State Monitoring System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14807v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14807v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deepak Ghimire, Sunghwan Jeong, Sunhong Yoon, Sanghyun Park, Juhwan Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A driver face monitoring system can detect driver fatigue, which is a
significant factor in many accidents, using computer vision techniques. In this
paper, we present a real-time technique for driver eye state detection. First,
the face is detected, and the eyes are located within the face region for
tracking. A normalized cross-correlation-based online dynamic template matching
technique, combined with Kalman filter tracking, is proposed to track the
detected eye positions in subsequent image frames. A support vector machine
with histogram of oriented gradients (HOG) features is used to classify the
state of the eyes as open or closed. If the eyes remain closed for a specified
period, the driver is considered to be asleep, and an alarm is triggered.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, published in GST 2015</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Small Sample Imbalance Problem: Metrics, Feature Analysis,
  and Solutions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14800v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14800v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuxian Zhao, Jie Gui, Minjing Dong, Baosheng Yu, Zhipeng Gui, Lu Dong, Yuan Yan Tang, James Tin-Yau Kwok
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The small sample imbalance (S&I) problem is a major challenge in machine
learning and data analysis. It is characterized by a small number of samples
and an imbalanced class distribution, which leads to poor model performance. In
addition, indistinct inter-class feature distributions further complicate
classification tasks. Existing methods often rely on algorithmic heuristics
without sufficiently analyzing the underlying data characteristics. We argue
that a detailed analysis from the data perspective is essential before
developing an appropriate solution. Therefore, this paper proposes a systematic
analytical framework for the S\&I problem. We first summarize imbalance metrics
and complexity analysis methods, highlighting the need for interpretable
benchmarks to characterize S&I problems. Second, we review recent solutions for
conventional, complexity-based, and extreme S&I problems, revealing
methodological differences in handling various data distributions. Our summary
finds that resampling remains a widely adopted solution. However, we conduct
experiments on binary and multiclass datasets, revealing that classifier
performance differences significantly exceed the improvements achieved through
resampling. Finally, this paper highlights open questions and discusses future
trends.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Verifying Robust Unlearning: Probing Residual Knowledge in Unlearned
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14798v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14798v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Xuan, Xingyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine Unlearning (MUL) is crucial for privacy protection and content
regulation, yet recent studies reveal that traces of forgotten information
persist in unlearned models, enabling adversaries to resurface removed
knowledge. Existing verification methods only confirm whether unlearning was
executed, failing to detect such residual information leaks. To address this,
we introduce the concept of Robust Unlearning, ensuring models are
indistinguishable from retraining and resistant to adversarial recovery. To
empirically evaluate whether unlearning techniques meet this security standard,
we propose the Unlearning Mapping Attack (UMA), a post-unlearning verification
framework that actively probes models for forgotten traces using adversarial
queries. Extensive experiments on discriminative and generative tasks show that
existing unlearning techniques remain vulnerable, even when passing existing
verification metrics. By establishing UMA as a practical verification tool,
this study sets a new standard for assessing and enhancing machine unlearning
security.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Segmentation with Noisy Labels via Spatially Correlated Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryu Tadokoro, Tsukasa Takagi, Shin-ichi Maeda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In semantic segmentation, the accuracy of models heavily depends on the
high-quality annotations. However, in many practical scenarios such as medical
imaging and remote sensing, obtaining true annotations is not straightforward
and usually requires significant human labor. Relying on human labor often
introduces annotation errors, including mislabeling, omissions, and
inconsistency between annotators. In the case of remote sensing, differences in
procurement time can lead to misaligned ground truth annotations. These label
errors are not independently distributed, and instead usually appear in
spatially connected regions where adjacent pixels are more likely to share the
same errors. To address these issues, we propose an approximate Bayesian
estimation based on a probabilistic model that assumes training data includes
label errors, incorporating the tendency for these errors to occur with spatial
correlations between adjacent pixels. Bayesian inference requires computing the
posterior distribution of label errors, which becomes intractable when spatial
correlations are present. We represent the correlation of label errors between
adjacent pixels through a Gaussian distribution whose covariance is structured
by a Kac-Murdock-Szeg\"{o} (KMS) matrix, solving the computational challenges.
Through experiments on multiple segmentation tasks, we confirm that leveraging
the spatial correlation of label errors significantly improves performance.
Notably, in specific tasks such as lung segmentation, the proposed method
achieves performance comparable to training with clean labels under moderate
noise levels. Code is available at
https://github.com/pfnet-research/Bayesian_SpatialCorr.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When Cloud Removal Meets Diffusion Model in Remote Sensing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14785v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14785v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenyu Yu, Mohd Yamani Idna Idris, Pei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cloud occlusion significantly hinders remote sensing applications by
obstructing surface information and complicating analysis. To address this, we
propose DC4CR (Diffusion Control for Cloud Removal), a novel multimodal
diffusion-based framework for cloud removal in remote sensing imagery. Our
method introduces prompt-driven control, allowing selective removal of thin and
thick clouds without relying on pre-generated cloud masks, thereby enhancing
preprocessing efficiency and model adaptability. Additionally, we integrate
low-rank adaptation for computational efficiency, subject-driven generation for
improved generalization, and grouped learning to enhance performance on small
datasets. Designed as a plug-and-play module, DC4CR seamlessly integrates into
existing cloud removal models, providing a scalable and robust solution.
Extensive experiments on the RICE and CUHK-CR datasets demonstrate
state-of-the-art performance, achieving superior cloud removal across diverse
conditions. This work presents a practical and efficient approach for remote
sensing image processing with broad real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Effective Can Dropout Be in Multiple Instance Learning ? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14783v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14783v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhui Zhu, Peijie Qiu, Xiwen Chen, Zhangsihao Yang, Aristeidis Sotiras, Abolfazl Razi, Yalin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multiple Instance Learning (MIL) is a popular weakly-supervised method for
various applications, with a particular interest in histological whole slide
image (WSI) classification. Due to the gigapixel resolution of WSI,
applications of MIL in WSI typically necessitate a two-stage training scheme:
first, extract features from the pre-trained backbone and then perform MIL
aggregation. However, it is well-known that this suboptimal training scheme
suffers from "noisy" feature embeddings from the backbone and inherent weak
supervision, hindering MIL from learning rich and generalizable features.
However, the most commonly used technique (i.e., dropout) for mitigating this
issue has yet to be explored in MIL. In this paper, we empirically explore how
effective the dropout can be in MIL. Interestingly, we observe that dropping
the top-k most important instances within a bag leads to better performance and
generalization even under noise attack. Based on this key observation, we
propose a novel MIL-specific dropout method, termed MIL-Dropout, which
systematically determines which instances to drop. Experiments on five MIL
benchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the
performance of current MIL methods with a negligible computational cost. The
code is available at https://github.com/ChongQingNoSubway/MILDropout.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ICE: Intrinsic Concept Extraction from a Single Image via Diffusion
  Models <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.19902v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.19902v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fernando Julio Cendra, Kai Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The inherent ambiguity in defining visual concepts poses significant
challenges for modern generative models, such as the diffusion-based
Text-to-Image (T2I) models, in accurately learning concepts from a single
image. Existing methods lack a systematic way to reliably extract the
interpretable underlying intrinsic concepts. To address this challenge, we
present ICE, short for Intrinsic Concept Extraction, a novel framework that
exclusively utilises a T2I model to automatically and systematically extract
intrinsic concepts from a single image. ICE consists of two pivotal stages. In
the first stage, ICE devises an automatic concept localization module to
pinpoint relevant text-based concepts and their corresponding masks within the
image. This critical stage streamlines concept initialization and provides
precise guidance for subsequent analysis. The second stage delves deeper into
each identified mask, decomposing the object-level concepts into intrinsic
concepts and general concepts. This decomposition allows for a more granular
and interpretable breakdown of visual elements. Our framework demonstrates
superior performance on intrinsic concept extraction from a single image in an
unsupervised manner. Project page: https://visual-ai.github.io/ice
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025, Project page: https://visual-ai.github.io/ice</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Analysing the Robustness of Vision-Language-Models to Common Corruptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13690v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13690v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Usama, Syeda Aishah Asim, Syed Bilal Ali, Syed Talal Wasim, Umair Bin Mansoor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) have demonstrated impressive capabilities in
understanding and reasoning about visual and textual content. However, their
robustness to common image corruptions remains under-explored. In this work, we
present the first comprehensive analysis of VLM robustness across 19 corruption
types from the ImageNet-C benchmark, spanning four categories: noise, blur,
weather, and digital distortions. We introduce two new benchmarks, TextVQA-C
and GQA-C, to systematically evaluate how corruptions affect scene text
understanding and object-based reasoning, respectively. Our analysis reveals
that transformer-based VLMs exhibit distinct vulnerability patterns across
tasks: text recognition deteriorates most severely under blur and snow
corruptions, while object reasoning shows higher sensitivity to corruptions
such as frost and impulse noise. We connect these observations to the
frequency-domain characteristics of different corruptions, revealing how
transformers' inherent bias toward low-frequency processing explains their
differential robustness patterns. Our findings provide valuable insights for
developing more corruption-robust vision-language models for real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2304.10592,
  arXiv:2301.12597 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DreamDistribution: Learning <span class="highlight-title">Prompt</span> Distribution for Diverse
  In-distribution Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.14216v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.14216v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian Nlong Zhao, Yuhang Xiao, Jiashu Xu, Xinyang Jiang, Yifan Yang, Dongsheng Li, Laurent Itti, Vibhav Vineet, Yunhao Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The popularization of Text-to-Image (T2I) diffusion models enables the
generation of high-quality images from text descriptions. However, generating
diverse customized images with reference visual attributes remains challenging.
This work focuses on personalizing T2I diffusion models at a more abstract
concept or category level, adapting commonalities from a set of reference
images while creating new instances with sufficient variations. We introduce a
solution that allows a pretrained T2I diffusion model to learn a set of soft
prompts, enabling the generation of novel images by sampling prompts from the
learned distribution. These prompts offer text-guided editing capabilities and
additional flexibility in controlling variation and mixing between multiple
distributions. We also show the adaptability of the learned prompt distribution
to other tasks, such as text-to-3D. Finally we demonstrate effectiveness of our
approach through quantitative analysis including automatic evaluation and human
assessment. Project website: https://briannlongzhao.github.io/DreamDistribution
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tree of Attributes <span class="highlight-title">Prompt</span> Learning for Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11201v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11201v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Ding, Wanhua Li, Zhongqi Miao, Hanspeter Pfister
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning has proven effective in adapting vision language models for
downstream tasks. However, existing methods usually append learnable prompt
tokens solely with the category names to obtain textual features, which fails
to fully leverage the rich context indicated in the category name. To address
this issue, we propose the Tree of Attributes Prompt learning (TAP), which
first instructs LLMs to generate a tree of attributes with a "concept -
attribute - description" structure for each category, and then learn the
hierarchy with vision and text prompt tokens. Unlike existing methods that
merely augment category names with a set of unstructured descriptions, our
approach essentially distills structured knowledge graphs associated with class
names from LLMs. Furthermore, our approach introduces text and vision prompts
designed to explicitly learn the corresponding visual attributes, effectively
serving as domain experts. Additionally, the general and diverse descriptions
generated based on the class names may be wrong or absent in the specific given
images. To address this misalignment, we further introduce a vision-conditional
pooling module to extract instance-specific text features. Extensive
experimental results demonstrate that our approach outperforms state-of-the-art
methods on the zero-shot base-to-novel generalization, cross-dataset transfer,
as well as few-shot classification across 11 diverse datasets. Code is
available at https://github.com/HHenryD/TAP.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Compression Autoencoder for Efficient High-Resolution Diffusion
  Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10733v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10733v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu, Song Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder
models for accelerating high-resolution diffusion models. Existing autoencoder
models have demonstrated impressive results at a moderate spatial compression
ratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for
high spatial compression ratios (e.g., 64x). We address this challenge by
introducing two key techniques: (1) Residual Autoencoding, where we design our
models to learn residuals based on the space-to-channel transformed features to
alleviate the optimization difficulty of high spatial-compression autoencoders;
(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases
training strategy for mitigating the generalization penalty of high
spatial-compression autoencoders. With these designs, we improve the
autoencoder's spatial compression ratio up to 128 while maintaining the
reconstruction quality. Applying our DC-AE to latent diffusion models, we
achieve significant speedup without accuracy drop. For example, on ImageNet
512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup
on H100 GPU for UViT-H while achieving a better FID, compared with the widely
used SD-VAE-f8 autoencoder. Our code is available at
https://github.com/mit-han-lab/efficientvit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025. The first two authors contributed equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10596v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10596v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Hu, Lianghui Zhu, Yuxuan Zhang, Tianheng Cheng, Lei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, Xinggang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pixel grounding, encompassing tasks such as Referring Expression Segmentation
(RES), has garnered considerable attention due to its immense potential for
bridging the gap between vision and language modalities. However, advancements
in this domain are currently constrained by limitations inherent in existing
datasets, including limited object categories, insufficient textual diversity,
and a scarcity of high-quality annotations. To mitigate these limitations, we
introduce GroundingSuite, which comprises: (1) an automated data annotation
framework leveraging multiple Vision-Language Model (VLM) agents; (2) a
large-scale training dataset encompassing 9.56 million diverse referring
expressions and their corresponding segmentations; and (3) a meticulously
curated evaluation benchmark consisting of 3,800 images. The GroundingSuite
training dataset facilitates substantial performance improvements, enabling
models trained on it to achieve state-of-the-art results. Specifically, a cIoU
of 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the
GroundingSuite annotation framework demonstrates superior efficiency compared
to the current leading data annotation method, i.e., $4.5 \times$ faster than
the GLaMM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Code: https://github.com/hustvl/GroundingSuite.
  Update: add more results & polish the report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World
  Understanding? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.23765v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.23765v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution
for Embodied AI and Autonomous Driving has become a prevailing trend. While
MLLMs have been extensively studied for visual semantic understanding tasks,
their ability to perform precise and quantitative spatial-temporal
understanding in real-world applications remains largely unexamined, leading to
uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we
introduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal
understanding through challenging tasks such as estimating and predicting the
appearance, pose, displacement, and motion of objects. Our benchmark
encompasses a wide range of robot and vehicle operations across desktop,
indoor, and outdoor scenarios. The extensive experiments reveals that the
state-of-the-art MLLMs still struggle in real-world spatial-temporal
understanding, especially in tasks requiring precise distance estimation and
motion analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Direct Learning of Mesh and Appearance via 3D Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06945v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06945v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ancheng Lin, Yusheng Xiang, Paul Kennedy, Jun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately reconstructing a 3D scene including explicit geometry information
is both attractive and challenging. Geometry reconstruction can benefit from
incorporating differentiable appearance models, such as Neural Radiance Fields
and 3D Gaussian Splatting (3DGS). However, existing methods encounter
efficiency issues due to indirect geometry learning and the paradigm of
separately modeling geometry and surface appearance. In this work, we propose a
learnable scene model that incorporates 3DGS with an explicit geometry
representation, namely a mesh. Our model learns the mesh and appearance in an
end-to-end manner, where we bind 3D Gaussians to the mesh faces and perform
differentiable rendering of 3DGS to obtain photometric supervision. The model
creates an effective information pathway to supervise the learning of both 3DGS
and mesh. Experimental results demonstrate that the learned scene model not
only improves efficiency and rendering quality but also enables manipulation
via the explicit mesh. In addition, our model has a unique advantage in
adapting to scene updates, thanks to the end-to-end learning of both mesh and
appearance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Depth Pro: Sharp Monocular Metric Depth in Less Than a Second <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02073v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02073v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleksei Bochkovskii, Amaël Delaunoy, Hugo Germain, Marcel Santos, Yichao Zhou, Stephan R. Richter, Vladlen Koltun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a foundation model for zero-shot metric monocular depth
estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with
unparalleled sharpness and high-frequency details. The predictions are metric,
with absolute scale, without relying on the availability of metadata such as
camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map
in 0.3 seconds on a standard GPU. These characteristics are enabled by a number
of technical contributions, including an efficient multi-scale vision
transformer for dense prediction, a training protocol that combines real and
synthetic datasets to achieve high metric accuracy alongside fine boundary
tracing, dedicated evaluation metrics for boundary accuracy in estimated depth
maps, and state-of-the-art focal length estimation from a single image.
Extensive experiments analyze specific design choices and demonstrate that
Depth Pro outperforms prior work along multiple dimensions. We release code and
weights at https://github.com/apple/ml-depth-pro
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025. Code and weights available at
  https://github.com/apple/ml-depth-pro</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Overcoming False Illusions in Real-World Face Restoration with
  Multi-Modal Guided Diffusion Model <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04161v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04161v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keda Tao, Jinjin Gu, Yulun Zhang, Xiucheng Wang, Nan Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel Multi-modal Guided Real-World Face Restoration (MGFR)
technique designed to improve the quality of facial image restoration from
low-quality inputs. Leveraging a blend of attribute text prompts, high-quality
reference images, and identity information, MGFR can mitigate the generation of
false facial attributes and identities often associated with generative face
restoration methods. By incorporating a dual-control adapter and a two-stage
training strategy, our method effectively utilizes multi-modal prior
information for targeted restoration tasks. We also present the Reface-HQ
dataset, comprising over 21,000 high-resolution facial images across 4800
identities, to address the need for reference face training images. Our
approach achieves superior visual quality in restoring facial details under
severe degradation and allows for controlled restoration processes, enhancing
the accuracy of identity preservation and attribute correction. Including
negative quality samples and attribute prompts in the training further refines
the model's ability to generate detailed and perceptually accurate images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 Pages, 28 Figures, ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continuous Locomotive Crowd Behavior Generation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04756v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04756v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Inhwan Bae, Junoh Lee, Hae-Gon Jeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and reproducing crowd behaviors are important in various domains
including psychology, robotics, transport engineering and virtual environments.
Conventional methods have focused on synthesizing momentary scenes, which have
difficulty in replicating the continuous nature of real-world crowds. In this
paper, we introduce a novel method for automatically generating continuous,
realistic crowd trajectories with heterogeneous behaviors and interactions
among individuals. We first design a crowd emitter model. To do this, we obtain
spatial layouts from single input images, including a segmentation map,
appearance map, population density map and population probability, prior to
crowd generation. The emitter then continually places individuals on the
timeline by assigning independent behavior characteristics such as agents'
type, pace, and start/end positions using diffusion models. Next, our crowd
simulator produces their long-term locomotions. To simulate diverse actions, it
can augment their behaviors based on a Markov chain. As a result, our overall
framework populates the scenes with heterogeneous crowd behaviors by
alternating between the proposed emitter and simulator. Note that all the
components in the proposed framework are user-controllable. Lastly, we propose
a benchmark protocol to evaluate the realism and quality of the generated
crowds in terms of the scene-level population dynamics and the individual-level
trajectory accuracy. We demonstrate that our approach effectively models
diverse crowd behavior patterns and generalizes well across different
geographical environments. Code is publicly available at
https://github.com/InhwanBae/CrowdES .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025. Project page:
  https://ihbae.com/publication/crowdes/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Cognitive Paradigm Approach to Probe the Perception-Reasoning
  Interface in VLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.13620v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.13620v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohit Vaishnav, Tanel Tammet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A fundamental challenge in artificial intelligence involves understanding the
cognitive processes underlying visual reasoning in sophisticated models like
Vision-Language Models (VLMs). How do these models integrate visual perception
with abstract thought, especially when reasoning across multiple images?
Drawing inspiration from cognitive science, this paper introduces a structured
evaluation framework using Bongard Problems (BPs) - a classic test of visual
abstraction to dissect the perception-reasoning interface in VLMs. We propose
three distinct evaluation paradigms, mirroring human problem-solving
strategies: Direct Visual Rule Learning (DVRL; holistic processing), Deductive
Rule Learning (DRL; rule extraction and application), and Componential Analysis
(CA; analytical decomposition via textual descriptions). These paradigms allow
us to systematically vary the cognitive load and probe specific processing
stages. Notably, the CA paradigm enables the evaluation of multi-image
reasoning even in VLMs architecturally limited to single images and facilitates
the isolation of reasoning capabilities from perceptual limitations by
controlling the descriptive input. Ablation studies further confirm that
reasoning abilities improve significantly when perceptual challenges are
mitigated. Our framework provides a valuable diagnostic tool, highlighting the
need to enhance visual processing fidelity for achieving more robust and
human-like visual intelligence in AI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transferable Adversarial Attacks on SAM and Its Downstream Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20197v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20197v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Song Xia, Wenhan Yang, Yi Yu, Xun Lin, Henghui Ding, Ling-Yu Duan, Xudong Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The utilization of large foundational models has a dilemma: while fine-tuning
downstream tasks from them holds promise for making use of the well-generalized
knowledge in practical applications, their open accessibility also poses
threats of adverse usage. This paper, for the first time, explores the
feasibility of adversarial attacking various downstream models fine-tuned from
the segment anything model (SAM), by solely utilizing the information from the
open-sourced SAM. In contrast to prevailing transfer-based adversarial attacks,
we demonstrate the existence of adversarial dangers even without accessing the
downstream task and dataset to train a similar surrogate model. To enhance the
effectiveness of the adversarial attack towards models fine-tuned on unknown
datasets, we propose a universal meta-initialization (UMI) algorithm to extract
the intrinsic vulnerability inherent in the foundation model, which is then
utilized as the prior knowledge to guide the generation of adversarial
perturbations. Moreover, by formulating the gradient difference in the
attacking process between the open-sourced SAM and its fine-tuned downstream
models, we theoretically demonstrate that a deviation occurs in the adversarial
update direction by directly maximizing the distance of encoded feature
embeddings in the open-sourced SAM. Consequently, we propose a gradient robust
loss that simulates the associated uncertainty with gradient-based noise
augmentation to enhance the robustness of generated adversarial examples (AEs)
towards this deviation, thus improving the transferability. Extensive
experiments demonstrate the effectiveness of the proposed universal
meta-initialized and gradient robust adversarial attack (UMI-GRAT) toward SAMs
and their downstream models. Code is available at
https://github.com/xiasong0501/GRAT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>update fig 1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DARB-Splatting: Generalizing Splatting with Decaying Anisotropic Radial
  Basis Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12369v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12369v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vishagar Arunan, Saeedha Nazar, Hashiru Pramuditha, Vinasirajan Viruthshaan, Sameera Ramasinghe, Simon Lucey, Ranga Rodrigo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Splatting-based 3D reconstruction methods have gained popularity with the
advent of 3D Gaussian Splatting, efficiently synthesizing high-quality novel
views. These methods commonly resort to using exponential family functions,
such as the Gaussian function, as reconstruction kernels due to their
anisotropic nature, ease of projection, and differentiability in rasterization.
However, the field remains restricted to variations within the exponential
family, leaving generalized reconstruction kernels largely underexplored,
partly due to the lack of easy integrability in 3D to 2D projections. In this
light, we show that a class of decaying anisotropic radial basis functions
(DARBFs), which are non-negative functions of the Mahalanobis distance,
supports splatting by approximating the Gaussian function's closed-form
integration advantage. With this fresh perspective, we demonstrate up to 34%
faster convergence during training and a 45% reduction in memory consumption
across various DARB reconstruction kernels, while maintaining comparable PSNR,
SSIM, and LPIPS results. We will make the code available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Link to the project page:
  https://randomnerds.github.io/darbs.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SkyReels-V2: Infinite-length Film Generative Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13074v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13074v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guibin Chen, Dixuan Lin, Jiangping Yang, Chunze Lin, Junchen Zhu, Mingyuan Fan, Hao Zhang, Sheng Chen, Zheng Chen, Chengcheng Ma, Weiming Xiong, Wei Wang, Nuo Pang, Kang Kang, Zhiheng Xu, Yuzhe Jin, Yupeng Liang, Yubing Song, Peng Zhao, Boyuan Xu, Di Qiu, Debang Li, Zhengcong Fei, Yang Li, Yahui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in video generation have been driven by diffusion models and
autoregressive frameworks, yet critical challenges persist in harmonizing
prompt adherence, visual quality, motion dynamics, and duration: compromises in
motion dynamics to enhance temporal visual quality, constrained video duration
(5-10 seconds) to prioritize resolution, and inadequate shot-aware generation
stemming from general-purpose MLLMs' inability to interpret cinematic grammar,
such as shot composition, actor expressions, and camera motions. These
intertwined limitations hinder realistic long-form synthesis and professional
film-style generation. To address these limitations, we propose SkyReels-V2, an
Infinite-length Film Generative Model, that synergizes Multi-modal Large
Language Model (MLLM), Multi-stage Pretraining, Reinforcement Learning, and
Diffusion Forcing Framework. Firstly, we design a comprehensive structural
representation of video that combines the general descriptions by the
Multi-modal LLM and the detailed shot language by sub-expert models. Aided with
human annotation, we then train a unified Video Captioner, named
SkyCaptioner-V1, to efficiently label the video data. Secondly, we establish
progressive-resolution pretraining for the fundamental video generation,
followed by a four-stage post-training enhancement: Initial concept-balanced
Supervised Fine-Tuning (SFT) improves baseline quality; Motion-specific
Reinforcement Learning (RL) training with human-annotated and synthetic
distortion data addresses dynamic artifacts; Our diffusion forcing framework
with non-decreasing noise schedules enables long-video synthesis in an
efficient search space; Final high-quality SFT refines visual fidelity. All the
code and models are available at https://github.com/SkyworkAI/SkyReels-V2.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages,10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03312v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03312v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) have demonstrated strong capabilities across
various visual understanding and reasoning tasks, driven by incorporating image
representations into the token inputs of Large Language Models (LLMs). However,
their real-world deployment is often constrained by high latency during
inference due to the substantial compute required by the LLM to process the
large number of input tokens, predominantly arising from the image. To reduce
inference costs, one can either downsize the LLM or reduce the number of input
tokens needed to represent the image, the latter of which has been the focus of
many recent efforts around token compression. However, it is unclear what the
optimal trade-off is given a fixed inference budget. We first characterize this
optimal trade-off between the number of visual tokens and LLM parameters by
establishing scaling laws that capture variations in performance with these two
factors. Our results reveal a surprising trend: for visual reasoning tasks, the
inference-optimal behavior in VLMs is achieved by using the largest LLM that
fits within the inference budget while minimizing visual token count - often to
a single token. While the token reduction literature has mainly focused on
maintaining base model performance by modestly reducing the token count (e.g.,
$5-10\times$), our results indicate that the compute-optimal inference regime
requires operating under even higher token compression ratios. Based on these
insights, we take the first steps toward designing token compression algorithms
tailored for high-compression settings, utilizing prompt-based compression of
tokens. Our work underscores the performance and efficiency benefits of
operating in low visual token regimes and the importance of developing tailored
token reduction algorithms for such conditions. Code is available at
https://github.com/locuslab/llava-token-compression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Radar Data Representations in Autonomous Driving: A
  Comprehensive <span class="highlight-title">Review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.04861v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.04861v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shanliang Yao, Runwei Guan, Zitian Peng, Chenhang Xu, Yilu Shi, Weiping Ding, Eng Gee Lim, Yong Yue, Hyungjoon Seo, Ka Lok Man, Jieming Ma, Xiaohui Zhu, Yutao Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancements of sensor technology and deep learning,
autonomous driving systems are providing safe and efficient access to
intelligent vehicles as well as intelligent transportation. Among these
equipped sensors, the radar sensor plays a crucial role in providing robust
perception information in diverse environmental conditions. This review focuses
on exploring different radar data representations utilized in autonomous
driving systems. Firstly, we introduce the capabilities and limitations of the
radar sensor by examining the working principles of radar perception and signal
processing of radar measurements. Then, we delve into the generation process of
five radar representations, including the ADC signal, radar tensor, point
cloud, grid map, and micro-Doppler signature. For each radar representation, we
examine the related datasets, methods, advantages and limitations. Furthermore,
we discuss the challenges faced in these data representations and propose
potential research directions. Above all, this comprehensive review offers an
in-depth insight into how these representations enhance autonomous system
capabilities, providing guidance for radar perception researchers. To
facilitate retrieval and comparison of different data representations, datasets
and methods, we provide an interactive website at
https://radar-camera-fusion.github.io/radar.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by TITS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SLAM&Render: A Benchmark for the Intersection Between Neural Rendering,
  Gaussian Splatting and SLAM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13713v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13713v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samuel Cerezo, Gaetano Meli, Tomás Berriel Martins, Kirill Safronov, Javier Civera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models and methods originally developed for novel view synthesis and scene
rendering, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, are
increasingly being adopted as representations in Simultaneous Localization and
Mapping (SLAM). However, existing datasets fail to include the specific
challenges of both fields, such as multimodality and sequentiality in SLAM or
generalization across viewpoints and illumination conditions in neural
rendering. To bridge this gap, we introduce SLAM&Render, a novel dataset
designed to benchmark methods in the intersection between SLAM and novel view
rendering. It consists of 40 sequences with synchronized RGB, depth, IMU, robot
kinematic data, and ground-truth pose streams. By releasing robot kinematic
data, the dataset also enables the assessment of novel SLAM strategies when
applied to robot manipulators. The dataset sequences span five different setups
featuring consumer and industrial objects under four different lighting
conditions, with separate training and test trajectories per scene, as well as
object rearrangements. Our experimental results, obtained with several
baselines from the literature, validate SLAM&Render as a relevant benchmark for
this emerging research area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures, RA-L submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A comprehensive <span class="highlight-title">review</span> of remote sensing in wetland classification and
  mapping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10842v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10842v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Yuan, Xiangan Liang, Tianwu Lin, Shuang Chen, Rui Liu, Jie Wang, Hongsheng Zhang, Peng Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Wetlands constitute critical ecosystems that support both biodiversity and
human well-being; however, they have experienced a significant decline since
the 20th century. Back in the 1970s, researchers began to employ remote sensing
technologies for wetland classification and mapping to elucidate the extent and
variations of wetlands. Although some review articles summarized the
development of this field, there is a lack of a thorough and in-depth
understanding of wetland classification and mapping: (1) the scientific
importance of wetlands, (2) major data, methods used in wetland classification
and mapping, (3) driving factors of wetland changes, (4) current research
paradigm and limitations, (5) challenges and opportunities in wetland
classification and mapping under the context of technological innovation and
global environmental change. In this review, we aim to provide a comprehensive
perspective and new insights into wetland classification and mapping for
readers to answer these questions. First, we conduct a meta-analysis of over
1,200 papers, encompassing wetland types, methods, sensor types, and study
sites, examining prevailing trends in wetland classification and mapping. Next,
we review and synthesize the wetland features and existing data and methods in
wetland classification and mapping. We also summarize typical wetland mapping
products and explore the intrinsic driving factors of wetland changes across
multiple spatial and temporal scales. Finally, we discuss current limitations
and propose future directions in response to global environmental change and
technological innovation. This review consolidates our understanding of wetland
remote sensing and offers scientific recommendations that foster transformative
progress in wetland science.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AnomalyCLIP: Object-agnostic <span class="highlight-title">Prompt</span> Learning for Zero-shot Anomaly
  Detection <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.18961v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.18961v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, Jiming Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot anomaly detection (ZSAD) requires detection models trained using
auxiliary data to detect anomalies without any training sample in a target
dataset. It is a crucial task when training data is not accessible due to
various concerns, eg, data privacy, yet it is challenging since the models need
to generalize to anomalies across different domains where the appearance of
foreground objects, abnormal regions, and background features, such as
defects/tumors on different products/organs, can vary significantly. Recently
large pre-trained vision-language models (VLMs), such as CLIP, have
demonstrated strong zero-shot recognition ability in various vision tasks,
including anomaly detection. However, their ZSAD performance is weak since the
VLMs focus more on modeling the class semantics of the foreground objects
rather than the abnormality/normality in the images. In this paper we introduce
a novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across
different domains. The key insight of AnomalyCLIP is to learn object-agnostic
text prompts that capture generic normality and abnormality in an image
regardless of its foreground objects. This allows our model to focus on the
abnormal image regions rather than the object semantics, enabling generalized
normality and abnormality recognition on diverse types of objects. Large-scale
experiments on 17 real-world anomaly detection datasets show that AnomalyCLIP
achieves superior zero-shot performance of detecting and segmenting anomalies
in datasets of highly diverse class semantics from various defect inspection
and medical imaging domains. Code will be made available at
https://github.com/zqhang/AnomalyCLIP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Packing Input Frame Context in Next-Frame Prediction Models for Video
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12626v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12626v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lvmin Zhang, Maneesh Agrawala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a neural network structure, FramePack, to train next-frame (or
next-frame-section) prediction models for video generation. The FramePack
compresses input frames to make the transformer context length a fixed number
regardless of the video length. As a result, we are able to process a large
number of frames using video diffusion with computation bottleneck similar to
image diffusion. This also makes the training video batch sizes significantly
higher (batch sizes become comparable to image diffusion training). We also
propose an anti-drifting sampling method that generates frames in inverted
temporal order with early-established endpoints to avoid exposure bias (error
accumulation over iterations). Finally, we show that existing video diffusion
models can be finetuned with FramePack, and their visual quality may be
improved because the next-frame prediction supports more balanced diffusion
schedulers with less extreme flow shift timesteps.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/lllyasviel/FramePack</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GATE3D: Generalized Attention-based Task-synergized Estimation in 3D* <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11014v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11014v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eunsoo Im, Changhyun Jee, Jung Kwon Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emerging trend in computer vision emphasizes developing universal models
capable of simultaneously addressing multiple diverse tasks. Such universality
typically requires joint training across multi-domain datasets to ensure
effective generalization. However, monocular 3D object detection presents
unique challenges in multi-domain training due to the scarcity of datasets
annotated with accurate 3D ground-truth labels, especially beyond typical
road-based autonomous driving contexts. To address this challenge, we introduce
a novel weakly supervised framework leveraging pseudo-labels. Current
pretrained models often struggle to accurately detect pedestrians in non-road
environments due to inherent dataset biases. Unlike generalized image-based 2D
object detection models, achieving similar generalization in monocular 3D
detection remains largely unexplored. In this paper, we propose GATE3D, a novel
framework designed specifically for generalized monocular 3D object detection
via weak supervision. GATE3D effectively bridges domain gaps by employing
consistency losses between 2D and 3D predictions. Remarkably, our model
achieves competitive performance on the KITTI benchmark as well as on an
indoor-office dataset collected by us to evaluate the generalization
capabilities of our framework. Our results demonstrate that GATE3D
significantly accelerates learning from limited annotated data through
effective pre-training strategies, highlighting substantial potential for
broader impacts in robotics, augmented reality, and virtual reality
applications. Project page: https://ies0411.github.io/GATE3D/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted (Poster) to the 3rd CV4MR Workshop at CVPR 2025:
  https://openreview.net/forum?id=00RQ8Cv3ia</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Novel Retinal Image Contrast Enhancement -- Fuzzy-Based Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17850v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17850v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adnan Shaout, Jiho Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The vascular structure in retinal images plays a crucial role in ophthalmic
diagnostics, and its accuracies are directly influenced by the quality of the
retinal image. Contrast enhancement is one of the crucial steps in any
segmentation algorithm - the more so since the retinal images are related to
medical diagnosis. Contrast enhancement is a vital step that not only
intensifies the darkness of the blood vessels but also prevents minor
capillaries from being disregarded during the process. This paper proposes a
novel model that utilizes the linear blending of Fuzzy Contrast Enhancement
(FCE) and Contrast Limited Adaptive Histogram Equalization (CLAHE) to enhance
the retinal image for retinal vascular structure segmentation. The scheme is
tested using the Digital Retinal Images for Vessel Extraction (DRIVE) dataset.
The assertion was then evaluated through performance comparison among other
methodologies which are Gray-scaling, Histogram Equalization (HE), FCE, and
CLAHE. It was evident in this paper that the combination of FCE and CLAHE
methods showed major improvement. Both FCE and CLAHE methods dominating with
88% as better enhancement methods proved that preprocessing through fuzzy logic
is effective.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This version corrects a typographical error in the title of the
  previous submission with no changes to the content of the paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zooming In on Fakes: A Novel <span class="highlight-title">Dataset</span> for Localized AI-Generated Image
  Detection with Forgery Amplification Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11922v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11922v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lvpan Cai, Haowei Wang, Jiayi Ji, YanShu ZhouMen, Yiwei Ma, Xiaoshuai Sun, Liujuan Cao, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of AI-generated image editing tools has made localized forgeries
increasingly realistic, posing challenges for visual content integrity.
Although recent efforts have explored localized AIGC detection, existing
datasets predominantly focus on object-level forgeries while overlooking
broader scene edits in regions such as sky or ground. To address these
limitations, we introduce \textbf{BR-Gen}, a large-scale dataset of 150,000
locally forged images with diverse scene-aware annotations, which are based on
semantic calibration to ensure high-quality samples. BR-Gen is constructed
through a fully automated Perception-Creation-Evaluation pipeline to ensure
semantic coherence and visual realism. In addition, we further propose
\textbf{NFA-ViT}, a Noise-guided Forgery Amplification Vision Transformer that
enhances the detection of localized forgeries by amplifying forgery-related
features across the entire image. NFA-ViT mines heterogeneous regions in
images, \emph{i.e.}, potential edited areas, by noise fingerprints.
Subsequently, attention mechanism is introduced to compel the interaction
between normal and abnormal features, thereby propagating the generalization
traces throughout the entire image, allowing subtle forgeries to influence a
broader context and improving overall detection robustness. Extensive
experiments demonstrate that BR-Gen constructs entirely new scenarios that are
not covered by existing methods. Take a step further, NFA-ViT outperforms
existing methods on BR-Gen and generalizes well across current benchmarks. All
data and codes are available at https://github.com/clpbc/BR-Gen.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of
  Complex Videos in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11326v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11326v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Henghui Ding, Chang Liu, Nikhila Ravi, Shuting He, Yunchao Wei, Song Bai, Philip Torr, Kehuan Song, Xinglin Xie, Kexin Zhang, Licheng Jiao, Lingling Li, Shuyuan Yang, Xuqiang Cao, Linnan Zhao, Jiaxuan Zhao, Fang Liu, Mengjiao Wang, Junpei Zhang, Xu Liu, Yuting Yang, Mengru Ma, Hao Fang, Runmin Cong, Xiankai Lu, Zhiyang Chen, Wei Zhang, Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu, Haobo Yuan, Xiangtai Li, Tao Zhang, Lu Qi, Ming-Hsuan Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This report provides a comprehensive overview of the 4th Pixel-level Video
Understanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025.
It summarizes the challenge outcomes, participating methodologies, and future
research directions. The challenge features two tracks: MOSE, which focuses on
complex scene video object segmentation, and MeViS, which targets
motion-guided, language-based video segmentation. Both tracks introduce new,
more challenging datasets designed to better reflect real-world scenarios.
Through detailed evaluation and analysis, the challenge offers valuable
insights into the current state-of-the-art and emerging trends in complex video
segmentation. More information can be found on the workshop website:
https://pvuw.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Workshop Page: https://pvuw.github.io/. arXiv admin note: text
  overlap with arXiv:2504.00476, arXiv:2504.05178</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ InstructEngine: Instruction-driven Text-to-Image Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10329v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10329v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Lu, Yuhang Hu, YiFan Zhang, Kaiyu Jiang, Changyi Liu, Tianke Zhang, Jinpeng Wang, Chun Yuan, Bin Wen, Fan Yang, Tingting Gao, Di Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been
extensively utilized for preference alignment of text-to-image models. Existing
methods face certain limitations in terms of both data and algorithm. For
training data, most approaches rely on manual annotated preference data, either
by directly fine-tuning the generators or by training reward models to provide
training signals. However, the high annotation cost makes them difficult to
scale up, the reward model consumes extra computation and cannot guarantee
accuracy. From an algorithmic perspective, most methods neglect the value of
text and only take the image feedback as a comparative signal, which is
inefficient and sparse. To alleviate these drawbacks, we propose the
InstructEngine framework. Regarding annotation cost, we first construct a
taxonomy for text-to-image generation, then develop an automated data
construction pipeline based on it. Leveraging advanced large multimodal models
and human-defined rules, we generate 25K text-image preference pairs. Finally,
we introduce cross-validation alignment method, which refines data efficiency
by organizing semantically analogous samples into mutually comparable pairs.
Evaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and
SDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art
baselines, with ablation study confirming the benefits of InstructEngine's all
components. A win rate of over 50% in human reviews also proves that
InstructEngine better aligns with human preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Vectorized Backpropagation Algorithms for Training Feedforward
  Networks Composed of Quadratic Neurons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.02901v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.02901v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mathew Mithra Noel, Venkataraman Muthiah-Nakarajan, Yug D Oswal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Higher order artificial neurons whose outputs are computed by applying an
activation function to a higher order multinomial function of the inputs have
been considered in the past, but did not gain acceptance due to the extra
parameters and computational cost. However, higher order neurons have
significantly greater learning capabilities since the decision boundaries of
higher order neurons can be complex surfaces instead of just hyperplanes. The
boundary of a single quadratic neuron can be a general hyper-quadric surface
allowing it to learn many nonlinearly separable datasets. Since quadratic forms
can be represented by symmetric matrices, only $\frac{n(n+1)}{2}$ additional
parameters are needed instead of $n^2$. A quadratic Logistic regression model
is first presented. Solutions to the XOR problem with a single quadratic neuron
are considered. The complete vectorized equations for both forward and backward
propagation in feedforward networks composed of quadratic neurons are derived.
A reduced parameter quadratic neural network model with just $ n $ additional
parameters per neuron that provides a compromise between learning ability and
computational cost is presented. Comparison on benchmark classification
datasets are used to demonstrate that a final layer of quadratic neurons
enables networks to achieve higher accuracy with significantly fewer hidden
layer neurons. In particular this paper shows that any dataset composed of
$\mathcal{C}$ bounded clusters can be separated with only a single layer of
$\mathcal{C}$ quadratic neurons.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ S-EO: A Large-Scale <span class="highlight-title">Dataset</span> for Geometry-Aware Shadow Detection in
  Remote Sensing Applications <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.06920v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.06920v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elías Masquil, Roger Marí, Thibaud Ehret, Enric Meinhardt-Llopis, Pablo Musé, Gabriele Facciolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the S-EO dataset: a large-scale, high-resolution dataset,
designed to advance geometry-aware shadow detection. Collected from diverse
public-domain sources, including challenge datasets and government providers
such as USGS, our dataset comprises 702 georeferenced tiles across the USA,
each covering 500x500 m. Each tile includes multi-date, multi-angle WorldView-3
pansharpened RGB images, panchromatic images, and a ground-truth DSM of the
area obtained from LiDAR scans. For each image, we provide a shadow mask
derived from geometry and sun position, a vegetation mask based on the NDVI
index, and a bundle-adjusted RPC model. With approximately 20,000 images, the
S-EO dataset establishes a new public resource for shadow detection in remote
sensing imagery and its applications to 3D reconstruction. To demonstrate the
dataset's impact, we train and evaluate a shadow detector, showcasing its
ability to generalize, even to aerial images. Finally, we extend EO-NeRF - a
state-of-the-art NeRF approach for satellite imagery - to leverage our shadow
predictions for improved 3D reconstructions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Earthvision 2025 (CVPR Workshop)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PK-YOLO: <span class="highlight-title">Pretrain</span>ed Knowledge Guided YOLO for Brain Tumor Detection in
  Multiplanar MRI Slices <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21822v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21822v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ming Kang, Fung Fung Ting, Raphaël C. -W. Phan, Chee-Ming Ting
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Brain tumor detection in multiplane Magnetic Resonance Imaging (MRI) slices
is a challenging task due to the various appearances and relationships in the
structure of the multiplane images. In this paper, we propose a new You Only
Look Once (YOLO)-based detection model that incorporates Pretrained Knowledge
(PK), called PK-YOLO, to improve the performance for brain tumor detection in
multiplane MRI slices. To our best knowledge, PK-YOLO is the first pretrained
knowledge guided YOLO-based object detector. The main components of the new
method are a pretrained pure lightweight convolutional neural network-based
backbone via sparse masked modeling, a YOLO architecture with the pretrained
backbone, and a regression loss function for improving small object detection.
The pretrained backbone allows for feature transferability of object queries on
individual plane MRI slices into the model encoders, and the learned domain
knowledge base can improve in-domain detection. The improved loss function can
further boost detection performance on small-size brain tumors in multiplanar
two-dimensional MRI slices. Experimental results show that the proposed PK-YOLO
achieves competitive performance on the multiplanar MRI brain tumor detection
datasets compared to state-of-the-art YOLO-like and DETR-like object detectors.
The code is available at https://github.com/mkang315/PK-YOLO.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>References updated; for example, papers in NeurIPS 2024 proceedings
  appeared on 6 Feb 2025 and AAAI 2025 one on 11 Apr 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HRAvatar: High-Quality and Relightable Gaussian Head Avatar <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08224v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08224v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongbin Zhang, Yunfei Liu, Lijian Lin, Ye Zhu, Kangjie Chen, Minghan Qin, Yu Li, Haoqian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reconstructing animatable and high-quality 3D head avatars from monocular
videos, especially with realistic relighting, is a valuable task. However, the
limited information from single-view input, combined with the complex head
poses and facial movements, makes this challenging. Previous methods achieve
real-time performance by combining 3D Gaussian Splatting with a parametric head
model, but the resulting head quality suffers from inaccurate face tracking and
limited expressiveness of the deformation model. These methods also fail to
produce realistic effects under novel lighting conditions. To address these
issues, we propose HRAvatar, a 3DGS-based method that reconstructs
high-fidelity, relightable 3D head avatars. HRAvatar reduces tracking errors
through end-to-end optimization and better captures individual facial
deformations using learnable blendshapes and learnable linear blend skinning.
Additionally, it decomposes head appearance into several physical properties
and incorporates physically-based shading to account for environmental
lighting. Extensive experiments demonstrate that HRAvatar not only reconstructs
superior-quality heads but also achieves realistic visual effects under varying
lighting conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025,Project page:
  https://eastbeanzhang.github.io/HRAvatar</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DLEN: Dual Branch of <span class="highlight-title">Transformer</span> for Low-Light Image Enhancement in Dual
  Domains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12235v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12235v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyu Xia, Jiesong Bai, Yihang Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-light image enhancement (LLE) aims to improve the visual quality of
images captured in poorly lit conditions, which often suffer from low
brightness, low contrast, noise, and color distortions. These issues hinder the
performance of computer vision tasks such as object detection, facial
recognition, and autonomous driving.Traditional enhancement techniques, such as
multi-scale fusion and histogram equalization, fail to preserve fine details
and often struggle with maintaining the natural appearance of enhanced images
under complex lighting conditions. Although the Retinex theory provides a
foundation for image decomposition, it often amplifies noise, leading to
suboptimal image quality. In this paper, we propose the Dual Light Enhance
Network (DLEN), a novel architecture that incorporates two distinct attention
mechanisms, considering both spatial and frequency domains. Our model
introduces a learnable wavelet transform module in the illumination estimation
phase, preserving high- and low-frequency components to enhance edge and
texture details. Additionally, we design a dual-branch structure that leverages
the power of the Transformer architecture to enhance both the illumination and
structural components of the image.Through extensive experiments, our model
outperforms state-of-the-art methods on standard benchmarks.Code is available
here: https://github.com/LaLaLoXX/DLEN
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages and 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TSceneJAL: Joint Active Learning of Traffic Scenes for 3D Object
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.18870v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.18870v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyang Lei, Weiyuan Peng, Guang Zhou, Meiying Zhang, Qi Hao, Chunlin Ji, Chengzhong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most autonomous driving (AD) datasets incur substantial costs for collection
and labeling, inevitably yielding a plethora of low-quality and redundant data
instances, thereby compromising performance and efficiency. Many applications
in AD systems necessitate high-quality training datasets using both existing
datasets and newly collected data. In this paper, we propose a traffic scene
joint active learning (TSceneJAL) framework that can efficiently sample the
balanced, diverse, and complex traffic scenes from both labeled and unlabeled
data. The novelty of this framework is threefold: 1) a scene sampling scheme
based on a category entropy, to identify scenes containing multiple object
classes, thus mitigating class imbalance for the active learner; 2) a
similarity sampling scheme, estimated through the directed graph representation
and a marginalize kernel algorithm, to pick sparse and diverse scenes; 3) an
uncertainty sampling scheme, predicted by a mixture density network, to select
instances with the most unclear or complex regression outcomes for the learner.
Finally, the integration of these three schemes in a joint selection strategy
yields an optimal and valuable subdataset. Experiments on the KITTI, Lyft,
nuScenes and SUScape datasets demonstrate that our approach outperforms
existing state-of-the-art methods on 3D object detection tasks with up to 12%
improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Intent Understanding for Ambiguous <span class="highlight-title">prompt</span>: A Human-Machine
  Co-Adaption Strategy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15167v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15167v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yangfan He, Jianhui Wang, Yijin Wang, Kun Li, Yan Zhong, Xinyuan Song, Li Sun, Jingyuan Lu, Miao Zhang, Tianyu Shi, Xinhang Yuan, Kuan Lu, Menghao Huo, Keqin Li, Jiaqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Today's image generation systems are capable of producing realistic and
high-quality images. However, user prompts often contain ambiguities, making it
difficult for these systems to interpret users' actual intentions.
Consequently, many users must modify their prompts several times to ensure the
generated images meet their expectations. While some methods focus on enhancing
prompts to make the generated images fit user needs, the model is still hard to
understand users' real needs, especially for non-expert users. In this
research, we aim to enhance the visual parameter-tuning process, making the
model user-friendly for individuals without specialized knowledge and better
understand user needs. We propose a human-machine co-adaption strategy using
mutual information between the user's prompts and the pictures under
modification as the optimizing target to make the system better adapt to user
needs. We find that an improved model can reduce the necessity for multiple
rounds of adjustments. We also collect multi-round dialogue datasets with
prompts and images pairs and user intent. Various experiments demonstrate the
effectiveness of the proposed method in our proposed dataset. Our annotation
tools and several examples of our dataset are available at
https://zenodo.org/records/14876029 for easier review. We will make open source
our full dataset and code.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DirDist: A Metric for Comparing 3D Shapes Using Directional Distance
  Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.09736v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.09736v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyu Ren, Junhui Hou, Xiaodong Chen, Hongkai Xiong, Wenping Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Qualifying the discrepancy between 3D geometric models, which could be
represented with either point clouds or triangle meshes, is a pivotal issue
with board applications. Existing methods mainly focus on directly establishing
the correspondence between two models and then aggregating point-wise distance
between corresponding points, resulting in them being either inefficient or
ineffective. In this paper, we propose DirDist, an efficient, effective,
robust, and differentiable distance metric for 3D geometry data. Specifically,
we construct DirDist based on the proposed implicit representation of 3D
models, namely directional distance field (DDF), which defines the directional
distances of 3D points to a model to capture its local surface geometry. We
then transfer the discrepancy between two 3D geometric models as the
discrepancy between their DDFs defined on an identical domain, naturally
establishing model correspondence. To demonstrate the advantage of our DirDist,
we explore various distance metric-driven 3D geometric modeling tasks,
including template surface fitting, rigid registration, non-rigid registration,
scene flow estimation and human pose optimization. Extensive experiments show
that our DirDist achieves significantly higher accuracy under all tasks. As a
generic distance metric, DirDist has the potential to advance the field of 3D
geometric modeling. The source code is available at
https://github.com/rsy6318/DirDist.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by T-PAMI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Activation-wise Propagation: A Universal Strategy to Break Timestep
  Constraints in Spiking Neural Networks for 3D Data Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12791v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12791v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Song, Xiangfei Yang, Donglin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to their event-driven and parameter-efficient effect, spiking neural
networks (SNNs) show potential in tasks requiring real-time multi-sensor
perception, such as autonomous driving. The spiking mechanism facilitates
sparse encoding, enabling spatial and temporal data to be represented in a
discrete manner. However, SNNs still lag behind artificial neural networks
(ANNs) in terms of performance and computational efficiency. One major
challenge in SNNs is the timestep-wise iterative update of neuronal states,
which makes it difficult to achieve an optimal trade-off among accuracy,
latency, and training cost. Although some methods perform well with shorter
timesteps, few propose strategies to overcome such constraint effectively.
Moreover, many recent SNN advancements rely on either optimizations tailored to
specific architectures or a collection of specialized neuron-level strategies.
While these approaches can enhance performance, they often lead to increased
computational expense and restrict their application to particular
architectures or modalities. This leaves room for further exploration of
simple, universal, and structure-agnostic strategies that could offer broader
applicability and efficiency. In this paper, we introduce Activation-wise
Membrane Potential Propagation (AMP2), a novel state update mechanism for
spiking neurons. Inspired by skip connections in deep networks, AMP2
incorporates the membrane potential of neurons into network, eliminating the
need for iterative updates. Our method achieves significant improvements across
various 3D modalities, including 3D point clouds and event streams, boosting
Spiking PointNet's accuracy on ModelNet40 from 87.36% to 89.74% and surpassing
ANN PointNet in recognition accuracy on the DVS128 Gesture dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Low-Cost Video Editing with Lightweight Adaptors and
  Temporal-Aware Inversion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04606v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04606v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yangfan He, Sida Li, Kun Li, Xinyuan Song, Xinhang Yuan, Keqin Li, Kuan Lu, Menghao Huo, Jiaqi Chen, Miao Zhang, Xueqian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-image (T2I) generation using diffusion models
have enabled cost-effective video-editing applications by leveraging
pre-trained models, eliminating the need for resource-intensive training.
However, the frame-independence of T2I generation often results in poor
temporal consistency. Existing methods address this issue through temporal
layer fine-tuning or inference-based temporal propagation, but these approaches
suffer from high training costs or limited temporal coherence. To address these
challenges, we propose a General and Efficient Adapter (GE-Adapter) that
integrates temporal-spatial and semantic consistency with Baliteral DDIM
inversion. This framework introduces three key components: (1) Frame-based
Temporal Consistency Blocks (FTC Blocks) to capture frame-specific features and
enforce smooth inter-frame transitions via temporally-aware loss functions; (2)
Channel-dependent Spatial Consistency Blocks (SCD Blocks) employing bilateral
filters to enhance spatial coherence by reducing noise and artifacts; and (3)
Token-based Semantic Consistency Module (TSC Module) to maintain semantic
alignment using shared prompt tokens and frame-specific tokens. Our method
significantly improves perceptual quality, text-image alignment, and temporal
coherence, as demonstrated on the MSR-VTT dataset. Additionally, it achieves
enhanced fidelity and frame-to-frame coherence, offering a practical solution
for T2V editing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TLAC: Two-stage LMM Augmented CLIP for Zero-Shot Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.12206v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.12206v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ans Munir, Faisal Z. Qureshi, Muhammad Haris Khan, Mohsen Ali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive Language-Image Pretraining (CLIP) has shown impressive zero-shot
performance on image classification. However, state-of-the-art methods often
rely on fine-tuning techniques like prompt learning and adapter-based tuning to
optimize CLIP's performance. The necessity for fine-tuning significantly limits
CLIP's adaptability to novel datasets and domains. This requirement mandates
substantial time and computational resources for each new dataset. To overcome
this limitation, we introduce simple yet effective training-free approaches,
Single-stage LMM Augmented CLIP (SLAC) and Two-stage LMM Augmented CLIP (TLAC),
that leverages powerful Large Multimodal Models (LMMs), such as Gemini, for
image classification. The proposed methods leverages the capabilities of
pre-trained LMMs, allowing for seamless adaptation to diverse datasets and
domains without the need for additional training. Our approaches involve
prompting the LMM to identify objects within an image. Subsequently, the CLIP
text encoder determines the image class by identifying the dataset class with
the highest semantic similarity to the LLM predicted object. Our models
achieved superior accuracy on 9 of 11 base-to-novel datasets, including
ImageNet, SUN397, and Caltech101, while maintaining a strictly training-free
paradigm. Our TLAC model achieved an overall accuracy of 83.44%, surpassing the
previous state-of-the-art few-shot methods by a margin of 6.75%. Compared to
other training-free approaches, our TLAC method achieved 83.6% average accuracy
across 13 datasets, a 9.7% improvement over the previous methods. Our Code is
available at https://github.com/ans92/TLAC
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Added code link in the abstract</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MaCTG: Multi-Agent Collaborative Thought Graph for Automatic Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19245v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19245v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixiao Zhao, Jing Sun, Zhe Hou, Zhiyuan Wei, Cheng-Hao Cai, Miao Qiao, Jin Song Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of Large Language Models (LLMs), LLM-based
approaches have demonstrated strong problem-solving capabilities across various
domains. However, in automatic programming, a single LLM is typically limited
to function-level code generation, while multi-agent systems composed of
multiple LLMs often suffer from inefficient task planning. This lack of
structured coordination can lead to cascading hallucinations, where accumulated
errors across agents result in suboptimal workflows and excessive computational
costs. To overcome these challenges, we introduce MaCTG (Multi-Agent
Collaborative Thought Graph), a novel multi-agent framework that employs a
dynamic graph structure to facilitate precise task allocation and controlled
collaboration among LLM agents. MaCTG autonomously assigns agent roles based on
programming requirements, dynamically refines task distribution through
context-aware adjustments, and systematically verifies and integrates
project-level code, effectively reducing hallucination errors and improving
overall accuracy. MaCTG enhances cost-effectiveness by implementing a hybrid
LLM deployment, where proprietary models handle complex reasoning, while
open-source models are used for routine coding and validation tasks. To
evaluate MaCTG's effectiveness, we applied it to traditional image processing
auto-programming tasks, achieving a state-of-the-art accuracy of 83.33%.
Additionally, by leveraging its hybrid LLM configuration, MaCTG significantly
reduced operational costs by 89.09% compared to existing multi-agent
frameworks, demonstrating its efficiency, scalability, and real-world
applicability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distill Any Depth: Distillation Creates a Stronger Monocular Depth
  Estimator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19204v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19204v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiankang He, Dongyan Guo, Hongji Li, Ruibo Li, Ying Cui, Chi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in zero-shot monocular depth estimation(MDE) have
significantly improved generalization by unifying depth distributions through
normalized depth representations and by leveraging large-scale unlabeled data
via pseudo-label distillation. However, existing methods that rely on global
depth normalization treat all depth values equally, which can amplify noise in
pseudo-labels and reduce distillation effectiveness. In this paper, we present
a systematic analysis of depth normalization strategies in the context of
pseudo-label distillation. Our study shows that, under recent distillation
paradigms (e.g., shared-context distillation), normalization is not always
necessary, as omitting it can help mitigate the impact of noisy supervision.
Furthermore, rather than focusing solely on how depth information is
represented, we propose Cross-Context Distillation, which integrates both
global and local depth cues to enhance pseudo-label quality. We also introduce
an assistant-guided distillation strategy that incorporates complementary depth
priors from a diffusion-based teacher model, enhancing supervision diversity
and robustness. Extensive experiments on benchmark datasets demonstrate that
our approach significantly outperforms state-of-the-art methods, both
quantitatively and qualitatively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>project page: https://distill-any-depth-official.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in
  Vision-Language Alignment <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14148v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14148v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent advancements in large language models (LLMs) and pre-trained
vision models have accelerated the development of vision-language large models
(VLLMs), enhancing the interaction between visual and linguistic modalities.
Despite their notable success across various domains, VLLMs face challenges in
modality alignment, which can lead to issues like hallucinations and unsafe
content generation. Current alignment techniques often rely on coarse feedback
and external datasets, limiting scalability and performance. In this paper, we
propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel
self-alignment method that utilizes the model's own visual encoder as a
fine-grained verifier to improve vision-language alignment without the need for
additional data. By leveraging token-level feedback from the vision encoder,
FiSAO significantly improves vision-language alignment, even surpassing
traditional preference tuning methods that require additional data. Through
both theoretical analysis and experimental validation, we demonstrate that
FiSAO effectively addresses the misalignment problem in VLLMs, marking the
first instance of token-level rewards being applied to such models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages; Published as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task-Specific Directions: Definition, Exploration, and Utilization in
  Parameter Efficient Fine-Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01035v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01035v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chongjie Si, Zhiyi Shi, Shifan Zhang, Xiaokang Yang, Hanspeter Pfister, Wei Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models demonstrate impressive performance on downstream tasks,
yet they require extensive resource consumption when fully fine-tuning all
parameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT)
strategies, such as LoRA, have been developed. In this paper, we delve into the
concept of task-specific directions (TSDs), which are critical for
transitioning large models from pretrained states to task-specific enhancements
in PEFT. We propose a framework to clearly define these directions and explore
their properties and practical utilization challenges. We then introduce a
novel approach, LoRA-Dash, which aims to maximize the impact of TSDs during the
fine-tuning process, thereby enhancing model performance on targeted tasks.
Additionally, based on our exploration of TSD, we focus on an important issue
in PEFT: the initialization of LoRA. While some works have pointed out the
significance of initialization for LoRA's performance and proposed various
strategies, these methods are often empirical and not task-specific. To address
this issue, we propose LoRA-Init. Starting from TSD, we identify the directions
that require the most adjustment during fine-tuning for downstream tasks. By
initializing the matrices in LoRA with these directions, LoRA-Init
significantly enhances LoRA's performance. Moreover, we can combine LoRA-Dash
and LoRA-Init to create the final version of LoRA based on TSDs, which we refer
to as LoRA-TSD. Extensive experiments have conclusively demonstrated the
effectiveness of these methods, and in-depth analyses further reveal the
underlying mechanisms behind their success.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes in https://github.com/Chongjie-Si/Subspace-Tuning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MultiSensor-Home: A Wide-area Multi-modal Multi-view <span class="highlight-title">Dataset</span> for Action
  Recognition and <span class="highlight-title">Transformer</span>-based Sensor Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.02287v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.02287v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung Thanh Nguyen, Yasutomo Kawanishi, Vijay John, Takahiro Komamizu, Ichiro Ide
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal multi-view action recognition is a rapidly growing field in
computer vision, offering significant potential for applications in
surveillance. However, current datasets often fail to address real-world
challenges such as wide-area distributed settings, asynchronous data streams,
and the lack of frame-level annotations. Furthermore, existing methods face
difficulties in effectively modeling inter-view relationships and enhancing
spatial feature learning. In this paper, we introduce the MultiSensor-Home
dataset, a novel benchmark designed for comprehensive action recognition in
home environments, and also propose the Multi-modal Multi-view
Transformer-based Sensor Fusion (MultiTSF) method. The proposed
MultiSensor-Home dataset features untrimmed videos captured by distributed
sensors, providing high-resolution RGB and audio data along with detailed
multi-view frame-level action labels. The proposed MultiTSF method leverages a
Transformer-based fusion mechanism to dynamically model inter-view
relationships. Furthermore, the proposed method integrates a human detection
module to enhance spatial feature learning, guiding the model to prioritize
frames with human activity to enhance action the recognition accuracy.
Experiments on the proposed MultiSensor-Home and the existing MM-Office
datasets demonstrate the superiority of MultiTSF over the state-of-the-art
methods. Quantitative and qualitative results highlight the effectiveness of
the proposed method in advancing real-world multi-modal multi-view action
recognition.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 19th IEEE International Conference on Automatic Face and Gesture
  Recognition (FG 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Circular Image Deturbulence using Quasi-conformal Geometry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13432v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13432v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chu Chen, Han Zhang, Lok Ming Lui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The presence of inhomogeneous media between optical sensors and objects leads
to distorted imaging outputs, significantly complicating downstream
image-processing tasks. A key challenge in image restoration is the lack of
high-quality, paired-label images required for training supervised models. In
this paper, we introduce the Circular Quasi-Conformal Deturbulence (CQCD)
framework, an unsupervised approach for removing image distortions through a
circular architecture. This design ensures that the restored image remains both
geometrically accurate and visually faithful while preventing the accumulation
of incorrect estimations. The circular restoration process involves both
forward and inverse mapping. To ensure the bijectivity of the estimated
non-rigid deformations, computational quasi-conformal geometry theories are
leveraged to regularize the mapping, enforcing its homeomorphic properties.
This guarantees a well-defined transformation that preserves structural
integrity and prevents unwanted artifacts. Furthermore, tight-frame blocks are
integrated to encode distortion-sensitive features for precise recovery. To
validate the performance of our approach, we conduct evaluations on various
synthetic and real-world captured images. Experimental results demonstrate that
CQCD not only outperforms existing state-of-the-art deturbulence methods in
terms of image restoration quality but also provides highly accurate
deformation field estimations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for
  Multi-Instance Synthesis in Diffusion <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10148v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10148v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunyang Zhang, Zhenhong Sun, Zhicheng Zhang, Junyan Wang, Yu Zhang, Dong Gong, Huadong Mo, Daoyi Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image (T2I) generation models often struggle with multi-instance
synthesis (MIS), where they must accurately depict multiple distinct instances
in a single image based on complex prompts detailing individual features.
Traditional MIS control methods for UNet architectures like SD v1.5/SDXL fail
to adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated
attention between image and text tokens rather than text-image cross-attention.
To enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT.
Our token-wise and layer-wise analysis of attention maps reveals a hierarchical
response structure: instance tokens dominate early layers, background tokens in
middle layers, and attribute tokens in later layers. Building on this
observation, we propose a training-free approach for enhancing MIS in DiT-based
models with hierarchical and step-layer-wise attention specialty tuning (AST).
AST amplifies key regions while suppressing irrelevant areas in distinct
attention maps across layers and steps, guided by the hierarchical structure.
This optimizes multimodal interactions by hierarchically decoupling the complex
prompts with instance-based sketches. We evaluate our approach using upgraded
sketch-based layouts for the T2I-CompBench and customized complex scenes. Both
quantitative and qualitative results confirm our method enhances complex layout
generation, ensuring precise instance placement and attribute representation in
MIS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single
  Panoramic Image for Your Immerse Exploration <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.00387v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.00387v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zilong Huang, Jun He, Junyan Ye, Lihan Jiang, Weijia Li, Yiping Chen, Ting Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The reconstruction of immersive and realistic 3D scenes holds significant
practical importance in various fields of computer vision and computer
graphics. Typically, immersive and realistic scenes should be free from
obstructions by dynamic objects, maintain global texture consistency, and allow
for unrestricted exploration. The current mainstream methods for image-driven
scene construction involves iteratively refining the initial image using a
moving virtual camera to generate the scene. However, previous methods struggle
with visual discontinuities due to global texture inconsistencies under varying
camera poses, and they frequently exhibit scene voids caused by
foreground-background occlusions. To this end, we propose a novel layered 3D
scene reconstruction framework from panoramic image, named Scene4U.
Specifically, Scene4U integrates an open-vocabulary segmentation model with a
large language model to decompose a real panorama into multiple layers. Then,
we employs a layered repair module based on diffusion model to restore occluded
regions using visual cues and depth information, generating a hierarchical
representation of the scene. The multi-layer panorama is then initialized as a
3D Gaussian Splatting representation, followed by layered optimization, which
ultimately produces an immersive 3D scene with semantic and structural
consistency that supports free exploration. Scene4U outperforms
state-of-the-art method, improving by 24.24% in LPIPS and 24.40% in BRISQUE,
while also achieving the fastest training speed. Additionally, to demonstrate
the robustness of Scene4U and allow users to experience immersive scenes from
various landmarks, we build WorldVista3D dataset for 3D scene reconstruction,
which contains panoramic images of globally renowned sites. The implementation
code and dataset will be released at https://github.com/LongHZ140516/Scene4U .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025, 11 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large
  Multimodal Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09732v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09732v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyan Ye, Baichuan Zhou, Zilong Huang, Junan Zhang, Tianyi Bai, Hengrui Kang, Jun He, Honglin Lin, Zihao Wang, Tong Wu, Zhizheng Wu, Yiping Chen, Dahua Lin, Conghui He, Weijia Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of AI-generated content, the future internet may
be inundated with synthetic data, making the discrimination of authentic and
credible multimodal data increasingly challenging. Synthetic data detection has
thus garnered widespread attention, and the performance of large multimodal
models (LMMs) in this task has attracted significant interest. LMMs can provide
natural language explanations for their authenticity judgments, enhancing the
explainability of synthetic content detection. Simultaneously, the task of
distinguishing between real and synthetic data effectively tests the
perception, knowledge, and reasoning capabilities of LMMs. In response, we
introduce LOKI, a novel benchmark designed to evaluate the ability of LMMs to
detect synthetic data across multiple modalities. LOKI encompasses video,
image, 3D, text, and audio modalities, comprising 18K carefully curated
questions across 26 subcategories with clear difficulty levels. The benchmark
includes coarse-grained judgment and multiple-choice questions, as well as
fine-grained anomaly selection and explanation tasks, allowing for a
comprehensive analysis of LMMs. We evaluated 22 open-source LMMs and 6
closed-source models on LOKI, highlighting their potential as synthetic data
detectors and also revealing some limitations in the development of LMM
capabilities. More information about LOKI can be found at
https://opendatalab.github.io/LOKI/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 SPOTLIGHT, 83 pages, 63 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LangCoop: Collaborative Driving with Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13406v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13406v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangbo Gao, Yuheng Wu, Rujia Wang, Chenxi Liu, Yang Zhou, Zhengzhong Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-agent collaboration holds great promise for enhancing the safety,
reliability, and mobility of autonomous driving systems by enabling information
sharing among multiple connected agents. However, existing multi-agent
communication approaches are hindered by limitations of existing communication
media, including high bandwidth demands, agent heterogeneity, and information
loss. To address these challenges, we introduce LangCoop, a new paradigm for
collaborative autonomous driving that leverages natural language as a compact
yet expressive medium for inter-agent communication. LangCoop features two key
innovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured
zero-shot vision-language reasoning and Natural Language Information Packaging
(LangPack) for efficiently packaging information into concise, language-based
messages. Through extensive experiments conducted in the CARLA simulations, we
demonstrate that LangCoop achieves a remarkable 96\% reduction in communication
bandwidth (< 2KB per message) compared to image-based communication, while
maintaining competitive driving performance in the closed-loop evaluation. Our
project page and code are at https://xiangbogaobarry.github.io/LangCoop/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modality Unified Attack for Omni-Modality Person Re-Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12761v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12761v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yunfeng Ma, Yaonan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning based person re-identification (re-id) models have been widely
employed in surveillance systems. Recent studies have demonstrated that
black-box single-modality and cross-modality re-id models are vulnerable to
adversarial examples (AEs), leaving the robustness of multi-modality re-id
models unexplored. Due to the lack of knowledge about the specific type of
model deployed in the target black-box surveillance system, we aim to generate
modality unified AEs for omni-modality (single-, cross- and multi-modality)
re-id models. Specifically, we propose a novel Modality Unified Attack method
to train modality-specific adversarial generators to generate AEs that
effectively attack different omni-modality models. A multi-modality model is
adopted as the surrogate model, wherein the features of each modality are
perturbed by metric disruption loss before fusion. To collapse the common
features of omni-modality models, Cross Modality Simulated Disruption approach
is introduced to mimic the cross-modality feature embeddings by intentionally
feeding images to non-corresponding modality-specific subnetworks of the
surrogate model. Moreover, Multi Modality Collaborative Disruption strategy is
devised to facilitate the attacker to comprehensively corrupt the informative
content of person images by leveraging a multi modality feature collaborative
metric disruption loss. Extensive experiments show that our MUA method can
effectively attack the omni-modality re-id models, achieving 55.9%, 24.4%,
49.0% and 62.7% mean mAP Drop Rate, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages,3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust multi-coil MRI reconstruction via <span class="highlight-title">self-supervised</span> denoising 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12919v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12919v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asad Aali, Marius Arvinte, Sidharth Kumar, Yamin I. Arefeen, Jonathan I. Tamir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To examine the effect of incorporating self-supervised denoising as a
pre-processing step for training deep learning (DL) based reconstruction
methods on data corrupted by Gaussian noise. K-space data employed for training
are typically multi-coil and inherently noisy. Although DL-based reconstruction
methods trained on fully sampled data can enable high reconstruction quality,
obtaining large, noise-free datasets is impractical. We leverage Generalized
Stein's Unbiased Risk Estimate (GSURE) for denoising. We evaluate two DL-based
reconstruction methods: Diffusion Probabilistic Models (DPMs) and Model-Based
Deep Learning (MoDL). We evaluate the impact of denoising on the performance of
these DL-based methods in solving accelerated multi-coil magnetic resonance
imaging (MRI) reconstruction. The experiments were carried out on T2-weighted
brain and fat-suppressed proton-density knee scans. We observed that
self-supervised denoising enhances the quality and efficiency of MRI
reconstructions across various scenarios. Specifically, employing denoised
images rather than noisy counterparts when training DL networks results in
lower normalized root mean squared error (NRMSE), higher structural similarity
index measure (SSIM) and peak signal-to-noise ratio (PSNR) across different SNR
levels, including 32dB, 22dB, and 12dB for T2-weighted brain data, and 24dB,
14dB, and 4dB for fat-suppressed knee data. Overall, we showed that denoising
is an essential pre-processing technique capable of improving the efficacy of
DL-based MRI reconstruction methods under diverse conditions. By refining the
quality of input data, denoising enables training more effective DL networks,
potentially bypassing the need for noise-free reference MRI scans.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Event Quality Score (EQS): Assessing the Realism of Simulated Event
  Camera Streams via Distances in Latent Space <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12515v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12515v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaustav Chanda, Aayush Atul Verma, Arpitsinh Vaghela, Yezhou Yang, Bharatesh Chakravarthi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Event cameras promise a paradigm shift in vision sensing with their low
latency, high dynamic range, and asynchronous nature of events. Unfortunately,
the scarcity of high-quality labeled datasets hinders their widespread adoption
in deep learning-driven computer vision. To mitigate this, several simulators
have been proposed to generate synthetic event data for training models for
detection and estimation tasks. However, the fundamentally different sensor
design of event cameras compared to traditional frame-based cameras poses a
challenge for accurate simulation. As a result, most simulated data fail to
mimic data captured by real event cameras. Inspired by existing work on using
deep features for image comparison, we introduce event quality score (EQS), a
quality metric that utilizes activations of the RVT architecture. Through
sim-to-real experiments on the DSEC driving dataset, it is shown that a higher
EQS implies improved generalization to real-world data after training on
simulated events. Thus, optimizing for EQS can lead to developing more
realistic event camera simulators, effectively reducing the simulation gap. EQS
is available at https://github.com/eventbasedvision/EQS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at 2025 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition Workshops (CVPRW); Fifth International Workshop on Event-Based
  Vision</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting underdiagnosed medical conditions with opportunistic imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11686v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11686v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin, Akshay S. Chaudhari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Abdominal computed tomography (CT) scans are frequently performed in clinical
settings. Opportunistic CT involves repurposing routine CT images to extract
diagnostic information and is an emerging tool for detecting underdiagnosed
conditions such as sarcopenia, hepatic steatosis, and ascites. This study
utilizes deep learning methods to promote accurate diagnosis and clinical
documentation. We analyze 2,674 inpatient CT scans to identify discrepancies
between imaging phenotypes (characteristics derived from opportunistic CT
scans) and their corresponding documentation in radiology reports and ICD
coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans
diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively)
through either opportunistic imaging or radiology reports were ICD-coded. Our
findings demonstrate opportunistic CT's potential to enhance diagnostic
precision and accuracy of risk adjustment models, offering advancements in
precision medicine.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">14</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus
  LLM Judges <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nandan Thakur, Ronak Pradeep, Shivani Upadhyay, Daniel Campos, Nick Craswell, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) enables large language models (LLMs) to
generate answers with citations from source documents containing "ground
truth", thereby reducing system hallucinations. A crucial factor in RAG
evaluation is "support", whether the information in the cited documents
supports the answer. To this end, we conducted a large-scale comparative study
of 45 participant submissions on 36 topics to the TREC 2024 RAG Track,
comparing an automatic LLM judge (GPT-4o) against human judges for support
assessment. We considered two conditions: (1) fully manual assessments from
scratch and (2) manual assessments with post-editing of LLM predictions. Our
results indicate that for 56% of the manual from-scratch assessments, human and
GPT-4o predictions match perfectly (on a three-level scale), increasing to 72%
in the manual with post-editing condition. Furthermore, by carefully analyzing
the disagreements in an unbiased study, we found that an independent human
judge correlates better with GPT-4o than a human judge, suggesting that LLM
judges can be a reliable alternative for support assessment. To conclude, we
provide a qualitative analysis of human and GPT-4o errors to help guide future
iterations of support assessment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025 (short)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juyeon Kim, Geon Lee, Taeuk Kim, Kijung Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity linking (EL) aligns textual mentions with their corresponding entities
in a knowledge base, facilitating various applications such as semantic search
and question answering. Recent advances in multimodal entity linking (MEL) have
shown that combining text and images can reduce ambiguity and improve alignment
accuracy. However, most existing MEL methods overlook the rich structural
information available in the form of knowledge-graph (KG) triples. In this
paper, we propose KGMEL, a novel framework that leverages KG triples to enhance
MEL. Specifically, it operates in three stages: (1) Generation: Produces
high-quality triples for each mention by employing vision-language models based
on its text and images. (2) Retrieval: Learns joint mention-entity
representations, via contrastive learning, that integrate text, images, and
(generated or KG) triples to retrieve candidate entities for each mention. (3)
Reranking: Refines the KG triples of the candidate entities and employs large
language models to identify the best-matching entity for the mention. Extensive
experiments on benchmark datasets demonstrate that KGMEL outperforms existing
methods. Our code and datasets are available at:
https://github.com/juyeonnn/KGMEL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGIR 2025 (Short)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation
  with Large Language Models <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15068v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15068v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronak Pradeep, Nandan Thakur, Shivani Upadhyay, Daniel Campos, Nick Craswell, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have significantly enhanced the capabilities of
information access systems, especially with retrieval-augmented generation
(RAG). Nevertheless, the evaluation of RAG systems remains a barrier to
continued progress, a challenge we tackle in this work by proposing an
automatic evaluation framework that is validated against human annotations. We
believe that the nugget evaluation methodology provides a solid foundation for
evaluating RAG systems. This approach, originally developed for the TREC
Question Answering (QA) Track in 2003, evaluates systems based on atomic facts
that should be present in good answers. Our efforts focus on "refactoring" this
methodology, where we describe the AutoNuggetizer framework that specifically
applies LLMs to both automatically create nuggets and automatically assign
nuggets to system answers. In the context of the TREC 2024 RAG Track, we
calibrate a fully automatic approach against strategies where nuggets are
created manually or semi-manually by human assessors and then assigned manually
to system answers. Based on results from a community-wide evaluation, we
observe strong agreement at the run level between scores derived from fully
automatic nugget evaluation and human-based variants. The agreement is stronger
when individual framework components such as nugget assignment are automated
independently. This suggests that our evaluation framework provides tradeoffs
between effort and quality that can be used to guide the development of future
RAG systems. However, further research is necessary to refine our approach,
particularly in establishing robust per-topic agreement to diagnose system
failures effectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in SIGIR 2025. Significant updates and revisions to
  arXiv:2411.09607</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Linear Item-Item Model with Neural Knowledge for Session-based
  Recommendation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15057v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15057v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minjin Choi, Sunkyung Lee, Seongmin Park, Jongwuk Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based recommendation (SBR) aims to predict users' subsequent actions
by modeling short-term interactions within sessions. Existing neural models
primarily focus on capturing complex dependencies for sequential item
transitions. As an alternative solution, linear item-item models mainly
identify strong co-occurrence patterns across items and support faster
inference speed. Although each paradigm has been actively studied in SBR, their
fundamental differences in capturing item relationships and how to bridge these
distinct modeling paradigms effectively remain unexplored. In this paper, we
propose a novel SBR model, namely Linear Item-Item model with Neural Knowledge
(LINK), which integrates both types of knowledge into a unified linear
framework. Specifically, we design two specialized components of LINK: (i)
Linear knowledge-enhanced Item-item Similarity model (LIS), which refines the
item similarity correlation via self-distillation, and (ii) Neural
knowledge-enhanced Item-item Transition model (NIT), which seamlessly
incorporates complicated neural knowledge distilled from the off-the-shelf
neural model. Extensive experiments demonstrate that LINK outperforms
state-of-the-art linear SBR models across six real-world datasets, achieving
improvements of up to 14.78% and 11.04% in Recall@20 and MRR@20 while showing
up to 813x fewer inference FLOPs. Our code is available at
https://github.com/jin530/LINK.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGIR 2025, 9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Accuracy-Fairness Trade-offs in Re-ranking through
  Elasticity in Economics <span class="chip">SIGIR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14991v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14991v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Xu, Jujia Zhao, Wenjie Wang, Liang Pang, Jun Xu, Tat-Seng Chua, Maarten de Rijke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fairness is an increasingly important factor in re-ranking tasks. Prior work
has identified a trade-off between ranking accuracy and item fairness. However,
the underlying mechanisms are still not fully understood. An analogy can be
drawn between re-ranking and the dynamics of economic transactions. The
accuracy-fairness trade-off parallels the coupling of the commodity tax
transfer process. Fairness considerations in re-ranking, similar to a commodity
tax on suppliers, ultimately translate into a cost passed on to consumers.
Analogously, item-side fairness constraints result in a decline in user-side
accuracy. In economics, the extent to which commodity tax on the supplier (item
fairness) transfers to commodity tax on users (accuracy loss) is formalized
using the notion of elasticity. The re-ranking fairness-accuracy trade-off is
similarly governed by the elasticity of utility between item groups. This
insight underscores the limitations of current fair re-ranking evaluations,
which often rely solely on a single fairness metric, hindering comprehensive
assessment of fair re-ranking algorithms. Centered around the concept of
elasticity, this work presents two significant contributions. We introduce the
Elastic Fairness Curve (EF-Curve) as an evaluation framework. This framework
enables a comparative analysis of algorithm performance across different
elasticity levels, facilitating the selection of the most suitable approach.
Furthermore, we propose ElasticRank, a fair re-ranking algorithm that employs
elasticity calculations to adjust inter-item distances within a curved space.
Experiments on three widely used ranking datasets demonstrate its effectiveness
and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in SIGIR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Col<span class="highlight-title">BERT</span>-serve: Efficient Multi-Stage Memory-Mapped Scoring <span class="chip">ECIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14903v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14903v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaili Huang, Thejas Venkatesh, Uma Dingankar, Antonio Mallia, Daniel Campos, Jian Jiao, Christopher Potts, Matei Zaharia, Kwabena Boahen, Omar Khattab, Saarthak Sarup, Keshav Santhanam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study serving retrieval models, specifically late interaction models like
ColBERT, to many concurrent users at once and under a small budget, in which
the index may not fit in memory. We present ColBERT-serve, a novel serving
system that applies a memory-mapping strategy to the ColBERT index, reducing
RAM usage by 90% and permitting its deployment on cheap servers, and
incorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's
query latency and supporting many concurrent queries in parallel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stitching Inner Product and Euclidean Metrics for Topology-aware Maximum
  Inner Product Search <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14861v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14861v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingyang Chen, Cong Fu, Xiangyu Ke, Yunjun Gao, Yabo Ni, Anxiang Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Maximum Inner Product Search (MIPS) is a fundamental challenge in machine
learning and information retrieval, particularly in high-dimensional data
applications. Existing approaches to MIPS either rely solely on Inner Product
(IP) similarity, which faces issues with local optima and redundant
computations, or reduce the MIPS problem to the Nearest Neighbor Search under
the Euclidean metric via space projection, leading to topology destruction and
information loss. Despite the divergence of the two paradigms, we argue that
there is no inherent binary opposition between IP and Euclidean metrics. By
stitching IP and Euclidean in the design of indexing and search algorithms, we
can significantly enhance MIPS performance. Specifically, this paper explores
the theoretical and empirical connections between these two metrics from the
MIPS perspective. Our investigation, grounded in graph-based search, reveals
that different indexing and search strategies offer distinct advantages for
MIPS, depending on the underlying data topology. Building on these insights, we
introduce a novel graph-based index called Metric-Amphibious Graph (MAG) and a
corresponding search algorithm, Adaptive Navigation with Metric Switch (ANMS).
To facilitate parameter tuning for optimal performance, we identify three
statistical indicators that capture essential data topology properties and
correlate strongly with parameter tuning. Extensive experiments on 12
real-world datasets demonstrate that MAG outperforms existing state-of-the-art
methods, achieving up to 4x search speedup while maintaining adaptability and
scalability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing the Patent Matching Capability of Large Language Models via
  the Memory Graph 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14845v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14845v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiushi Xiong, Zhipeng Xu, Zhenghao Liu, Mengjia Wang, Zulong Chen, Yue Sun, Yu Gu, Xiaohua Li, Ge Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intellectual Property (IP) management involves strategically protecting and
utilizing intellectual assets to enhance organizational innovation,
competitiveness, and value creation. Patent matching is a crucial task in
intellectual property management, which facilitates the organization and
utilization of patents. Existing models often rely on the emergent capabilities
of Large Language Models (LLMs) and leverage them to identify related patents
directly. However, these methods usually depend on matching keywords and
overlook the hierarchical classification and categorical relationships of
patents. In this paper, we propose MemGraph, a method that augments the patent
matching capabilities of LLMs by incorporating a memory graph derived from
their parametric memory. Specifically, MemGraph prompts LLMs to traverse their
memory to identify relevant entities within patents, followed by attributing
these entities to corresponding ontologies. After traversing the memory graph,
we utilize extracted entities and ontologies to improve the capability of LLM
in comprehending the semantics of patents. Experimental results on the
PatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a
17.68% performance improvement over baseline LLMs. The further analysis
highlights the generalization ability of MemGraph across various LLMs, both
in-domain and out-of-domain, and its capacity to enhance the internal reasoning
processes of LLMs during patent matching. All data and codes are available at
https://github.com/NEUIR/MemGraph.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring $\ell_0$ Sparsification for Inference-free Sparse Retrievers <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14839v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14839v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinjie Shen, Zhichao Geng, Yang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With increasing demands for efficiency, information retrieval has developed a
branch of sparse retrieval, further advancing towards inference-free retrieval
where the documents are encoded during indexing time and there is no
model-inference for queries. Existing sparse retrieval models rely on FLOPS
regularization for sparsification, while this mechanism was originally designed
for Siamese encoders, it is considered to be suboptimal in inference-free
scenarios which is asymmetric. Previous attempts to adapt FLOPS for
inference-free scenarios have been limited to rule-based methods, leaving the
potential of sparsification approaches for inference-free retrieval models
largely unexplored. In this paper, we explore $\ell_0$ inspired sparsification
manner for inference-free retrievers. Through comprehensive out-of-domain
evaluation on the BEIR benchmark, our method achieves state-of-the-art
performance among inference-free sparse retrieval models and is comparable to
leading Siamese sparse retrieval models. Furthermore, we provide insights into
the trade-off between retrieval effectiveness and computational efficiency,
demonstrating practical value for real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Self-improving Token Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14808v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14808v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mario M. Kubek, Shiraj Pokharel, Thomas Böhme, Emma L. McDaniel, Herwig Unger, Armin R. Mikler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article introduces a novel and fast method for refining pre-trained
static word or, more generally, token embeddings. By incorporating the
embeddings of neighboring tokens in text corpora, it continuously updates the
representation of each token, including those without pre-assigned embeddings.
This approach effectively addresses the out-of-vocabulary problem, too.
Operating independently of large language models and shallow neural networks,
it enables versatile applications such as corpus exploration, conceptual
search, and word sense disambiguation. The method is designed to enhance token
representations within topically homogeneous corpora, where the vocabulary is
restricted to a specific domain, resulting in more meaningful embeddings
compared to general-purpose pre-trained vectors. As an example, the methodology
is applied to explore storm events and their impacts on infrastructure and
communities using narratives from a subset of the NOAA Storm Events database.
The article also demonstrates how the approach improves the representation of
storm-related terms over time, providing valuable insights into the evolving
nature of disaster narratives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 4 figures, 3 tables, accepted at the 2025 25th
  International Conference on Innovations for Community Services (I4CS), June
  11 - 13, Munich, Germany, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The 1st EReL@MIR Workshop on Efficient Representation Learning for
  Multimodal Information Retrieval <span class="chip">WWW2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14788v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14788v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junchen Fu, Xuri Ge, Xin Xin, Haitao Yu, Yue Feng, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal representation learning has garnered significant attention in the
AI community, largely due to the success of large pre-trained multimodal
foundation models like LLaMA, GPT, Mistral, and CLIP. These models have
achieved remarkable performance across various tasks of multimodal information
retrieval (MIR), including web search, cross-modal retrieval, and recommender
systems, etc. However, due to their enormous parameter sizes, significant
efficiency challenges emerge across training, deployment, and inference stages
when adapting these models' representation for IR tasks. These challenges
present substantial obstacles to the practical adaptation of foundation models
for representation learning in information retrieval tasks.
  To address these pressing issues, we propose organizing the first EReL@MIR
workshop at the Web Conference 2025, inviting participants to explore novel
solutions, emerging problems, challenges, efficiency evaluation metrics and
benchmarks. This workshop aims to provide a platform for both academic and
industry researchers to engage in discussions, share insights, and foster
collaboration toward achieving efficient and effective representation learning
for multimodal information retrieval in the era of large foundation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WWW2025 Workshop Summary</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FROG: Effective Friend Recommendation in Online Games via Modality-aware
  User Preferences <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09428v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09428v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiwei Wang, Dandan Lin, Wenqing Lin, Ziming Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the convenience of mobile devices, the online games have become an
important part for user entertainments in reality, creating a demand for friend
recommendation in online games. However, none of existing approaches can
effectively incorporate the multi-modal user features (e.g., images and texts)
with the structural information in the friendship graph, due to the following
limitations: (1) some of them ignore the high-order structural proximity
between users, (2) some fail to learn the pairwise relevance between users at
modality-specific level, and (3) some cannot capture both the local and global
user preferences on different modalities. By addressing these issues, in this
paper, we propose an end-to-end model FROG that better models the user
preferences on potential friends. Comprehensive experiments on both offline
evaluation and online deployment at Tencent have demonstrated the superiority
of FROG over existing approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MRAMG-Bench: A Comprehensive Benchmark for Advancing Multimodal
  Retrieval-Augmented Multimodal Generation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinhan Yu, Zhiyou Xiao, Binghui Li, Zhengren Wang, Chong Chen, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Retrieval-Augmented Generation (RAG) have significantly
improved response accuracy and relevance by incorporating external knowledge
into Large Language Models (LLMs). However, existing RAG methods primarily
focus on generating text-only answers, even in Multimodal Retrieval-Augmented
Generation (MRAG) scenarios, where multimodal elements are retrieved to assist
in generating text answers. To address this, we introduce the Multimodal
Retrieval-Augmented Multimodal Generation (MRAMG) task, in which we aim to
generate multimodal answers that combine both text and images, fully leveraging
the multimodal data within a corpus. Despite growing attention to this
challenging task, a notable lack of a comprehensive benchmark persists for
effectively evaluating its performance. To bridge this gap, we provide
MRAMG-Bench, a meticulously curated, human-annotated benchmark comprising 4,346
documents, 14,190 images, and 4,800 QA pairs, distributed across six distinct
datasets and spanning three domains: Web, Academia, and Lifestyle. The datasets
incorporate diverse difficulty levels and complex multi-image scenarios,
providing a robust foundation for evaluating the MRAMG task. To facilitate
rigorous evaluation, MRAMG-Bench incorporates a comprehensive suite of both
statistical and LLM-based metrics, enabling a thorough analysis of the
performance of generative models in the MRAMG task. Additionally, we propose an
efficient and flexible multimodal answer generation framework that can leverage
LLMs/MLLMs to generate multimodal responses. Our datasets and complete
evaluation results for 11 popular generative models are available at
https://github.com/MRAMG-Bench/MRAMG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at SIGIR 2025; 11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Representations Can be What Recommenders Need: Findings and
  Potentials <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05441v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05441v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to
prevailing understanding that LMs and traditional recommenders learn two
distinct representation spaces due to the huge gap in language and behavior
modeling objectives, this work re-examines such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the possible homomorphism between the
advanced language representation space and an effective item representation
space for recommendation, implying that collaborative signals may be implicitly
encoded within LMs. Motivated by these findings, we explore the possibility of
designing advanced collaborative filtering (CF) models purely based on language
representations without ID-based embeddings. To be specific, we incorporate
several crucial components to build a simple yet effective model, with item
titles as the input. Empirical results show that such a simple model can
outperform leading ID-based CF models, which sheds light on using language
representations for better recommendation. Moreover, we systematically analyze
this simple model and find several key features for using advanced language
representations: a good initialization for item representations, zero-shot
recommendation abilities, and being aware of user intention. Our findings
highlight the connection between language modeling and behavior modeling, which
can inspire both natural language processing and recommender system
communities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 (Oral). Codes are available at
  https://github.com/LehengTHU/AlphaRec</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">123</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stop Summation: Min-Form Credit Assignment Is All Process Reward Model
  Needs for Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15275v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15275v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Cheng, Ruixi Qiao, Lijun Li, Chao Guo, Junle Wang, Gang Xiong, Yisheng Lv, Fei-Yue Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Process reward models (PRMs) have proven effective for test-time scaling of
Large Language Models (LLMs) on challenging reasoning tasks. However, reward
hacking issues with PRMs limit their successful application in reinforcement
fine-tuning. In this paper, we identify the main cause of PRM-induced reward
hacking: the canonical summation-form credit assignment in reinforcement
learning (RL), which defines the value as cumulative gamma-decayed future
rewards, easily induces LLMs to hack steps with high rewards. To address this,
we propose PURE: Process sUpervised Reinforcement lEarning. The key innovation
of PURE is a min-form credit assignment that formulates the value function as
the minimum of future rewards. This method significantly alleviates reward
hacking by limiting the value function range and distributing advantages more
reasonably. Through extensive experiments on 3 base models, we show that
PRM-based approaches enabling min-form credit assignment achieve comparable
reasoning performance to verifiable reward-based methods within only 30% steps.
In contrast, the canonical sum-form credit assignment collapses training even
at the beginning! Additionally, when we supplement PRM-based fine-tuning with
just 10% verifiable rewards, we further alleviate reward hacking and produce
the best fine-tuned model based on Qwen2.5-Math-7B in our experiments,
achieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5
benchmarks. Moreover, we summarize the observed reward hacking cases and
analyze the causes of training collapse. Code and models are available at
https://github.com/CJReinforce/PURE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Roll the dice & look before you leap: Going beyond the creative limits
  of next-token prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15266v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15266v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vaishnavh Nagarajan, Chen Henry Wu, Charles Ding, Aditi Raghunathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We design a suite of minimal algorithmic tasks that are a loose abstraction
of open-ended real-world tasks. This allows us to cleanly and controllably
quantify the creative limits of the present-day language model. Much like
real-world tasks that require a creative, far-sighted leap of thought, our
tasks require an implicit, open-ended stochastic planning step that either (a)
discovers new connections in an abstract knowledge graph (like in wordplay,
drawing analogies, or research) or (b) constructs new patterns (like in
designing math problems or new proteins). In these tasks, we empirically and
conceptually argue how next-token learning is myopic and memorizes excessively;
comparatively, multi-token approaches, namely teacherless training and
diffusion models, excel in producing diverse and original output. Secondly, in
our tasks, we find that to elicit randomness from the Transformer without
hurting coherence, it is better to inject noise right at the input layer (via a
method we dub hash-conditioning) rather than defer to temperature sampling from
the output layer. Thus, our work offers a principled, minimal test-bed for
analyzing open-ended creative skills, and offers new arguments for going beyond
next-token learning and softmax-based sampling. We make part of the code
available under https://github.com/chenwu98/algorithmic-creativity
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Language Models for Automated Patient Record Linkage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15261v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15261v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Beheshti, Lovedeep Gondara, Iris Zachary
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objective: Healthcare data fragmentation presents a major challenge for
linking patient data, necessitating robust record linkage to integrate patient
records from diverse sources. This study investigates the feasibility of
leveraging language models for automated patient record linkage, focusing on
two key tasks: blocking and matching. Materials and Methods: We utilized
real-world healthcare data from the Missouri Cancer Registry and Research
Center, linking patient records from two independent sources using
probabilistic linkage as a baseline. A transformer-based model, RoBERTa, was
fine-tuned for blocking using sentence embeddings. For matching, several
language models were experimented under fine-tuned and zero-shot settings,
assessing their performance against ground truth labels. Results: The
fine-tuned blocking model achieved a 92% reduction in the number of candidate
pairs while maintaining near-perfect recall. In the matching task, fine-tuned
Mistral-7B achieved the best performance with only 6 incorrect predictions.
Among zero-shot models, Mistral-Small-24B performed best, with a total of 55
incorrect predictions. Discussion: Fine-tuned language models achieved strong
performance in patient record blocking and matching with minimal errors.
However, they remain less accurate and efficient than a hybrid rule-based and
probabilistic approach for blocking. Additionally, reasoning models like
DeepSeek-R1 are impractical for large-scale record linkage due to high
computational costs. Conclusion: This study highlights the potential of
language models for automating patient record linkage, offering improved
efficiency by eliminating the manual efforts required to perform patient record
linkage. Overall, language models offer a scalable solution that can enhance
data integration, reduce manual effort, and support disease surveillance and
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as
  Test-Time Scaling Evaluators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15253v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15253v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilun Zhou, Austin Xu, Peifeng Wang, Caiming Xiong, Shafiq Joty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling test-time computation, or affording a generator large language model
(LLM) extra compute during inference, typically employs the help of external
non-generative evaluators (i.e., reward models). Concurrently, LLM-judges,
models trained to generate evaluations and critiques (explanations) in natural
language, are becoming increasingly popular in automatic evaluation. Despite
judge empirical successes, their effectiveness as evaluators in test-time
scaling settings is largely unknown. In this paper, we introduce the Judge
Evaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge
performance in three domains (math reasoning, code generation, and instruction
following) under three task settings: response reranking, step-level beam
search, and critique-based response refinement. We evaluate 10 different judge
models (7B-70B parameters) for 8 different base generator models (6.7B-72B
parameters). Our benchmark shows that while judges are competitive with outcome
reward models in reranking, they are consistently worse than process reward
models in beam search procedures. Furthermore, though unique to LLM-judges,
their natural language critiques are currently ineffective in guiding the
generator towards better responses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally. The codebase is at
  https://github.com/SalesforceAIResearch/jetts-benchmark</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SuoiAI: Building a <span class="highlight-title">Dataset</span> for Aquatic Invertebrates in Vietnam <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tue Vo, Lakshay Sharma, Tuan Dinh, Khuong Dinh, Trang Nguyen, Trung Phan, Minh Do, Duong Vu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and monitoring aquatic biodiversity is critical for ecological
health and conservation efforts. This paper proposes SuoiAI, an end-to-end
pipeline for building a dataset of aquatic invertebrates in Vietnam and
employing machine learning (ML) techniques for species classification. We
outline the methods for data collection, annotation, and model training,
focusing on reducing annotation effort through semi-supervised learning and
leveraging state-of-the-art object detection and classification models. Our
approach aims to overcome challenges such as data scarcity, fine-grained
classification, and deployment in diverse environmental conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a workshop paper at "Tackling Climate Change with
  Machine Learning", ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Learning Parallel Pancakes with Mostly Uniform Weights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15251v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15251v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilias Diakonikolas, Daniel M. Kane, Sushrut Karmalkar, Jasper C. H. Lee, Thanasis Pittas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on
$\mathbb{R}^d$. This task is known to have complexity $d^{\Omega(k)}$ in full
generality. To circumvent this exponential lower bound on the number of
components, research has focused on learning families of GMMs satisfying
additional structural properties. A natural assumption posits that the
component weights are not exponentially small and that the components have the
same unknown covariance. Recent work gave a $d^{O(\log(1/w_{\min}))}$-time
algorithm for this class of GMMs, where $w_{\min}$ is the minimum weight. Our
first main result is a Statistical Query (SQ) lower bound showing that this
quasi-polynomial upper bound is essentially best possible, even for the special
case of uniform weights. Specifically, we show that it is SQ-hard to
distinguish between such a mixture and the standard Gaussian. We further
explore how the distribution of weights affects the complexity of this task.
Our second main result is a quasi-polynomial upper bound for the aforementioned
testing task when most of the weights are uniform while a small fraction of the
weights are potentially arbitrary.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Faster Algorithms for Agnostically Learning Disjunctions and their
  Implications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15244v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15244v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilias Diakonikolas, Daniel M. Kane, Lisheng Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the algorithmic task of learning Boolean disjunctions in the
distribution-free agnostic PAC model. The best known agnostic learner for the
class of disjunctions over $\{0, 1\}^n$ is the $L_1$-polynomial regression
algorithm, achieving complexity $2^{\tilde{O}(n^{1/2})}$. This complexity bound
is known to be nearly best possible within the class of Correlational
Statistical Query (CSQ) algorithms. In this work, we develop an agnostic
learner for this concept class with complexity $2^{\tilde{O}(n^{1/3})}$. Our
algorithm can be implemented in the Statistical Query (SQ) model, providing the
first separation between the SQ and CSQ models in distribution-free agnostic
learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Single-loop Algorithms for Stochastic Non-convex Optimization with
  Weakly-Convex Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15243v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15243v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ming Yang, Gang Li, Quanqi Hu, Qihang Lin, Tianbao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Constrained optimization with multiple functional inequality constraints has
significant applications in machine learning. This paper examines a crucial
subset of such problems where both the objective and constraint functions are
weakly convex. Existing methods often face limitations, including slow
convergence rates or reliance on double-loop algorithmic designs. To overcome
these challenges, we introduce a novel single-loop penalty-based stochastic
algorithm. Following the classical exact penalty method, our approach employs a
{\bf hinge-based penalty}, which permits the use of a constant penalty
parameter, enabling us to achieve a {\bf state-of-the-art complexity} for
finding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our
algorithm to address finite-sum coupled compositional objectives, which are
prevalent in artificial intelligence applications, establishing improved
complexity over existing approaches. Finally, we validate our method through
experiments on fair learning with receiver operating characteristic (ROC)
fairness constraints and continual learning with non-forgetting constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees
  for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhossein Mollaali, Christian Bolivar Moya, Amanda A. Howard, Alexander Heinlein, Panos Stinis, Guang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores uncertainty quantification (UQ) methods in the context of
Kolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to
obtain a heuristic measure of UQ, enhancing interpretability and robustness in
modeling complex functions. Building on this, we introduce Conformalized-KANs,
which integrate conformal prediction, a distribution-free UQ technique, with
KAN ensembles to generate calibrated prediction intervals with guaranteed
coverage. Extensive numerical experiments are conducted to evaluate the
effectiveness of these methods, focusing particularly on the robustness and
accuracy of the prediction intervals under various hyperparameter settings. We
show that the conformal KAN predictions can be applied to recent extensions of
KANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The
results demonstrate the potential of our approaches to improve the reliability
and applicability of KANs in scientific machine learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures,</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Values in the Wild: Discovering and Analyzing Values in Real-World
  Language Model Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15236v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15236v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saffron Huang, Esin Durmus, Miles McCain, Kunal Handa, Alex Tamkin, Jerry Hong, Michael Stern, Arushi Somani, Xiuruo Zhang, Deep Ganguli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI assistants can impart value judgments that shape people's decisions and
worldviews, yet little is known empirically about what values these systems
rely on in practice. To address this, we develop a bottom-up,
privacy-preserving method to extract the values (normative considerations
stated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit
in hundreds of thousands of real-world interactions. We empirically discover
and taxonomize 3,307 AI values and study how they vary by context. We find that
Claude expresses many practical and epistemic values, and typically supports
prosocial human values while resisting values like "moral nihilism". While some
values appear consistently across contexts (e.g. "transparency"), many are more
specialized and context-dependent, reflecting the diversity of human
interlocutors and their varied contexts. For example, "harm prevention" emerges
when Claude resists users, "historical accuracy" when responding to queries
about controversial events, "healthy boundaries" when asked for relationship
advice, and "human agency" in technology ethics discussions. By providing the
first large-scale empirical mapping of AI values in deployment, our work
creates a foundation for more grounded evaluation and design of values in AI
systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>44 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global
  Scoring and Calibrated Thresholding <span class="chip">AISTATS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarah Alnegheimish, Zelin He, Matthew Reimherr, Akash Chandrayan, Abhinav Pradhan, Luca D'Angelo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the widespread availability of sensor data across industrial and
operational systems, we frequently encounter heterogeneous time series from
multiple systems. Anomaly detection is crucial for such systems to facilitate
predictive maintenance. However, most existing anomaly detection methods are
designed for either univariate or single-system multivariate data, making them
insufficient for these complex scenarios. To address this, we introduce
M$^2$AD, a framework for unsupervised anomaly detection in multivariate time
series data from multiple systems. M$^2$AD employs deep models to capture
expected behavior under normal conditions, using the residuals as indicators of
potential anomalies. These residuals are then aggregated into a global anomaly
score through a Gaussian Mixture Model and Gamma calibration. We theoretically
demonstrate that this framework can effectively address heterogeneity and
dependencies across sensors and systems. Empirically, M$^2$AD outperforms
existing methods in extensive evaluations by 21% on average, and its
effectiveness is demonstrated on a large-scale real-world case study on 130
assets in Amazon Fulfillment Centers. Our code and results are available at
https://github.com/sarahmish/M2AD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Deep Learning Framework for Sequence Mining with Bidirectional LSTM
  and Multi-Scale Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15223v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15223v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Yang, Yu Cheng, Yaokun Ren, Yujia Lou, Minggu Wei, Honghui Xin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the challenges of mining latent patterns and modeling
contextual dependencies in complex sequence data. A sequence pattern mining
algorithm is proposed by integrating Bidirectional Long Short-Term Memory
(BiLSTM) with a multi-scale attention mechanism. The BiLSTM captures both
forward and backward dependencies in sequences, enhancing the model's ability
to perceive global contextual structures. At the same time, the multi-scale
attention module assigns adaptive weights to key feature regions under
different window sizes. This improves the model's responsiveness to both local
and global important information. Extensive experiments are conducted on a
publicly available multivariate time series dataset. The proposed model is
compared with several mainstream sequence modeling methods. Results show that
it outperforms existing models in terms of accuracy, precision, and recall.
This confirms the effectiveness and robustness of the proposed architecture in
complex pattern recognition tasks. Further ablation studies and sensitivity
analyses are carried out to investigate the effects of attention scale and
input sequence length on model performance. These results provide empirical
support for structural optimization of the model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fully Bayesian Approaches to Topics over Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julián Cendrero, Julio Gonzalo, Ivar Zapata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Topics over Time (ToT) model captures thematic changes in timestamped
datasets by explicitly modeling publication dates jointly with word
co-occurrence patterns. However, ToT was not approached in a fully Bayesian
fashion, a flaw that makes it susceptible to stability problems. To address
this issue, we propose a fully Bayesian Topics over Time (BToT) model via the
introduction of a conjugate prior to the Beta distribution. This prior acts as
a regularization that prevents the online version of the algorithm from
unstable updates when a topic is poorly represented in a mini-batch. The
characteristics of this prior to the Beta distribution are studied here for the
first time. Still, this model suffers from a difference in scale between the
single-time observations and the multiplicity of words per document. A
variation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a
solution. In WBToT, publication dates are repeated a certain number of times
per document, which balances the relative influence of words and timestamps
along the inference process. We have tested our models on two datasets: a
collection of over 200 years of US state-of-the-union (SOTU) addresses and a
large-scale COVID-19 Twitter corpus of 10 million tweets. The results show that
WBToT captures events better than Latent Dirichlet Allocation and other SOTA
topic models like BERTopic: the median absolute deviation of the topic presence
over time is reduced by $51\%$ and $34\%$, respectively. Our experiments also
demonstrate the superior coherence of WBToT over BToT, which highlights the
importance of balancing the time and word modalities. Finally, we illustrate
the stability of the online optimization algorithm in WBToT, which allows the
application of WBToT to problems that are intractable for standard ToT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DRAGON: Distributional Rewards Optimize Diffusion Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yatong Bai, Jonah Casebeer, Somayeh Sojoudi, Nicholas J. Bryan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Distributional RewArds for Generative OptimizatioN (DRAGON), a
versatile framework for fine-tuning media generation models towards a desired
outcome. Compared with traditional reinforcement learning with human feedback
(RLHF) or pairwise preference approaches such as direct preference optimization
(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate
either individual examples or distributions of them, making it compatible with
a broad spectrum of instance-wise, instance-to-distribution, and
distribution-to-distribution rewards. Leveraging this versatility, we construct
novel reward functions by selecting an encoder and a set of reference examples
to create an exemplar distribution. When cross-modality encoders such as CLAP
are used, the reference examples may be of a different modality (e.g., text
versus audio). Then, DRAGON gathers online and on-policy generations, scores
them to construct a positive demonstration set and a negative set, and
leverages the contrast between the two sets to maximize the reward. For
evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20
different reward functions, including a custom music aesthetics model, CLAP
score, Vendi diversity, and Frechet audio distance (FAD). We further compare
instance-wise (per-song) and full-dataset FAD settings while ablating multiple
FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an
81.45% average win rate. Moreover, reward functions based on exemplar sets
indeed enhance generations and are comparable to model-based rewards. With an
appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality
win rate without training on human preference annotations. As such, DRAGON
exhibits a new approach to designing and optimizing reward functions for
improving human-perceived quality. Sound examples at
https://ml-dragon.github.io/web.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Histogram-based Parameter-efficient Tuning for Passive Sonar
  Classification <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirmohammad Mohammadi, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-efficient transfer learning (PETL) methods adapt large artificial
neural networks to downstream tasks without fine-tuning the entire model.
However, existing additive methods, such as adapters, sometimes struggle to
capture distributional shifts in intermediate feature embeddings. We propose a
novel histogram-based parameter-efficient tuning (HPT) technique that captures
the statistics of the target domain and modulates the embeddings. Experimental
results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)
demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves
91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields
feature representations closer to those of fully fine-tuned models. Overall,
HPT balances parameter savings and performance, providing a distribution-aware
alternative to existing adapters and shows a promising direction for scalable
transfer learning in resource-constrained environments. The code is publicly
available:
https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures. Submitted to IEEE WASPAA 2025 for possible
  publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Causal Convolutional Low-rank Representation Model for Imputation of
  Water Quality Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15209v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15209v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Liao, Bing Yang, Tan Dongli, Cai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The monitoring of water quality is a crucial part of environmental
protection, and a large number of monitors are widely deployed to monitor water
quality. Due to unavoidable factors such as data acquisition breakdowns,
sensors and communication failures, water quality monitoring data suffers from
missing values over time, resulting in High-Dimensional and Sparse (HDS) Water
Quality Data (WQD). The simple and rough filling of the missing values leads to
inaccurate results and affects the implementation of relevant measures.
Therefore, this paper proposes a Causal convolutional Low-rank Representation
(CLR) model for imputing missing WQD to improve the completeness of the WQD,
which employs a two-fold idea: a) applying causal convolutional operation to
consider the temporal dependence of the low-rank representation, thus
incorporating temporal information to improve the imputation accuracy; and b)
implementing a hyperparameters adaptation scheme to automatically adjust the
best hyperparameters during model training, thereby reducing the tedious manual
adjustment of hyper-parameters. Experimental studies on three real-world water
quality datasets demonstrate that the proposed CLR model is superior to some of
the existing state-of-the-art imputation models in terms of imputation accuracy
and time cost, as well as indicating that the proposed model provides more
reliable decision support for environmental monitoring.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compute-Optimal LLMs Provably Generalize Better With Scale <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15208v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15208v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marc Finzi, Sanyam Kapoor, Diego Granziol, Anming Gu, Christopher De Sa, J. Zico Kolter, Andrew Gordon Wilson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Why do larger language models generalize better? To investigate this
question, we develop generalization bounds on the pretraining objective of
large language models (LLMs) in the compute-optimal regime, as described by the
Chinchilla scaling laws. We introduce a novel, fully empirical Freedman-type
martingale concentration inequality that tightens existing bounds by accounting
for the variance of the loss function. This generalization bound can be
decomposed into three interpretable components: the number of parameters per
token, the loss variance, and the quantization error at a fixed bitrate. As
compute-optimal language models are scaled up, the number of parameters per
data point remains constant; however, both the loss variance and the
quantization error decrease, implying that larger models should have smaller
generalization gaps. We examine why larger models tend to be more quantizable
from an information theoretic perspective, showing that the rate at which they
can integrate new information grows more slowly than their capacity on the
compute-optimal frontier. From these findings we produce a scaling law for the
generalization gap, with bounds that become predictably stronger with scale.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Global Calibration Strengthens Multiaccuracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15206v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15206v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sílvia Casacuberta, Parikshit Gopalan, Varun Kanade, Omer Reingold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multiaccuracy and multicalibration are multigroup fairness notions for
prediction that have found numerous applications in learning and computational
complexity. They can be achieved from a single learning primitive: weak
agnostic learning. Here we investigate the power of multiaccuracy as a learning
primitive, both with and without the additional assumption of calibration. We
find that multiaccuracy in itself is rather weak, but that the addition of
global calibration (this notion is called calibrated multiaccuracy) boosts its
power substantially, enough to recover implications that were previously known
only assuming the stronger notion of multicalibration.
  We give evidence that multiaccuracy might not be as powerful as standard weak
agnostic learning, by showing that there is no way to post-process a
multiaccurate predictor to get a weak learner, even assuming the best
hypothesis has correlation $1/2$. Rather, we show that it yields a restricted
form of weak agnostic learning, which requires some concept in the class to
have correlation greater than $1/2$ with the labels. However, by also requiring
the predictor to be calibrated, we recover not just weak, but strong agnostic
learning.
  A similar picture emerges when we consider the derivation of hardcore
measures from predictors satisfying multigroup fairness notions. On the one
hand, while multiaccuracy only yields hardcore measures of density half the
optimal, we show that (a weighted version of) calibrated multiaccuracy achieves
optimal density.
  Our results yield new insights into the complementary roles played by
multiaccuracy and calibration in each setting. They shed light on why
multiaccuracy and global calibration, although not particularly powerful by
themselves, together yield considerably stronger notions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's
  LLM-CLIP Framework for Image Captioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15199v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15199v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yassir Benhammou, Alessandro Tiberio, Gabriel Trautmann, Suman Kalyan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MILS (Multimodal Iterative LLM Solver) is a recently published framework that
claims "LLMs can see and hear without any training" by leveraging an iterative,
LLM-CLIP based approach for zero-shot image captioning. While this MILS
approach demonstrates good performance, our investigation reveals that this
success comes at a hidden, substantial computational cost due to its expensive
multi-step refinement process. In contrast, alternative models such as BLIP-2
and GPT-4V achieve competitive results through a streamlined, single-pass
approach. We hypothesize that the significant overhead inherent in MILS's
iterative process may undermine its practical benefits, thereby challenging the
narrative that zero-shot performance can be attained without incurring heavy
resource demands. This work is the first to expose and quantify the trade-offs
between output quality and computational cost in MILS, providing critical
insights for the design of more efficient multimodal models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 tables, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Measurement of Eczema Severity with <span class="highlight-title">Self-Supervised</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neelesh Kumar, Oya Aran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated diagnosis of eczema using images acquired from digital camera can
enable individuals to self-monitor their recovery. The process entails first
segmenting out the eczema region from the image and then measuring the severity
of eczema in the segmented region. The state-of-the-art methods for automated
eczema diagnosis rely on deep neural networks such as convolutional neural
network (CNN) and have shown impressive performance in accurately measuring the
severity of eczema. However, these methods require massive volume of annotated
data to train which can be hard to obtain. In this paper, we propose a
self-supervised learning framework for automated eczema diagnosis under limited
training data regime. Our framework consists of two stages: i) Segmentation,
where we use an in-context learning based algorithm called SegGPT for few-shot
segmentation of eczema region from the image; ii) Feature extraction and
classification, where we extract DINO features from the segmented regions and
feed it to a multi-layered perceptron (MLP) for 4-class classification of
eczema severity. When evaluated on a dataset of annotated "in-the-wild" eczema
images, we show that our method outperforms (Weighted F1: 0.67 $\pm$ 0.01) the
state-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted
F1: 0.44 $\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\pm$ 0.22). Our
results show that self-supervised learning can be a viable solution for
automated skin diagnosis where labeled data is scarce.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio-Visual Class-Incremental Learning for Fish Feeding intensity
  Assessment in Aquaculture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15171v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15171v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Cui, Xianghu Yue, Xinyuan Qian, Jinzheng Zhao, Haohe Liu, Xubo Liu, Daoliang Li, Wenwu Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture
management. Recent multi-modal approaches have shown promise in improving FFIA
robustness and efficiency. However, these methods face significant challenges
when adapting to new fish species or environments due to catastrophic
forgetting and the lack of suitable datasets. To address these limitations, we
first introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled
audio-visual clips capturing feeding intensities across six different fish
species in real aquaculture environments. Then, we pioneer audio-visual class
incremental learning (CIL) for FFIA and demonstrate through benchmarking on
AV-CIL-FFIA that it significantly outperforms single-modality methods. Existing
CIL methods rely heavily on historical data. Exemplar-based approaches store
raw samples, creating storage challenges, while exemplar-free methods avoid
data storage but struggle to distinguish subtle feeding intensity variations
across different fish species. To overcome these limitations, we introduce
HAIL-FFIA, a novel audio-visual class-incremental learning framework that
bridges this gap with a prototype-based approach that achieves exemplar-free
efficiency while preserving essential knowledge through compact feature
representations. Specifically, HAIL-FFIA employs hierarchical representation
learning with a dual-path knowledge preservation mechanism that separates
general intensity knowledge from fish-specific characteristics. Additionally,
it features a dynamic modality balancing system that adaptively adjusts the
importance of audio versus visual information based on feeding behaviour
stages. Experimental results show that HAIL-FFIA is superior to SOTA methods on
AV-CIL-FFIA, achieving higher accuracy with lower storage needs while
effectively mitigating catastrophic forgetting in incremental fish species
learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Survey</span> of Loss Augmented Knowledge Tracing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15163v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15163v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Altun Shukurlu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The training of artificial neural networks is heavily dependent on the
careful selection of an appropriate loss function. While commonly used loss
functions, such as cross-entropy and mean squared error (MSE), generally
suffice for a broad range of tasks, challenges often emerge due to limitations
in data quality or inefficiencies within the learning process. In such
circumstances, the integration of supplementary terms into the loss function
can serve to address these challenges, enhancing both model performance and
robustness. Two prominent techniques, loss regularization and contrastive
learning, have been identified as effective strategies for augmenting the
capacity of loss functions in artificial neural networks.
  Knowledge tracing is a compelling area of research that leverages predictive
artificial intelligence to facilitate the automation of personalized and
efficient educational experiences for students. In this paper, we provide a
comprehensive review of the deep learning-based knowledge tracing (DKT)
algorithms trained using advanced loss functions and discuss their improvements
over prior techniques. We discuss contrastive knowledge tracing algorithms,
such as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT,
providing performance benchmarks and insights into real-world deployment
challenges. The survey concludes with future research directions, including
hybrid loss strategies and context-aware modeling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, no figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advanced posterior analyses of hidden Markov models: finite Markov chain
  imbedding and hybrid decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15156v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15156v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zenia Elise Damgaard Bæk, Moisès Coll Macià, Laurits Skov, Asger Hobolth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Two major tasks in applications of hidden Markov models are to (i) compute
distributions of summary statistics of the hidden state sequence, and (ii)
decode the hidden state sequence. We describe finite Markov chain imbedding
(FMCI) and hybrid decoding to solve each of these two tasks. In the first part
of our paper we use FMCI to compute posterior distributions of summary
statistics such as the number of visits to a hidden state, the total time spent
in a hidden state, the dwell time in a hidden state, and the longest run
length. We use simulations from the hidden state sequence, conditional on the
observed sequence, to establish the FMCI framework. In the second part of our
paper we apply hybrid segmentation for improved decoding of a HMM. We
demonstrate that hybrid decoding shows increased performance compared to
Viterbi or Posterior decoding (often also referred to as global or local
decoding), and we introduce a novel procedure for choosing the tuning parameter
in the hybrid procedure. Furthermore, we provide an alternative derivation of
the hybrid loss function based on weighted geometric means. We demonstrate and
apply FMCI and hybrid decoding on various classical data sets, and supply
accompanying code for reproducibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15133v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15133v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziwen Xu, Shuxun Wang, Kewei Xu, Haoming Xu, Mengru Wang, Xinle Deng, Yunzhi Yao, Guozhou Zheng, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce EasyEdit2, a framework designed to enable
plug-and-play adjustability for controlling Large Language Model (LLM)
behaviors. EasyEdit2 supports a wide range of test-time interventions,
including safety, sentiment, personality, reasoning patterns, factuality, and
language features. Unlike its predecessor, EasyEdit2 features a new
architecture specifically designed for seamless model steering. It comprises
key modules such as the steering vector generator and the steering vector
applier, which enable automatic generation and application of steering vectors
to influence the model's behavior without modifying its parameters. One of the
main advantages of EasyEdit2 is its ease of use-users do not need extensive
technical knowledge. With just a single example, they can effectively guide and
adjust the model's responses, making precise control both accessible and
efficient. Empirically, we report model steering performance across different
LLMs, demonstrating the effectiveness of these techniques. We have released the
source code on GitHub at https://github.com/zjunlp/EasyEdit along with a
demonstration notebook. In addition, we provide a demo video at
https://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Demo:
  https://zjunlp.github.io/project/EasyEdit2/video; code:
  https://github.com/zjunlp/EasyEdit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A General Infrastructure and Workflow for Quadrotor Deep Reinforcement
  Learning and Reality Deployment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangyao Huang, Hao Wang, Yu Luo, Jingyu Chen, Jintao Chen, Xiangkui Zhang, Xiangyang Ji, Huaping Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deploying robot learning methods to a quadrotor in unstructured outdoor
environments is an exciting task. Quadrotors operating in real-world
environments by learning-based methods encounter several challenges: a large
amount of simulator generated data required for training, strict demands for
real-time processing onboard, and the sim-to-real gap caused by dynamic and
noisy conditions. Current works have made a great breakthrough in applying
learning-based methods to end-to-end control of quadrotors, but rarely mention
the infrastructure system training from scratch and deploying to reality, which
makes it difficult to reproduce methods and applications. To bridge this gap,
we propose a platform that enables the seamless transfer of end-to-end deep
reinforcement learning (DRL) policies. We integrate the training environment,
flight dynamics control, DRL algorithms, the MAVROS middleware stack, and
hardware into a comprehensive workflow and architecture that enables
quadrotors' policies to be trained from scratch to real-world deployment in
several minutes. Our platform provides rich types of environments including
hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and
planning in unknown environments, as a physical experiment benchmark. Through
extensive empirical validation, we demonstrate the efficiency of proposed
sim-to-real platform, and robust outdoor flight performance under real-world
perturbations. Details can be found from our website
https://emnavi.tech/AirGym/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for
  Functions and their Derivatives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15110v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15110v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anastasis Kratsios, Takashi Furuya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold
Networks (KANs) have recently emerged as an improved backbone for most deep
learning frameworks, promising more adaptivity than their multilayer perception
(MLP) predecessor by allowing for trainable spline-based activation functions.
In this paper, we probe the theoretical foundations of the KAN architecture by
showing that it can optimally approximate any Besov function in
$B^{s}_{p,q}(\mathcal{X})$ on a bounded open, or even fractal, domain
$\mathcal{X}$ in $\mathbb{R}^d$ at the optimal approximation rate with respect
to any weaker Besov norm $B^{\alpha}_{p,q}(\mathcal{X})$; where $\alpha < s$.
We complement our approximation guarantee with a dimension-free estimate on the
sample complexity of a residual KAN model when learning a function of Besov
regularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates
contemporary deep learning wisdom by leveraging residual/skip connections
between layers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Application of Sensitivity Analysis Methods for Studying Neural Network
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15100v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15100v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxuan Miao, Sergey Matveev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study demonstrates the capabilities of several methods for analyzing the
sensitivity of neural networks to perturbations of the input data and
interpreting their underlying mechanisms. The investigated approaches include
the Sobol global sensitivity analysis, the local sensitivity method for input
pixel perturbations and the activation maximization technique. As examples, in
this study we consider a small feedforward neural network for analyzing an open
tabular dataset of clinical diabetes data, as well as two classical
convolutional architectures, VGG-16 and ResNet-18, which are widely used in
image processing and classification. Utilization of the global sensitivity
analysis allows us to identify the leading input parameters of the chosen tiny
neural network and reduce their number without significant loss of the
accuracy. As far as global sensitivity analysis is not applicable to larger
models we try the local sensitivity analysis and activation maximization method
in application to the convolutional neural networks. These methods show
interesting patterns for the convolutional models solving the image
classification problem. All in all, we compare the results of the activation
maximization method with popular Grad-CAM technique in the context of
ultrasound data analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 16 figures, 32 references</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training
  of GAN 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15099v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15099v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin Wang, Xiancheng Wang, Rui Wang, Zhibo Zhang, Minghang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Up to now, the training processes of typical Generative Adversarial Networks
(GANs) are still particularly sensitive to data properties and hyperparameters,
which may lead to severe oscillations, difficulties in convergence, or even
failures to converge, especially when the overall variances of the training
sets are large. These phenomena are often attributed to the training
characteristics of such networks. Aiming at the problem, this paper develops a
new intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which
employs reinforcement learning in the training process of GANs to make training
easier. Specifically, this paper allows the training step size to be controlled
by an agent to improve training stability, and makes the training process more
intelligent with variable learning rates, making GANs less sensitive to step
size. Experiments have been conducted on three benchmark datasets to verify the
effectiveness of the developed FSCO.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking the Potential of Multimodality in Collaborative Problem
  Solving Diagnosis with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15093v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15093v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        K. Wong, B. Wu, S. Bulathwela, M. Cukurova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting collaborative and problem-solving behaviours from digital traces to
interpret students' collaborative problem solving (CPS) competency is a
long-term goal in the Artificial Intelligence in Education (AIEd) field.
Although multimodal data and advanced models are argued to have the potential
to detect complex CPS behaviours, empirical evidence on their value remains
limited with some contrasting evidence. In this study, we investigated the
potential of multimodal data to improve model performance in diagnosing 78
secondary school students' CPS subskills and indicators in authentic
educational settings. In particular, text embeddings from verbal data and
acoustic embeddings from audio data were used in a multimodal classification
model for CPS diagnosis. Both unimodal and multimodal transformer-based models
outperformed traditional models in detecting CPS classes. Although the
inclusion of multimodality did not improve the performance of traditional
unimodal models, its integration into transformer-based models demonstrated
improved performance for diagnosing social-cognitive CPS classes compared to
unimodal transformer-based models. Based on the results, the paper argues that
multimodality and the selection of a particular modelling technique should not
be taken for granted to achieve the best performance in the automated detection
of every CPS subskill and indicator. Rather, their value is limited to certain
types of CPS indicators, affected by the complexity of the labels, and
dependent on the composition of indicators in the dataset. We conclude the
paper by discussing the required nuance when considering the value of LLMs and
multimodality in automated CPS diagnosis, highlighting the need for human-AI
complementarity, and proposing the exploration of relevant model architectures
and techniques to improve CPS diagnosis in authentic educational contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for 26th International Conference on Artificial Intelligence
  in Education (AIED 2025), 22 - 26 July 2025, Palermo, Italy. 17 pages, 1
  figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Federated Latent Factor Model for Bias-Aware Recommendation with
  Privacy-Preserving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15090v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15090v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junxiang Gao, Yixin Ran, Jia Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A recommender system (RS) aims to provide users with personalized item
recommendations, enhancing their overall experience. Traditional RSs collect
and process all user data on a central server. However, this centralized
approach raises significant privacy concerns, as it increases the risk of data
breaches and privacy leakages, which are becoming increasingly unacceptable to
privacy-sensitive users. To address these privacy challenges, federated
learning has been integrated into RSs, ensuring that user data remains secure.
In centralized RSs, the issue of rating bias is effectively addressed by
jointly analyzing all users' raw interaction data. However, this becomes a
significant challenge in federated RSs, as raw data is no longer accessible due
to privacy-preserving constraints. To overcome this problem, we propose a
Federated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is
explicitly incorporated into every local model's loss function, allowing for
the effective elimination of rating bias without compromising data privacy.
Extensive experiments conducted on three real-world datasets demonstrate that
FBALF achieves significantly higher recommendation accuracy compared to other
state-of-the-art federated RSs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15077v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15077v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simone Papicchio, Simone Rossi, Luca Cagliero, Paolo Papotti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown impressive capabilities in
transforming natural language questions about relational databases into SQL
queries. Despite recent improvements, small LLMs struggle to handle questions
involving multiple tables and complex SQL patterns under a Zero-Shot Learning
(ZSL) setting. Supervised Fine-Tuning (SFT) partially compensate the knowledge
deficits in pretrained models but falls short while dealing with queries
involving multi-hop reasoning. To bridge this gap, different LLM training
strategies to reinforce reasoning capabilities have been proposed, ranging from
leveraging a thinking process within ZSL, including reasoning traces in SFT, or
adopt Reinforcement Learning (RL) strategies. However, the influence of
reasoning on Text2SQL performance is still largely unexplored. This paper
investigates to what extent LLM reasoning capabilities influence their Text2SQL
performance on four benchmark datasets. To this end, it considers the following
LLM settings: (1) ZSL, including general-purpose reasoning or not; (2) SFT,
with and without task-specific reasoning traces; (3) RL, leveraging execution
accuracy as primary reward function; (4) SFT+RL, i.e, a two-stage approach that
combines SFT and RL. The results show that general-purpose reasoning under ZSL
proves to be ineffective in tackling complex Text2SQL cases. Small LLMs benefit
from SFT with reasoning much more than larger ones, bridging the gap of their
(weaker) model pretraining. RL is generally beneficial across all tested models
and datasets, particularly when SQL queries involve multi-hop reasoning and
multiple tables. Small LLMs with SFT+RL excel on most complex datasets thanks
to a strategic balance between generality of the reasoning process and
optimization of the execution accuracy. Thanks to RL, the7B Qwen-Coder-2.5
model performs on par with 100+ Billion ones on the Bird dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating Degree Bias in Graph Representation Learning with Learnable
  Structural Augmentation and Structural Self-Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15075v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15075v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Van Thuy Hoang, Hyeon-Ju Jeon, O-Joun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) update node representations through message
passing, which is primarily based on the homophily principle, assuming that
adjacent nodes share similar features. However, in real-world graphs with
long-tailed degree distributions, high-degree nodes dominate message passing,
causing a degree bias where low-degree nodes remain under-represented due to
inadequate messages. The main challenge in addressing degree bias is how to
discover non-adjacent nodes to provide additional messages to low-degree nodes
while reducing excessive messages for high-degree nodes. Nevertheless,
exploiting non-adjacent nodes to provide valuable messages is challenging, as
it could generate noisy information and disrupt the original graph structures.
To solve it, we propose a novel Degree Fairness Graph Transformer, named
DegFairGT, to mitigate degree bias by discovering structural similarities
between non-adjacent nodes through learnable structural augmentation and
structural self-attention. Our key idea is to exploit non-adjacent nodes with
similar roles in the same community to generate informative edges under our
augmentation, which could provide informative messages between nodes with
similar roles while ensuring that the homophily principle is maintained within
the community. To enable DegFairGT to learn such structural similarities, we
then propose a structural self-attention to capture the similarities between
node pairs. To preserve global graph structures and prevent graph augmentation
from hindering graph structure, we propose a Self-Supervised Learning task to
preserve p-step transition probability and regularize graph augmentation.
Extensive experiments on six datasets showed that DegFairGT outperformed
state-of-the-art baselines in degree fairness analysis, node classification,
and node clustering tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IEEE TNSE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VeLU: Variance-enhanced Learning Unit for Deep Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo Nicolè, Stefano Ghidoni, Nassir Navab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Activation functions are fundamental in deep neural networks and directly
impact gradient flow, optimization stability, and generalization. Although ReLU
remains standard because of its simplicity, it suffers from vanishing gradients
and lacks adaptability. Alternatives like Swish and GELU introduce smooth
transitions, but fail to dynamically adjust to input statistics. We propose
VeLU, a Variance-enhanced Learning Unit as an activation function that
dynamically scales based on input variance by integrating ArcTan-Sin
transformations and Wasserstein-2 regularization, effectively mitigating
covariate shifts and stabilizing optimization. Extensive experiments on
ViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm
VeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.
The codes of VeLU are publicly available on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Call for New Recipes to Enhance Spatial Reasoning in MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huanyu Zhang, Chengzu Li, Wenshan Wu, Shaoguang Mao, Yan xia, Ivan Vulić, Zhang Zhang, Liang Wang, Tieniu Tan, Furu Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have demonstrated impressive
performance in general vision-language tasks. However, recent studies have
exposed critical limitations in their spatial reasoning capabilities. This
deficiency in spatial reasoning significantly constrains MLLMs' ability to
interact effectively with the physical world, thereby limiting their broader
applications. We argue that spatial reasoning capabilities will not naturally
emerge from merely scaling existing architectures and training methodologies.
Instead, this challenge demands dedicated attention to fundamental
modifications in the current MLLM development approach. In this position paper,
we first establish a comprehensive framework for spatial reasoning within the
context of MLLMs. We then elaborate on its pivotal role in real-world
applications. Through systematic analysis, we examine how individual components
of the current methodology-from training data to reasoning mechanisms-influence
spatial reasoning capabilities. This examination reveals critical limitations
while simultaneously identifying promising avenues for advancement. Our work
aims to direct the AI research community's attention toward these crucial yet
underexplored aspects. By highlighting these challenges and opportunities, we
seek to catalyze progress toward achieving human-like spatial reasoning
capabilities in MLLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Is Intelligence the Right Direction in New OS Scheduling for Multiple
  Resources in Cloud Environments? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15021v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15021v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinglei Dou, Lei Liu, Limin Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Making it intelligent is a promising way in System/OS design. This paper
proposes OSML+, a new ML-based resource scheduling mechanism for co-located
cloud services. OSML+ intelligently schedules the cache and main memory
bandwidth resources at the memory hierarchy and the computing core resources
simultaneously. OSML+ uses a multi-model collaborative learning approach during
its scheduling and thus can handle complicated cases, e.g., avoiding resource
cliffs, sharing resources among applications, enabling different scheduling
policies for applications with different priorities, etc. OSML+ can converge
faster using ML models than previous studies. Moreover, OSML+ can automatically
learn on the fly and handle dynamically changing workloads accordingly. Using
transfer learning technologies, we show our design can work well across various
cloud servers, including the latest off-the-shelf large-scale servers. Our
experimental results show that OSML+ supports higher loads and meets QoS
targets with lower overheads than previous studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 14 figures, to be published in ACM Transactions on Storage</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trainable Quantum Neural Network for Multiclass Image Classification
  with the Power of <span class="highlight-title">Pre-train</span>ed Tree Tensor Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14995v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14995v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keisuke Murota, Takumi Kobori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tree tensor networks (TTNs) offer powerful models for image classification.
While these TTN image classifiers already show excellent performance on
classical hardware, embedding them into quantum neural networks (QNNs) may
further improve the performance by leveraging quantum resources. However,
embedding TTN classifiers into QNNs for multiclass classification remains
challenging. Key obstacles are the highorder gate operations required for large
bond dimensions and the mid-circuit postselection with exponentially low
success rates necessary for the exact embedding. In this work, to address these
challenges, we propose forest tensor network (FTN)-classifiers, which aggregate
multiple small-bond-dimension TTNs. This allows us to handle multiclass
classification without requiring large gates in the embedded circuits. We then
remove the overhead of mid-circuit postselection by extending the adiabatic
encoding framework to our setting and smoothly encode the FTN-classifiers into
a quantum forest tensor network (qFTN)- classifiers. Numerical experiments on
MNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers
and encode them into qFTN-classifiers, while maintaining or even improving the
performance of the pre-trained FTN-classifiers. These results suggest that
synergy between TTN classification models and QNNs can provide a robust and
scalable framework for multiclass quantum-enhanced image classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 12 figures, 2 tables. This work has been submitted to the
  IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Compositional Transferability of Time Series for Source-Free
  Domain Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hankang Sun, Guiming Li, Su Yang, Baoqi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain adaptation is challenging for time series classification due to the
highly dynamic nature. This study tackles the most difficult subtask when both
target labels and source data are inaccessible, namely, source-free domain
adaptation. To reuse the classification backbone pre-trained on source data,
time series reconstruction is a sound solution that aligns target and source
time series by minimizing the reconstruction errors of both. However, simply
fine-tuning the source pre-trained reconstruction model on target data may lose
the learnt priori, and it struggles to accommodate domain varying temporal
patterns in a single encoder-decoder. Therefore, this paper tries to
disentangle the composition of domain transferability by using a compositional
architecture for time series reconstruction. Here, the preceding component is a
U-net frozen since pre-trained, the output of which during adaptation is the
initial reconstruction of a given target time series, acting as a coarse step
to prompt the subsequent finer adaptation. The following pipeline for finer
adaptation includes two parallel branches: The source replay branch using a
residual link to preserve the output of U-net, and the offset compensation
branch that applies an additional autoencoder (AE) to further warp U-net's
output. By deploying a learnable factor on either branch to scale their
composition in the final output of reconstruction, the data transferability is
disentangled and the learnt reconstructive capability from source data is
retained. During inference, aside from the batch-level optimization in the
training, we search at test time stability-aware rescaling of source replay
branch to tolerate instance-wise variation. The experimental results show that
such compositional architecture of time series reconstruction leads to SOTA
performance on 3 widely used benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Corresponding author: Su Yang</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in
  Multiparty Dialogues 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14963v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14963v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Ribeiro, Luísa Coheur, Joao P. Carvalho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speaker identification using voice recordings leverages unique acoustic
features, but this approach fails when only textual data is available. Few
approaches have attempted to tackle the problem of identifying speakers solely
from text, and the existing ones have primarily relied on traditional methods.
In this work, we explore the use of fuzzy fingerprints from large pre-trained
models to improve text-based speaker identification. We integrate
speaker-specific tokens and context-aware modeling, demonstrating that
conversational context significantly boosts accuracy, reaching 70.6% on the
Friends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show
that fuzzy fingerprints can approximate full fine-tuning performance with fewer
hidden units, offering improved interpretability. Finally, we analyze ambiguous
utterances and propose a mechanism to detect speaker-agnostic lines. Our
findings highlight key challenges and provide insights for future improvements
in text-based speaker identification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted at the FUZZY IEEE 2025 conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoE Parallel Folding: Heterogeneous Parallelism Mappings for Efficient
  Large-Scale MoE Model Training with Megatron Core 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14960v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14960v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dennis Liu, Zijie Yan, Xin Yao, Tong Liu, Vijay Korthikanti, Evan Wu, Shiqing Fan, Gao Deng, Hongxiao Bai, Ashwath Aithal, Michael Andersch, Mohammad Shoeybi, Jiajie Yao, Chandler Zhou, David Wu, Xipeng Li, June Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture of Experts (MoE) models enhance neural network scalability by
dynamically selecting relevant experts per input token, enabling larger model
sizes while maintaining manageable computation costs. However, efficient
training of large-scale MoE models across thousands of GPUs presents
significant challenges due to limitations in existing parallelism strategies.
We introduce an end-to-end training framework for large-scale MoE models that
utilizes five-dimensional hybrid parallelism: Tensor Parallelism, Expert
Parallelism, Context Parallelism, Data Parallelism, and Pipeline Parallelism.
Central to our approach is MoE Parallel Folding, a novel strategy that
decouples the parallelization of attention and MoE layers in Transformer
models, allowing each layer type to adopt optimal parallel configurations.
Additionally, we develop a flexible token-level dispatcher that supports both
token-dropping and token-dropless MoE training across all five dimensions of
parallelism. This dispatcher accommodates dynamic tensor shapes and coordinates
different parallelism schemes for Attention and MoE layers, facilitating
complex parallelism implementations. Our experiments demonstrate significant
improvements in training efficiency and scalability. We achieve up to 49.3%
Model Flops Utilization (MFU) for the Mixtral 8x22B model and 39.0% MFU for the
Qwen2-57B-A14B model on H100 GPUs, outperforming existing methods. The
framework scales efficiently up to 1,024 GPUs and maintains high performance
with sequence lengths up to 128K tokens, validating its effectiveness for
large-scale MoE model training. The code is available in Megatron-Core.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Document Retrieval with G-Retriever <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14955v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14955v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manthankumar Solanki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Textual data question answering has gained significant attention due to its
growing applicability. Recently, a novel approach leveraging the
Retrieval-Augmented Generation (RAG) method was introduced, utilizing the
Prize-Collecting Steiner Tree (PCST) optimization for sub-graph construction.
However, this method focused solely on node attributes, leading to incomplete
contextual understanding. In this paper, we propose an enhanced approach that
replaces the PCST method with an attention-based sub-graph construction
technique, enabling more efficient and context-aware retrieval. Additionally,
we encode both node and edge attributes, leading to richer graph
representations. Our method also incorporates an improved projection layer and
multi-head attention pooling for better alignment with Large Language Models
(LLMs). Experimental evaluations on the WebQSP dataset demonstrate that our
approach is competitive and achieves marginally better results compared to the
original method, underscoring its potential for more accurate question
answering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended version of a paper presented at NeurIPS 2024
  (arXiv:2402.07630)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Symmetry-Preserving Architecture for Multi-NUMA Environments (SPANE): A
  Deep Reinforcement Learning Approach for Dynamic VM Scheduling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14946v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14946v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tin Ping Chan, Yunlong Cheng, Yizhan Zhu, Xiaofeng Gao, Guihai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As cloud computing continues to evolve, the adoption of multi-NUMA
(Non-Uniform Memory Access) architecture by cloud service providers has
introduced new challenges in virtual machine (VM) scheduling. To address these
challenges and more accurately reflect the complexities faced by modern cloud
environments, we introduce the Dynamic VM Allocation problem in Multi-NUMA PM
(DVAMP). We formally define both offline and online versions of DVAMP as
mixed-integer linear programming problems, providing a rigorous mathematical
foundation for analysis. A tight performance bound for greedy online algorithms
is derived, offering insights into the worst-case optimality gap as a function
of the number of physical machines and VM lifetime variability. To address the
challenges posed by DVAMP, we propose SPANE (Symmetry-Preserving Architecture
for Multi-NUMA Environments), a novel deep reinforcement learning approach that
exploits the problem's inherent symmetries. SPANE produces invariant results
under arbitrary permutations of physical machine states, enhancing learning
efficiency and solution quality. Extensive experiments conducted on the
Huawei-East-1 dataset demonstrate that SPANE outperforms existing baselines,
reducing average VM wait time by 45%. Our work contributes to the field of
cloud resource management by providing both theoretical insights and practical
solutions for VM scheduling in multi-NUMA environments, addressing a critical
gap in the literature and offering improved performance for real-world cloud
systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures. Accepted to IEEE INFOCOM 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Reason under Off-Policy Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14945v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14945v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianhao Yan, Yafu Li, Zican Hu, Zhi Wang, Ganqu Cui, Xiaoye Qu, Yu Cheng, Yue Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large reasoning models (LRMs) demonstrate that
sophisticated behaviors such as multi-step reasoning and self-reflection can
emerge via reinforcement learning (RL) with simple rule-based rewards. However,
existing zero-RL approaches are inherently ``on-policy'', limiting learning to
a model's own outputs and failing to acquire reasoning abilities beyond its
initial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY
guidance), a framework that augments zero-RL with off-policy reasoning traces.
LUFFY dynamically balances imitation and exploration by combining off-policy
demonstrations with on-policy rollouts during training. Notably, we propose
policy shaping via regularized importance sampling to avoid superficial and
rigid imitation during mixed-policy training. Remarkably, LUFFY achieves an
over +7.0 average gain across six math benchmarks and an advantage of over +6.2
points in out-of-distribution tasks. It also substantially surpasses
imitation-based supervised fine-tuning (SFT), particularly in generalization.
Analysis shows LUFFY not only imitates effectively but also explores beyond
demonstrations, offering a scalable path to train generalizable reasoning
models with off-policy guidance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrating Response Time and Attention Duration in Bayesian Preference
  Learning for Multiple Criteria Decision Aiding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14938v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14938v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxuan Jiang, Jiapeng Liu, Miłosz Kadziński, Xiuwu Liao, Jingyu Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a multiple criteria Bayesian preference learning framework
incorporating behavioral cues for decision aiding. The framework integrates
pairwise comparisons, response time, and attention duration to deepen insights
into decision-making processes. The approach employs an additive value function
model and utilizes a Bayesian framework to derive the posterior distribution of
potential ranking models by defining the likelihood of observed preference data
and specifying a prior on the preference structure. This distribution
highlights each model's ability to reconstruct Decision-Makers' holistic
pairwise comparisons. By leveraging both response time as a proxy for cognitive
effort and alternative discriminability as well as attention duration as an
indicator of criterion importance, the proposed model surpasses traditional
methods by uncovering richer behavioral patterns. We report the results of a
laboratory experiment on mobile phone contract selection involving 30 real
subjects using a dedicated application with time-, eye-, and mouse-tracking
components. We validate the novel method's ability to reconstruct complete
preferences. The detailed ablation studies reveal time- and attention-related
behavioral patterns, confirming that integrating comprehensive data leads to
developing models that better align with the DM's actual preferences.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causal DAG Summarization (Full Version) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14937v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14937v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Zeng, Michael Cafarella, Batya Kenig, Markos Markakis, Brit Youngmann, Babak Salimi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal inference aids researchers in discovering cause-and-effect
relationships, leading to scientific insights. Accurate causal estimation
requires identifying confounding variables to avoid false discoveries. Pearl's
causal model uses causal DAGs to identify confounding variables, but incorrect
DAGs can lead to unreliable causal conclusions. However, for high dimensional
data, the causal DAGs are often complex beyond human verifiability. Graph
summarization is a logical next step, but current methods for general-purpose
graph summarization are inadequate for causal DAG summarization. This paper
addresses these challenges by proposing a causal graph summarization objective
that balances graph simplification for better understanding while retaining
essential causal information for reliable inference. We develop an efficient
greedy algorithm and show that summary causal DAGs can be directly used for
inference and are more robust to misspecification of assumptions, enhancing
robustness for causal inference. Experimenting with six real-life datasets, we
compared our algorithm to three existing solutions, showing its effectiveness
in handling high-dimensional data and its ability to generate summary DAGs that
ensure both reliable causal inference and robustness against misspecifications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for
  Medical Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14917v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14917v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunjing Gan, Dan Yang, Binbin Hu, Ziqi Liu, Yue Shen, Zhiqiang Zhang, Jian Wang, Jun Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become a disruptive force in the industry,
introducing unprecedented capabilities in natural language processing, logical
reasoning and so on. However, the challenges of knowledge updates and
hallucination issues have limited the application of LLMs in medical scenarios,
where retrieval-augmented generation (RAG) can offer significant assistance.
Nevertheless, existing retrieve-then-read approaches generally digest the
retrieved documents, without considering the timeliness, authoritativeness and
commonality of retrieval. We argue that these approaches can be suboptimal,
especially in real-world applications where information from different sources
might conflict with each other and even information from the same source in
different time scale might be different, and totally relying on this would
deteriorate the performance of RAG approaches. We propose PolyRAG that
carefully incorporate judges from different perspectives and finally integrate
the polyviews for retrieval augmented generation in medical applications. Due
to the scarcity of real-world benchmarks for evaluation, to bridge the gap we
propose PolyEVAL, a benchmark consists of queries and documents collected from
real-world medical scenarios (including medical policy, hospital & doctor
inquiry and healthcare) with multiple tagging (e.g., timeliness,
authoritativeness) on them. Extensive experiments and analysis on PolyEVAL have
demonstrated the superiority of PolyRAG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Graph-Like Learning with Contrastive Clustering on
  Temporally-Factored Ship Motion Data for Imbalanced Sea State Estimation in
  Autonomous Vessel 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14907v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14907v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kexin Wang, Mengna Liu, Xu Cheng, Fan Shi, Shanshan Qi, Shengyong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate sea state estimation is crucial for the real-time control and future
state prediction of autonomous vessels. However, traditional methods struggle
with challenges such as data imbalance and feature redundancy in ship motion
data, limiting their effectiveness. To address these challenges, we propose the
Temporal-Graph Contrastive Clustering Sea State Estimator (TGC-SSE), a novel
deep learning model that combines three key components: a time dimension
factorization module to reduce data redundancy, a dynamic graph-like learning
module to capture complex variable interactions, and a contrastive clustering
loss function to effectively manage class imbalance. Our experiments
demonstrate that TGC-SSE significantly outperforms existing methods across 14
public datasets, achieving the highest accuracy in 9 datasets, with a 20.79%
improvement over EDI. Furthermore, in the field of sea state estimation,
TGC-SSE surpasses five benchmark methods and seven deep learning models.
Ablation studies confirm the effectiveness of each module, demonstrating their
respective roles in enhancing overall model performance. Overall, TGC-SSE not
only improves the accuracy of sea state estimation but also exhibits strong
generalization capabilities, providing reliable support for autonomous vessel
operations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages,15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Expected Free Energy-based Planning as Variational Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14898v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14898v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bert de Vries, Wouter Nuijten, Thijs van de Laar, Wouter Kouw, Sepideh Adamiat, Tim Nisslbeck, Mykola Lukashchuk, Hoang Minh Huu Nguyen, Marco Hidalgo Araya, Raphael Tresor, Thijs Jenneskens, Ivana Nikoloska, Raaja Subramanian, Bart van Erp, Dmitry Bagaev, Albert Podusenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the problem of planning under uncertainty, where an agent must
choose actions that not only achieve desired outcomes but also reduce
uncertainty. Traditional methods often treat exploration and exploitation as
separate objectives, lacking a unified inferential foundation. Active
inference, grounded in the Free Energy Principle, offers such a foundation by
minimizing Expected Free Energy (EFE), a cost function that combines utility
with epistemic drives like ambiguity resolution and novelty seeking. However,
the computational burden of EFE minimization has remained a major obstacle to
its scalability. In this paper, we show that EFE-based planning arises
naturally from minimizing a variational free energy functional on a generative
model augmented with preference and epistemic priors. This result reinforces
theoretical consistency with the Free Energy Principle, by casting planning
itself as variational inference. Our formulation yields optimal policies that
jointly support goal achievement and information gain, while incorporating a
complexity term that accounts for bounded computational resources. This
unifying framework connects and extends existing methods, enabling scalable,
resource-aware implementations of active inference agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Latent Bayesian Optimization via Autoregressive Normalizing Flows <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14889v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14889v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seunghun Lee, Jinyoung Park, Jaewon Chu, Minseo Yoon, Hyunwoo J. Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian Optimization (BO) has been recognized for its effectiveness in
optimizing expensive and complex objective functions. Recent advancements in
Latent Bayesian Optimization (LBO) have shown promise by integrating generative
models such as variational autoencoders (VAEs) to manage the complexity of
high-dimensional and structured data spaces. However, existing LBO approaches
often suffer from the value discrepancy problem, which arises from the
reconstruction gap between input and latent spaces. This value discrepancy
problem propagates errors throughout the optimization process, leading to
suboptimal outcomes. To address this issue, we propose a Normalizing Flow-based
Bayesian Optimization (NF-BO), which utilizes normalizing flow as a generative
model to establish one-to-one encoding function from the input space to the
latent space, along with its left-inverse decoding function, eliminating the
reconstruction gap. Specifically, we introduce SeqFlow, an autoregressive
normalizing flow for sequence data. In addition, we develop a new candidate
sampling strategy that dynamically adjusts the exploration probability for each
token based on its importance. Through extensive experiments, our NF-BO method
demonstrates superior performance in molecule generation tasks, significantly
outperforming both traditional and recent LBO approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Some Optimizers are More Equal: Understanding the Role of Optimizers in
  Group Fairness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14882v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14882v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mojtaba Kolahdouzi, Hatice Gunes, Ali Etemad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study whether and how the choice of optimization algorithm can impact
group fairness in deep neural networks. Through stochastic differential
equation analysis of optimization dynamics in an analytically tractable setup,
we demonstrate that the choice of optimization algorithm indeed influences
fairness outcomes, particularly under severe imbalance. Furthermore, we show
that when comparing two categories of optimizers, adaptive methods and
stochastic methods, RMSProp (from the adaptive category) has a higher
likelihood of converging to fairer minima than SGD (from the stochastic
category). Building on this insight, we derive two new theoretical guarantees
showing that, under appropriate conditions, RMSProp exhibits fairer parameter
updates and improved fairness in a single optimization step compared to SGD. We
then validate these findings through extensive experiments on three publicly
available datasets, namely CelebA, FairFace, and MS-COCO, across different
tasks as facial expression recognition, gender classification, and multi-label
classification, using various backbones. Considering multiple fairness
definitions including equalized odds, equal opportunity, and demographic
parity, adaptive optimizers like RMSProp and Adam consistently outperform SGD
in terms of group fairness, while maintaining comparable predictive accuracy.
Our results highlight the role of adaptive updates as a crucial yet overlooked
mechanism for promoting fair outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Impact of Latent Space Dimension on IoT Botnet Detection Performance:
  VAE-Encoder Versus ViT-Encoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14879v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14879v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hassan Wasswa, Aziida Nanyonga, Timothy Lynar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid evolution of Internet of Things (IoT) technology has led to a
significant increase in the number of IoT devices, applications, and services.
This surge in IoT devices, along with their widespread presence, has made them
a prime target for various cyber-attacks, particularly through IoT botnets. As
a result, security has become a major concern within the IoT ecosystem. This
study focuses on investigating how the latent dimension impacts the performance
of different deep learning classifiers when trained on latent vector
representations of the train dataset. The primary objective is to compare the
outcomes of these models when encoder components from two cutting-edge
architectures: the Vision Transformer (ViT) and the Variational Auto-Encoder
(VAE) are utilized to project the high dimensional train dataset to the learned
low dimensional latent space. The encoder components are employed to project
high-dimensional structured .csv IoT botnet traffic datasets to various latent
sizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that
VAE-encoder based dimension reduction outperforms ViT-encoder based dimension
reduction for both datasets in terms of four performance metrics including
accuracy, precision, recall, and F1-score for all models which can be
attributed to absence of spatial patterns in the datasets the ViT model
attempts to learn and extract from image instances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReSpec: Relevance and Specificity Grounded Online Filtering for Learning
  on Video-Text Data Streams <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14875v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14875v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chris Dongjoo Kim, Jihwan Moon, Sangwoo Moon, Heeseung Yun, Sihaeng Lee, Aniruddha Kembhavi, Soonyoung Lee, Gunhee Kim, Sangho Lee, Christopher Clark
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid growth of video-text data presents challenges in storage and
computation during training. Online learning, which processes streaming data in
real-time, offers a promising solution to these issues while also allowing
swift adaptations in scenarios demanding real-time responsiveness. One strategy
to enhance the efficiency and effectiveness of learning involves identifying
and prioritizing data that enhances performance on target downstream tasks. We
propose Relevance and Specificity-based online filtering framework (ReSpec)
that selects data based on four criteria: (i) modality alignment for clean
data, (ii) task relevance for target focused data, (iii) specificity for
informative and detailed data, and (iv) efficiency for low-latency processing.
Relevance is determined by the probabilistic alignment of incoming data with
downstream tasks, while specificity employs the distance to a root embedding
representing the least specific data as an efficient proxy for informativeness.
By establishing reference points from target task data, ReSpec filters incoming
data in real-time, eliminating the need for extensive storage and compute.
Evaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains
state-of-the-art performance on five zeroshot video retrieval tasks, using as
little as 5% of the data while incurring minimal compute. The source code is
available at https://github.com/cdjkim/ReSpec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025 (main conference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncertainty quantification of neural network models of evolving
  processes via Langevin sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cosmin Safta, Reese E. Jones, Ravi G. Patel, Raelynn Wonnacot, Dan S. Bolintineanu, Craig M. Hamel, Sharlotte L. B. Kramer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a scalable, approximate inference hypernetwork framework for a
general model of history-dependent processes. The flexible data model is based
on a neural ordinary differential equation (NODE) representing the evolution of
internal states together with a trainable observation model subcomponent. The
posterior distribution corresponding to the data model parameters (weights and
biases) follows a stochastic differential equation with a drift term related to
the score of the posterior that is learned jointly with the data model
parameters. This Langevin sampling approach offers flexibility in balancing the
computational budget between the evaluation cost of the data model and the
approximation of the posterior density of its parameters. We demonstrate
performance of the hypernetwork on chemical reaction and material physics data
and compare it to mean-field variational inference.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14815v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14815v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyong Yuan, Xiaolong Ma, Linke Guo, Lan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models (DMs) have revolutionized text-to-image generation, enabling
the creation of highly realistic and customized images from text prompts. With
the rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users
can now customize powerful pre-trained models using minimal computational
resources. However, the widespread sharing of fine-tuned DMs on open platforms
raises growing ethical and legal concerns, as these models may inadvertently or
deliberately generate sensitive or unauthorized content, such as copyrighted
material, private individuals, or harmful content. Despite the increasing
regulatory attention on generative AI, there are currently no practical tools
for systematically auditing these models before deployment. In this paper, we
address the problem of concept auditing: determining whether a fine-tuned DM
has learned to generate a specific target concept. Existing approaches
typically rely on prompt-based input crafting and output-based image
classification but suffer from critical limitations, including prompt
uncertainty, concept drift, and poor scalability. To overcome these challenges,
we introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric
concept auditing framework. By treating the DM as the object of inspection,
PAIA enables direct analysis of internal model behavior, bypassing the need for
optimized prompts or generated images. We evaluate PAIA on 320 controlled model
and 690 real-world community models sourced from a public DM sharing platform.
PAIA achieves over 90% detection accuracy while reducing auditing time by
18-40x compared to existing baselines. To our knowledge, PAIA is the first
scalable and practical solution for pre-deployment concept auditing of
diffusion models, providing a practical foundation for safer and more
transparent diffusion model sharing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Basic Evaluation of Neural Networks Trained with the Error Diffusion
  Learning Algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14814v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14814v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazuhisa Fujita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial neural networks are powerful tools capable of addressing various
tasks. Although the backpropagation algorithm has become a standard training
method for these neural networks, its lack of biological plausibility has
inspired the development of alternative learning approaches. One such
alternative is Kaneko's Error Diffusion Learning Algorithm (EDLA), a
biologically motivated approach wherein a single global error signal diffuses
throughout a network composed of paired excitatory-inhibitory sublayers,
thereby eliminating the necessity for layer-wise backpropagation. This study
presents a contemporary formulation of the EDLA framework and evaluates its
effectiveness through parity check, regression, and image classification tasks.
Our experimental results indicate that EDLA networks can consistently achieve
high accuracy across these benchmarks, with performance efficiency and
convergence speed notably influenced by the choice of learning rate, neuron
count, and network depth. Further investigation of the internal representations
formed by EDLA networks reveals their capacity for meaningful feature
extraction, similar to traditional neural networks. These results suggest that
EDLA is a biologically motivated alternative for training feedforward networks
and will motivate future work on extending this method to biologically inspired
neural networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via
  Model-Intrinsic <span class="highlight-title">Dataset</span> Pruning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14810v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14810v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jucheng Hu, Surong Yang, Dongzhan Zhou, Lijun Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ad-hoc instruction fine-tuning of large language models (LLMs) is widely
adopted for domain-specific adaptation. While domain-specific supervised
fine-tuning (SFT) is effective and efficient, it often weakens cross-domain
generalization and struggles with noisy training data. To address these
challenges, we propose DONOD, a lightweight model-intrinsic data pruning
method. Our approach evaluates data using two model-parameter-based metrics:
Delta of Norm (DON), which captures the cumulative influence on model weights,
and Norm of Delta (NOD), which quantifies weight instability. Moreover, by
employing the Technique for Order of Preference by Similarity to Ideal Solution
(TOPSIS) algorithm, we effectively filter noisy, unlearnable, and
generalization-harming samples without relying on auxiliary models during the
SFT process. Experiments on mathematical tasks demonstrate that data selected
by DONOD achieve superior fine-tuning efficiency and improved robustness
against noisy data. By filtering out 70% of the full dataset, we improve
target-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile,
our selected data present superior cross-architecture generalization. Data
pruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger
models (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD
demonstrates comparable or superior performance while remaining
dataset-agnostic, enabling broader applicability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Self-improving Token Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14808v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14808v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mario M. Kubek, Shiraj Pokharel, Thomas Böhme, Emma L. McDaniel, Herwig Unger, Armin R. Mikler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article introduces a novel and fast method for refining pre-trained
static word or, more generally, token embeddings. By incorporating the
embeddings of neighboring tokens in text corpora, it continuously updates the
representation of each token, including those without pre-assigned embeddings.
This approach effectively addresses the out-of-vocabulary problem, too.
Operating independently of large language models and shallow neural networks,
it enables versatile applications such as corpus exploration, conceptual
search, and word sense disambiguation. The method is designed to enhance token
representations within topically homogeneous corpora, where the vocabulary is
restricted to a specific domain, resulting in more meaningful embeddings
compared to general-purpose pre-trained vectors. As an example, the methodology
is applied to explore storm events and their impacts on infrastructure and
communities using narratives from a subset of the NOAA Storm Events database.
The article also demonstrates how the approach improves the representation of
storm-related terms over time, providing valuable insights into the evolving
nature of disaster narratives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 4 figures, 3 tables, accepted at the 2025 25th
  International Conference on Innovations for Community Services (I4CS), June
  11 - 13, Munich, Germany, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Sleepiness Detection for Driver State Monitoring System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14807v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14807v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deepak Ghimire, Sunghwan Jeong, Sunhong Yoon, Sanghyun Park, Juhwan Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A driver face monitoring system can detect driver fatigue, which is a
significant factor in many accidents, using computer vision techniques. In this
paper, we present a real-time technique for driver eye state detection. First,
the face is detected, and the eyes are located within the face region for
tracking. A normalized cross-correlation-based online dynamic template matching
technique, combined with Kalman filter tracking, is proposed to track the
detected eye positions in subsequent image frames. A support vector machine
with histogram of oriented gradients (HOG) features is used to classify the
state of the eyes as open or closed. If the eyes remain closed for a specified
period, the driver is considered to be asleep, and an alarm is triggered.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, published in GST 2015</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Contrastive Skill Learning with State-Transition Based Skill
  Clustering and Dynamic Length Adjustment <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14805v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14805v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinwoo Choi, Seung-Woo Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) has made significant progress in various domains,
but scaling it to long-horizon tasks with complex decision-making remains
challenging. Skill learning attempts to address this by abstracting actions
into higher-level behaviors. However, current approaches often fail to
recognize semantically similar behaviors as the same skill and use fixed skill
lengths, limiting flexibility and generalization. To address this, we propose
Dynamic Contrastive Skill Learning (DCSL), a novel framework that redefines
skill representation and learning. DCSL introduces three key ideas:
state-transition based skill representation, skill similarity function
learning, and dynamic skill length adjustment. By focusing on state transitions
and leveraging contrastive learning, DCSL effectively captures the semantic
context of behaviors and adapts skill lengths to match the appropriate temporal
extent of behaviors. Our approach enables more flexible and adaptive skill
extraction, particularly in complex or noisy datasets, and demonstrates
competitive performance compared to existing methods in task completion and
efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025; 23 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Small Sample Imbalance Problem: Metrics, Feature Analysis,
  and Solutions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14800v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14800v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuxian Zhao, Jie Gui, Minjing Dong, Baosheng Yu, Zhipeng Gui, Lu Dong, Yuan Yan Tang, James Tin-Yau Kwok
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The small sample imbalance (S&I) problem is a major challenge in machine
learning and data analysis. It is characterized by a small number of samples
and an imbalanced class distribution, which leads to poor model performance. In
addition, indistinct inter-class feature distributions further complicate
classification tasks. Existing methods often rely on algorithmic heuristics
without sufficiently analyzing the underlying data characteristics. We argue
that a detailed analysis from the data perspective is essential before
developing an appropriate solution. Therefore, this paper proposes a systematic
analytical framework for the S\&I problem. We first summarize imbalance metrics
and complexity analysis methods, highlighting the need for interpretable
benchmarks to characterize S&I problems. Second, we review recent solutions for
conventional, complexity-based, and extreme S&I problems, revealing
methodological differences in handling various data distributions. Our summary
finds that resampling remains a widely adopted solution. However, we conduct
experiments on binary and multiclass datasets, revealing that classifier
performance differences significantly exceed the improvements achieved through
resampling. Finally, this paper highlights open questions and discusses future
trends.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Verifying Robust Unlearning: Probing Residual Knowledge in Unlearned
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14798v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14798v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Xuan, Xingyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine Unlearning (MUL) is crucial for privacy protection and content
regulation, yet recent studies reveal that traces of forgotten information
persist in unlearned models, enabling adversaries to resurface removed
knowledge. Existing verification methods only confirm whether unlearning was
executed, failing to detect such residual information leaks. To address this,
we introduce the concept of Robust Unlearning, ensuring models are
indistinguishable from retraining and resistant to adversarial recovery. To
empirically evaluate whether unlearning techniques meet this security standard,
we propose the Unlearning Mapping Attack (UMA), a post-unlearning verification
framework that actively probes models for forgotten traces using adversarial
queries. Extensive experiments on discriminative and generative tasks show that
existing unlearning techniques remain vulnerable, even when passing existing
verification metrics. By establishing UMA as a practical verification tool,
this study sets a new standard for assessing and enhancing machine unlearning
security.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Edge-boosted graph learning for functional brain connectivity analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Yang, Mostafa Abdelmegeed, John Modl, Minjeong Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting disease states from functional brain connectivity is critical for
the early diagnosis of severe neurodegenerative diseases such as Alzheimer's
Disease and Parkinson's Disease. Existing studies commonly employ Graph Neural
Networks (GNNs) to infer clinical diagnoses from node-based brain connectivity
matrices generated through node-to-node similarities of regionally averaged
fMRI signals. However, recent neuroscience studies found that such node-based
connectivity does not accurately capture ``functional connections" within the
brain. This paper proposes a novel approach to brain network analysis that
emphasizes edge functional connectivity (eFC), shifting the focus to inter-edge
relationships. Additionally, we introduce a co-embedding technique to integrate
edge functional connections effectively. Experimental results on the ADNI and
PPMI datasets demonstrate that our method significantly outperforms
state-of-the-art GNN methods in classifying functional brain networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IEEE International Symposium on Biomedical Imaging (ISBI)
  2025, 4 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Segmentation with Noisy Labels via Spatially Correlated Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryu Tadokoro, Tsukasa Takagi, Shin-ichi Maeda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In semantic segmentation, the accuracy of models heavily depends on the
high-quality annotations. However, in many practical scenarios such as medical
imaging and remote sensing, obtaining true annotations is not straightforward
and usually requires significant human labor. Relying on human labor often
introduces annotation errors, including mislabeling, omissions, and
inconsistency between annotators. In the case of remote sensing, differences in
procurement time can lead to misaligned ground truth annotations. These label
errors are not independently distributed, and instead usually appear in
spatially connected regions where adjacent pixels are more likely to share the
same errors. To address these issues, we propose an approximate Bayesian
estimation based on a probabilistic model that assumes training data includes
label errors, incorporating the tendency for these errors to occur with spatial
correlations between adjacent pixels. Bayesian inference requires computing the
posterior distribution of label errors, which becomes intractable when spatial
correlations are present. We represent the correlation of label errors between
adjacent pixels through a Gaussian distribution whose covariance is structured
by a Kac-Murdock-Szeg\"{o} (KMS) matrix, solving the computational challenges.
Through experiments on multiple segmentation tasks, we confirm that leveraging
the spatial correlation of label errors significantly improves performance.
Notably, in specific tasks such as lung segmentation, the proposed method
achieves performance comparable to training with clean labels under moderate
noise levels. Code is available at
https://github.com/pfnet-research/Bayesian_SpatialCorr.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhanced Data-driven Topology Design Methodology with Multi-level Mesh
  and Correlation-based Mutation for Stress-related Multi-objective
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14790v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14790v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Yang, Shintaro Yamasaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topology optimization (TO) serves as a widely applied structural design
approach to tackle various engineering problems. Nevertheless,
sensitivity-based TO methods usually struggle with solving strongly nonlinear
optimization problems. By leveraging high capacity of deep generative model,
which is an influential machine learning technique, the sensitivity-free
data-driven topology design (DDTD) methodology is regarded as an effective
means of overcoming these issues. The DDTD methodology depends on initial
dataset with a certain regularity, making its results highly sensitive to
initial dataset quality. This limits its effectiveness and generalizability,
especially for optimization problems without priori information. In this
research, we proposed a multi-level mesh DDTD-based method with
correlation-based mutation module to escape from the limitation of the quality
of the initial dataset on the results and enhance computational efficiency. The
core is to employ a correlation-based mutation module to assign new geometric
features with physical meaning to the generated data, while utilizing a
multi-level mesh strategy to progressively enhance the refinement of the
structural representation, thus avoiding the maintenance of a high
degree-of-freedom (DOF) representation throughout the iterative process. The
proposed multi-level mesh DDTD-based method can be driven by a low quality
initial dataset without the need for time-consuming construction of a specific
dataset, thus significantly increasing generality and reducing application
difficulty, while further lowering computational cost of DDTD methodology.
Various comparison experiments with the traditional sensitivity-based TO
methods on stress-related strongly nonlinear problems demonstrate the
generality and effectiveness of the proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 22 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Novel Concept-Oriented Synthetic Data approach for Training Generative
  AI-Driven Crystal Grain Analysis Using Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed Sobhi Saleh, Kristof Croes, Hajdin Ceric, Ingrid De Wolf, Houman Zahedmanesh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The traditional techniques for extracting polycrystalline grain structures
from microscopy images, such as transmission electron microscopy (TEM) and
scanning electron microscopy (SEM), are labour-intensive, subjective, and
time-consuming, limiting their scalability for high-throughput analysis. In
this study, we present an automated methodology integrating edge detection with
generative diffusion models to effectively identify grains, eliminate noise,
and connect broken segments in alignment with predicted grain boundaries. Due
to the limited availability of adequate images preventing the training of deep
machine learning models, a new seven-stage methodology is employed to generate
synthetic TEM images for training. This concept-oriented synthetic data
approach can be extended to any field of interest where the scarcity of data is
a challenge. The presented model was applied to various metals with average
grain sizes down to the nanoscale, producing grain morphologies from
low-resolution TEM images that are comparable to those obtained from advanced
and demanding experimental techniques with an average accuracy of 97.23%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 Pages, 5 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14773v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14773v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoming Li, Zhaoliang Chen, Jonathan Zhang, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Planning is central to agents and agentic AI. The ability to plan, e.g.,
creating travel itineraries within a budget, holds immense potential in both
scientific and commercial contexts. Moreover, optimal plans tend to require
fewer resources compared to ad-hoc methods. To date, a comprehensive
understanding of existing planning benchmarks appears to be lacking. Without
it, comparing planning algorithms' performance across domains or selecting
suitable algorithms for new scenarios remains challenging. In this paper, we
examine a range of planning benchmarks to identify commonly used testbeds for
algorithm development and highlight potential gaps. These benchmarks are
categorized into embodied environments, web navigation, scheduling, games and
puzzles, and everyday task automation. Our study recommends the most
appropriate benchmarks for various algorithms and offers insights to guide
future benchmark development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RILe: Reinforced Imitation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.08472v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.08472v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mert Albaba, Sammy Christen, Thomas Langarek, Christoph Gebhardt, Otmar Hilliges, Michael J. Black
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acquiring complex behaviors is essential for artificially intelligent agents,
yet learning these behaviors in high-dimensional settings poses a significant
challenge due to the vast search space. Traditional reinforcement learning (RL)
requires extensive manual effort for reward function engineering. Inverse
reinforcement learning (IRL) uncovers reward functions from expert
demonstrations but relies on an iterative process that is often computationally
expensive. Imitation learning (IL) provides a more efficient alternative by
directly comparing an agent's actions to expert demonstrations; however, in
high-dimensional environments, such direct comparisons often offer insufficient
feedback for effective learning. We introduce RILe (Reinforced Imitation
Learning), a framework that combines the strengths of imitation learning and
inverse reinforcement learning to learn a dense reward function efficiently and
achieve strong performance in high-dimensional tasks. RILe employs a novel
trainer-student framework: the trainer learns an adaptive reward function, and
the student uses this reward signal to imitate expert behaviors. By dynamically
adjusting its guidance as the student evolves, the trainer provides nuanced
feedback across different phases of learning. Our framework produces
high-performing policies in high-dimensional tasks where direct imitation fails
to replicate complex behaviors. We validate RILe in challenging robotic
locomotion tasks, demonstrating that it significantly outperforms existing
methods and achieves near-expert performance across multiple settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DataComp-LM: In search of the next generation of training sets for
  language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11794v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11794v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muennighoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldaini, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, Vaishaal Shankar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce DataComp for Language Models (DCLM), a testbed for controlled
dataset experiments with the goal of improving language models. As part of
DCLM, we provide a standardized corpus of 240T tokens extracted from Common
Crawl, effective pretraining recipes based on the OpenLM framework, and a broad
suite of 53 downstream evaluations. Participants in the DCLM benchmark can
experiment with data curation strategies such as deduplication, filtering, and
data mixing at model scales ranging from 412M to 7B parameters. As a baseline
for DCLM, we conduct extensive experiments and find that model-based filtering
is key to assembling a high-quality training set. The resulting dataset,
DCLM-Baseline enables training a 7B parameter language model from scratch to
64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the
previous state-of-the-art in open-data language models, DCLM-Baseline
represents a 6.6 percentage point improvement on MMLU while being trained with
40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and
Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53
natural language understanding tasks while being trained with 6.6x less compute
than Llama 3 8B. Our results highlight the importance of dataset design for
training language models and offer a starting point for further research on
data curation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://www.datacomp.ai/dclm/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ASIDE: Architectural Separation of Instructions and Data in Language
  Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10566v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10566v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Egor Zverev, Evgenii Kortukov, Alexander Panfilov, Alexandra Volkova, Soroush Tabesh, Sebastian Lapuschkin, Wojciech Samek, Christoph H. Lampert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their remarkable performance, large language models lack elementary
safety features, and this makes them susceptible to numerous malicious attacks.
In particular, previous work has identified the absence of an intrinsic
separation between instructions and data as a root cause for the success of
prompt injection attacks. In this work, we propose a method, ASIDE, that allows
the model to clearly separate between instructions and data on the level of
embeddings. ASIDE applies a fixed orthogonal rotation to the embeddings of data
tokens, thus creating distinct representations of instructions and data tokens
without introducing any additional parameters. We demonstrate the effectiveness
of our method by instruct-tuning LLMs with ASIDE and showing (1) highly
increased instruction-data separation scores without a loss in model
capabilities and (2) competitive results on prompt injection benchmarks, even
without dedicated safety training. Additionally, we study the working mechanism
behind our method through an analysis of model representations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Workshop on Building Trust in Language Models and
  Applications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explorable INR: An Implicit Neural Representation for Ensemble
  Simulation Enabling Efficient Spatial and Parameter Exploration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.00904v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.00904v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi-Tang Chen, Haoyu Li, Neng Shi, Xihaier Luo, Wei Xu, Han-Wei Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing computational power available for high-resolution ensemble
simulations in scientific fields such as cosmology and oceanology, storage and
computational demands present significant challenges. Current surrogate models
fall short in the flexibility of point- or region-based predictions as the
entire field reconstruction is required for each parameter setting, hence
hindering the efficiency of parameter space exploration. Limitations exist in
capturing physical attribute distributions and pinpointing optimal parameter
configurations. In this work, we propose Explorable INR, a novel implicit
neural representation-based surrogate model, designed to facilitate exploration
and allow point-based spatial queries without computing full-scale field data.
In addition, to further address computational bottlenecks of spatial
exploration, we utilize probabilistic affine forms (PAFs) for uncertainty
propagation through Explorable INR to obtain statistical summaries,
facilitating various ensemble analysis and visualization tasks that are
expensive with existing models. Furthermore, we reformulate the parameter
exploration problem as optimization tasks using gradient descent and KL
divergence minimization that ensures scalability. We demonstrate that the
Explorable INR with the proposed approach for spatial and parameter exploration
can significantly reduce computation and memory costs while providing effective
ensemble analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Visualization and Computer Graphics
  (TVCG)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BlendRL: A Framework for Merging Symbolic and Neural Policy Learning <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11689v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11689v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hikaru Shindo, Quentin Delfosse, Devendra Singh Dhami, Kristian Kersting
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans can leverage both symbolic reasoning and intuitive reactions. In
contrast, reinforcement learning policies are typically encoded in either
opaque systems like neural networks or symbolic systems that rely on predefined
symbols and rules. This disjointed approach severely limits the agents'
capabilities, as they often lack either the flexible low-level reaction
characteristic of neural agents or the interpretable reasoning of symbolic
agents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL
framework that harmoniously integrates both paradigms within RL agents that use
mixtures of both logic and neural policies. We empirically demonstrate that
BlendRL agents outperform both neural and symbolic baselines in standard Atari
environments, and showcase their robustness to environmental changes.
Additionally, we analyze the interaction between neural and symbolic policies,
illustrating how their hybrid use helps agents overcome each other's
limitations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 (Spotlight)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training on the Test Task Confounds Evaluation and Emergence <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07890v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07890v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a fundamental problem in the evaluation of large language models
that we call training on the test task. Unlike wrongful practices like training
on the test data, leakage, or data contamination, training on the test task is
not a malpractice. Rather, the term describes a growing set of practices that
utilize knowledge about evaluation tasks at training time. We demonstrate that
training on the test task confounds both relative model evaluations and claims
about emergent capabilities. We argue that the seeming superiority of one model
family over another may be explained by a different degree of training on the
test task. To this end, we propose an effective method to adjust for the effect
of training on the test task on benchmark evaluations. Put simply, to fine-tune
each model under comparison on the same task-relevant data prior to evaluation.
We then show that instances of emergent behavior disappear gradually as models
train on the test task. Our work promotes a new perspective on the evaluation
of large language models, with broad implications for benchmarking and the
study of emergent capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast and scalable Wasserstein-1 neural optimal transport solver for
  single-cell perturbation prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.00614v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.00614v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanshuo Chen, Zhengmian Hu, Wei Chen, Heng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  \textbf{Motivation:} Predicting single-cell perturbation responses requires
mapping between two unpaired single-cell data distributions. Optimal transport
(OT) theory provides a principled framework for constructing such mappings by
minimizing transport cost. Recently, Wasserstein-2 ($W_2$) neural optimal
transport solvers (\textit{e.g.}, CellOT) have been employed for this
prediction task. However, $W_2$ OT relies on the general Kantorovich dual
formulation, which involves optimizing over two conjugate functions, leading to
a complex min-max optimization problem that converges slowly. \\
\textbf{Results:} To address these challenges, we propose a novel solver based
on the Wasserstein-1 ($W_1$) dual formulation. Unlike $W_2$, the $W_1$ dual
simplifies the optimization to a maximization problem over a single 1-Lipschitz
function, thus eliminating the need for time-consuming min-max optimization.
While solving the $W_1$ dual only reveals the transport direction and does not
directly provide a unique optimal transport map, we incorporate an additional
step using adversarial training to determine an appropriate transport step
size, effectively recovering the transport map. Our experiments demonstrate
that the proposed $W_1$ neural optimal transport solver can mimic the $W_2$ OT
solvers in finding a unique and ``monotonic" map on 2D datasets. Moreover, the
$W_1$ OT solver achieves performance on par with or surpasses $W_2$ OT solvers
on real single-cell perturbation datasets. Furthermore, we show that $W_1$ OT
solver achieves $25 \sim 45\times$ speedup, scales better on high dimensional
transportation task, and can be directly applied on single-cell RNA-seq dataset
with highly variable genes. \\ \textbf{Availability and Implementation:} Our
implementation and experiments are open-sourced at
https://github.com/poseidonchan/w1ot.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ISMB/ECCB 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CAP: A General Algorithm for Online Selective Conformal Prediction with
  FCR Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.07728v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.07728v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yajie Bao, Yuyang Huo, Haojie Ren, Changliang Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of post-selection predictive inference in an online
fashion. To avoid devoting resources to unimportant units, a preliminary
selection of the current individual before reporting its prediction interval is
common and meaningful in online predictive tasks. Since the online selection
causes a temporal multiplicity in the selected prediction intervals, it is
important to control the real-time false coverage-statement rate (FCR) which
measures the overall miscoverage level. We develop a general framework named
CAP (Calibration after Adaptive Pick) that performs an adaptive pick rule on
historical data to construct a calibration set if the current individual is
selected and then outputs a conformal prediction interval for the unobserved
label. We provide tractable procedures for constructing the calibration set for
popular online selection rules. We proved that CAP can achieve an exact
selection-conditional coverage guarantee in the finite-sample and
distribution-free regimes. To account for the distribution shift in online
data, we also embed CAP into some recent dynamic conformal prediction
algorithms and show that the proposed method can deliver long-run FCR control.
Numerical results on both synthetic and real data corroborate that CAP can
effectively control FCR around the target level and yield more narrowed
prediction intervals over existing baselines across various settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tree of Attributes <span class="highlight-title">Prompt</span> Learning for Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11201v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11201v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Ding, Wanhua Li, Zhongqi Miao, Hanspeter Pfister
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning has proven effective in adapting vision language models for
downstream tasks. However, existing methods usually append learnable prompt
tokens solely with the category names to obtain textual features, which fails
to fully leverage the rich context indicated in the category name. To address
this issue, we propose the Tree of Attributes Prompt learning (TAP), which
first instructs LLMs to generate a tree of attributes with a "concept -
attribute - description" structure for each category, and then learn the
hierarchy with vision and text prompt tokens. Unlike existing methods that
merely augment category names with a set of unstructured descriptions, our
approach essentially distills structured knowledge graphs associated with class
names from LLMs. Furthermore, our approach introduces text and vision prompts
designed to explicitly learn the corresponding visual attributes, effectively
serving as domain experts. Additionally, the general and diverse descriptions
generated based on the class names may be wrong or absent in the specific given
images. To address this misalignment, we further introduce a vision-conditional
pooling module to extract instance-specific text features. Extensive
experimental results demonstrate that our approach outperforms state-of-the-art
methods on the zero-shot base-to-novel generalization, cross-dataset transfer,
as well as few-shot classification across 11 diverse datasets. Code is
available at https://github.com/HHenryD/TAP.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding LLM Behaviors via Compression: Data Generation, Knowledge
  Acquisition and Scaling Laws 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09597v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09597v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhixuan Pan, Shaowen Wang, Jian Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable capabilities across
numerous tasks, yet principled explanations for their underlying mechanisms and
several phenomena, such as scaling laws, hallucinations, and related behaviors,
remain elusive. In this work, we revisit the classical relationship between
compression and prediction, grounded in Kolmogorov complexity and Shannon
information theory, to provide deeper insights into LLM behaviors. By
leveraging the Kolmogorov Structure Function and interpreting LLM compression
as a two-part coding process, we offer a detailed view of how LLMs acquire and
store information across increasing model and data scales -- from pervasive
syntactic patterns to progressively rarer knowledge elements. Motivated by this
theoretical perspective and natural assumptions inspired by Heap's and Zipf's
laws, we introduce a simplified yet representative hierarchical data-generation
framework called the Syntax-Knowledge model. Under the Bayesian setting, we
show that prediction and compression within this model naturally lead to
diverse learning and scaling behaviors of LLMs. In particular, our theoretical
analysis offers intuitive and principled explanations for both data and model
scaling laws, the dynamics of knowledge acquisition during training and
fine-tuning, factual knowledge hallucinations in LLMs. The experimental results
validate our theoretical predictions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LServe: Efficient Long-sequence LLM Serving with Unified Sparse
  Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.14866v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.14866v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shang Yang, Junxian Guo, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable potential in processing
long sequences and complex reasoning tasks, yet efficiently serving these
models remains challenging due to the quadratic computational complexity of
attention in the prefilling stage and the large memory footprint of the KV
cache in the decoding stage. To address these issues, we introduce LServe, an
efficient system that accelerates long-sequence LLM serving via hybrid sparse
attention. This method unifies different hardware-friendly, structured sparsity
patterns for both prefilling and decoding attention into a single framework,
where computations on less important tokens are skipped block-wise. LServe
demonstrates the compatibility of static and dynamic sparsity in long-context
LLM attention. This design enables multiplicative speedups by combining these
optimizations. Specifically, we convert half of the attention heads to nearly
free streaming heads in both the prefilling and decoding stages. Additionally,
we find that only a constant number of KV pages is required to preserve
long-context and reasoning capabilities, irrespective of context length. We
then design a hierarchical KV page selection policy that dynamically prunes KV
pages based on query-centric similarity. On average, LServe accelerates LLM
prefilling by up to 2.9x and decoding by 1.3-2.1x over vLLM, maintaining
long-context accuracy. Code is released at
https://github.com/mit-han-lab/omniserve.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MLSys 2025. Code available at:
  https://github.com/mit-han-lab/omniserve</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph
  Construction Using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21060v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21060v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI knowledge extraction methods lack flexibility
and generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through: (1) a carefully designed automatic prompt
construction strategy with optimal demonstration retrieval for extracting a
wide range of cybersecurity entities and relations; (2) a hierarchical entity
alignment technique that canonicalizes the extracted knowledge and removes
redundancy; (3) an long-distance relation prediction technique to further
complete the CSKG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKG, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at 2025 IEEE European Symposium on Security and Privacy
  (Euro S&P)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic Wave Functions: Exploring Meaning in Large Language Models
  Through Quantum Formalism 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10664v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10664v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timo Aukusti Laine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) encode semantic relationships in
high-dimensional vector embeddings. This paper explores the analogy between LLM
embedding spaces and quantum mechanics, positing that LLMs operate within a
quantized semantic space where words and phrases behave as quantum states. To
capture nuanced semantic interference effects, we extend the standard
real-valued embedding space to the complex domain, drawing parallels to the
double-slit experiment. We introduce a "semantic wave function" to formalize
this quantum-derived representation and utilize potential landscapes, such as
the double-well potential, to model semantic ambiguity. Furthermore, we propose
a complex-valued similarity measure that incorporates both magnitude and phase
information, enabling a more sensitive comparison of semantic representations.
We develop a path integral formalism, based on a nonlinear Schr\"odinger
equation with a gauge field and Mexican hat potential, to model the dynamic
evolution of LLM behavior. This interdisciplinary approach offers a new
theoretical framework for understanding and potentially manipulating LLMs, with
the goal of advancing both artificial and natural language understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 4 figures. Some corrections added</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A direct proof of a unified law of robustness for Bregman divergence
  losses 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16639v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16639v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santanu Das, Jatin Batra, Piyush Srivastava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In contemporary deep learning practice, models are often trained to near zero
loss i.e. to nearly interpolate the training data. However, the number of
parameters in the model is usually far more than the number of data points n,
the theoretical minimum needed for interpolation: a phenomenon referred to as
overparameterization. In an interesting piece of work, Bubeck and Sellke
considered a natural notion of interpolation: the model is said to interpolate
when the model's training loss goes below the loss of the conditional
expectation of the response given the covariate. For this notion of
interpolation and for a broad class of covariate distributions (specifically
those satisfying a natural notion of concentration of measure), they showed
that overparameterization is necessary for robust interpolation i.e. if the
interpolating function is required to be Lipschitz. Their main proof technique
applies to regression with square loss against a scalar response, but they
remark that via a connection to Rademacher complexity and using tools such as
the Ledoux-Talagrand contraction inequality, their result can be extended to
more general losses, at least in the case of scalar response variables. In this
work, we recast the original proof technique of Bubeck and Sellke in terms of a
bias-variance type decomposition, and show that this view directly unlocks a
generalization to Bregman divergence losses (even for vector-valued responses),
without the use of tools such as Rademacher complexity or the Ledoux-Talagrand
contraction principle. Bregman divergences are a natural class of losses since
for these, the best estimator is the conditional expectation of the response
given the covariate, and include other practical losses such as the cross
entropy loss. Our work thus gives a more general understanding of the main
proof technique of Bubeck and Sellke and demonstrates its broad utility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages; fixed a typo in a citation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Commonalities in Explanation Frameworks: A Multi-Domain <span class="highlight-title">Survey</span>
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11958v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11958v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduard Barbu, Marharyta Domnich, Raul Vicente, Nikos Sakkas, André Morim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents insights gathered from surveys and discussions with
specialists in three domains, aiming to find essential elements for a universal
explanation framework that could be applied to these and other similar use
cases. The insights are incorporated into a software tool that utilizes GP
algorithms, known for their interpretability. The applications analyzed include
a medical scenario (involving predictive ML), a retail use case (involving
prescriptive ML), and an energy use case (also involving predictive ML). We
interviewed professionals from each sector, transcribing their conversations
for further analysis. Additionally, experts and non-experts in these fields
filled out questionnaires designed to probe various dimensions of explanatory
methods. The findings indicate a universal preference for sacrificing a degree
of accuracy in favor of greater explainability. Additionally, we highlight the
significance of feature importance and counterfactual explanations as critical
components of such a framework. Our questionnaires are publicly available to
facilitate the dissemination of knowledge in the field of XAI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Depth Pro: Sharp Monocular Metric Depth in Less Than a Second <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02073v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02073v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleksei Bochkovskii, Amaël Delaunoy, Hugo Germain, Marcel Santos, Yichao Zhou, Stephan R. Richter, Vladlen Koltun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a foundation model for zero-shot metric monocular depth
estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with
unparalleled sharpness and high-frequency details. The predictions are metric,
with absolute scale, without relying on the availability of metadata such as
camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map
in 0.3 seconds on a standard GPU. These characteristics are enabled by a number
of technical contributions, including an efficient multi-scale vision
transformer for dense prediction, a training protocol that combines real and
synthetic datasets to achieve high metric accuracy alongside fine boundary
tracing, dedicated evaluation metrics for boundary accuracy in estimated depth
maps, and state-of-the-art focal length estimation from a single image.
Extensive experiments analyze specific design choices and demonstrate that
Depth Pro outperforms prior work along multiple dimensions. We release code and
weights at https://github.com/apple/ml-depth-pro
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025. Code and weights available at
  https://github.com/apple/ml-depth-pro</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Barren plateaus are amplified by the dimension of qudits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08190v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08190v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Friedrich, Tiago de Souza Farias, Jonas Maziero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Variational Quantum Algorithms (VQAs) have emerged as pivotal strategies for
attaining quantum advantage in diverse scientific and technological domains,
notably within Quantum Neural Networks. However, despite their potential, VQAs
encounter significant obstacles, chief among them being the vanishing gradient
problem, commonly referred to as barren plateaus. In this article, through
meticulous analysis, we demonstrate that existing literature implicitly
suggests the intrinsic influence of qudit dimensionality on barren plateaus. To
instantiate these findings, we present numerical results that exemplify the
impact of qudit dimensionality on barren plateaus. Therefore, despite the
proposition of various error mitigation techniques, our results call for
further scrutiny about their efficacy in the context of VQAs with qudits.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MRAMG-Bench: A Comprehensive Benchmark for Advancing Multimodal
  Retrieval-Augmented Multimodal Generation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinhan Yu, Zhiyou Xiao, Binghui Li, Zhengren Wang, Chong Chen, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Retrieval-Augmented Generation (RAG) have significantly
improved response accuracy and relevance by incorporating external knowledge
into Large Language Models (LLMs). However, existing RAG methods primarily
focus on generating text-only answers, even in Multimodal Retrieval-Augmented
Generation (MRAG) scenarios, where multimodal elements are retrieved to assist
in generating text answers. To address this, we introduce the Multimodal
Retrieval-Augmented Multimodal Generation (MRAMG) task, in which we aim to
generate multimodal answers that combine both text and images, fully leveraging
the multimodal data within a corpus. Despite growing attention to this
challenging task, a notable lack of a comprehensive benchmark persists for
effectively evaluating its performance. To bridge this gap, we provide
MRAMG-Bench, a meticulously curated, human-annotated benchmark comprising 4,346
documents, 14,190 images, and 4,800 QA pairs, distributed across six distinct
datasets and spanning three domains: Web, Academia, and Lifestyle. The datasets
incorporate diverse difficulty levels and complex multi-image scenarios,
providing a robust foundation for evaluating the MRAMG task. To facilitate
rigorous evaluation, MRAMG-Bench incorporates a comprehensive suite of both
statistical and LLM-based metrics, enabling a thorough analysis of the
performance of generative models in the MRAMG task. Additionally, we propose an
efficient and flexible multimodal answer generation framework that can leverage
LLMs/MLLMs to generate multimodal responses. Our datasets and complete
evaluation results for 11 popular generative models are available at
https://github.com/MRAMG-Bench/MRAMG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at SIGIR 2025; 11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continuous Locomotive Crowd Behavior Generation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04756v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04756v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Inhwan Bae, Junoh Lee, Hae-Gon Jeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and reproducing crowd behaviors are important in various domains
including psychology, robotics, transport engineering and virtual environments.
Conventional methods have focused on synthesizing momentary scenes, which have
difficulty in replicating the continuous nature of real-world crowds. In this
paper, we introduce a novel method for automatically generating continuous,
realistic crowd trajectories with heterogeneous behaviors and interactions
among individuals. We first design a crowd emitter model. To do this, we obtain
spatial layouts from single input images, including a segmentation map,
appearance map, population density map and population probability, prior to
crowd generation. The emitter then continually places individuals on the
timeline by assigning independent behavior characteristics such as agents'
type, pace, and start/end positions using diffusion models. Next, our crowd
simulator produces their long-term locomotions. To simulate diverse actions, it
can augment their behaviors based on a Markov chain. As a result, our overall
framework populates the scenes with heterogeneous crowd behaviors by
alternating between the proposed emitter and simulator. Note that all the
components in the proposed framework are user-controllable. Lastly, we propose
a benchmark protocol to evaluate the realism and quality of the generated
crowds in terms of the scene-level population dynamics and the individual-level
trajectory accuracy. We demonstrate that our approach effectively models
diverse crowd behavior patterns and generalizes well across different
geographical environments. Code is publicly available at
https://github.com/InhwanBae/CrowdES .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025. Project page:
  https://ihbae.com/publication/crowdes/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Contractivity and linear convergence in bilinear saddle-point problems:
  An operator-theoretic approach <span class="chip">AISTATS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Colin Dirren, Mattia Bianchi, Panagiotis D. Grontas, John Lygeros, Florian Dörfler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the convex-concave bilinear saddle-point problem $\min_x \max_y f(x)
+ y^\top Ax - g(y)$, where both, only one, or none of the functions $f$ and $g$
are strongly convex, and suitable rank conditions on the matrix $A$ hold. The
solution of this problem is at the core of many machine learning tasks. By
employing tools from monotone operator theory, we systematically prove the
contractivity (in turn, the linear convergence) of several first-order
primal-dual algorithms, including the Chambolle-Pock method. Our approach
results in concise proofs, and it yields new convergence guarantees and tighter
bounds compared to known results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Accelerating Goal-Conditioned RL Algorithms and Research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11052v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11052v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michał Bortkiewicz, Władysław Pałucki, Vivek Myers, Tadeusz Dziarmaga, Tomasz Arczewski, Łukasz Kuciński, Benjamin Eysenbach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervision has the potential to transform reinforcement learning (RL),
paralleling the breakthroughs it has enabled in other areas of machine
learning. While self-supervised learning in other domains aims to find patterns
in a fixed dataset, self-supervised goal-conditioned reinforcement learning
(GCRL) agents discover new behaviors by learning from the goals achieved during
unstructured interaction with the environment. However, these methods have
failed to see similar success, both due to a lack of data from slow environment
simulations as well as a lack of stable algorithms. We take a step toward
addressing both of these issues by releasing a high-performance codebase and
benchmark (JaxGCRL) for self-supervised GCRL, enabling researchers to train
agents for millions of environment steps in minutes on a single GPU. By
utilizing GPU-accelerated replay buffers, environments, and a stable
contrastive RL algorithm, we reduce training time by up to $22\times$.
Additionally, we assess key design choices in contrastive RL, identifying those
that most effectively stabilize and enhance training performance. With this
approach, we provide a foundation for future research in self-supervised GCRL,
enabling researchers to quickly iterate on new ideas and evaluate them in
diverse and challenging environments. Website + Code:
https://github.com/MichalBortkiewicz/JaxGCRL
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Website: https://michalbortkiewicz.github.io/JaxGCRL/ Code:
  https://github.com/MichalBortkiewicz/JaxGCRL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Generative Artificial Intelligence and Large Language Models
  for Demand Side Management with Internet of Electric Vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15544v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15544v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanwen Zhang, Ruichen Zhang, Wei Zhang, Dusit Niyato, Yonggang Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative artificial intelligence, particularly through large language
models (LLMs), is poised to transform energy optimization and demand side
management (DSM) within microgrids. This paper explores the integration of LLMs
into energy management, emphasizing their roles in automating the optimization
of DSM strategies with Internet of electric vehicles. We investigate challenges
and solutions associated with DSM and explore the new opportunities presented
by leveraging LLMs. Then, we propose an innovative solution that enhances LLMs
with retrieval-augmented generation for automatic problem formulation, code
generation, and customizing optimization. We present a case study to
demonstrate the effectiveness of our proposed solution in charging scheduling
and optimization for electric vehicles, highlighting our solution's significant
advancements in energy efficiency and user adaptability. This work underscores
the potential of LLMs for energy optimization and fosters a new era of
intelligent DSM solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 Pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transferable Adversarial Attacks on SAM and Its Downstream Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20197v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20197v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Song Xia, Wenhan Yang, Yi Yu, Xun Lin, Henghui Ding, Ling-Yu Duan, Xudong Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The utilization of large foundational models has a dilemma: while fine-tuning
downstream tasks from them holds promise for making use of the well-generalized
knowledge in practical applications, their open accessibility also poses
threats of adverse usage. This paper, for the first time, explores the
feasibility of adversarial attacking various downstream models fine-tuned from
the segment anything model (SAM), by solely utilizing the information from the
open-sourced SAM. In contrast to prevailing transfer-based adversarial attacks,
we demonstrate the existence of adversarial dangers even without accessing the
downstream task and dataset to train a similar surrogate model. To enhance the
effectiveness of the adversarial attack towards models fine-tuned on unknown
datasets, we propose a universal meta-initialization (UMI) algorithm to extract
the intrinsic vulnerability inherent in the foundation model, which is then
utilized as the prior knowledge to guide the generation of adversarial
perturbations. Moreover, by formulating the gradient difference in the
attacking process between the open-sourced SAM and its fine-tuned downstream
models, we theoretically demonstrate that a deviation occurs in the adversarial
update direction by directly maximizing the distance of encoded feature
embeddings in the open-sourced SAM. Consequently, we propose a gradient robust
loss that simulates the associated uncertainty with gradient-based noise
augmentation to enhance the robustness of generated adversarial examples (AEs)
towards this deviation, thus improving the transferability. Extensive
experiments demonstrate the effectiveness of the proposed universal
meta-initialized and gradient robust adversarial attack (UMI-GRAT) toward SAMs
and their downstream models. Code is available at
https://github.com/xiasong0501/GRAT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>update fig 1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TinyML NLP Scheme for Semantic Wireless Sentiment Classification with
  Privacy Preservation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06291v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06291v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed Y. Radwan, Mohammad Shehab, Mohamed-Slim Alouini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural Language Processing (NLP) operations, such as semantic sentiment
analysis and text synthesis, often raise privacy concerns and demand
significant on-device computational resources. Centralized learning (CL) on the
edge provides an energy-efficient alternative but requires collecting raw data,
compromising user privacy. While federated learning (FL) enhances privacy, it
imposes high computational energy demands on resource-constrained devices. This
study provides insights into deploying privacy-preserving, energy-efficient NLP
models on edge devices. We introduce semantic split learning (SL) as an
energy-efficient, privacy-preserving tiny machine learning (TinyML) framework
and compare it to FL and CL in the presence of Rayleigh fading and additive
noise. Our results show that SL significantly reduces computational power and
CO2 emissions while enhancing privacy, as evidenced by a fourfold increase in
reconstruction error compared to FL and nearly eighteen times that of CL. In
contrast, FL offers a balanced trade-off between privacy and efficiency. Our
code is available for replication at our GitHub repository:
https://github.com/AhmedRadwan02/TinyEco2AI-NLP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EuCNC & 6G Summit 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Context-Parametric Inversion: Why Instruction Finetuning Can Worsen
  Context Reliance <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10796v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10796v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A standard practice when using large language models is for users to
supplement their instruction with an input context containing new information
for the model to process. However, models struggle to reliably follow the input
context, especially when it conflicts with their parametric knowledge from
pretraining. In-principle, one would expect models to adapt to the user context
better after instruction finetuning, particularly when handling knowledge
conflicts. However, we observe a surprising failure mode: during instruction
tuning, the context reliance under knowledge conflicts initially increases as
expected, but then gradually decreases as instruction finetuning progresses.
This happens while the performance on standard benchmarks keeps on increasing
far after this drop. We call this phenomenon context-parametric inversion and
observe it across multiple general purpose instruction tuning datasets such as
TULU, Alpaca and Ultrachat, across different model families like Llama,
Mistral, and Pythia. We perform various controlled studies and theoretical
analysis to show that context-parametric inversion occurs due to examples in
the instruction finetuning data where the input context provides information
that aligns with model's parametric knowledge. Our analysis suggests some
natural mitigation strategies with limited but insightful gains, and serves as
a useful starting point in addressing this deficiency in instruction
finetuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03312v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03312v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) have demonstrated strong capabilities across
various visual understanding and reasoning tasks, driven by incorporating image
representations into the token inputs of Large Language Models (LLMs). However,
their real-world deployment is often constrained by high latency during
inference due to the substantial compute required by the LLM to process the
large number of input tokens, predominantly arising from the image. To reduce
inference costs, one can either downsize the LLM or reduce the number of input
tokens needed to represent the image, the latter of which has been the focus of
many recent efforts around token compression. However, it is unclear what the
optimal trade-off is given a fixed inference budget. We first characterize this
optimal trade-off between the number of visual tokens and LLM parameters by
establishing scaling laws that capture variations in performance with these two
factors. Our results reveal a surprising trend: for visual reasoning tasks, the
inference-optimal behavior in VLMs is achieved by using the largest LLM that
fits within the inference budget while minimizing visual token count - often to
a single token. While the token reduction literature has mainly focused on
maintaining base model performance by modestly reducing the token count (e.g.,
$5-10\times$), our results indicate that the compute-optimal inference regime
requires operating under even higher token compression ratios. Based on these
insights, we take the first steps toward designing token compression algorithms
tailored for high-compression settings, utilizing prompt-based compression of
tokens. Our work underscores the performance and efficiency benefits of
operating in low visual token regimes and the importance of developing tailored
token reduction algorithms for such conditions. Code is available at
https://github.com/locuslab/llava-token-compression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multiple-Resolution Tokenization for Time Series Forecasting with an
  Application to Pricing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03185v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03185v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Egon Peršak, Miguel F. Anjos, Sebastian Lautz, Aleksandar Kolev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a transformer architecture for time series forecasting with a
focus on time series tokenisation and apply it to a real-world prediction
problem from the pricing domain. Our architecture aims to learn effective
representations at many scales across all available data simultaneously. The
model contains a number of novel modules: a differentiated form of time series
patching which employs multiple resolutions, a multiple-resolution module for
time-varying known variables, a mixer-based module for capturing cross-series
information, and a novel output head with favourable scaling to account for the
increased number of tokens. We present an application of this model to a real
world prediction problem faced by the markdown team at a very large retailer.
On the experiments conducted our model outperforms in-house models and the
selected existing deep learning architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Audio-Language Models through <span class="highlight-title">Self-Supervised</span> Post-Training
  with Text-Audio Pairs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09269v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09269v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anshuman Sinha, Camille Migozzi, Aubin Rey, Chao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on multi-modal contrastive learning strategies for audio and text
has rapidly gained interest. Contrastively trained Audio-Language Models
(ALMs), such as CLAP, which establish a unified representation across audio and
language modalities, have enhanced the efficacy in various subsequent tasks by
providing good text aligned audio encoders and vice versa. These improvements
are evident in areas like zero-shot audio classification and audio retrieval,
among others. However, the ability of these models to understand natural
language and temporal relations is still a largely unexplored and open field
for research. In this paper, we propose to equip the multi-modal ALMs with
temporal understanding without loosing their inherent prior capabilities of
audio-language tasks with a temporal instillation method TeminAL. We implement
a two-stage training scheme TeminAL A $\&$ B, where the model first learns to
differentiate between multiple sounds in TeminAL A, followed by a phase that
instills a sense of time, thereby enhancing its temporal understanding in
TeminAL B. This approach results in an average performance gain of $5.28\%$ in
temporal understanding on the ESC-50 dataset, while the model remains
competitive in zero-shot retrieval and classification tasks on the
AudioCap/Clotho datasets. We also note the lack of proper evaluation techniques
for contrastive ALMs and propose a strategy for evaluating ALMs in zero-shot
settings. The general-purpose zero-shot model evaluation strategy ZSTE, is used
to evaluate various prior models. ZSTE demonstrates a general strategy to
evaluate all ZS contrastive models. The model trained with TeminAL successfully
outperforms current models on most downstream tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Self-Growth Maps for Fast and Accurate Imbalanced Streaming
  Data Clustering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.09243v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.09243v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqun Zhang, Sen Feng, Pengkai Wang, Zexi Tan, Xiaopeng Luo, Yuzhu Ji, Rong Zou, Yiu-ming Cheung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Streaming data clustering is a popular research topic in data mining and
machine learning. Since streaming data is usually analyzed in data chunks, it
is more susceptible to encounter the dynamic cluster imbalance issue. That is,
the imbalance ratio of clusters changes over time, which can easily lead to
fluctuations in either the accuracy or the efficiency of streaming data
clustering. Therefore, we propose an accurate and efficient streaming data
clustering approach to adapt the drifting and imbalanced cluster distributions.
We first design a Self-Growth Map (SGM) that can automatically arrange neurons
on demand according to local distribution, and thus achieve fast and
incremental adaptation to the streaming distributions. Since SGM allocates an
excess number of density-sensitive neurons to describe the global distribution,
it can avoid missing small clusters among imbalanced distributions. We also
propose a fast hierarchical merging strategy to combine the neurons that break
up the relatively large clusters. It exploits the maintained SGM to quickly
retrieve the intra-cluster distribution pairs for merging, which circumvents
the most laborious global searching. It turns out that the proposed SGM can
incrementally adapt to the distributions of new chunks, and the Self-grOwth
map-guided Hierarchical merging for Imbalanced data clustering (SOHI) approach
can quickly explore a true number of imbalanced clusters. Extensive experiments
demonstrate that SOHI can efficiently and accurately explore cluster
distributions for streaming data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AlphaNet: Scaling Up Local-frame-based Atomistic Interatomic Potential 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.07155v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.07155v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bangchen Yin, Jiaao Wang, Weitao Du, Pengbo Wang, Penghua Ying, Haojun Jia, Zisheng Zhang, Yuanqi Du, Carla P. Gomes, Chenru Duan, Graeme Henkelman, Hai Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular dynamics simulations demand an unprecedented combination of
accuracy and scalability to tackle grand challenges in catalysis and materials
design. To bridge this gap, we present AlphaNet, a local-frame-based
equivariant model that simultaneously improves computational efficiency and
predictive precision for interatomic interactions. By constructing equivariant
local frames with learnable geometric transitions, AlphaNet encodes atomic
environments with enhanced representational capacity, achieving
state-of-the-art accuracy in energy and force predictions. Extensive benchmarks
on large-scale datasets spanning molecular reactions, crystal stability, and
surface catalysis (Matbench Discovery and OC2M) demonstrate its superior
performance over existing neural network interatomic potentials while ensuring
scalability across diverse system sizes with varying types of interatomic
interactions. The synergy of accuracy, efficiency, and transferability
positions AlphaNet as a transformative tool for modeling multiscale phenomena,
decoding dynamics in catalysis and functional interfaces, with direct
implications for accelerating the discovery of complex molecular systems and
functional materials.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Active Learning for Continual Learning: Keeping the Past Alive in the
  Present 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.14278v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.14278v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehyun Park, Dongmin Park, Jae-Gil Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Continual learning (CL) enables deep neural networks to adapt to
ever-changing data distributions. In practice, there may be scenarios where
annotation is costly, leading to active continual learning (ACL), which
performs active learning (AL) for the CL scenarios when reducing the labeling
cost by selecting the most informative subset is preferable. However,
conventional AL strategies are not suitable for ACL, as they focus solely on
learning the new knowledge, leading to catastrophic forgetting of previously
learned tasks. Therefore, ACL requires a new AL strategy that can balance the
prevention of catastrophic forgetting and the ability to quickly learn new
tasks. In this paper, we propose AccuACL, Accumulated informativeness-based
Active Continual Learning, by the novel use of the Fisher information matrix as
a criterion for sample selection, derived from a theoretical analysis of the
Fisher-optimality preservation properties within the framework of ACL, while
also addressing the scalability issue of Fisher information-based AL. Extensive
experiments demonstrate that AccuACL significantly outperforms AL baselines
across various CL algorithms, increasing the average accuracy and forgetting by
23.8% and 17.0%, respectively, on average.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lorentzian Graph Isomorphic Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.00142v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.00142v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Srinitish Srinivasan, Omkumar CU
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Lorentzian Graph Isomorphic Network (LGIN), a novel graph
neural network (GNN) designed to operate in hyperbolic spaces, leveraging the
Lorentzian model to enhance graph representation learning. Existing GNNs
primarily operate in Euclidean spaces, which can limit their ability to capture
hierarchical and multi-relational structures inherent to complex graphs. LGIN
addresses this by incorporating curvature-aware aggregation functions that
preserve the Lorentzian metric tensor, ensuring embeddings remain constrained
within the hyperbolic space by proposing a new update rule that effectively
captures both local neighborhood interactions and global structural properties,
enabling LGIN to distinguish non-isomorphic graphs with expressiveness at least
as powerful as the Weisfeiler-Lehman test. Through extensive evaluation across
nine benchmark datasets, including molecular and protein structures, LGIN
consistently outperforms or matches state-of-the-art GNNs, demonstrating its
robustness and efficacy in modeling complex graph structures. To the best of
our knowledge, this is the first study to extend the concept of a powerful
graph neural network to Riemannian manifolds, paving the way for future
advancements in hyperbolic graph learning. The code for our paper can be found
at https://github.com/Deceptrax123/LGIN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Learning Models Meet Financial Data Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13521v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13521v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kasymkhan Khubiev, Mikhail Semenov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Algorithmic trading relies on extracting meaningful signals from diverse
financial data sources, including candlestick charts, order statistics on put
and canceled orders, traded volume data, limit order books, and news flow.
While deep learning has demonstrated remarkable success in processing
unstructured data and has significantly advanced natural language processing,
its application to structured financial data remains an ongoing challenge. This
study investigates the integration of deep learning models with financial data
modalities, aiming to enhance predictive performance in trading strategies and
portfolio optimization. We present a novel approach to incorporating limit
order book analysis into algorithmic trading by developing embedding techniques
and treating sequential limit order book snapshots as distinct input channels
in an image-based representation. Our methodology for processing limit order
book data achieves state-of-the-art performance in high-frequency trading
algorithms, underscoring the effectiveness of deep learning in financial
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 14 images, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Strategic Coordination Framework of Small LLMs Matches Large LLMs in
  Data Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12322v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12322v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, Honglin Lin, Jiang Wu, Lijun Wu, Conghui He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While data synthesis and distillation are promising strategies to enhance
small language models, current approaches heavily rely on Large Language Models
(LLMs), which suffer from high computational costs, environmental inefficiency,
and potential biases inherited from monolithic architectures. In contrast,
smaller LLMs are more accessible and sustainable, but their individual
capabilities often fall short in generating high-quality, diverse, and reliable
data. Inspired by collaborative human processes (e.g., peer review), we propose
a multiple small LLMs involved framework, GRA, that aggregates specialized
roles across small LLMs to iterative refinement and quality control typically
achieved by a single large LLM. In this collaborative framework, multiple small
LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a
peer-review-inspired data synthesis pipeline. The Generator proposes initial
data samples, the Reviewer critiques their quality and diversity, and the
Adjudicator resolves conflicts to finalize the output. By decomposing the
synthesis process into specialized sub-tasks, collaborative small LLMs can
achieve data-level parity with large LLM-based distillation. Through
experiments across multiple benchmarks, we demonstrate that GRA-produced data
matches or exceeds the quality of single large LLM outputs, e.g.,
Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large
models for high-quality data synthesis, advocating instead for strategic
coordination of smaller agents. Our datasets, models, and code are publicly
available at https://github.com/GX-XinGao/GRA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Communication Optimization for Decentralized Learning atop
  Bandwidth-limited Edge Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12210v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12210v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingyang Sun, Tuan Nguyen, Ting He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decentralized federated learning (DFL) is a promising machine learning
paradigm for bringing artificial intelligence (AI) capabilities to the network
edge. Running DFL on top of edge networks, however, faces severe performance
challenges due to the extensive parameter exchanges between agents. Most
existing solutions for these challenges were based on simplistic communication
models, which cannot capture the case of learning over a multi-hop
bandwidth-limited network. In this work, we address this problem by jointly
designing the communication scheme for the overlay network formed by the agents
and the mixing matrix that controls the communication demands between the
agents. By carefully analyzing the properties of our problem, we cast each
design problem into a tractable optimization and develop an efficient algorithm
with guaranteed performance. Our evaluations based on real topology and data
show that the proposed algorithm can reduce the total training time by over
$80\%$ compared to the baseline without sacrificing accuracy, while
significantly improving the computational efficiency over the state of the art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2408.04705</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Structuring Multiple Simple Cycle Reservoirs with Particle Swarm
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05347v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05347v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiang Li, Robert Simon Fong, Kantaro Fujiwara, Kazuyuki Aihara, Gouhei Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reservoir Computing (RC) is a time-efficient computational paradigm derived
from Recurrent Neural Networks (RNNs). The Simple Cycle Reservoir (SCR) is an
RC model that stands out for its minimalistic design, offering extremely low
construction complexity and proven capability of universally approximating
time-invariant causal fading memory filters, even in the linear dynamics
regime. This paper introduces Multiple Simple Cycle Reservoirs (MSCRs), a
multi-reservoir framework that extends Echo State Networks (ESNs) by replacing
a single large reservoir with multiple interconnected SCRs. We demonstrate that
optimizing MSCR using Particle Swarm Optimization (PSO) outperforms existing
multi-reservoir models, achieving competitive predictive performance with a
lower-dimensional state space. By modeling interconnections as a weighted
Directed Acyclic Graph (DAG), our approach enables flexible, task-specific
network topology adaptation. Numerical simulations on three benchmark
time-series prediction tasks confirm these advantages over rival algorithms.
These findings highlight the potential of MSCR-PSO as a promising framework for
optimizing multi-reservoir systems, providing a foundation for further
advancements and applications of interconnected SCRs for developing efficient
AI devices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Constrained Multi-objective Bayesian Optimization through Optimistic
  Constraints Estimation <span class="chip">AISTATS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03641v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03641v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Diantong Li, Fengxue Zhang, Chong Liu, Yuxin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-objective Bayesian optimization has been widely adopted in scientific
experiment design, including drug discovery and hyperparameter optimization. In
practice, regulatory or safety concerns often impose additional thresholds on
certain attributes of the experimental outcomes. Previous work has primarily
focused on constrained single-objective optimization tasks or active search
under constraints. The existing constrained multi-objective algorithms address
the issue with heuristics and approximations, posing challenges to the analysis
of the sample efficiency. We propose a novel constrained multi-objective
Bayesian optimization algorithm COMBOO that balances active learning of the
level-set defined on multiple unknowns with multi-objective optimization within
the feasible region. We provide both theoretical analysis and empirical
evidence, demonstrating the efficacy of our approach on various synthetic
benchmarks and real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted to AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hierarchical Split Federated Learning: Convergence Analysis and System
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07197v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07197v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Lin, Wei Wei, Zhe Chen, Chan-Tong Lam, Xianhao Chen, Yue Gao, Jun Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As AI models expand in size, it has become increasingly challenging to deploy
federated learning (FL) on resource-constrained edge devices. To tackle this
issue, split federated learning (SFL) has emerged as an FL framework with
reduced workload on edge devices via model splitting; it has received extensive
attention from the research community in recent years. Nevertheless, most prior
works on SFL focus only on a two-tier architecture without harnessing
multi-tier cloudedge computing resources. In this paper, we intend to analyze
and optimize the learning performance of SFL under multi-tier systems.
Specifically, we propose the hierarchical SFL (HSFL) framework and derive its
convergence bound. Based on the theoretical results, we formulate a joint
optimization problem for model splitting (MS) and model aggregation (MA). To
solve this rather hard problem, we then decompose it into MS and MA subproblems
that can be solved via an iterative descending algorithm. Simulation results
demonstrate that the tailored algorithm can effectively optimize MS and MA for
SFL within virtually any multi-tier system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Satellite Federated Fine-Tuning for Foundation Models in Space Computing
  Power Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10403v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10403v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Zhu, Jingyang Zhu, Ting Wang, Yuanming Shi, Chunxiao Jiang, Khaled Ben Letaief
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in artificial intelligence (AI) and low-earth orbit (LEO)
satellites have promoted the application of large remote sensing foundation
models for various downstream tasks. However, direct downloading of these
models for fine-tuning on the ground is impeded by privacy concerns and limited
bandwidth. Satellite federated learning (FL) offers a solution by enabling
model fine-tuning directly on-board satellites and aggregating model updates
without data downloading. Nevertheless, for large foundation models, the
computational capacity of satellites is insufficient to support effective
on-board fine-tuning in traditional satellite FL frameworks. To address these
challenges, we propose a satellite-ground collaborative federated fine-tuning
framework. The key of the framework lies in how to reasonably decompose and
allocate model components to alleviate insufficient on-board computation
capabilities. During fine-tuning, satellites exchange intermediate results with
ground stations or other satellites for forward propagation and back
propagation, which brings communication challenges due to the special
communication topology of space transmission networks, such as intermittent
satellite-ground communication, short duration of satellite-ground
communication windows, and unstable inter-orbit inter-satellite links (ISLs).
To reduce transmission delays, we further introduce tailored communication
strategies that integrate both communication and computing resources.
Specifically, we propose a parallel intra-orbit communication strategy, a
topology-aware satellite-ground communication strategy, and a
latency-minimalization inter-orbit communication strategy to reduce space
communication costs. Simulation results demonstrate significant reductions in
training time with improvements of approximately 33%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adapting Multilingual LLMs to Low-Resource Languages using Continued
  <span class="highlight-title">Pre-train</span>ing and Synthetic Corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14815v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14815v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raviraj Joshi, Kanishk Singla, Anusha Kamath, Raunak Kalani, Rakesh Paul, Utkarsh Vaidya, Sanjay Singh Chauhan, Niranjan Wartikar, Eileen Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilingual LLMs support a variety of languages; however, their performance
is suboptimal for low-resource languages. In this work, we emphasize the
importance of continued pre-training of multilingual LLMs and the use of
translation-based synthetic pre-training corpora for improving LLMs in
low-resource languages. We conduct our study in the context of the low-resource
Indic language Hindi. We introduce Nemotron-Mini-Hindi 4B, a bilingual SLM
supporting both Hindi and English, based on Nemotron-Mini 4B. The model is
trained using a mix of real and synthetic Hindi + English tokens, with
continuous pre-training performed on 400B tokens. We demonstrate that both the
base and instruct models achieve state-of-the-art results on Hindi benchmarks
while remaining competitive on English tasks. Additionally, we observe that the
continued pre-training approach enhances the model's overall factual accuracy.
We perform an ablation study to highlight the impact of Hindi pre-training,
showing significant improvements in Hindi chat capabilities and factual
accuracy, which cannot be achieved through Hindi alignment alone.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Activation-wise Propagation: A Universal Strategy to Break Timestep
  Constraints in Spiking Neural Networks for 3D Data Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12791v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12791v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Song, Xiangfei Yang, Donglin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to their event-driven and parameter-efficient effect, spiking neural
networks (SNNs) show potential in tasks requiring real-time multi-sensor
perception, such as autonomous driving. The spiking mechanism facilitates
sparse encoding, enabling spatial and temporal data to be represented in a
discrete manner. However, SNNs still lag behind artificial neural networks
(ANNs) in terms of performance and computational efficiency. One major
challenge in SNNs is the timestep-wise iterative update of neuronal states,
which makes it difficult to achieve an optimal trade-off among accuracy,
latency, and training cost. Although some methods perform well with shorter
timesteps, few propose strategies to overcome such constraint effectively.
Moreover, many recent SNN advancements rely on either optimizations tailored to
specific architectures or a collection of specialized neuron-level strategies.
While these approaches can enhance performance, they often lead to increased
computational expense and restrict their application to particular
architectures or modalities. This leaves room for further exploration of
simple, universal, and structure-agnostic strategies that could offer broader
applicability and efficiency. In this paper, we introduce Activation-wise
Membrane Potential Propagation (AMP2), a novel state update mechanism for
spiking neurons. Inspired by skip connections in deep networks, AMP2
incorporates the membrane potential of neurons into network, eliminating the
need for iterative updates. Our method achieves significant improvements across
various 3D modalities, including 3D point clouds and event streams, boosting
Spiking PointNet's accuracy on ModelNet40 from 87.36% to 89.74% and surpassing
ANN PointNet in recognition accuracy on the DVS128 Gesture dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large-Scale Contextual Market Equilibrium Computation through Deep
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15459v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15459v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunxuan Ma, Yide Bian, Hao Xu, Weitao Yang, Jingshu Zhao, Zhijian Duan, Feng Wang, Xiaotie Deng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Market equilibrium is one of the most fundamental solution concepts in
economics and social optimization analysis. Existing works on market
equilibrium computation primarily focus on settings with relatively few buyers.
Motivated by this, our paper investigates the computation of market equilibrium
in scenarios with a large-scale buyer population, where buyers and goods are
represented by their contexts. Building on this realistic and generalized
contextual market model, we introduce MarketFCNet, a deep learning-based method
for approximating market equilibrium. We start by parameterizing the allocation
of each good to each buyer using a neural network, which depends solely on the
context of the buyer and the good. Next, we propose an efficient method to
unbiasedly estimate the loss function of the training algorithm, enabling us to
optimize the network parameters through gradient. To evaluate the approximated
solution, we propose a metric called Nash Gap, which quantifies the deviation
of the given allocation and price pair from the market equilibrium.
Experimental results indicate that MarketFCNet delivers competitive performance
and significantly lower running times compared to existing methods as the
market scale expands, demonstrating the potential of deep learning-based
methods to accelerate the approximation of large-scale contextual market
equilibrium.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 4 figures, recieved at IJTCS2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Simplifying Graph Convolutional Networks with Redundancy-Free Neighbors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13426v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13426v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jielong Lu, Zhihao Wu, Zhiling Cai, Yueyang Pi, Shiping Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Graph Convolutional Networks (GCNs) have gained popularity
for their exceptional ability to process graph-structured data. Existing
GCN-based approaches typically employ a shallow model architecture due to the
over-smoothing phenomenon. Current approaches to mitigating over-smoothing
primarily involve adding supplementary components to GCN architectures, such as
residual connections and random edge-dropping strategies. However, these
improvements toward deep GCNs have achieved only limited success. In this work,
we analyze the intrinsic message passing mechanism of GCNs and identify a
critical issue: messages originating from high-order neighbors must traverse
through low-order neighbors to reach the target node. This repeated reliance on
low-order neighbors leads to redundant information aggregation, a phenomenon we
term over-aggregation. Our analysis demonstrates that over-aggregation not only
introduces significant redundancy but also serves as the fundamental cause of
over-smoothing in GCNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Does Critical Batch Size Scale in <span class="highlight-title">Pre-train</span>ing? <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21676v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21676v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training large-scale models under given resources requires careful design of
parallelism strategies. In particular, the efficiency notion of critical batch
size (CBS), concerning the compromise between time and compute, marks the
threshold beyond which greater data parallelism leads to diminishing returns.
To operationalize it, we propose a measure of CBS and pre-train a series of
auto-regressive language models, ranging from 85 million to 1.2 billion
parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and
careful control of factors such as batch size, momentum, and learning rate
along with its scheduling, we systematically investigate the impact of scale on
CBS. Then we fit scaling laws with respect to model and data sizes to decouple
their effects. Overall, our results demonstrate that CBS scales primarily with
data size rather than model size, a finding we justify theoretically through
the analysis of infinite-width limits of neural networks and
infinite-dimensional least squares regression. Of independent interest, we
highlight the importance of common hyper-parameter choices and strategies for
studying large-scale pre-training beyond fixed training durations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025, Blog post:
  https://kempnerinstitute.harvard.edu/research/deeper-learning/how-does-critical-batch-size-scale-in-pre-training-decoupling-data-and-model-size</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task-Specific Directions: Definition, Exploration, and Utilization in
  Parameter Efficient Fine-Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01035v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01035v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chongjie Si, Zhiyi Shi, Shifan Zhang, Xiaokang Yang, Hanspeter Pfister, Wei Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models demonstrate impressive performance on downstream tasks,
yet they require extensive resource consumption when fully fine-tuning all
parameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT)
strategies, such as LoRA, have been developed. In this paper, we delve into the
concept of task-specific directions (TSDs), which are critical for
transitioning large models from pretrained states to task-specific enhancements
in PEFT. We propose a framework to clearly define these directions and explore
their properties and practical utilization challenges. We then introduce a
novel approach, LoRA-Dash, which aims to maximize the impact of TSDs during the
fine-tuning process, thereby enhancing model performance on targeted tasks.
Additionally, based on our exploration of TSD, we focus on an important issue
in PEFT: the initialization of LoRA. While some works have pointed out the
significance of initialization for LoRA's performance and proposed various
strategies, these methods are often empirical and not task-specific. To address
this issue, we propose LoRA-Init. Starting from TSD, we identify the directions
that require the most adjustment during fine-tuning for downstream tasks. By
initializing the matrices in LoRA with these directions, LoRA-Init
significantly enhances LoRA's performance. Moreover, we can combine LoRA-Dash
and LoRA-Init to create the final version of LoRA based on TSDs, which we refer
to as LoRA-TSD. Extensive experiments have conclusively demonstrated the
effectiveness of these methods, and in-depth analyses further reveal the
underlying mechanisms behind their success.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes in https://github.com/Chongjie-Si/Subspace-Tuning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aioli: A Unified Optimization Framework for Language Model Data Mixing <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.05735v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.05735v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mayee F. Chen, Michael Y. Hu, Nicholas Lourie, Kyunghyun Cho, Christopher Ré
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model performance depends on identifying the optimal mixture of data
groups to train on (e.g., law, code, math). Prior work has proposed a diverse
set of methods to efficiently learn mixture proportions, ranging from fitting
regression models over training runs to dynamically updating proportions
throughout training. Surprisingly, we find that no existing method consistently
outperforms a simple stratified sampling baseline in terms of average test
perplexity. To understand this inconsistency, we unify existing methods into a
standard framework, showing they are equivalent to solving a common
optimization problem: minimize average loss subject to a method-specific mixing
law -- an implicit assumption on the relationship between loss and mixture
proportions. This framework suggests that measuring the fidelity of a method's
mixing law can offer insights into its performance. Empirically, we find that
existing methods set their mixing law parameters inaccurately, resulting in the
inconsistent mixing performance we observe. Using this insight, we derive a new
online method named Aioli, which directly estimates the mixing law parameters
throughout training and uses them to dynamically adjust proportions. Aioli
outperforms stratified sampling on 6 out of 6 datasets by an average of 0.27
test perplexity points, whereas existing methods fail to consistently beat
stratified sampling, doing up to 6.9 points worse. Moreover, in a practical
setting where proportions are learned on shorter runs due to computational
constraints, Aioli can dynamically adjust these proportions over the full
training run, consistently improving performance over existing methods by up to
12.012 test perplexity points.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Camera Ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recursive Deep Inverse Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13241v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13241v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Tales Imbiriba
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inferring an adversary's goals from exhibited behavior is crucial for
counterplanning and non-cooperative multi-agent systems in domains like
cybersecurity, military, and strategy games. Deep Inverse Reinforcement
Learning (IRL) methods based on maximum entropy principles show promise in
recovering adversaries' goals but are typically offline, require large batch
sizes with gradient descent, and rely on first-order updates, limiting their
applicability in real-time scenarios. We propose an online Recursive Deep
Inverse Reinforcement Learning (RDIRL) approach to recover the cost function
governing the adversary actions and goals. Specifically, we minimize an upper
bound on the standard Guided Cost Learning (GCL) objective using sequential
second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading
to a fast (in terms of convergence) learning algorithm. We demonstrate that
RDIRL is able to recover cost and reward functions of expert agents in standard
and adversarial benchmark tasks. Experiments on benchmark tasks show that our
proposed approach outperforms several leading IRL algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Context Parallelism for Scalable Million-Token Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.01783v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.01783v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amy Yang, Jingyi Yang, Aya Ibrahim, Xinfeng Xie, Bangsheng Tang, Grigory Sizov, Jeremy Reizenstein, Jongsoo Park, Jianyu Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present context parallelism for long-context large language model
inference, which achieves near-linear scaling for long-context prefill latency
with up to 128 H100 GPUs across 16 nodes. Particularly, our method achieves 1M
context prefill with Llama3 405B model in 77s (93% parallelization efficiency,
63% FLOPS utilization) and 128K context prefill in 3.8s. We develop two
lossless exact ring attention variants: pass-KV and pass-Q to cover a wide
range of use cases with the state-of-the-art performance: full prefill,
persistent KV prefill and decode. Benchmarks on H100 GPU hosts inter-connected
with RDMA and TCP both show similar scalability for long-context prefill,
demonstrating that our method scales well using common commercial data center
with medium-to-low inter-host bandwidth.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Temporal Knowledge Graph Question Answering: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14191v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14191v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miao Su, Zixuan Li, Zhuo Chen, Long Bai, Xiaolong Jin, Jiafeng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Base Question Answering (KBQA) has been a long-standing field to
answer questions based on knowledge bases. Recently, the evolving dynamics of
knowledge have attracted a growing interest in Temporal Knowledge Graph
Question Answering (TKGQA), an emerging task to answer temporal questions.
However, this field grapples with ambiguities in defining temporal questions
and lacks a systematic categorization of existing methods for TKGQA. In
response, this paper provides a thorough survey from two perspectives: the
taxonomy of temporal questions and the methodological categorization for TKGQA.
Specifically, we first establish a detailed taxonomy of temporal questions
engaged in prior studies. Subsequently, we provide a comprehensive review of
TKGQA techniques of two categories: semantic parsing-based and TKG
embedding-based. Building on this review, the paper outlines potential research
directions aimed at advancing the field of TKGQA. This work aims to serve as a
comprehensive reference for TKGQA and to stimulate further research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures. This work has been submitted to the IEEE for
  possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Training Data of Large Language Models via Expectation
  Maximization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07582v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07582v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gyuwan Kim, Yang Li, Evangelia Spiliopoulou, Jie Ma, Miguel Ballesteros, William Yang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancement of large language models has grown parallel to the opacity of
their training data. Membership inference attacks (MIAs) aim to determine
whether specific data was used to train a model. They offer valuable insights
into detecting data contamination and ensuring compliance with privacy and
copyright standards. However, MIA for LLMs is challenging due to the massive
scale of training data and the inherent ambiguity of membership in texts.
Moreover, creating realistic MIA evaluation benchmarks is difficult as training
and test data distributions are often unknown. We introduce EM-MIA, a novel
membership inference method that iteratively refines membership scores and
prefix scores via an expectation-maximization algorithm. Our approach leverages
the observation that these scores can improve each other: membership scores
help identify effective prefixes for detecting training data, while prefix
scores help determine membership. As a result, EM-MIA achieves state-of-the-art
results on WikiMIA. To enable comprehensive evaluation, we introduce OLMoMIA, a
benchmark built from OLMo resources, which allows controlling task difficulty
through varying degrees of overlap between training and test data
distributions. Our experiments demonstrate EM-MIA is robust across different
scenarios while also revealing fundamental limitations of current MIA
approaches when member and non-member distributions are nearly identical.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mining the Minoria: Unknown, Under-represented, and Under-performing
  Minority Groups <span class="chip">VLDB 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04761v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04761v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohsen Dehghankar, Abolfazl Asudeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to a variety of reasons, such as privacy, data in the wild often misses
the grouping information required for identifying minorities. On the other
hand, it is known that machine learning models are only as good as the data
they are trained on and, hence, may underperform for the under-represented
minority groups. The missing grouping information presents a dilemma for
responsible data scientists who find themselves in an unknown-unknown
situation, where not only do they not have access to the grouping attributes
but do not also know what groups to consider.
  This paper is an attempt to address this dilemma. Specifically, we propose a
minority mining problem, where we find vectors in the attribute space that
reveal potential groups that are under-represented and under-performing.
Technically speaking, we propose a geometric transformation of data into a dual
space and use notions such as the arrangement of hyperplanes to design an
efficient algorithm for the problem in lower dimensions. Generalizing our
solution to the higher dimensions is cursed by dimensionality. Therefore, we
propose a solution based on smart exploration of the search space for such
cases. We conduct comprehensive experiments using real-world and synthetic
datasets alongside the theoretical analysis. Our experiment results demonstrate
the effectiveness of our proposed solutions in mining the unknown,
under-represented, and under-performing minorities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in VLDB 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modality Unified Attack for Omni-Modality Person Re-Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12761v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12761v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yunfeng Ma, Yaonan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning based person re-identification (re-id) models have been widely
employed in surveillance systems. Recent studies have demonstrated that
black-box single-modality and cross-modality re-id models are vulnerable to
adversarial examples (AEs), leaving the robustness of multi-modality re-id
models unexplored. Due to the lack of knowledge about the specific type of
model deployed in the target black-box surveillance system, we aim to generate
modality unified AEs for omni-modality (single-, cross- and multi-modality)
re-id models. Specifically, we propose a novel Modality Unified Attack method
to train modality-specific adversarial generators to generate AEs that
effectively attack different omni-modality models. A multi-modality model is
adopted as the surrogate model, wherein the features of each modality are
perturbed by metric disruption loss before fusion. To collapse the common
features of omni-modality models, Cross Modality Simulated Disruption approach
is introduced to mimic the cross-modality feature embeddings by intentionally
feeding images to non-corresponding modality-specific subnetworks of the
surrogate model. Moreover, Multi Modality Collaborative Disruption strategy is
devised to facilitate the attacker to comprehensively corrupt the informative
content of person images by leveraging a multi modality feature collaborative
metric disruption loss. Extensive experiments show that our MUA method can
effectively attack the omni-modality re-id models, achieving 55.9%, 24.4%,
49.0% and 62.7% mean mAP Drop Rate, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages,3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs
  on the Edge <span class="chip">AAAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.05693v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.05693v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuan Shen, Peiyan Dong, Lei Lu, Zhenglun Kong, Zhengang Li, Ming Lin, Chao Wu, Yanzhi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) stand out for their impressive performance in
intricate language modeling tasks. However, their demanding computational and
memory needs pose obstacles for broad use on edge devices. Quantization is then
introduced to boost LLMs' on-device efficiency. Recent works show that 8-bit or
lower weight quantization is feasible with minimal impact on end-to-end task
performance, while the activation is still not quantized. On the other hand,
mainstream commodity edge devices still struggle to execute these sub-8-bit
quantized networks effectively. In this paper, we propose Agile-Quant, an
activation-guided quantization framework for popular Large Language Models
(LLMs), and implement an end-to-end accelerator on multiple edge devices for
faster inference. Considering the hardware profiling and activation analysis,
we first introduce a basic activation quantization strategy to balance the
trade-off of task performance and real inference speed. Then we leverage the
activation-aware token pruning technique to reduce the outliers and the adverse
impact on attentivity. Ultimately, we utilize the SIMD-based 4-bit multiplier
and our efficient TRIP matrix multiplication to implement the accelerator for
LLMs on the edge. We apply our framework on different scales of LLMs including
LLaMA, OPT, and BLOOM with 4-bit or 8-bit for the activation and 4-bit for the
weight quantization. Experiments show that Agile-Quant achieves simultaneous
quantization of model weights and activations while maintaining task
performance comparable to existing weight-only quantization methods. Moreover,
in the 8- and 4-bit scenario, Agile-Quant achieves an on-device speedup of up
to 2.55x compared to its FP16 counterparts across multiple edge devices,
marking a pioneering advancement in this domain. Code:
https://github.com/shawnricecake/agile-quant
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust multi-coil MRI reconstruction via <span class="highlight-title">self-supervised</span> denoising 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12919v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12919v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asad Aali, Marius Arvinte, Sidharth Kumar, Yamin I. Arefeen, Jonathan I. Tamir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To examine the effect of incorporating self-supervised denoising as a
pre-processing step for training deep learning (DL) based reconstruction
methods on data corrupted by Gaussian noise. K-space data employed for training
are typically multi-coil and inherently noisy. Although DL-based reconstruction
methods trained on fully sampled data can enable high reconstruction quality,
obtaining large, noise-free datasets is impractical. We leverage Generalized
Stein's Unbiased Risk Estimate (GSURE) for denoising. We evaluate two DL-based
reconstruction methods: Diffusion Probabilistic Models (DPMs) and Model-Based
Deep Learning (MoDL). We evaluate the impact of denoising on the performance of
these DL-based methods in solving accelerated multi-coil magnetic resonance
imaging (MRI) reconstruction. The experiments were carried out on T2-weighted
brain and fat-suppressed proton-density knee scans. We observed that
self-supervised denoising enhances the quality and efficiency of MRI
reconstructions across various scenarios. Specifically, employing denoised
images rather than noisy counterparts when training DL networks results in
lower normalized root mean squared error (NRMSE), higher structural similarity
index measure (SSIM) and peak signal-to-noise ratio (PSNR) across different SNR
levels, including 32dB, 22dB, and 12dB for T2-weighted brain data, and 24dB,
14dB, and 4dB for fat-suppressed knee data. Overall, we showed that denoising
is an essential pre-processing technique capable of improving the efficacy of
DL-based MRI reconstruction methods under diverse conditions. By refining the
quality of input data, denoising enables training more effective DL networks,
potentially bypassing the need for noise-free reference MRI scans.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting underdiagnosed medical conditions with opportunistic imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11686v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11686v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin, Akshay S. Chaudhari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Abdominal computed tomography (CT) scans are frequently performed in clinical
settings. Opportunistic CT involves repurposing routine CT images to extract
diagnostic information and is an emerging tool for detecting underdiagnosed
conditions such as sarcopenia, hepatic steatosis, and ascites. This study
utilizes deep learning methods to promote accurate diagnosis and clinical
documentation. We analyze 2,674 inpatient CT scans to identify discrepancies
between imaging phenotypes (characteristics derived from opportunistic CT
scans) and their corresponding documentation in radiology reports and ICD
coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans
diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively)
through either opportunistic imaging or radiology reports were ICD-coded. Our
findings demonstrate opportunistic CT's potential to enhance diagnostic
precision and accuracy of risk adjustment models, offering advancements in
precision medicine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Algorithm for Sparse Fourier Transform of Generalized $q$-ary
  Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12365v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12365v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Darin Tsui, Kunal Talreja, Amirali Aghazadeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computing the Fourier transform of a $q$-ary function
$f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to
real numbers, is an important problem in mathematics with wide-ranging
applications in biology, signal processing, and machine learning. Previous
studies have shown that, under the sparsity assumption, the Fourier transform
can be computed efficiently using fast and sample-efficient algorithms.
However, in most practical settings, the function is defined over a more
general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1}
\times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each
$\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. Herein, we develop
GFast, a coding theoretic algorithm that computes the $S$-sparse Fourier
transform of $f$ with a sample complexity of $O(Sn)$, computational complexity
of $O(Sn \log N)$, and a failure probability that approaches zero as
$N=\prod_{i=1}^n q_i \rightarrow \infty$ with $S = N^\delta$ for some $0 \leq
\delta < 1$. We show that a noise-robust version of GFast computes the
transform with a sample complexity of $O(Sn^2)$ and computational complexity of
$O(Sn^2 \log N)$ under the same high probability guarantees. Additionally, we
demonstrate that GFast computes the sparse Fourier transform of generalized
$q$-ary functions $8\times$ faster using $16\times$ fewer samples on synthetic
experiments, and enables explaining real-world heart disease diagnosis and
protein fitness models using up to $13\times$ fewer samples compared to
existing Fourier algorithms applied to the most efficient parameterization of
the models as $q$-ary functions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Sequence: Impact of Geometric Context for RNA Property Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11933v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11933v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjie Xu, Artem Moskalev, Tommaso Mansi, Mangal Prakash, Rui Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate prediction of RNA properties, such as stability and interactions, is
crucial for advancing our understanding of biological processes and developing
RNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D
topological graphs, or 3D all-atom models, each offering different insights
into its function. Existing works predominantly focus on 1D sequence-based
models, which overlook the geometric context provided by 2D and 3D geometries.
This study presents the first systematic evaluation of incorporating explicit
2D and 3D geometric information into RNA property prediction, considering not
only performance but also real-world challenges such as limited data
availability, partial labeling, sequencing noise, and computational efficiency.
To this end, we introduce a newly curated set of RNA datasets with enhanced 2D
and 3D structural annotations, providing a resource for model evaluation on RNA
data. Our findings reveal that models with explicit geometry encoding generally
outperform sequence-based models, with an average prediction RMSE reduction of
around 12% across all various RNA tasks and excelling in low-data and partial
labeling regimes, underscoring the value of explicitly incorporating geometric
context. On the other hand, geometry-unaware sequence-based models are more
robust under sequencing noise but often require around $2-5\times$ training
data to match the performance of geometry-aware models. Our study offers
further insights into the trade-offs between different RNA representations in
practical applications and addresses a significant gap in evaluating deep
learning models for RNA tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Skewness-Based Criterion for Addressing Heteroscedastic Noise in
  Causal Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06407v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06407v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingyu Lin, Yuxing Huang, Wenqin Liu, Haoran Deng, Ignavier Ng, Kun Zhang, Mingming Gong, Yi-An Ma, Biwei Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-world data often violates the equal-variance assumption
(homoscedasticity), making it essential to account for heteroscedastic noise in
causal discovery. In this work, we explore heteroscedastic symmetric noise
models (HSNMs), where the effect $Y$ is modeled as $Y = f(X) + \sigma(X)N$,
with $X$ as the cause and $N$ as independent noise following a symmetric
distribution. We introduce a novel criterion for identifying HSNMs based on the
skewness of the score (i.e., the gradient of the log density) of the data
distribution. This criterion establishes a computationally tractable
measurement that is zero in the causal direction but nonzero in the anticausal
direction, enabling the causal direction discovery. We extend this
skewness-based criterion to the multivariate setting and propose SkewScore, an
algorithm that handles heteroscedastic noise without requiring the extraction
of exogenous noise. We also conduct a case study on the robustness of SkewScore
in a bivariate model with a latent confounder, providing theoretical insights
into its performance. Empirical studies further validate the effectiveness of
the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chinese-LiPS: A Chinese audio-visual speech recognition <span class="highlight-title">dataset</span> with
  Lip-reading and Presentation Slides 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.15066v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.15066v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinghua Zhao, Yuhang Jia, Shiyao Wang, Jiaming Zhou, Hui Wang, Yong Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Incorporating visual modalities to assist Automatic Speech Recognition (ASR)
tasks has led to significant improvements. However, existing Audio-Visual
Speech Recognition (AVSR) datasets and methods typically rely solely on
lip-reading information or speaking contextual video, neglecting the potential
of combining these different valuable visual cues within the speaking context.
In this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,
comprising 100 hours of speech, video, and corresponding manual transcription,
with the visual modality encompassing both lip-reading information and the
presentation slides used by the speaker. Based on Chinese-LiPS, we develop a
simple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and
presentation slide information as visual modalities for AVSR tasks. Experiments
show that lip-reading and presentation slide information improve ASR
performance by approximately 8\% and 25\%, respectively, with a combined
performance improvement of about 35\%. The dataset is available at
https://kiri0824.github.io/Chinese-LiPS/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VLM as Policy: Common-Law Content Moderation Framework for Short Video
  Platform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Lu, Tianke Zhang, Chang Meng, Xiaobei Wang, Jinpeng Wang, YiFan Zhang, Shisong Tang, Changyi Liu, Haojie Ding, Kaiyu Jiang, Kaiyu Tang, Bin Wen, Hai-Tao Zheng, Fan Yang, Tingting Gao, Di Zhang, Kun Gai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exponentially growing short video platforms (SVPs) face significant
challenges in moderating content detrimental to users' mental health,
particularly for minors. The dissemination of such content on SVPs can lead to
catastrophic societal consequences. Although substantial efforts have been
dedicated to moderating such content, existing methods suffer from critical
limitations: (1) Manual review is prone to human bias and incurs high
operational costs. (2) Automated methods, though efficient, lack nuanced
content understanding, resulting in lower accuracy. (3) Industrial moderation
regulations struggle to adapt to rapidly evolving trends due to long update
cycles. In this paper, we annotate the first SVP content moderation benchmark
with authentic user/reviewer feedback to fill the absence of benchmark in this
field. Then we evaluate various methods on the benchmark to verify the
existence of the aforementioned limitations. We further propose our common-law
content moderation framework named KuaiMod to address these challenges. KuaiMod
consists of three components: training data construction, offline adaptation,
and online deployment & refinement. Leveraging large vision language model
(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video
toxicity based on sparse user feedback and fosters dynamic moderation policy
with rapid update speed and high accuracy. Offline experiments and large-scale
online A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the
best moderation performance on our benchmark. The deployment of KuaiMod reduces
the user reporting rate by 20% and its application in video recommendation
increases both Daily Active User (DAU) and APP Usage Time (AUT) on several
Kuaishou scenarios. We have open-sourced our benchmark at
https://kuaimod.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-20T00:00:00Z">2025-04-20</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">51</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Distillation and <span class="highlight-title">Dataset</span> Distillation of Large Language
  Models: Emerging Trends, Challenges, and Future Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyang Fang, Xiaowei Yu, Jiazhang Cai, Yongkai Chen, Shushan Wu, Zhengliang Liu, Zhenyuan Yang, Haoran Lu, Xilin Gong, Yufang Liu, Terry Ma, Wei Ruan, Ali Abbasi, Jing Zhang, Tao Wang, Ehsan Latif, Wei Liu, Wei Zhang, Soheil Kolouri, Xiaoming Zhai, Dajiang Zhu, Wenxuan Zhong, Tianming Liu, Ping Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exponential growth of Large Language Models (LLMs) continues to highlight
the need for efficient strategies to meet ever-expanding computational and data
demands. This survey provides a comprehensive analysis of two complementary
paradigms: Knowledge Distillation (KD) and Dataset Distillation (DD), both
aimed at compressing LLMs while preserving their advanced reasoning
capabilities and linguistic diversity. We first examine key methodologies in
KD, such as task-specific alignment, rationale-based training, and
multi-teacher frameworks, alongside DD techniques that synthesize compact,
high-impact datasets through optimization-based gradient matching, latent space
regularization, and generative synthesis. Building on these foundations, we
explore how integrating KD and DD can produce more effective and scalable
compression strategies. Together, these approaches address persistent
challenges in model scalability, architectural heterogeneity, and the
preservation of emergent LLM abilities. We further highlight applications
across domains such as healthcare and education, where distillation enables
efficient deployment without sacrificing performance. Despite substantial
progress, open challenges remain in preserving emergent reasoning and
linguistic diversity, enabling efficient adaptation to continually evolving
teacher models and datasets, and establishing comprehensive evaluation
protocols. By synthesizing methodological innovations, theoretical foundations,
and practical insights, our survey charts a path toward sustainable,
resource-efficient LLMs through the tighter integration of KD and DD
principles.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangling Linguistic Features with Dimension-Wise Analysis of Vector
  Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14766v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14766v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saniya Karwa, Navpreet Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the inner workings of neural embeddings, particularly in models
such as BERT, remains a challenge because of their high-dimensional and opaque
nature. This paper proposes a framework for uncovering the specific dimensions
of vector embeddings that encode distinct linguistic properties (LPs). We
introduce the Linguistically Distinct Sentence Pairs (LDSP-10) dataset, which
isolates ten key linguistic features such as synonymy, negation, tense, and
quantity. Using this dataset, we analyze BERT embeddings with various methods,
including the Wilcoxon signed-rank test, mutual information, and recursive
feature elimination, to identify the most influential dimensions for each LP.
We introduce a new metric, the Embedding Dimension Impact (EDI) score, which
quantifies the relevance of each embedding dimension to a LP. Our findings show
that certain properties, such as negation and polarity, are robustly encoded in
specific dimensions, while others, like synonymy, exhibit more complex
patterns. This study provides insights into the interpretability of embeddings,
which can guide the development of more transparent and optimized language
models, with implications for model bias mitigation and the responsible
deployment of AI systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">PROMPT</span>EVALS: A <span class="highlight-title">Dataset</span> of Assertions and Guardrails for Custom
  Production Large Language Model Pipelines <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14738v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14738v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Reya Vir, Shreya Shankar, Harrison Chase, Will Fu-Hinthorn, Aditya Parameswaran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly deployed in specialized
production data processing pipelines across diverse domains -- such as finance,
marketing, and e-commerce. However, when running them in production across many
inputs, they often fail to follow instructions or meet developer expectations.
To improve reliability in these applications, creating assertions or guardrails
for LLM outputs to run alongside the pipelines is essential. Yet, determining
the right set of assertions that capture developer requirements for a task is
challenging. In this paper, we introduce PROMPTEVALS, a dataset of 2087 LLM
pipeline prompts with 12623 corresponding assertion criteria, sourced from
developers using our open-source LLM pipeline tools. This dataset is 5x larger
than previous collections. Using a hold-out test split of PROMPTEVALS as a
benchmark, we evaluated closed- and open-source models in generating relevant
assertions. Notably, our fine-tuned Mistral and Llama 3 models outperform
GPT-4o by 20.93% on average, offering both reduced latency and improved
performance. We believe our dataset can spur further research in LLM
reliability, alignment, and prompt engineering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NAACL 2025 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating <span class="highlight-title">BERT</span>opic on Open-Ended Data: A Case Study with Belgian Dutch
  Daily Narratives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ratna Kandala, Katie Hoemann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores BERTopic's potential for modeling open-ended Belgian
Dutch daily narratives, contrasting its performance with Latent Dirichlet
Allocation (LDA) and KMeans. Although LDA scores well on certain automated
metrics, human evaluations reveal semantically irrelevant co-occurrences,
highlighting the limitations of purely statistic-based methods. In contrast,
BERTopic's reliance on contextual embeddings yields culturally resonant themes,
underscoring the importance of hybrid evaluation frameworks that account for
morphologically rich languages. KMeans performed less coherently than prior
research suggested, pointing to the unique challenges posed by personal
narratives. Our findings emphasize the need for robust generalization in NLP
models, especially in underrepresented linguistic contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songtao Jiang, Yuan Wang, Sibo Song, Yan Zhang, Zijie Meng, Bohan Lei, Jian Wu, Jimeng Sun, Zuozhu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The practical deployment of medical vision-language models (Med-VLMs)
necessitates seamless integration of textual data with diverse visual
modalities, including 2D/3D images and videos, yet existing models typically
employ separate encoders for different modalities. To address this limitation,
we present OmniV-Med, a unified framework for multimodal medical understanding.
Our technical contributions are threefold: First, we construct
OmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252K
instructional samples spanning 14 medical image modalities and 11 clinical
tasks. Second, we devise a rotary position-adaptive encoder that processes
multi-resolution 2D/3D images and videos within a unified architecture,
diverging from conventional modality-specific encoders. Third, we introduce a
medical-aware token pruning mechanism that exploits spatial-temporal redundancy
in volumetric data (e.g., consecutive CT slices) and medical videos,
effectively reducing 60\% of visual tokens without performance degradation.
Empirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-art
performance on 7 benchmarks spanning 2D/3D medical imaging and video
understanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attains
comparable performance while requiring only 8 RTX3090 GPUs for training and
supporting efficient long-video inference. Data, code and model will be
released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FarsEval-PKBETS: A new diverse benchmark for evaluating Persian large
  language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehrnoush Shamsfard, Zahra Saaberi, Mostafa Karimi manesh, Seyed Mohammad Hossein Hashemi, Zahra Vatankhah, Motahareh Ramezani, Niki Pourazin, Tara Zare, Maryam Azimi, Sarina Chitsaz, Sama Khoraminejad, Morteza Mahdavi Mortazavi, Mohammad Mahdi Chizari, Sahar Maleki, Seyed Soroush Majd, Mostafa Masumi, Sayed Ali Musavi Khoeini, Amir Mohseni, Sogol Alipour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on evaluating and analyzing large language models (LLMs) has been
extensive for resource-rich languages such as English, yet their performance in
languages such as Persian has received considerably less attention. This paper
introduces FarsEval-PKBETS benchmark, a subset of FarsEval project for
evaluating large language models in Persian. This benchmark consists of 4000
questions and answers in various formats, including multiple choice, short
answer and descriptive responses. It covers a wide range of domains and
tasks,including medicine, law, religion, Persian language, encyclopedic
knowledge, human preferences, social knowledge, ethics and bias, text
generation, and respecting others' rights. This bechmark incorporates
linguistics, cultural, and local considerations relevant to the Persian
language and Iran. To ensure the questions are challenging for current LLMs,
three models -- Llama3-70B, PersianMind, and Dorna -- were evaluated using this
benchmark. Their average accuracy was below 50%, meaning they provided fully
correct answers to fewer than half of the questions. These results indicate
that current language models are still far from being able to solve this
benchmark
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 3 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trans-Zero: Self-Play Incentivizes Large Language Models for
  Multilingual Translation Without Parallel Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Zou, Sen Yang, Yu Bao, Shujian Huang, Jiajun Chen, Shanbo Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of Large Language Models (LLMs) has reshaped machine translation
(MT), but multilingual MT still relies heavily on parallel data for supervised
fine-tuning (SFT), facing challenges like data scarcity for low-resource
languages and catastrophic forgetting. To address these issues, we propose
TRANS-ZERO, a self-play framework that leverages only monolingual data and the
intrinsic multilingual knowledge of LLM. TRANS-ZERO combines Genetic
Monte-Carlo Tree Search (G-MCTS) with preference optimization, achieving strong
translation performance that rivals supervised methods. Experiments demonstrate
that this approach not only matches the performance of models trained on
large-scale parallel data but also excels in non-English translation
directions. Further analysis reveals that G-MCTS itself significantly enhances
translation quality by exploring semantically consistent candidates through
iterative translations, providing a robust foundation for the framework's
succuss.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Case Study Exploring the Current Landscape of Synthetic Medical Record
  Generation with Commercial LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihan Lin, Zhirong Bella Yu, Simon Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic Electronic Health Records (EHRs) offer a valuable opportunity to
create privacy preserving and harmonized structured data, supporting numerous
applications in healthcare. Key benefits of synthetic data include precise
control over the data schema, improved fairness and representation of patient
populations, and the ability to share datasets without concerns about
compromising real individuals privacy. Consequently, the AI community has
increasingly turned to Large Language Models (LLMs) to generate synthetic data
across various domains. However, a significant challenge in healthcare is
ensuring that synthetic health records reliably generalize across different
hospitals, a long standing issue in the field. In this work, we evaluate the
current state of commercial LLMs for generating synthetic data and investigate
multiple aspects of the generation process to identify areas where these models
excel and where they fall short. Our main finding from this work is that while
LLMs can reliably generate synthetic health records for smaller subsets of
features, they struggle to preserve realistic distributions and correlations as
the dimensionality of the data increases, ultimately limiting their ability to
generalize across diverse hospital settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the Conference of Health, Inference, Learning (CHIL 2025)
  in Berkeley, CA. To appear in PMLR later in 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LeetCode<span class="highlight-title">Dataset</span>: A Temporal <span class="highlight-title">Dataset</span> for Robust Evaluation and Efficient
  Training of Code LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunhui Xia, Wei Shen, Yan Wang, Jason Klein Liu, Huifeng Sun, Siyue Wu, Jian Hu, Xiaolong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LeetCodeDataset, a high-quality benchmark for evaluating and
training code-generation models, addressing two key challenges in LLM research:
the lack of reasoning-focused coding benchmarks and self-contained training
testbeds. By curating LeetCode Python problems with rich metadata, broad
coverage, 100+ test cases per problem, and temporal splits (pre/post July
2024), our dataset enables contamination-free evaluation and efficient
supervised fine-tuning (SFT). Experiments show reasoning models significantly
outperform non-reasoning counterparts, while SFT with only 2.6K model-generated
solutions achieves performance comparable to 110K-sample counterparts. The
dataset and evaluation framework are available on Hugging Face and Github.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Risk Assessment Framework for Code LLMs via Leveraging Internal States 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14640v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14640v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuheng Huang, Lei Ma, Keizaburo Nishikino, Takumi Akazaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The pre-training paradigm plays a key role in the success of Large Language
Models (LLMs), which have been recognized as one of the most significant
advancements of AI recently. Building on these breakthroughs, code LLMs with
advanced coding capabilities bring huge impacts on software engineering,
showing the tendency to become an essential part of developers' daily routines.
However, the current code LLMs still face serious challenges related to
trustworthiness, as they can generate incorrect, insecure, or unreliable code.
Recent exploratory studies find that it can be promising to detect such risky
outputs by analyzing LLMs' internal states, akin to how the human brain
unconsciously recognizes its own mistakes. Yet, most of these approaches are
limited to narrow sub-domains of LLM operations and fall short of achieving
industry-level scalability and practicability. To address these challenges, in
this paper, we propose PtTrust, a two-stage risk assessment framework for code
LLM based on internal state pre-training, designed to integrate seamlessly with
the existing infrastructure of software companies. The core idea is that the
risk assessment framework could also undergo a pre-training process similar to
LLMs. Specifically, PtTrust first performs unsupervised pre-training on
large-scale unlabeled source code to learn general representations of LLM
states. Then, it uses a small, labeled dataset to train a risk predictor. We
demonstrate the effectiveness of PtTrust through fine-grained, code line-level
risk assessment and demonstrate that it generalizes across tasks and different
programming languages. Further experiments also reveal that PtTrust provides
highly intuitive and interpretable features, fostering greater user trust. We
believe PtTrust makes a promising step toward scalable and trustworthy
assurance for code LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in the 33rd ACM International Conference on the Foundations
  of Software Engineering (FSE Companion'25 Industry Track), June 23-28, 2025,
  Trondheim, Norway. This work was supported by Fujitsu Limited</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Harnessing Generative LLMs for Enhanced Financial Event Entity
  Extraction Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soo-joon Choi, Ji-jun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Financial event entity extraction is a crucial task for analyzing market
dynamics and building financial knowledge graphs, yet it presents significant
challenges due to the specialized language and complex structures in financial
texts. Traditional approaches often rely on sequence labeling models, which can
struggle with long-range dependencies and the inherent complexity of extracting
multiple, potentially overlapping entities. Motivated by the advanced language
understanding and generative capabilities of Large Language Models (LLMs), we
propose a novel method that reframes financial event entity extraction as a
text-to-structured-output generation task. Our approach involves fine-tuning a
pre-trained LLM using Parameter-Efficient Fine-Tuning (PEFT) to directly
generate a structured representation, such as a JSON object, containing the
extracted entities and their precise character spans from the input text. We
evaluate our method on the challenging CCKS 2019 Financial Event Entity
Extraction dataset, comparing its performance against strong sequence labeling
baselines, including SEBERTNets and sebertNets. Experimental results
demonstrate that our generative LLM method achieves a new state-of-the-art F1
score on this benchmark, significantly outperforming previous methods. Through
detailed quantitative analysis across event types, entity types, and instance
complexity, as well as human evaluation, we show that our approach is more
effective at handling the nuances of financial text and extracting high-quality
entities. This work validates the potential of applying generative LLMs
directly to complex, domain-specific information extraction tasks requiring
structured output.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automatic Text Summarization (ATS) for Research Documents in Sorani
  Kurdish 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14630v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14630v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rondik Hadi Abdulrahman, Hossein Hassani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extracting concise information from scientific documents aids learners,
researchers, and practitioners. Automatic Text Summarization (ATS), a key
Natural Language Processing (NLP) application, automates this process. While
ATS methods exist for many languages, Kurdish remains underdeveloped due to
limited resources. This study develops a dataset and language model based on
231 scientific papers in Sorani Kurdish, collected from four academic
departments in two universities in the Kurdistan Region of Iraq (KRI),
averaging 26 pages per document. Using Sentence Weighting and Term
Frequency-Inverse Document Frequency (TF-IDF) algorithms, two experiments were
conducted, differing in whether the conclusions were included. The average word
count was 5,492.3 in the first experiment and 5,266.96 in the second. Results
were evaluated manually and automatically using ROUGE-1, ROUGE-2, and ROUGE-L
metrics, with the best accuracy reaching 19.58%. Six experts conducted manual
evaluations using three criteria, with results varying by document. This
research provides valuable resources for Kurdish NLP researchers to advance ATS
and related fields.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 11 figures, 8 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Hierarchical Framework for Measuring Scientific Paper Innovation via
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongming Tan, Shaoxiong Zhan, Fengwei Jia, Hai-Tao Zheng, Wai Kin Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Measuring scientific paper innovation is both important and challenging.
Existing content-based methods often overlook the full-paper context, fail to
capture the full scope of innovation, and lack generalization. We propose
HSPIM, a hierarchical and training-free framework based on large language
models (LLMs). It introduces a Paper-to-Sections-to-QAs decomposition to assess
innovation. We segment the text by section titles and use zero-shot LLM
prompting to implement section classification, question-answering (QA)
augmentation, and weighted novelty scoring. The generated QA pair focuses on
section-level innovation and serves as additional context to improve the LLM
scoring. For each chunk, the LLM outputs a novelty score and a confidence
score. We use confidence scores as weights to aggregate novelty scores into a
paper-level innovation score. To further improve performance, we propose a
two-layer question structure consisting of common and section-specific
questions, and apply a genetic algorithm to optimize the question-prompt
combinations. Comprehensive experiments on scientific conference paper datasets
show that HSPIM outperforms baseline methods in effectiveness, generalization,
and interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Translation Analytics for Freelancers: I. Introduction, Data
  Preparation, Baseline Evaluations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuri Balashov, Alex Balashov, Shiho Fukuda Koski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This is the first in a series of papers exploring the rapidly expanding new
opportunities arising from recent progress in language technologies for
individual translators and language service providers with modest resources.
The advent of advanced neural machine translation systems, large language
models, and their integration into workflows via computer-assisted translation
tools and translation management systems have reshaped the translation
landscape. These advancements enable not only translation but also quality
evaluation, error spotting, glossary generation, and adaptation to
domain-specific needs, creating new technical opportunities for freelancers. In
this series, we aim to empower translators with actionable methods to harness
these advancements. Our approach emphasizes Translation Analytics, a suite of
evaluation techniques traditionally reserved for large-scale industry
applications but now becoming increasingly available for smaller-scale users.
This first paper introduces a practical framework for adapting automatic
evaluation metrics -- such as BLEU, chrF, TER, and COMET -- to freelancers'
needs. We illustrate the potential of these metrics using a trilingual corpus
derived from a real-world project in the medical domain and provide statistical
analysis correlating human evaluations with automatic scores. Our findings
emphasize the importance of proactive engagement with emerging technologies to
not only adapt but thrive in the evolving professional environment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 4 figures. Accepted at the MT Summit, University of Geneva,
  June 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ a1: Steep Test-time Scaling Law via Environment Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Yuyao Ge, Jun Wan, Yurong Wu, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have made remarkable breakthroughs in reasoning,
yet continue to struggle with hallucinations, logical errors, and inability to
self-correct during complex multi-step tasks. Current approaches like
chain-of-thought prompting offer limited reasoning capabilities that fail when
precise step validation is required. We propose Environment Augmented
Generation (EAG), a framework that enhances LLM reasoning through: (1)
real-time environmental feedback validating each reasoning step, (2) dynamic
branch exploration for investigating alternative solution paths when faced with
errors, and (3) experience-based learning from successful reasoning
trajectories. Unlike existing methods, EAG enables deliberate backtracking and
strategic replanning through tight integration of execution feedback with
branching exploration. Our a1-32B model achieves state-of-the-art performance
among similar-sized models across all benchmarks, matching larger models like
o1 on competition mathematics while outperforming comparable models by up to
24.4 percentage points. Analysis reveals EAG's distinctive scaling pattern:
initial token investment in environment interaction yields substantial
long-term performance dividends, with advantages amplifying proportionally to
task complexity. EAG's theoretical framework demonstrates how environment
interactivity and systematic branch exploration together establish a new
paradigm for reliable machine reasoning, particularly for problems requiring
precise multi-step calculation and logical verification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HealthGenie: Empowering Users with Healthy Dietary Guidance through
  Knowledge Graph and Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fan Gao, Xinjie Zhao, Ding Xia, Zhongyi Zhou, Rui Yang, Jinghui Lu, Hang Jiang, Chanjun Park, Irene Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Seeking dietary guidance often requires navigating complex professional
knowledge while accommodating individual health conditions. Knowledge Graphs
(KGs) offer structured and interpretable nutritional information, whereas Large
Language Models (LLMs) naturally facilitate conversational recommendation
delivery. In this paper, we present HealthGenie, an interactive system that
combines the strengths of LLMs and KGs to provide personalized dietary
recommendations along with hierarchical information visualization for a quick
and intuitive overview. Upon receiving a user query, HealthGenie performs query
refinement and retrieves relevant information from a pre-built KG. The system
then visualizes and highlights pertinent information, organized by defined
categories, while offering detailed, explainable recommendation rationales.
Users can further tailor these recommendations by adjusting preferences
interactively. Our evaluation, comprising a within-subject comparative
experiment and an open-ended discussion, demonstrates that HealthGenie
effectively supports users in obtaining personalized dietary guidance based on
their health conditions while reducing interaction effort and cognitive load.
These findings highlight the potential of LLM-KG integration in supporting
decision-making through explainable and visualized information. We examine the
system's usefulness and effectiveness with an N=12 within-subject study and
provide design considerations for future systems that integrate conversational
LLM and KG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BookWorld: From Novels to Interactive Agent Societies for Creative Story
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14538v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14538v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiting Ran, Xintao Wang, Tian Qiu, Jiaqing Liang, Yanghua Xiao, Deqing Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models (LLMs) have enabled social
simulation through multi-agent systems. Prior efforts focus on agent societies
created from scratch, assigning agents with newly defined personas. However,
simulating established fictional worlds and characters remain largely
underexplored, despite its significant practical value. In this paper, we
introduce BookWorld, a comprehensive system for constructing and simulating
book-based multi-agent societies. BookWorld's design covers comprehensive
real-world intricacies, including diverse and dynamic characters, fictional
worldviews, geographical constraints and changes, e.t.c. BookWorld enables
diverse applications including story generation, interactive games and social
simulation, offering novel ways to extend and explore beloved fictional works.
Through extensive experiments, we demonstrate that BookWorld generates
creative, high-quality stories while maintaining fidelity to the source books,
surpassing previous methods with a win rate of 75.36%. The code of this paper
can be found at the project page: https://bookworld2025.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causality for Natural Language Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14530v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14530v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijing Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal reasoning is a cornerstone of human intelligence and a critical
capability for artificial systems aiming to achieve advanced understanding and
decision-making. This thesis delves into various dimensions of causal reasoning
and understanding in large language models (LLMs). It encompasses a series of
studies that explore the causal inference skills of LLMs, the mechanisms behind
their performance, and the implications of causal and anticausal learning for
natural language processing (NLP) tasks. Additionally, it investigates the
application of causal reasoning in text-based computational social science,
specifically focusing on political decision-making and the evaluation of
scientific impact through citations. Through novel datasets, benchmark tasks,
and methodological frameworks, this work identifies key challenges and
opportunities to improve the causal capabilities of LLMs, providing a
comprehensive foundation for future research in this evolving field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PhD Thesis 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Vision LLMs Road-Ready? A Comprehensive Benchmark for
  Safety-Critical Driving Video Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Zeng, Longfeng Wu, Liang Shi, Dawei Zhou, Feng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Large Language Models (VLLMs) have demonstrated impressive
capabilities in general visual tasks such as image captioning and visual
question answering. However, their effectiveness in specialized,
safety-critical domains like autonomous driving remains largely unexplored.
Autonomous driving systems require sophisticated scene understanding in complex
environments, yet existing multimodal benchmarks primarily focus on normal
driving conditions, failing to adequately assess VLLMs' performance in
safety-critical scenarios. To address this, we introduce DVBench, a pioneering
benchmark designed to evaluate the performance of VLLMs in understanding
safety-critical driving videos. Built around a hierarchical ability taxonomy
that aligns with widely adopted frameworks for describing driving scenarios
used in assessing highly automated driving systems, DVBench features 10,000
multiple-choice questions with human-annotated ground-truth answers, enabling a
comprehensive evaluation of VLLMs' capabilities in perception and reasoning.
Experiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, reveal
significant performance gaps, with no model achieving over 40% accuracy,
highlighting critical limitations in understanding complex driving scenarios.
To probe adaptability, we fine-tuned selected models using domain-specific data
from DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentage
points, with relative improvements of up to 43.59%. This improvement
underscores the necessity of targeted adaptation to bridge the gap between
general-purpose VLLMs and mission-critical driving applications. DVBench
establishes an essential evaluation framework and research roadmap for
developing VLLMs that meet the safety and robustness requirements for
real-world autonomous systems. We released the benchmark toolbox and the
fine-tuned model at: https://github.com/tong-zeng/DVBench.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahsan Bilal, Muhammad Ahmed Mohsin, Muhammad Umer, Muhammad Awais Khan Bangash, Muhammad Ali Jamshed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This survey explores the development of meta-thinking capabilities in Large
Language Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL)
perspective. Meta-thinking self-reflection, assessment, and control of thinking
processes is an important next step in enhancing LLM reliability, flexibility,
and performance, particularly for complex or high-stakes tasks. The survey
begins by analyzing current LLM limitations, such as hallucinations and the
lack of internal self-assessment mechanisms. It then talks about newer methods,
including RL from human feedback (RLHF), self-distillation, and
chain-of-thought prompting, and each of their limitations. The crux of the
survey is to talk about how multi-agent architectures, namely supervisor-agent
hierarchies, agent debates, and theory of mind frameworks, can emulate
human-like introspective behavior and enhance LLM robustness. By exploring
reward mechanisms, self-play, and continuous learning methods in MARL, this
survey gives a comprehensive roadmap to building introspective, adaptive, and
trustworthy LLMs. Evaluation metrics, datasets, and future research avenues,
including neuroscience-inspired architectures and hybrid symbolic reasoning,
are also discussed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE Transactions on Artificial Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Functional Abstraction of Knowledge Recall in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zijian Wang, Chang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained transformer large language models (LLMs) demonstrate strong
knowledge recall capabilities. This paper investigates the knowledge recall
mechanism in LLMs by abstracting it into a functional structure. We propose
that during knowledge recall, the model's hidden activation space implicitly
entails a function execution process where specific activation vectors align
with functional components (Input argument, Function body, and Return values).
Specifically, activation vectors of relation-related tokens define a mapping
function from subjects to objects, with subject-related token activations
serving as input arguments and object-related token activations as return
values. For experimental verification, we first design a patching-based
knowledge-scoring algorithm to identify knowledge-aware activation vectors as
independent functional components. Then, we conduct counter-knowledge testing
to examine the independent functional effects of each component on knowledge
recall outcomes. From this functional perspective, we improve the contextual
knowledge editing approach augmented by activation patching. By rewriting
incoherent activations in context, we enable improved short-term memory
retention for new knowledge prompting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FairSteer: Inference Time Debiasing for LLMs with Dynamic Activation
  Steering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichen Li, Zhiting Fan, Ruizhe Chen, Xiaotang Gai, Luqi Gong, Yan Zhang, Zuozhu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are prone to capturing biases from training
corpus, leading to potential negative social impacts. Existing prompt-based
debiasing methods exhibit instability due to their sensitivity to prompt
changes, while fine-tuning-based techniques incur substantial computational
overhead and catastrophic forgetting. In this paper, we propose FairSteer, a
novel inference-time debiasing framework without requiring customized prompt
design or model retraining. Motivated by the linear representation hypothesis,
our preliminary investigation demonstrates that fairness-related features can
be encoded into separable directions in the hidden activation space. FairSteer
operates in three steps: biased activation detection, debiasing steering vector
(DSV) computation, and dynamic activation steering. Specifically, it first
trains a lightweight linear classifier to detect bias signatures in
activations, and then computes DSVs as intervention directions derived from
small contrastive prompt pairs. Subsequently, it performs debiasing by
adjusting activations with DSVs in the inference stage. Comprehensive
evaluation with six LLMs demonstrates the superiority of FairSteer across
question-answering, counterfactual input evaluation and open-ended text
generation tasks. Code will be released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for
  Multi-Party Dialogue <span class="chip">ICME 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Duyi Pan, Hongru Xiao, Jiale Han, Jing Tang, Jiabao Ma, Wei Wang, Bo Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech synthesis is crucial for human-computer interaction, enabling natural
and intuitive communication. However, existing datasets involve high
construction costs due to manual annotation and suffer from limited character
diversity, contextual scenarios, and emotional expressiveness. To address these
issues, we propose DialogueAgents, a novel hybrid agent-based speech synthesis
framework, which integrates three specialized agents -- a script writer, a
speech synthesizer, and a dialogue critic -- to collaboratively generate
dialogues. Grounded in a diverse character pool, the framework iteratively
refines dialogue scripts and synthesizes speech based on speech review,
boosting emotional expressiveness and paralinguistic features of the
synthesized dialogues. Using DialogueAgent, we contribute MultiTalk, a
bilingual, multi-party, multi-turn speech dialogue dataset covering diverse
topics. Extensive experiments demonstrate the effectiveness of our framework
and the high quality of the MultiTalk dataset. We release the dataset and code
https://github.com/uirlx/DialogueAgents to facilitate future research on
advanced speech synthesis models and customized data generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICME 2025. Dataset and code are publicly available:
  [https://github.com/uirlx/DialogueAgents](https://github.com/uirlx/DialogueAgents)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning
  Approach to Brain-Language Alignment <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14468v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14468v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interpreting neural activity through meaningful latent representations
remains a complex and evolving challenge at the intersection of neuroscience
and artificial intelligence. We investigate the potential of multimodal
foundation models to align invasive brain recordings with natural language. We
present SSENSE, a contrastive learning framework that projects single-subject
stereo-electroencephalography (sEEG) signals into the sentence embedding space
of a frozen CLIP model, enabling sentence-level retrieval directly from brain
activity. SSENSE trains a neural encoder on spectral representations of sEEG
using InfoNCE loss, without fine-tuning the text encoder. We evaluate our
method on time-aligned sEEG and spoken transcripts from a naturalistic
movie-watching dataset. Despite limited data, SSENSE achieves promising
results, demonstrating that general-purpose language representations can serve
as effective priors for neural decoding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for poster presentation at the CVPR 2025 Workshop on
  Multimodal Foundation Models (MMFM3)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoLoTa: A <span class="highlight-title">Dataset</span> for Entity-based Commonsense Reasoning over Long-Tail
  Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Armin Toroghi, Willis Guo, Scott Sanner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of Large Language Models (LLMs) has redefined the AI landscape,
particularly due to their ability to encode factual and commonsense knowledge,
and their outstanding performance in tasks requiring reasoning. Despite these
advances, hallucinations and reasoning errors remain a significant barrier to
their deployment in high-stakes settings. In this work, we observe that even
the most prominent LLMs, such as OpenAI-o1, suffer from high rates of reasoning
errors and hallucinations on tasks requiring commonsense reasoning over
obscure, long-tail entities. To investigate this limitation, we present a new
dataset for Commonsense reasoning over Long-Tail entities (CoLoTa), that
consists of 3,300 queries from question answering and claim verification tasks
and covers a diverse range of commonsense reasoning skills. We remark that
CoLoTa can also serve as a Knowledge Graph Question Answering (KGQA) dataset
since the support of knowledge required to answer its queries is present in the
Wikidata knowledge graph. However, as opposed to existing KGQA benchmarks that
merely focus on factoid questions, our CoLoTa queries also require commonsense
reasoning. Our experiments with strong LLM-based KGQA methodologies indicate
their severe inability to answer queries involving commonsense reasoning.
Hence, we propose CoLoTa as a novel benchmark for assessing both (i) LLM
commonsense reasoning capabilities and their robustness to hallucinations on
long-tail entities and (ii) the commonsense reasoning capabilities of KGQA
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of
  <span class="highlight-title">Pre-train</span>ing Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Chen, Faeze Brahman, Jiacheng Liu, Niloofar Mireshghallah, Weijia Shi, Pang Wei Koh, Luke Zettlemoyer, Hannaneh Hajishirzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models (LMs) can memorize and reproduce segments from their
pretraining data verbatim even in non-adversarial settings, raising concerns
about copyright, plagiarism, privacy, and creativity. We introduce Paraphrase
Preference Optimization (ParaPO), a post-training method that fine-tunes LMs to
reduce unintentional regurgitation while preserving their overall utility.
ParaPO trains LMs to prefer paraphrased versions of memorized segments over the
original verbatim content from the pretraining data. To maintain the ability to
recall famous quotations when appropriate, we develop a variant of ParaPO that
uses system prompts to control regurgitation behavior. In our evaluation on
Llama3.1-8B, ParaPO consistently reduces regurgitation across all tested
datasets (e.g., reducing the regurgitation metric from 17.3 to 12.9 in creative
writing), whereas unlearning methods used in prior work to mitigate
regurgitation are less effective outside their targeted unlearned domain (from
17.3 to 16.9). When applied to the instruction-tuned Tulu3-8B model, ParaPO
with system prompting successfully preserves famous quotation recall while
reducing unintentional regurgitation (from 8.7 to 6.3 in creative writing) when
prompted not to regurgitate. In contrast, without ParaPO tuning, prompting the
model not to regurgitate produces only a marginal reduction (8.7 to 8.4).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LoRe: Personalizing LLMs via Low-Rank Reward Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Avinandan Bose, Zhihan Xiong, Yuejie Chi, Simon Shaolei Du, Lin Xiao, Maryam Fazel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalizing large language models (LLMs) to accommodate diverse user
preferences is essential for enhancing alignment and user satisfaction.
Traditional reinforcement learning from human feedback (RLHF) approaches often
rely on monolithic value representations, limiting their ability to adapt to
individual preferences. We introduce a novel framework that leverages low-rank
preference modeling to efficiently learn and generalize user-specific reward
functions. By representing reward functions in a low-dimensional subspace and
modeling individual preferences as weighted combinations of shared basis
functions, our approach avoids rigid user categorization while enabling
scalability and few-shot adaptation. We validate our method on multiple
preference datasets, demonstrating superior generalization to unseen users and
improved accuracy in preference prediction tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Star Attention: Efficient LLM Inference over Long Sequences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.17116v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.17116v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shantanu Acharya, Fei Jia, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inference with Transformer-based Large Language Models (LLMs) on long
sequences is both costly and slow due to the quadratic complexity of the
self-attention mechanism. We introduce Star Attention, a two-phase block-sparse
approximation that improves computational efficiency by sharding attention
across multiple hosts while minimizing communication overhead. In the first
phase, the context is processed using blockwise-local attention across hosts,
in parallel. In the second phase, query and response tokens attend to all prior
cached tokens through sequence-global attention. Star Attention integrates
seamlessly with most Transformer-based LLMs trained with global attention,
reducing memory requirements and inference time by up to 11x while preserving
97-100% of accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/NVIDIA/Star-Attention</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09344v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09344v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenlong Deng, Yize Zhao, Vala Vakilian, Minghui Chen, Xiaoxiao Li, Christos Thrampoulidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Storing open-source fine-tuned models separately introduces redundancy and
increases response times in applications utilizing multiple models.
Delta-parameter pruning (DPP), particularly the random drop and rescale (DARE)
method proposed by Yu et al., addresses this by pruning the majority of delta
parameters--the differences between fine-tuned and pre-trained model
weights--while typically maintaining minimal performance loss. However, DARE
fails when either the pruning rate or the magnitude of the delta parameters is
large. We highlight two key reasons for this failure: (1) an excessively large
rescaling factor as pruning rates increase, and (2) high mean and variance in
the delta parameters. To push DARE's limits, we introduce DAREx (DARE the
eXtreme), which features two algorithmic improvements: (1) DAREx-q, a rescaling
factor modification that significantly boosts performance at high pruning rates
(e.g., >30 % on COLA and SST2 for encoder models, with even greater gains in
decoder models), and (2) DAREx-L2, which combines DARE with AdamR, an
in-training method that applies appropriate delta regularization before DPP. We
also demonstrate that DAREx-q can be seamlessly combined with vanilla
parameter-efficient fine-tuning techniques like LoRA and can facilitate
structural DPP. Additionally, we revisit the application of importance-based
pruning techniques within DPP, demonstrating that they outperform random-based
methods when delta parameters are large. Through this comprehensive study, we
develop a pipeline for selecting the most appropriate DPP method under various
practical scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Language Anchor-Guided Method for Robust Noisy Domain Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.17211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.17211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zilin Dai, Lehong Wang, Fangzhou Lin, Yidong Wang, Zhigang Li, Kazunori D Yamada, Ziming Zhang, Wang Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-world machine learning applications often struggle with two major
challenges: distribution shift and label noise. Models tend to overfit by
focusing on redundant and uninformative features in the training data, which
makes it hard for them to generalize to the target domain. Noisy data worsens
this problem by causing further overfitting to the noise, meaning that existing
methods often fail to tell the difference between true, invariant features and
misleading, spurious ones. To tackle these issues, we introduce Anchor
Alignment and Adaptive Weighting (A3W). This new algorithm uses sample
reweighting guided by natural language processing (NLP) anchors to extract more
representative features. In simple terms, A3W leverages semantic
representations from natural language models as a source of domain-invariant
prior knowledge. Additionally, it employs a weighted loss function that adjusts
each sample's contribution based on its similarity to the corresponding NLP
anchor. This adjustment makes the model more robust to noisy labels. Extensive
experiments on standard benchmark datasets show that A3W consistently
outperforms state-of-the-art domain generalization methods, offering
significant improvements in both accuracy and robustness across different
datasets and noise levels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wrong Answers Can Also Be Useful: PlausibleQA -- A Large-Scale QA
  <span class="highlight-title">Dataset</span> with Answer Plausibility Scores <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16358v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16358v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jamshid Mozafari, Abdelrahman Abdallah, Bhawna Piryani, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are revolutionizing information retrieval, with
chatbots becoming an important source for answering user queries. As by their
design, LLMs prioritize generating correct answers, the value of highly
plausible yet incorrect answers (candidate answers) tends to be overlooked.
However, such answers can still prove useful, for example, they can play a
crucial role in tasks like Multiple-Choice Question Answering (MCQA) and QA
Robustness Assessment (QARA). Existing QA datasets primarily focus on correct
answers without explicit consideration of the plausibility of other candidate
answers, limiting opportunity for more nuanced evaluations of models. To
address this gap, we introduce PlausibleQA, a large-scale dataset comprising
10,000 questions and 100,000 candidate answers, each annotated with
plausibility scores and justifications for their selection. Additionally, the
dataset includes 900,000 justifications for pairwise comparisons between
candidate answers, further refining plausibility assessments. We evaluate
PlausibleQA through human assessments and empirical experiments, demonstrating
its utility in MCQA and QARA analysis. Our findings show that
plausibility-aware approaches are effective for MCQA distractor generation and
QARA. We release PlausibleQA as a resource for advancing QA research and
enhancing LLM performance in distinguishing plausible distractors from correct
answers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WikiHint: A Human-Annotated <span class="highlight-title">Dataset</span> for Hint Ranking and Generation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.01626v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.01626v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jamshid Mozafari, Florian Gerhold, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The use of Large Language Models (LLMs) has increased significantly with
users frequently asking questions to chatbots. In the time when information is
readily accessible, it is crucial to stimulate and preserve human cognitive
abilities and maintain strong reasoning skills. This paper addresses such
challenges by promoting the use of hints as an alternative or a supplement to
direct answers. We first introduce a manually constructed hint dataset,
WikiHint, which is based on Wikipedia and includes 5,000 hints created for
1,000 questions. We then finetune open-source LLMs for hint generation in
answer-aware and answer-agnostic contexts. We assess the effectiveness of the
hints with human participants who answer questions with and without the aid of
hints. Additionally, we introduce a lightweight evaluation method, HintRank, to
evaluate and rank hints in both answer-aware and answer-agnostic settings. Our
findings show that (a) the dataset helps generate more effective hints, (b)
including answer information along with questions generally improves the
quality of generated hints, and (c) encoder-based models perform better than
decoder-based models in hint ranking.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Forecasting from Clinical Textual Time Series: Adaptations of the
  Encoder and Decoder Language Model Families 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10340v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10340v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinical case reports encode rich, temporal patient trajectories that are
often underexploited by traditional machine learning methods relying on
structured data. In this work, we introduce the forecasting problem from
textual time series, where timestamped clinical findings -- extracted via an
LLM-assisted annotation pipeline -- serve as the primary input for prediction.
We systematically evaluate a diverse suite of models, including fine-tuned
decoder-based large language models and encoder-based transformers, on tasks of
event occurrence prediction, temporal ordering, and survival analysis. Our
experiments reveal that encoder-based models consistently achieve higher F1
scores and superior temporal concordance for short- and long-horizon event
forecasting, while fine-tuned masking approaches enhance ranking performance.
In contrast, instruction-tuned decoder models demonstrate a relative advantage
in survival analysis, especially in early prognosis settings. Our sensitivity
analyses further demonstrate the importance of time ordering, which requires
clinical time series construction, as compared to text ordering, the format of
the text inputs that LLMs are classically trained on. This highlights the
additional benefit that can be ascertained from time-ordered corpora, with
implications for temporal tasks in the era of widespread LLM use.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Machine Learning for Healthcare (MLHC 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SLMRec: Distilling Large Language Models into Small for Sequential
  Recommendation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17890v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17890v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wujiang Xu, Qitian Wu, Zujie Liang, Jiaojiao Han, Xuying Ning, Yunxiao Shi, Wenfang Lin, Yongfeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential Recommendation (SR) task involves predicting the next item a user
is likely to interact with, given their past interactions. The SR models
examine the sequence of a user's actions to discern more complex behavioral
patterns and temporal dynamics. Recent research demonstrates the great impact
of LLMs on sequential recommendation systems, either viewing sequential
recommendation as language modeling or serving as the backbone for user
representation. Although these methods deliver outstanding performance, there
is scant evidence of the necessity of a large language model and how large the
language model is needed, especially in the sequential recommendation scene.
Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to
apply a LLM-based model in real-world platforms that often need to process
billions of traffic logs daily. In this paper, we explore the influence of
LLMs' depth by conducting extensive experiments on large-scale industry
datasets. Surprisingly, our motivational experiments reveal that most
intermediate layers of LLMs are redundant, indicating that pruning the
remaining layers can still maintain strong performance. Motivated by this
insight, we empower small language models for SR, namely SLMRec, which adopt a
simple yet effective knowledge distillation method. Moreover, SLMRec is
orthogonal to other post-training efficiency techniques, such as quantization
and pruning, so that they can be leveraged in combination. Comprehensive
experimental results illustrate that the proposed SLMRec model attains the best
performance using only 13% of the parameters found in LLM-based recommendation
models while simultaneously achieving up to 6.6x and 8.0x speedups in training
and inference time costs, respectively. Besides, we provide a theoretical
justification for why small language models can perform comparably to large
language models in SR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>International Conference on Learning Representations (ICLR 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-evolving Agents with reflective and memory-augmented abilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00872v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00872v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuechen Liang, Yangfan He, Yinghui Xia, Xinyuan Song, Jianhui Wang, Meiling Tao, Li Sun, Xinhang Yuan, Jiayi Su, Keqin Li, Jiaqi Chen, Jinsong Yang, Siyuan Chen, Tianyu Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have made significant advances in the field of
natural language processing, but they still face challenges such as continuous
decision-making. In this research, we propose a novel framework by integrating
iterative feedback, reflective mechanisms, and a memory optimization mechanism
based on the Ebbinghaus forgetting curve, it significantly enhances the agents'
capabilities in handling multi-tasking and long-span information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing MoE Efficiency: A Collaboration-Constrained Routing (C2R)
  Strategy for Better Expert Parallelism Design <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.01337v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.01337v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohan Zhang, Pingzhi Li, Jie Peng, Mufan Qiu, Tianlong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-Experts (MoE) has successfully scaled up models while maintaining
nearly constant computing costs. By employing a gating network to route input
tokens, it selectively activates a subset of expert networks to process the
corresponding token embeddings. However, in practice, the efficiency of MoE is
challenging to achieve due to two key reasons: imbalanced expert activation,
which leads to substantial idle time during model or expert parallelism, and
insufficient capacity utilization; massive communication overhead, induced by
numerous expert routing combinations in expert parallelism at the system level.
Previous works typically formulate it as the load imbalance issue characterized
by the gating network favoring certain experts over others or attribute it to
static execution which fails to adapt to the dynamic expert workload at
runtime. In this paper, we exploit it from a brand new perspective, a
higher-order view and analysis of MoE routing policies: expert collaboration
and specialization where some experts tend to activate broadly with others
(collaborative), while others are more likely to activate only with a specific
subset of experts (specialized). Our experiments reveal that most experts tend
to be overly collaborative, leading to increased communication overhead from
repeatedly sending tokens to different accelerators. To this end, we propose a
novel collaboration-constrained routing (C2R) strategy to encourage more
specialized expert groups, as well as to improve expert utilization, and
present an efficient implementation of MoE that further leverages expert
specialization. We achieve an average performance improvement of 0.51% and
0.33% on LLaMA-MoE and Qwen-MoE respectively across ten downstream NLP
benchmarks, and reduce the all2all communication costs between GPUs, bringing
an extra 20%-30% total running time savings on top of the existing SoTA, i.e.
MegaBlocks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025, SAC award for Low-resource Methods for NLP</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Idiom Detection in Sorani Kurdish Texts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.14528v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.14528v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Skala Kamaran Omer, Hossein Hassani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Idiom detection using Natural Language Processing (NLP) is the computerized
process of recognizing figurative expressions within a text that convey
meanings beyond the literal interpretation of the words. While idiom detection
has seen significant progress across various languages, the Kurdish language
faces a considerable research gap in this area despite the importance of idioms
in tasks like machine translation and sentiment analysis. This study addresses
idiom detection in Sorani Kurdish by approaching it as a text classification
task using deep learning techniques. To tackle this, we developed a dataset
containing 10,580 sentences embedding 101 Sorani Kurdish idioms across diverse
contexts. Using this dataset, we developed and evaluated three deep learning
models: KuBERT-based transformer sequence classification, a Recurrent
Convolutional Neural Network (RCNN), and a BiLSTM model with an attention
mechanism. The evaluations revealed that the transformer model, the fine-tuned
BERT, consistently outperformed the others, achieving nearly 99% accuracy while
the RCNN achieved 96.5% and the BiLSTM 80%. These results highlight the
effectiveness of Transformer-based architectures in low-resource languages like
Kurdish. This research provides a dataset, three optimized models, and insights
into idiom detection, laying a foundation for advancing Kurdish NLP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 8 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Seek and Solve Reasoning for Table Question Answering <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05286v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05286v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruya Jiang, Chun Wang, Weihong Deng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The complexities of table structures and question logic make table-based
question answering (TQA) tasks challenging for Large Language Models (LLMs),
often requiring task simplification before solving. This paper reveals that the
reasoning process during task simplification may be more valuable than the
simplified tasks themselves and aims to improve TQA performance by leveraging
LLMs' reasoning capabilities. We propose a Seek-and-Solve pipeline that
instructs the LLM to first seek relevant information and then answer questions,
integrating these two stages at the reasoning level into a coherent
Seek-and-Solve Chain of Thought (SS-CoT). Additionally, we distill a
single-step TQA-solving prompt from this pipeline, using demonstrations with
SS-CoT paths to guide the LLM in solving complex TQA tasks under In-Context
Learning settings. Our experiments show that our approaches result in improved
performance and reliability while being efficient. Our findings emphasize the
importance of eliciting LLMs' reasoning capabilities to handle complex TQA
tasks effectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in: ICASSP 2025 - 2025 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Following the Whispers of Values: Unraveling Neural Mechanisms Behind
  Value-Oriented Behaviors in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04994v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04994v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ling Hu, Yuemei Xu, Xiaoyang Gu, Letao Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the impressive performance of large language models (LLMs), they can
present unintended biases and harmful behaviors driven by encoded values,
emphasizing the urgent need to understand the value mechanisms behind them.
However, current research primarily evaluates these values through external
responses with a focus on AI safety, lacking interpretability and failing to
assess social values in real-world contexts. In this paper, we propose a novel
framework called ValueExploration, which aims to explore the behavior-driven
mechanisms of National Social Values within LLMs at the neuron level. As a case
study, we focus on Chinese Social Values and first construct C-voice, a
large-scale bilingual benchmark for identifying and evaluating Chinese Social
Values in LLMs. By leveraging C-voice, we then identify and locate the neurons
responsible for encoding these values according to activation difference.
Finally, by deactivating these neurons, we analyze shifts in model behavior,
uncovering the internal mechanism by which values influence LLM
decision-making. Extensive experiments on four representative LLMs validate the
efficacy of our framework. The benchmark and code will be available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BenchMAX: A Comprehensive Multilingual Evaluation Suite for Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xu Huang, Wenhao Zhu, Hanxu Hu, Conghui He, Lei Li, Shujian Huang, Fei Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous multilingual benchmarks focus primarily on simple understanding
tasks, but for large language models(LLMs), we emphasize proficiency in
instruction following, reasoning, long context understanding, code generation,
and so on. However, measuring these advanced capabilities across languages is
underexplored. To address the disparity, we introduce BenchMAX, a multi-way
multilingual evaluation benchmark that allows for fair comparisons of these
important abilities across languages. To maintain high quality, three distinct
native-speaking annotators independently annotate each sample within all tasks
after the data was machine-translated from English into 16 other languages.
Additionally, we present a novel translation challenge stemming from dataset
construction. Extensive experiments on BenchMAX reveal varying effectiveness of
core capabilities across languages, highlighting performance gaps that cannot
be bridged by simply scaling up model size. BenchMAX serves as a comprehensive
multilingual evaluation platform, providing a promising test bed to promote the
development of multilingual language models. The dataset and code are publicly
accessible.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Grained and Multi-Dimensional Metrics for Document-Level Machine
  Translation <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20941v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20941v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yirong Sun, Dawei Zhu, Yanjun Chen, Erjia Xiao, Xinghao Chen, Xiaoyu Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have excelled in various NLP tasks, including
machine translation (MT), yet most studies focus on sentence-level translation.
This work investigates the inherent capability of instruction-tuned LLMs for
document-level translation (docMT). Unlike prior approaches that require
specialized techniques, we evaluate LLMs by directly prompting them to
translate entire documents in a single pass. Our results show that this method
improves translation quality compared to translating sentences separately, even
without document-level fine-tuning. However, this advantage is not reflected in
BLEU scores, which often favor sentence-based translations. We propose using
the LLM-as-a-judge paradigm for evaluation, where GPT-4 is used to assess
document coherence, accuracy, and fluency in a more nuanced way than
n-gram-based metrics. Overall, our work demonstrates that instruction-tuned
LLMs can effectively leverage document context for translation. However, we
caution against using BLEU scores for evaluating docMT, as they often provide
misleading outcomes, failing to capture the quality of document-level
translation. Code and the outputs from GPT4-as-a-judge are available at
https://github.com/EIT-NLP/BLEUless_DocMT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NAACL 2025 Student Research Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Persona Dynamics: Unveiling the Impact of Personality Traits on Agents
  in Text-Based Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.06868v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.06868v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seungwon Lim, Seungbeen Lee, Dongjun Min, Youngjae Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial agents are increasingly central to complex interactions and
decision-making tasks, yet aligning their behaviors with desired human values
remains an open challenge. In this work, we investigate how human-like
personality traits influence agent behavior and performance within text-based
interactive environments. We introduce PANDA: Personality Adapted Neural
Decision Agents, a novel method for projecting human personality traits onto
agents to guide their behavior. To induce personality in a text-based game
agent, (i) we train a personality classifier to identify what personality type
the agent's actions exhibit, and (ii) we integrate the personality profiles
directly into the agent's policy-learning pipeline. By deploying agents
embodying 16 distinct personality types across 25 text-based games and
analyzing their trajectories, we demonstrate that an agent's action decisions
can be guided toward specific personality profiles. Moreover, certain
personality types, such as those characterized by higher levels of Openness,
display marked advantages in performance. These findings underscore the promise
of personality-adapted agents for fostering more aligned, effective, and
human-centric decision-making in interactive environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community
  Retrieval <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04585v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04585v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengcheng Jiang, Cao Xiao, Minhao Jiang, Parminder Bhatia, Taha Kass-Hout, Jimeng Sun, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated significant potential in
clinical decision support. Yet LLMs still suffer from hallucinations and lack
fine-grained contextual medical knowledge, limiting their high-stake healthcare
applications such as clinical diagnosis. Traditional retrieval-augmented
generation (RAG) methods attempt to address these limitations but frequently
retrieve sparse or irrelevant information, undermining prediction accuracy. We
introduce KARE, a novel framework that integrates knowledge graph (KG)
community-level retrieval with LLM reasoning to enhance healthcare predictions.
KARE constructs a comprehensive multi-source KG by integrating biomedical
databases, clinical literature, and LLM-generated insights, and organizes it
using hierarchical graph community detection and summarization for precise and
contextually relevant information retrieval. Our key innovations include: (1) a
dense medical knowledge structuring approach enabling accurate retrieval of
relevant information; (2) a dynamic knowledge retrieval mechanism that enriches
patient contexts with focused, multi-faceted medical insights; and (3) a
reasoning-enhanced prediction framework that leverages these enriched contexts
to produce both accurate and interpretable clinical predictions. Extensive
experiments demonstrate that KARE outperforms leading models by up to
10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and
readmission predictions. In addition to its impressive prediction accuracy, our
framework leverages the reasoning capabilities of LLMs, enhancing the
trustworthiness of clinical predictions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Camera-Ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CHATTER: A Character Attribution <span class="highlight-title">Dataset</span> for Narrative Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.05227v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.05227v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabyasachee Baruah, Shrikanth Narayanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computational narrative understanding studies the identification,
description, and interaction of the elements of a narrative: characters,
attributes, events, and relations. Narrative research has given considerable
attention to defining and classifying character types. However, these
character-type taxonomies do not generalize well because they are small, too
simple, or specific to a domain. We require robust and reliable benchmarks to
test whether narrative models truly understand the nuances of the character's
development in the story. Our work addresses this by curating the CHATTER
dataset that labels whether a character portrays some attribute for 88124
character-attribute pairs, encompassing 2998 characters, 12967 attributes and
660 movies. We validate a subset of CHATTER, called CHATTEREVAL, using human
annotations to serve as a benchmark to evaluate the character attribution task
in movie scripts. \evaldataset{} also assesses narrative understanding and the
long-context modeling capacity of language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted to 7th Workshop on Narrative Understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GLoRE: Evaluating Logical Reasoning of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09107v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09107v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanmeng liu, Zhiyang Teng, Ruoxi Ning, Yiran Ding, Xiulai Li, Xiaozhang Liu, Yue Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown significant general language
understanding abilities. However, there has been a scarcity of attempts to
assess the logical reasoning capacities of these LLMs, an essential facet of
natural language understanding. To encourage further investigation in this
area, we introduce GLoRE, a General Logical Reasoning Evaluation platform that
not only consolidates diverse datasets but also standardizes them into a
unified format suitable for evaluating large language models across zero-shot
and few-shot scenarios. Our experimental results show that compared to the
performance of humans and supervised fine-tuning models, the logical reasoning
capabilities of large reasoning models, such as OpenAI's o1 mini, DeepSeek R1
and QwQ-32B, have seen remarkable improvements, with QwQ-32B achieving the
highest benchmark performance to date. GLoRE is designed as a living project
that continuously integrates new datasets and models, facilitating robust and
comparative assessments of model performance in both commercial and Huggingface
communities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ToReMi: Topic-Aware Data Reweighting for Dynamic <span class="highlight-title">Pre-Train</span>ing Data
  Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.00695v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.00695v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoxuan Zhu, Zhouhong Gu, Baiqian Wu, Suhang Zheng, Tao Wang, Tianyu Li, Hongwei Feng, Yanghua Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-training large language models (LLMs) necessitates enormous diverse
textual corpora, making effective data selection a key challenge for balancing
computational resources and model performance. Current methodologies primarily
emphasize data quality metrics and mixing proportions, yet they fail to
adequately capture the underlying semantic connections between training samples
and quality disparities within individual domains. We introduce ToReMi
(Topic-based Reweighting for Model improvement), a novel two-stage framework
that dynamically adjusts training sample weights according to their topical
associations and observed learning patterns. Our comprehensive experiments
reveal that ToReMi variants consistently achieve superior performance over
conventional pre-training approaches, demonstrating accelerated perplexity
reduction across multiple domains and enhanced capabilities on downstream
evaluation tasks. Code is available at https://github.com/zxx000728/ToReMi.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AI-Slop to AI-Polish? Aligning Language Models through Edit-Based
  Writing Rewards and Test-time Computation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.07532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.07532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuhin Chakrabarty, Philippe Laban, Chien-Sheng Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI-generated text is proliferating across domains, from creative writing and
journalism to marketing content and scientific articles. Models can follow
user-provided instructions to generate coherent and grammatically correct
outputs but in this work, we study a more fundamental question: how do we
evaluate and improve the writing quality of AI-generated text? Writing quality
assessment has received less attention from the community, in part because it
is fundamentally subjective and requires expertise. We first introduce the
Writing Quality Benchmark (WQ) by consolidating five writing-preference
datasets into 4,729 writing quality judgments. Our experiments show that most
of the competitive baselines, including state-of-the-art LLMs that excel at
reasoning tasks, barely outperform random baselines on WQ. We then train
specialized Writing Quality Reward Models (WQRM) of various sizes for writing
quality assessment that demonstrate strong generalization on four
out-of-distribution test sets and 74% accuracy on the WQ benchmark. To further
show WQRM's practical benefits during inference, we leverage additional
test-time compute to generate and rank multiple candidate revisions, allowing
us to select higher-quality outputs from an initial draft. Human evaluation
with 9 experienced writers confirm that WQRM-based selection produces writing
samples preferred by experts 66% overall, and 72.2% when the reward gap is
larger than 1 point. We release our datasets and models to encourage community
engagement with writing quality assessment and development of AI writing
systems better aligned with human preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IFShip: Interpretable Fine-grained Ship Classification with Domain
  Knowledge-Enhanced Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06631v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06631v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingning Guo, Mengwei Wu, Yuxiang Shen, Haifeng Li, Chao Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end interpretation currently dominates the remote sensing fine-grained
ship classification (RS-FGSC) task. However, the inference process remains
uninterpretable, leading to criticisms of these models as "black box" systems.
To address this issue, we propose a domain knowledge-enhanced Chain-of-Thought
(CoT) prompt generation mechanism, which is used to semi-automatically
construct a task-specific instruction-following dataset, TITANIC-FGS. By
training on TITANIC-FGS, we adapt general-domain vision-language models (VLMs)
to the FGSC task, resulting in a model named IFShip. Building upon IFShip, we
develop an FGSC visual chatbot that redefines the FGSC problem as a
step-by-step reasoning task and conveys the reasoning process in natural
language. Experimental results show that IFShip outperforms state-of-the-art
FGSC algorithms in both interpretability and classification accuracy.
Furthermore, compared to VLMs such as LLaVA and MiniGPT-4, IFShip demonstrates
superior performance on the FGSC task. It provides an accurate chain of
reasoning when fine-grained ship types are recognizable to the human eye and
offers interpretable explanations when they are not. Our dataset is publicly
available at: https://github.com/lostwolves/IFShip.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How to Enable Effective Cooperation Between Humans and NLP Models: A
  <span class="highlight-title">Survey</span> of Principles, Formalizations, and Beyond 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05714v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05714v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua, Jimmy Xiangji Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the advancement of large language models (LLMs), intelligent models have
evolved from mere tools to autonomous agents with their own goals and
strategies for cooperating with humans. This evolution has birthed a novel
paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable
progress in numerous NLP tasks in recent years. In this paper, we take the
first step to present a thorough review of human-model cooperation, exploring
its principles, formalizations, and open challenges. In particular, we
introduce a new taxonomy that provides a unified perspective to summarize
existing approaches. Also, we discuss potential frontier areas and their
corresponding challenges. We regard our work as an entry point, paving the way
for more breakthrough research in this regard.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>V2: Only minor edits were made to the main text, and we've added more
  supplementary materials</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging <span class="chip">SemEval</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.21088v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.21088v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4:
Unlearning Sensitive Content from Large Language Models. This task aims to
selectively erase sensitive knowledge from large language models, avoiding both
over-forgetting and under-forgetting issues. We propose an unlearning system
that leverages Model Merging (specifically TIES-Merging), combining two
specialized models into a more balanced unlearned model. Our system achieves
competitive results, ranking second among 26 teams, with an online score of
0.944 for Task Aggregate and 0.487 for overall Aggregate. In this paper, we
also conduct local experiments and perform a comprehensive analysis of the
unlearning process, examining performance trajectories, loss dynamics, and
weight perspectives, along with several supplementary experiments, to
understand the effectiveness of our method. Furthermore, we analyze the
shortcomings of our method and evaluation metrics, emphasizing that MIA scores
and ROUGE-based metrics alone are insufficient to fully evaluate successful
unlearning. Finally, we emphasize the need for more comprehensive evaluation
methodologies and rethinking of unlearning objectives in future research. Code
is available at https://github.com/zjunlp/unlearn/tree/main/semeval25.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SemEval@ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nudging: Inference-time Alignment of LLMs via Guided Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Fei, Yasaman Razeghi, Sameer Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) require alignment to effectively and safely
follow user instructions. This process necessitates training an aligned version
for every base model, resulting in significant computational overhead. In this
work, we propose nudging, a simple, plug-and-play, and training-free algorithm
that aligns any base model at inference time using a small aligned model.
Nudging is motivated by recent findings that alignment primarily alters the
model's behavior on a small subset of stylistic tokens (e.g., discourse
markers). We find that base models are significantly more uncertain when
generating these tokens. Building on this insight, nudging employs a small
aligned model to generate nudging tokens to guide the base model's output
during decoding when the base model's uncertainty is high. We evaluate nudging
across 3 model families on a diverse range of open-instruction tasks. Without
any training, nudging a large base model with a 7x-14x smaller aligned model
achieves zero-shot performance comparable to, and sometimes surpassing, that of
large aligned models. By operating at the token level, nudging enables
off-the-shelf collaboration between model families. For instance, nudging
Gemma-2-27b with Llama-2-7b-chat outperforms Llama-2-70b-chat on various tasks.
Overall, our work offers a modular and cost-efficient solution to LLM
alignment. Our project website: https://fywalter.github.io/nudging/ .
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">26</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for
  Enhanced Single- and Multi-Task Approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14753v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14753v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guodong Shen, Yuqi Ouyang, Junru Lu, Yixuan Yang, Victor Sanchez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the prevailing transition from single-task to multi-task approaches
in video anomaly detection, we observe that many adopt sub-optimal frameworks
for individual proxy tasks. Motivated by this, we contend that optimizing
single-task frameworks can advance both single- and multi-task approaches.
Accordingly, we leverage middle-frame prediction as the primary proxy task, and
introduce an effective hybrid framework designed to generate accurate
predictions for normal frames and flawed predictions for abnormal frames. This
hybrid framework is built upon a bi-directional structure that seamlessly
integrates both vision transformers and ConvLSTMs. Specifically, we utilize
this bi-directional structure to fully analyze the temporal dimension by
predicting frames in both forward and backward directions, significantly
boosting the detection stability. Given the transformer's capacity to model
long-range contextual dependencies, we develop a convolutional temporal
transformer that efficiently associates feature maps from all context frames to
generate attention-based predictions for target frames. Furthermore, we devise
a layer-interactive ConvLSTM bridge that facilitates the smooth flow of
low-level features across layers and time-steps, thereby strengthening
predictions with fine details. Anomalies are eventually identified by
scrutinizing the discrepancies between target frames and their corresponding
predictions. Several experiments conducted on public benchmarks affirm the
efficacy of our hybrid framework, whether used as a standalone single-task
approach or integrated as a branch in a multi-task approach. These experiments
also underscore the advantages of merging vision transformers and ConvLSTMs for
video anomaly detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Image Processing (TIP)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SuperCL: Superpixel Guided Contrastive Learning for Medical Image
  Segmentation <span class="highlight-title">Pre-train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14737v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14737v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuang Zeng, Lei Zhu, Xinliang Zhang, Hangzhou He, Yanye Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image segmentation is a critical yet challenging task, primarily due
to the difficulty of obtaining extensive datasets of high-quality,
expert-annotated images. Contrastive learning presents a potential but still
problematic solution to this issue. Because most existing methods focus on
extracting instance-level or pixel-to-pixel representation, which ignores the
characteristics between intra-image similar pixel groups. Moreover, when
considering contrastive pairs generation, most SOTA methods mainly rely on
manually setting thresholds, which requires a large number of gradient
experiments and lacks efficiency and generalization. To address these issues,
we propose a novel contrastive learning approach named SuperCL for medical
image segmentation pre-training. Specifically, our SuperCL exploits the
structural prior and pixel correlation of images by introducing two novel
contrastive pairs generation strategies: Intra-image Local Contrastive Pairs
(ILCP) Generation and Inter-image Global Contrastive Pairs (IGCP) Generation.
Considering superpixel cluster aligns well with the concept of contrastive
pairs generation, we utilize the superpixel map to generate pseudo masks for
both ILCP and IGCP to guide supervised contrastive learning. Moreover, we also
propose two modules named Average SuperPixel Feature Map Generation (ASP) and
Connected Components Label Generation (CCL) to better exploit the prior
structural information for IGCP. Finally, experiments on 8 medical image
datasets indicate our SuperCL outperforms existing 12 methods. i.e. Our SuperCL
achieves a superior performance with more precise predictions from
visualization figures and 3.15%, 5.44%, 7.89% DSC higher than the previous best
results on MMWHS, CHAOS, Spleen with 10% annotations. Our code will be released
after acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ChronoRoot 2.0: An Open AI-Powered Platform for 2D Temporal Plant
  Phenotyping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicolás Gaggion, Rodrigo Bonazzola, María Florencia Legascue, María Florencia Mammarella, Florencia Sol Rodriguez, Federico Emanuel Aballay, Florencia Belén Catulo, Andana Barrios, Franco Accavallo, Santiago Nahuel Villarreal, Martin Crespi, Martiniano María Ricardi, Ezequiel Petrillo, Thomas Blein, Federico Ariel, Enzo Ferrante
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The analysis of plant developmental plasticity, including root system
architecture, is fundamental to understanding plant adaptability and
development, particularly in the context of climate change and agricultural
sustainability. While significant advances have been made in plant phenotyping
technologies, comprehensive temporal analysis of root development remains
challenging, with most existing solutions providing either limited throughput
or restricted structural analysis capabilities. Here, we present ChronoRoot
2.0, an integrated open-source platform that combines affordable hardware with
advanced artificial intelligence to enable sophisticated temporal plant
phenotyping. The system introduces several major advances, offering an integral
perspective of seedling development: (i) simultaneous multi-organ tracking of
six distinct plant structures, (ii) quality control through real-time
validation, (iii) comprehensive architectural measurements including novel
gravitropic response parameters, and (iv) dual specialized user interfaces for
both architectural analysis and high-throughput screening. We demonstrate the
system's capabilities through three use cases for Arabidopsis thaliana:
characterization of circadian growth patterns under different light conditions,
detailed analysis of gravitropic responses in transgenic plants, and
high-throughput screening of etiolation responses across multiple genotypes.
ChronoRoot 2.0 maintains its predecessor's advantages of low cost and
modularity while significantly expanding its capabilities, making sophisticated
temporal phenotyping more accessible to the broader plant science community.
The system's open-source nature, combined with extensive documentation and
containerized deployment options, ensures reproducibility and enables
community-driven development of new analytical capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semi-parametric Memory Consolidation: Towards Brain-like Deep Continual
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Geng Liu, Fei Zhu, Rong Feng, Zhiqiang Yi, Shiqi Wang, Gaofeng Meng, Zhaoxiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans and most animals inherently possess a distinctive capacity to
continually acquire novel experiences and accumulate worldly knowledge over
time. This ability, termed continual learning, is also critical for deep neural
networks (DNNs) to adapt to the dynamically evolving world in open
environments. However, DNNs notoriously suffer from catastrophic forgetting of
previously learned knowledge when trained on sequential tasks. In this work,
inspired by the interactive human memory and learning system, we propose a
novel biomimetic continual learning framework that integrates semi-parametric
memory and the wake-sleep consolidation mechanism. For the first time, our
method enables deep neural networks to retain high performance on novel tasks
while maintaining prior knowledge in real-world challenging continual learning
scenarios, e.g., class-incremental learning on ImageNet. This study
demonstrates that emulating biological intelligence provides a promising path
to enable deep neural networks with continual learning capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TAPIP3D: Tracking Any Point in Persistent 3D Geometry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14717v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14717v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowei Zhang, Lei Ke, Adam W. Harley, Katerina Fragkiadaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce TAPIP3D, a novel approach for long-term 3D point tracking in
monocular RGB and RGB-D videos. TAPIP3D represents videos as camera-stabilized
spatio-temporal feature clouds, leveraging depth and camera motion information
to lift 2D video features into a 3D world space where camera motion is
effectively canceled. TAPIP3D iteratively refines multi-frame 3D motion
estimates within this stabilized representation, enabling robust tracking over
extended periods. To manage the inherent irregularities of 3D point
distributions, we propose a Local Pair Attention mechanism. This 3D
contextualization strategy effectively exploits spatial relationships in 3D,
forming informative feature neighborhoods for precise 3D trajectory estimation.
Our 3D-centric approach significantly outperforms existing 3D point tracking
methods and even enhances 2D tracking accuracy compared to conventional 2D
pixel trackers when accurate depth is available. It supports inference in both
camera coordinates (i.e., unstabilized) and world coordinates, and our results
demonstrate that compensating for camera motion improves tracking performance.
Our approach replaces the conventional 2D square correlation neighborhoods used
in prior 2D and 3D trackers, leading to more robust and accurate results across
various 3D point tracking benchmarks. Project Page: https://tapip3d.github.io
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Long-term feed-forward 3D point tracking in persistent 3D point maps.
  Code:https://github.com/zbw001/TAPIP3D</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Med-2D SegNet: A Light Weight Deep Neural Network for Medical 2D Image
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14715v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14715v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md. Sanaullah Chowdhury, Salauddin Tapu, Noyon Kumar Sarkar, Ferdous Bin Ali, Lameya Sabrin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate and efficient medical image segmentation is crucial for advancing
clinical diagnostics and surgical planning, yet remains a complex challenge due
to the variability in anatomical structures and the demand for low-complexity
models. In this paper, we introduced Med-2D SegNet, a novel and highly
efficient segmentation architecture that delivers outstanding accuracy while
maintaining a minimal computational footprint. Med-2D SegNet achieves
state-of-the-art performance across multiple benchmark datasets, including
KVASIR-SEG, PH2, EndoVis, and GLAS, with an average Dice similarity coefficient
(DSC) of 89.77% across 20 diverse datasets. Central to its success is the
compact Med Block, a specialized encoder design that incorporates dimension
expansion and parameter reduction, enabling precise feature extraction while
keeping model parameters to a low count of just 2.07 million. Med-2D SegNet
excels in cross-dataset generalization, particularly in polyp segmentation,
where it was trained on KVASIR-SEG and showed strong performance on unseen
datasets, demonstrating its robustness in zero-shot learning scenarios, even
though we acknowledge that further improvements are possible. With top-tier
performance in both binary and multi-class segmentation, Med-2D SegNet
redefines the balance between accuracy and efficiency, setting a new benchmark
for medical image analysis. This work paves the way for developing accessible,
high-performance diagnostic tools suitable for clinical environments and
resource-constrained settings, making it a step forward in the democratization
of advanced medical technology.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exposing the Copycat Problem of Imitation-based Planner: A Novel
  Closed-Loop Simulator, Causal Benchmark and Joint IL-RL Baseline 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14709v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14709v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Zhou, Shaoshuai Shi, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning (ML)-based planners have recently gained significant
attention. They offer advantages over traditional optimization-based planning
algorithms. These advantages include fewer manually selected parameters and
faster development. Within ML-based planning, imitation learning (IL) is a
common algorithm. It primarily learns driving policies directly from supervised
trajectory data. While IL has demonstrated strong performance on many open-loop
benchmarks, it remains challenging to determine if the learned policy truly
understands fundamental driving principles, rather than simply extrapolating
from the ego-vehicle's initial state. Several studies have identified this
limitation and proposed algorithms to address it. However, these methods often
use original datasets for evaluation. In these datasets, future trajectories
are heavily dependent on initial conditions. Furthermore, IL often overfits to
the most common scenarios. It struggles to generalize to rare or unseen
situations.
  To address these challenges, this work proposes: 1) a novel closed-loop
simulator supporting both imitation and reinforcement learning, 2) a causal
benchmark derived from the Waymo Open Dataset to rigorously assess the impact
of the copycat problem, and 3) a novel framework integrating imitation learning
and reinforcement learning to overcome the limitations of purely imitative
approaches. The code for this work will be released soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Time Frequency Analysis of EMG Signal for Gesture Recognition using Fine
  grained Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14708v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14708v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parshuram N. Aarotale, Ajita Rattani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electromyography (EMG) based hand gesture recognition converts forearm muscle
activity into control commands for prosthetics, rehabilitation, and human
computer interaction. This paper proposes a novel approach to EMG-based hand
gesture recognition that uses fine-grained classification and presents XMANet,
which unifies low-level local and high level semantic cues through cross layer
mutual attention among shallow to deep CNN experts. Using stacked spectrograms
and scalograms derived from the Short Time Fourier Transform (STFT) and Wavelet
Transform (WT), we benchmark XMANet against ResNet50, DenseNet-121,
MobileNetV3, and EfficientNetB0. Experimental results on the Grabmyo dataset
indicate that, using STFT, the proposed XMANet model outperforms the baseline
ResNet50, EfficientNetB0, MobileNetV3, and DenseNet121 models with improvement
of approximately 1.72%, 4.38%, 5.10%, and 2.53%, respectively. When employing
the WT approach, improvements of around 1.57%, 1.88%, 1.46%, and 2.05% are
observed over the same baselines. Similarly, on the FORS EMG dataset, the
XMANet(ResNet50) model using STFT shows an improvement of about 5.04% over the
baseline ResNet50. In comparison, the XMANet(DenseNet121) and
XMANet(MobileNetV3) models yield enhancements of approximately 4.11% and 2.81%,
respectively. Moreover, when using WT, the proposed XMANet achieves gains of
around 4.26%, 9.36%, 5.72%, and 6.09% over the baseline ResNet50, DenseNet121,
MobileNetV3, and EfficientNetB0 models, respectively. These results confirm
that XMANet consistently improves performance across various architectures and
signal processing techniques, demonstrating the strong potential of fine
grained features for accurate and robust EMG classification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed
  Real X-rays 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14699v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14699v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sascha Jecklin, Aidana Massalimova, Ruyi Zha, Lilian Calvet, Christoph J. Laux, Mazda Farshad, Philipp Fürnstahl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spine surgery is a high-risk intervention demanding precise execution, often
supported by image-based navigation systems. Recently, supervised learning
approaches have gained attention for reconstructing 3D spinal anatomy from
sparse fluoroscopic data, significantly reducing reliance on
radiation-intensive 3D imaging systems. However, these methods typically
require large amounts of annotated training data and may struggle to generalize
across varying patient anatomies or imaging conditions. Instance-learning
approaches like Gaussian splatting could offer an alternative by avoiding
extensive annotation requirements. While Gaussian splatting has shown promise
for novel view synthesis, its application to sparse, arbitrarily posed real
intraoperative X-rays has remained largely unexplored. This work addresses this
limitation by extending the $R^2$-Gaussian splatting framework to reconstruct
anatomically consistent 3D volumes under these challenging conditions. We
introduce an anatomy-guided radiographic standardization step using style
transfer, improving visual consistency across views, and enhancing
reconstruction quality. Notably, our framework requires no pretraining, making
it inherently adaptable to new patients and anatomies. We evaluated our
approach using an ex-vivo dataset. Expert surgical evaluation confirmed the
clinical utility of the 3D reconstructions for navigation, especially when
using 20 to 30 views, and highlighted the standardization's benefit for
anatomical clarity. Benchmarking via quantitative 2D metrics (PSNR/SSIM)
confirmed performance trade-offs compared to idealized settings, but also
validated the improvement gained from standardization over raw inputs. This
work demonstrates the feasibility of instance-based volumetric reconstruction
from arbitrary sparse-view X-rays, advancing intraoperative 3D imaging for
surgical navigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Video-MMLU: A Massive Multi-Discipline Lecture Understanding Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14693v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14693v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enxin Song, Wenhao Chai, Weili Xu, Jianwen Xie, Yuxuan Liu, Gaoang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in language multimodal models (LMMs) for video have
demonstrated their potential for understanding video content, yet the task of
comprehending multi-discipline lectures remains largely unexplored. We
introduce Video-MMLU, a massive benchmark designed to evaluate the capabilities
of LMMs in understanding Multi-Discipline Lectures. We evaluate over 90
open-source and proprietary models, ranging from 0.5B to 40B parameters. Our
results highlight the limitations of current models in addressing the cognitive
challenges presented by these lectures, especially in tasks requiring both
perception and reasoning. Additionally, we explore how the number of visual
tokens and the large language models influence performance, offering insights
into the interplay between multimodal perception and reasoning in lecture
comprehension.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code, docs, and benchmark are all avaliable at
  https://enxinsong.com/Video-MMLU-web/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seurat: From Moving Points to Depth <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seokju Cho, Jiahui Huang, Seungryong Kim, Joon-Young Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate depth estimation from monocular videos remains challenging due to
ambiguities inherent in single-view geometry, as crucial depth cues like
stereopsis are absent. However, humans often perceive relative depth
intuitively by observing variations in the size and spacing of objects as they
move. Inspired by this, we propose a novel method that infers relative depth by
examining the spatial relationships and temporal evolution of a set of tracked
2D trajectories. Specifically, we use off-the-shelf point tracking models to
capture 2D trajectories. Then, our approach employs spatial and temporal
transformers to process these trajectories and directly infer depth changes
over time. Evaluated on the TAPVid-3D benchmark, our method demonstrates robust
zero-shot performance, generalizing effectively from synthetic to real-world
datasets. Results indicate that our approach achieves temporally smooth,
high-accuracy depth predictions across diverse domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025 Highlight. Project page: https://seurat-cvpr.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Multimodal <span class="highlight-title">Pretrain</span>ing with Discrete Diffusion Timestep
  Tokens <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaihang Pan, Wang Lin, Zhongqi Yue, Tenglong Ao, Liyu Jia, Wei Zhao, Juncheng Li, Siliang Tang, Hanwang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent endeavors in Multimodal Large Language Models (MLLMs) aim to unify
visual comprehension and generation by combining LLM and diffusion models, the
state-of-the-art in each task, respectively. Existing approaches rely on
spatial visual tokens, where image patches are encoded and arranged according
to a spatial order (e.g., raster scan). However, we show that spatial tokens
lack the recursive structure inherent to languages, hence form an impossible
language for LLM to master. In this paper, we build a proper visual language by
leveraging diffusion timesteps to learn discrete, recursive visual tokens. Our
proposed tokens recursively compensate for the progressive attribute loss in
noisy images as timesteps increase, enabling the diffusion model to reconstruct
the original image at any timestep. This approach allows us to effectively
integrate the strengths of LLMs in autoregressive reasoning and diffusion
models in precise image generation, achieving seamless multimodal comprehension
and generation within a unified framework. Extensive experiments show that we
achieve superior performance for multimodal comprehension and generation
simultaneously compared with other MLLMs. Project Page:
https://DDT-LLaMA.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DMPCN: Dynamic Modulated Predictive Coding Network with Hybrid Feedback
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        A S M Sharifuzzaman Sagar, Yu Chen, Jun Hoong Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional predictive coding networks, inspired by theories of brain
function, consistently achieve promising results across various domains,
extending their influence into the field of computer vision. However, the
performance of the predictive coding networks is limited by their error
feedback mechanism, which traditionally employs either local or global
recurrent updates, leading to suboptimal performance in processing both local
and broader details simultaneously. In addition, traditional predictive coding
networks face difficulties in dynamically adjusting to the complexity and
context of varying input data, which is crucial for achieving high levels of
performance in diverse scenarios. Furthermore, there is a gap in the
development and application of specific loss functions that could more
effectively guide the model towards optimal performance. To deal with these
issues, this paper introduces a hybrid prediction error feedback mechanism with
dynamic modulation for deep predictive coding networks by effectively combining
global contexts and local details while adjusting feedback based on input
complexity. Additionally, we present a loss function tailored to this framework
to improve accuracy by focusing on precise prediction error minimization.
Experimental results demonstrate the superiority of our model over other
approaches, showcasing faster convergence and higher predictive accuracy in
CIFAR-10, CIFAR-100, MNIST, and FashionMNIST datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Frequency-domain Learning with Kernel Prior for Blind Image Deblurring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14664v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14664v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jixiang Sun, Fei Lei, Jiawei Zhang, Wenxiu Sun, Yujiu Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While achieving excellent results on various datasets, many deep learning
methods for image deblurring suffer from limited generalization capabilities
with out-of-domain data. This limitation is likely caused by their dependence
on certain domain-specific datasets. To address this challenge, we argue that
it is necessary to introduce the kernel prior into deep learning methods, as
the kernel prior remains independent of the image context. For effective fusion
of kernel prior information, we adopt a rational implementation method inspired
by traditional deblurring algorithms that perform deconvolution in the
frequency domain. We propose a module called Frequency Integration Module (FIM)
for fusing the kernel prior and combine it with a frequency-based deblurring
Transfomer network. Experimental results demonstrate that our method
outperforms state-of-the-art methods on multiple blind image deblurring tasks,
showcasing robust generalization abilities. Source code will be available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating Parameter Interference in Model Merging via Sharpness-Aware
  Fine-Tuning <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14662v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14662v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yeoreum Lee, Jinwook Jung, Sungyong Baik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large-scale deep learning models with a pretraining-finetuning paradigm have
led to a surge of numerous task-specific models fine-tuned from a common
pre-trained model. Recently, several research efforts have been made on merging
these large models into a single multi-task model, particularly with simple
arithmetic on parameters. Such merging methodology faces a central challenge:
interference between model parameters fine-tuned on different tasks. Few recent
works have focused on designing a new fine-tuning scheme that can lead to small
parameter interference, however at the cost of the performance of each
task-specific fine-tuned model and thereby limiting that of a merged model. To
improve the performance of a merged model, we note that a fine-tuning scheme
should aim for (1) smaller parameter interference and (2) better performance of
each fine-tuned model on the corresponding task. In this work, we aim to design
a new fine-tuning objective function to work towards these two goals. In the
course of this process, we find such objective function to be strikingly
similar to sharpness-aware minimization (SAM) objective function, which aims to
achieve generalization by finding flat minima. Drawing upon our observation, we
propose to fine-tune pre-trained models via sharpness-aware minimization. The
experimental and theoretical results showcase the effectiveness and
orthogonality of our proposed approach, improving performance upon various
merging and fine-tuning methods. Our code is available at
https://github.com/baiklab/SAFT-Merge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EmoSEM: Segment and Explain Emotion Stimuli in Visual Art 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14658v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14658v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Zhang, Dan Guo, Zhangbin Li, Meng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper focuses on a key challenge in visual art understanding: given an
art image, the model pinpoints pixel regions that trigger a specific human
emotion, and generates linguistic explanations for the emotional arousal.
Despite recent advances in art understanding, pixel-level emotion understanding
still faces a dual challenge: first, the subjectivity of emotion makes it
difficult for general segmentation models like SAM to adapt to emotion-oriented
segmentation tasks; and second, the abstract nature of art expression makes it
difficult for captioning models to balance pixel-level semantic understanding
and emotion reasoning. To solve the above problems, this paper proposes the
Emotion stimuli Segmentation and Explanation Model (EmoSEM) to endow the
segmentation model SAM with emotion comprehension capability. First, to enable
the model to perform segmentation under the guidance of emotional intent well,
we introduce an emotional prompt with a learnable mask token as the conditional
input for segmentation decoding. Then, we design an emotion projector to
establish the association between emotion and visual features. Next, more
importantly, to address emotion-visual stimuli alignment, we develop a
lightweight prefix projector, a module that fuses the learned emotional mask
with the corresponding emotion into a unified representation compatible with
the language model.Finally, we input the joint visual, mask, and emotional
tokens into the language model and output the emotional explanations. It
ensures that the generated interpretations remain semantically and emotionally
coherent with the visual stimuli. The method innovatively realizes end-to-end
modeling from low-level pixel features to high-level emotion interpretation,
providing the first interpretable fine-grained analysis framework for artistic
emotion computing. Extensive experiments validate the effectiveness of our
model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Comparative clinical evaluation of "memory-efficient" synthetic 3d
  generative adversarial networks (gan) head-to-head to state of art: results
  on computed tomography of the chest 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15572v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15572v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahshid Shiri, Chandra Bortolotto, Alessandro Bruno, Alessio Consonni, Daniela Maria Grasso, Leonardo Brizzi, Daniele Loiacono, Lorenzo Preda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative Adversarial Networks (GANs) are increasingly used to generate
synthetic medical images, addressing the critical shortage of annotated data
for training Artificial Intelligence systems. This study introduces CRF-GAN, a
novel memory-efficient GAN architecture that enhances structural consistency in
3D medical image synthesis. Integrating Conditional Random Fields within a
two-step generation process allows CRF-GAN improving spatial coherence while
maintaining high-resolution image quality. The model's performance is evaluated
against the state-of-the-art hierarchical (HA)-GAN model. Materials and
Methods: We evaluate the performance of CRF-GAN against the HA-GAN model. The
comparison between the two models was made through a quantitative evaluation,
using FID and MMD metrics, and a qualitative evaluation, through a
two-alternative forced choice (2AFC) test completed by a pool of 12 resident
radiologists, to assess the realism of the generated images. Results: CRF-GAN
outperformed HA-GAN with lower FID and MMD scores, indicating better image
fidelity. The 2AFC test showed a significant preference for images generated by
CRF-Gan over those generated by HA-GAN. Additionally, CRF-GAN demonstrated
9.34% lower memory usage and achieved up to 14.6% faster training speeds,
offering substantial computational savings. Discussion: CRF-GAN model
successfully generates high-resolution 3D medical images with non-inferior
quality to conventional models, while being more memory-efficient and faster.
The key objective was not only to lower the computational cost but also to
reallocate the freed-up resources towards the creation of higher-resolution 3D
imaging, which is still a critical factor limiting their direct clinical
applicability. Moreover, unlike many previous studies, we combined qualitative
and quantitative assessments to obtain a more holistic feedback on the model's
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accpeted to Journal of Imaging Informatics in Medicine</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MedUnifier: Unifying Vision-and-Language <span class="highlight-title">Pre-train</span>ing on Medical Data
  with Vision Generation Task using Discrete Visual Representations <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01019v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01019v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyang Zhang, Yang Yu, Yucheng Chen, Xulei Yang, Si Yong Yeo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant progress in Vision-Language Pre-training (VLP), current
approaches predominantly emphasize feature extraction and cross-modal
comprehension, with limited attention to generating or transforming visual
content. This gap hinders the model's ability to synthesize coherent and novel
visual representations from textual prompts, thereby reducing the effectiveness
of multi-modal learning. In this work, we propose MedUnifier, a unified VLP
framework tailored for medical data. MedUnifier seamlessly integrates
text-grounded image generation capabilities with multi-modal learning
strategies, including image-text contrastive alignment, image-text matching and
image-grounded text generation. Unlike traditional methods that reply on
continuous visual representations, our approach employs visual vector
quantization, which not only facilitates a more cohesive learning strategy for
cross-modal understanding but also enhances multi-modal generation quality by
effectively leveraging discrete representations. Our framework's effectiveness
is evidenced by the experiments on established benchmarks, including uni-modal
tasks (supervised fine-tuning), cross-modal tasks (image-text retrieval and
zero-shot image classification), and multi-modal tasks (medical report
generation, image synthesis), where it achieves state-of-the-art performance
across various tasks. MedUnifier also offers a highly adaptable tool for a wide
range of language and vision tasks in healthcare, marking advancement toward
the development of a generalizable AI model for medical applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be pubilshed in CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.14462v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.14462v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jixuan He, Wanhua Li, Ye Liu, Junsik Kim, Donglai Wei, Hanspeter Pfister
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a common image editing operation, image composition involves integrating
foreground objects into background scenes. In this paper, we expand the
application of the concept of Affordance from human-centered image composition
tasks to a more general object-scene composition framework, addressing the
complex interplay between foreground objects and background scenes. Following
the principle of Affordance, we define the affordance-aware object insertion
task, which aims to seamlessly insert any object into any scene with various
position prompts. To address the limited data issue and incorporate this task,
we constructed the SAM-FB dataset, which contains over 3 million examples
across more than 3,000 object categories. Furthermore, we propose the
Mask-Aware Dual Diffusion (MADD) model, which utilizes a dual-stream
architecture to simultaneously denoise the RGB image and the insertion mask. By
explicitly modeling the insertion mask in the diffusion process, MADD
effectively facilitates the notion of affordance. Extensive experimental
results show that our method outperforms the state-of-the-art methods and
exhibits strong generalization performance on in-the-wild images. Please refer
to our code on https://github.com/KaKituken/affordance-aware-any.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available at:
  https://github.com/KaKituken/affordance-aware-any. Project page at:
  https://kakituken.github.io/affordance-any.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Language Anchor-Guided Method for Robust Noisy Domain Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.17211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.17211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zilin Dai, Lehong Wang, Fangzhou Lin, Yidong Wang, Zhigang Li, Kazunori D Yamada, Ziming Zhang, Wang Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-world machine learning applications often struggle with two major
challenges: distribution shift and label noise. Models tend to overfit by
focusing on redundant and uninformative features in the training data, which
makes it hard for them to generalize to the target domain. Noisy data worsens
this problem by causing further overfitting to the noise, meaning that existing
methods often fail to tell the difference between true, invariant features and
misleading, spurious ones. To tackle these issues, we introduce Anchor
Alignment and Adaptive Weighting (A3W). This new algorithm uses sample
reweighting guided by natural language processing (NLP) anchors to extract more
representative features. In simple terms, A3W leverages semantic
representations from natural language models as a source of domain-invariant
prior knowledge. Additionally, it employs a weighted loss function that adjusts
each sample's contribution based on its similarity to the corresponding NLP
anchor. This adjustment makes the model more robust to noisy labels. Extensive
experiments on standard benchmark datasets show that A3W consistently
outperforms state-of-the-art domain generalization methods, offering
significant improvements in both accuracy and robustness across different
datasets and noise levels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual
  Descriptions Using Gaussian Splatting, Chat<span class="highlight-title">GPT</span>/Deepseek, and Google Maps
  Platform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05769v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05769v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Urban digital twins are virtual replicas of cities that use multi-source data
and data analytics to optimize urban planning, infrastructure management, and
decision-making. Towards this, we propose a framework focused on the
single-building scale. By connecting to cloud mapping platforms such as Google
Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language
Models data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using our
Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings
framework can retrieve a building's 3D model, visual descriptions, and achieve
cloud-based mapping integration with large language model-based data analytics
using a building's address, postal code, or geographic coordinates.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>-Fixed minor typo</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MANGO: Learning Disentangled Image Transformation Manifolds with Grouped
  Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09542v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09542v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brighton Ancelin, Yenho Chen, Peimeng Guan, Chiraag Kaushik, Belen Martin-Urcelay, Alex Saad-Falcon, Nakul Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning semantically meaningful image transformations (i.e. rotation,
thickness, blur) directly from examples can be a challenging task. Recently,
the Manifold Autoencoder (MAE) proposed using a set of Lie group operators to
learn image transformations directly from examples. However, this approach has
limitations, as the learned operators are not guaranteed to be disentangled and
the training routine is prohibitively expensive when scaling up the model. To
address these limitations, we propose MANGO (transformation Manifolds with
Grouped Operators) for learning disentangled operators that describe image
transformations in distinct latent subspaces. Moreover, our approach allows
practitioners the ability to define which transformations they aim to model,
thus improving the semantic meaning of the learned operators. Through our
experiments, we demonstrate that MANGO enables composition of image
transformations and introduces a one-phase training routine that leads to a
100x speedup over prior works.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to SampTA 2025. This work has been submitted to the IEEE
  for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Self-Attention for Crop-type Classification Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.13167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.13167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivica Obadic, Ribana Roscher, Dario Augusto Borges Oliveira, Xiao Xiang Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer models have become a promising approach for crop-type
classification. Although their attention weights can be used to understand the
relevant time points for crop disambiguation, the validity of these insights
depends on how closely the attention weights approximate the actual workings of
these black-box models, which is not always clear. In this paper, we introduce
a novel explainability framework that systematically evaluates the explanatory
power of the attention weights of a standard transformer encoder for crop-type
classification. Our results show that attention patterns strongly relate to key
dates, which are often associated with critical phenological events for
crop-type classification. Further, the sensitivity analysis reveals the limited
capability of the attention weights to characterize crop phenology as the
identified phenological events depend on the other crops considered during
training. This limitation highlights the relevance of future work towards the
development of deep learning approaches capable of automatically learning the
temporal vegetation dynamics for accurate crop disambiguation
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HyperFusion: A Hypernetwork Approach to Multimodal Integration of
  Tabular and Medical Imaging Data for Predictive Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13319v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13319v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Duenias, Brennan Nichyporuk, Tal Arbel, Tammy Riklin Raviv
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of diverse clinical modalities such as medical imaging and
the tabular data extracted from patients' Electronic Health Records (EHRs) is a
crucial aspect of modern healthcare. Integrative analysis of multiple sources
can provide a comprehensive understanding of the clinical condition of a
patient, improving diagnosis and treatment decision. Deep Neural Networks
(DNNs) consistently demonstrate outstanding performance in a wide range of
multimodal tasks in the medical domain. However, the complex endeavor of
effectively merging medical imaging with clinical, demographic and genetic
information represented as numerical tabular data remains a highly active and
ongoing research pursuit.
  We present a novel framework based on hypernetworks to fuse clinical imaging
and tabular data by conditioning the image processing on the EHR's values and
measurements. This approach aims to leverage the complementary information
present in these modalities to enhance the accuracy of various medical
applications. We demonstrate the strength and generality of our method on two
different brain Magnetic Resonance Imaging (MRI) analysis tasks, namely, brain
age prediction conditioned by subject's sex and multi-class Alzheimer's Disease
(AD) classification conditioned by tabular data. We show that our framework
outperforms both single-modality models and state-of-the-art MRI tabular data
fusion methods. A link to our code can be found at
https://github.com/daniel4725/HyperFusion
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MedM-VL: What Makes a Good Medical LVLM? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04323v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04323v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Shi, Shaoshuai Yang, Xun Zhu, Haoyu Wang, Miao Li, Ji Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image analysis is essential in modern healthcare. Deep learning has
redirected research focus toward complex medical multimodal tasks, including
report generation and visual question answering. Traditional task-specific
models often fall short in handling these challenges. Large vision-language
models (LVLMs) offer new solutions for solving such tasks. In this study, we
build on the popular LLaVA framework to systematically explore model
architectures and training strategies for both 2D and 3D medical LVLMs. We
present extensive empirical findings and practical guidance. To support
reproducibility and future research, we release a modular codebase, MedM-VL,
and two pre-trained models: MedM-VL-2D for 2D medical image analysis and
MedM-VL-CT-Chest for 3D CT-based applications. The code and models are
available at: https://github.com/MSIIP/MedM-VL
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sparse-DeRF: Deblurred Neural Radiance Fields from Sparse View 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06613v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06613v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dogyoon Lee, Donghyeong Kim, Jungho Lee, Minhyeok Lee, Seunghoon Lee, Sangyoun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies construct deblurred neural radiance fields~(DeRF) using dozens
of blurry images, which are not practical scenarios if only a limited number of
blurry images are available. This paper focuses on constructing DeRF from
sparse-view for more pragmatic real-world scenarios. As observed in our
experiments, establishing DeRF from sparse views proves to be a more
challenging problem due to the inherent complexity arising from the
simultaneous optimization of blur kernels and NeRF from sparse view.
Sparse-DeRF successfully regularizes the complicated joint optimization,
presenting alleviated overfitting artifacts and enhanced quality on radiance
fields. The regularization consists of three key components: Surface
smoothness, helps the model accurately predict the scene structure utilizing
unseen and additional hidden rays derived from the blur kernel based on
statistical tendencies of real-world; Modulated gradient scaling, helps the
model adjust the amount of the backpropagated gradient according to the
arrangements of scene objects; Perceptual distillation improves the perceptual
quality by overcoming the ill-posed multi-view inconsistency of image
deblurring and distilling the pre-deblurred information, compensating for the
lack of clean information in blurry images. We demonstrate the effectiveness of
the Sparse-DeRF with extensive quantitative and qualitative experimental
results by training DeRF from 2-view, 4-view, and 6-view blurry images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted and to appear in IEEE Transactions on Pattern Analysis and
  Machine Intelligence (TPAMI). Project page:
  https://dogyoonlee.github.io/sparsederf/</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Auto-Bidding with Value-Guided Explorations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14587v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14587v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingtong Gao, Yewen Li, Shuai Mao, Peng Jiang, Nan Jiang, Yejing Wang, Qingpeng Cai, Fei Pan, Peng Jiang, Kun Gai, Bo An, Xiangyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Auto-bidding, with its strong capability to optimize bidding decisions within
dynamic and competitive online environments, has become a pivotal strategy for
advertising platforms. Existing approaches typically employ rule-based
strategies or Reinforcement Learning (RL) techniques. However, rule-based
strategies lack the flexibility to adapt to time-varying market conditions, and
RL-based methods struggle to capture essential historical dependencies and
observations within Markov Decision Process (MDP) frameworks. Furthermore,
these approaches often face challenges in ensuring strategy adaptability across
diverse advertising objectives. Additionally, as offline training methods are
increasingly adopted to facilitate the deployment and maintenance of stable
online strategies, the issues of documented behavioral patterns and behavioral
collapse resulting from training on fixed offline datasets become increasingly
significant. To address these limitations, this paper introduces a novel
offline Generative Auto-bidding framework with Value-Guided Explorations
(GAVE). GAVE accommodates various advertising objectives through a score-based
Return-To-Go (RTG) module. Moreover, GAVE integrates an action exploration
mechanism with an RTG-based evaluation method to explore novel actions while
ensuring stability-preserving updates. A learnable value function is also
designed to guide the direction of action exploration and mitigate
Out-of-Distribution (OOD) problems. Experimental results on two offline
datasets and real-world deployments demonstrate that GAVE outperforms
state-of-the-art baselines in both offline evaluations and online A/B tests.
The implementation code is publicly available to facilitate reproducibility and
further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Matrix Factorization with Dynamic Multi-view Clustering for Recommender
  System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14565v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14565v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shangde Gao, Ke Liu, Yichao Fu, Hongxia Xu, Jian Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Matrix factorization (MF), a cornerstone of recommender systems, decomposes
user-item interaction matrices into latent representations. Traditional MF
approaches, however, employ a two-stage, non-end-to-end paradigm, sequentially
performing recommendation and clustering, resulting in prohibitive
computational costs for large-scale applications like e-commerce and IoT, where
billions of users interact with trillions of items. To address this, we propose
Matrix Factorization with Dynamic Multi-view Clustering (MFDMC), a unified
framework that balances efficient end-to-end training with comprehensive
utilization of web-scale data and enhances interpretability. MFDMC leverages
dynamic multi-view clustering to learn user and item representations,
adaptively pruning poorly formed clusters. Each entity's representation is
modeled as a weighted projection of robust clusters, capturing its diverse
roles across views. This design maximizes representation space utilization,
improves interpretability, and ensures resilience for downstream tasks.
Extensive experiments demonstrate MFDMC's superior performance in recommender
systems and other representation learning domains, such as computer vision,
highlighting its scalability and versatility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Regret-aware Re-ranking for Guaranteeing Two-sided Fairness and Accuracy
  in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14550v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14550v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopeng Ye, Chen Xu, Jun Xu, Xuyang Xie, Gang Wang, Zhenhua Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multi-stakeholder recommender systems (RS), users and providers operate as
two crucial and interdependent roles, whose interests must be well-balanced.
Prior research, including our work BankFair, has demonstrated the importance of
guaranteeing both provider fairness and user accuracy to meet their interests.
However, when they balance the two objectives, another critical factor emerges
in RS: individual fairness, which manifests as a significant disparity in
individual recommendation accuracy, with some users receiving high accuracy
while others are left with notably low accuracy. This oversight severely harms
the interests of users and exacerbates social polarization. How to guarantee
individual fairness while ensuring user accuracy and provider fairness remains
an unsolved problem. To bridge this gap, in this paper, we propose our method
BankFair+. Specifically, BankFair+ extends BankFair with two steps: (1)
introducing a non-linear function from regret theory to ensure individual
fairness while enhancing user accuracy; (2) formulating the re-ranking process
as a regret-aware fuzzy programming problem to meet the interests of both
individual user and provider, therefore balancing the trade-off between
individual fairness and provider fairness. Experiments on two real-world
recommendation datasets demonstrate that BankFair+ outperforms all baselines
regarding individual fairness, user accuracy, and provider fairness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FinSage: A Multi-aspect RAG System for Financial Filings Question
  Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14493v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14493v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Ling Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging large language models in real-world settings often entails a need
to utilize domain-specific data and tools in order to follow the complex
regulations that need to be followed for acceptable use. Within financial
sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation
(RAG) systems to address complex compliance requirements in financial document
workflows. However, existing solutions struggle to account for the inherent
heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of
regulatory standards used in financial filings, leading to compromised accuracy
in critical information extraction. We propose the FinSage framework as a
solution, utilizing a multi-aspect RAG framework tailored for regulatory
compliance analysis in multi-modal financial documents. FinSage introduces
three innovative components: (1) a multi-modal pre-processing pipeline that
unifies diverse data formats and generates chunk-level metadata summaries, (2)
a multi-path sparse-dense retrieval system augmented with query expansion
(HyDE) and metadata-aware semantic search, and (3) a domain-specialized
re-ranking module fine-tuned via Direct Preference Optimization (DPO) to
prioritize compliance-critical content. Extensive experiments demonstrate that
FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions
derived from surpasses the best baseline method on the FinanceBench question
answering datasets by 24.06% in accuracy. Moreover, FinSage has been
successfully deployed as financial question-answering agent in online meetings,
where it has already served more than 1,200 people.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wrong Answers Can Also Be Useful: PlausibleQA -- A Large-Scale QA
  <span class="highlight-title">Dataset</span> with Answer Plausibility Scores <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16358v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16358v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jamshid Mozafari, Abdelrahman Abdallah, Bhawna Piryani, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are revolutionizing information retrieval, with
chatbots becoming an important source for answering user queries. As by their
design, LLMs prioritize generating correct answers, the value of highly
plausible yet incorrect answers (candidate answers) tends to be overlooked.
However, such answers can still prove useful, for example, they can play a
crucial role in tasks like Multiple-Choice Question Answering (MCQA) and QA
Robustness Assessment (QARA). Existing QA datasets primarily focus on correct
answers without explicit consideration of the plausibility of other candidate
answers, limiting opportunity for more nuanced evaluations of models. To
address this gap, we introduce PlausibleQA, a large-scale dataset comprising
10,000 questions and 100,000 candidate answers, each annotated with
plausibility scores and justifications for their selection. Additionally, the
dataset includes 900,000 justifications for pairwise comparisons between
candidate answers, further refining plausibility assessments. We evaluate
PlausibleQA through human assessments and empirical experiments, demonstrating
its utility in MCQA and QARA analysis. Our findings show that
plausibility-aware approaches are effective for MCQA distractor generation and
QARA. We release PlausibleQA as a resource for advancing QA research and
enhancing LLM performance in distinguishing plausible distractors from correct
answers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WikiHint: A Human-Annotated <span class="highlight-title">Dataset</span> for Hint Ranking and Generation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.01626v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.01626v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jamshid Mozafari, Florian Gerhold, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The use of Large Language Models (LLMs) has increased significantly with
users frequently asking questions to chatbots. In the time when information is
readily accessible, it is crucial to stimulate and preserve human cognitive
abilities and maintain strong reasoning skills. This paper addresses such
challenges by promoting the use of hints as an alternative or a supplement to
direct answers. We first introduce a manually constructed hint dataset,
WikiHint, which is based on Wikipedia and includes 5,000 hints created for
1,000 questions. We then finetune open-source LLMs for hint generation in
answer-aware and answer-agnostic contexts. We assess the effectiveness of the
hints with human participants who answer questions with and without the aid of
hints. Additionally, we introduce a lightweight evaluation method, HintRank, to
evaluate and rank hints in both answer-aware and answer-agnostic settings. Our
findings show that (a) the dataset helps generate more effective hints, (b)
including answer information along with questions generally improves the
quality of generated hints, and (c) encoder-based models perform better than
decoder-based models in hint ranking.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SLMRec: Distilling Large Language Models into Small for Sequential
  Recommendation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17890v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17890v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wujiang Xu, Qitian Wu, Zujie Liang, Jiaojiao Han, Xuying Ning, Yunxiao Shi, Wenfang Lin, Yongfeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential Recommendation (SR) task involves predicting the next item a user
is likely to interact with, given their past interactions. The SR models
examine the sequence of a user's actions to discern more complex behavioral
patterns and temporal dynamics. Recent research demonstrates the great impact
of LLMs on sequential recommendation systems, either viewing sequential
recommendation as language modeling or serving as the backbone for user
representation. Although these methods deliver outstanding performance, there
is scant evidence of the necessity of a large language model and how large the
language model is needed, especially in the sequential recommendation scene.
Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to
apply a LLM-based model in real-world platforms that often need to process
billions of traffic logs daily. In this paper, we explore the influence of
LLMs' depth by conducting extensive experiments on large-scale industry
datasets. Surprisingly, our motivational experiments reveal that most
intermediate layers of LLMs are redundant, indicating that pruning the
remaining layers can still maintain strong performance. Motivated by this
insight, we empower small language models for SR, namely SLMRec, which adopt a
simple yet effective knowledge distillation method. Moreover, SLMRec is
orthogonal to other post-training efficiency techniques, such as quantization
and pruning, so that they can be leveraged in combination. Comprehensive
experimental results illustrate that the proposed SLMRec model attains the best
performance using only 13% of the parameters found in LLM-based recommendation
models while simultaneously achieving up to 6.6x and 8.0x speedups in training
and inference time costs, respectively. Besides, we provide a theoretical
justification for why small language models can perform comparably to large
language models in SR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>International Conference on Learning Representations (ICLR 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Preference Diffusion for Recommendation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13117v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13117v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Liu, An Zhang, Guoqing Hu, Hong Qian, Tat-seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems predict personalized item rankings based on user
preference distributions derived from historical behavior data. Recently,
diffusion models (DMs) have gained attention in recommendation for their
ability to model complex distributions, yet current DM-based recommenders often
rely on traditional objectives like mean squared error (MSE) or recommendation
objectives, which are not optimized for personalized ranking tasks or fail to
fully leverage DM's generative potential. To address this, we propose
PreferDiff, a tailored optimization objective for DM-based recommenders.
PreferDiff transforms BPR into a log-likelihood ranking objective and
integrates multiple negative samples to better capture user preferences.
Specifically, we employ variational inference to handle the intractability
through minimizing the variational upper bound and replaces MSE with cosine
error to improve alignment with recommendation tasks. Finally, we balance
learning generation and preference to enhance the training stability of DMs.
PreferDiff offers three key benefits: it is the first personalized ranking loss
designed specifically for DM-based recommenders and it improves ranking and
faster convergence by addressing hard negatives. We also prove that it is
theoretically connected to Direct Preference Optimization which indicates that
it has the potential to align user preferences in DM-based recommenders via
generative modeling. Extensive experiments across three benchmarks validate its
superior recommendation performance and commendable general sequential
recommendation capabilities. Our codes are available at
https://github.com/lswhim/PreferDiff.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">27</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Distillation and <span class="highlight-title">Dataset</span> Distillation of Large Language
  Models: Emerging Trends, Challenges, and Future Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyang Fang, Xiaowei Yu, Jiazhang Cai, Yongkai Chen, Shushan Wu, Zhengliang Liu, Zhenyuan Yang, Haoran Lu, Xilin Gong, Yufang Liu, Terry Ma, Wei Ruan, Ali Abbasi, Jing Zhang, Tao Wang, Ehsan Latif, Wei Liu, Wei Zhang, Soheil Kolouri, Xiaoming Zhai, Dajiang Zhu, Wenxuan Zhong, Tianming Liu, Ping Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exponential growth of Large Language Models (LLMs) continues to highlight
the need for efficient strategies to meet ever-expanding computational and data
demands. This survey provides a comprehensive analysis of two complementary
paradigms: Knowledge Distillation (KD) and Dataset Distillation (DD), both
aimed at compressing LLMs while preserving their advanced reasoning
capabilities and linguistic diversity. We first examine key methodologies in
KD, such as task-specific alignment, rationale-based training, and
multi-teacher frameworks, alongside DD techniques that synthesize compact,
high-impact datasets through optimization-based gradient matching, latent space
regularization, and generative synthesis. Building on these foundations, we
explore how integrating KD and DD can produce more effective and scalable
compression strategies. Together, these approaches address persistent
challenges in model scalability, architectural heterogeneity, and the
preservation of emergent LLM abilities. We further highlight applications
across domains such as healthcare and education, where distillation enables
efficient deployment without sacrificing performance. Despite substantial
progress, open challenges remain in preserving emergent reasoning and
linguistic diversity, enabling efficient adaptation to continually evolving
teacher models and datasets, and establishing comprehensive evaluation
protocols. By synthesizing methodological innovations, theoretical foundations,
and practical insights, our survey charts a path toward sustainable,
resource-efficient LLMs through the tighter integration of KD and DD
principles.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Combinatorial Theory of Dropout: Subnetworks, Graph Geometry, and
  Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14762v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14762v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sahil Rajesh Dhayalkar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a combinatorial and graph-theoretic theory of dropout by modeling
training as a random walk over a high-dimensional graph of binary subnetworks.
Each node represents a masked version of the network, and dropout induces
stochastic traversal across this space. We define a subnetwork contribution
score that quantifies generalization and show that it varies smoothly over the
graph. Using tools from spectral graph theory, PAC-Bayes analysis, and
combinatorics, we prove that generalizing subnetworks form large, connected,
low-resistance clusters, and that their number grows exponentially with network
width. This reveals dropout as a mechanism for sampling from a robust,
structured ensemble of well-generalizing subnetworks with built-in redundancy.
Extensive experiments validate every theoretical claim across diverse
architectures. Together, our results offer a unified foundation for
understanding dropout and suggest new directions for mask-guided regularization
and subnetwork optimization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages (9 pages main content and remaining pages are references,
  appendix which includes 7 figures, proofs and derivations)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AI for the Open-World: the Learning Principles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14751v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14751v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  During the past decades, numerous successes of AI has been made on "specific
capabilities", named closed-world, such as artificial environments or specific
real-world tasks. This well-defined narrow capability brings two nice benefits,
a clear criterion of success and the opportunity to collect a lot of examples.
The criteria not only reveal whether a machine has achieved a goal, but reveal
how the machine falls short of the goal. As a result, human designers can fix
the problems one after the other until the machine is deemed good enough for
the task. Furthermore, the large set of collected examples reduces the
difficulty of this problem-fixing process (by the central limit theorem).
  Do the success in closed-world translate into broad open-world, where a
machine is required to perform any task that a human could possibly undertake
with fewer examples and less priori knowledge from human designers? No. Because
competence in a specific task provides little insight in handling other tasks,
the valuable criteria for specific tasks become helpless when handling broader
unseen tasks. Furthermore, due to the shortage of examples in unseen tasks,
central limit theorem does not stand on our side. At the end, human designers
lose the oscilloscope to "hack" an AI system for the open-world.
  Achieving AI for the open-world requires unique learning principles and
innovated techniques, which are different from the ones in building AI for the
closed-world. This thesis explores necessary learning principles required to
construct AI for the open-world, including rich features (analogy a large tool
box), disentangled representation (an organized tool box), and inference-time
learning (a tool-savvy hand). Driven by the learning principles, this thesis
further proposes techniques to use the learning principles, conducts enormous
large-scale experiments to verify the learning principles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PhD thesis. This is not a compilation of published papers, but a new
  one</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Tunability of Random Survival Forests Model for Predictive
  Maintenance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14744v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14744v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yigitcan Yardımcı, Mustafa Cavus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the tunability of the Random Survival Forest (RSF)
model in predictive maintenance, where accurate time-to-failure estimation is
crucial. Although RSF is widely used due to its flexibility and ability to
handle censored data, its performance is sensitive to hyperparameter
configurations. However, systematic evaluations of RSF tunability remain
limited, especially in predictive maintenance contexts. We introduce a
three-level framework to quantify tunability: (1) a model-level metric
measuring overall performance gain from tuning, (2) a hyperparameter-level
metric assessing individual contributions, and (3) identification of optimal
tuning ranges. These metrics are evaluated across multiple datasets using
survival-specific criteria: the C-index for discrimination and the Brier score
for calibration. Experiments on four CMAPSS dataset subsets, simulating
aircraft engine degradation, reveal that hyperparameter tuning consistently
improves model performance. On average, the C-index increased by 0.0547, while
the Brier score decreased by 0.0199. These gains were consistent across all
subsets. Moreover, ntree and mtry showed the highest average tunability, while
nodesize offered stable improvements within the range of 10 to 30. In contrast,
splitrule demonstrated negative tunability on average, indicating that improper
tuning may reduce model performance. Our findings emphasize the practical
importance of hyperparameter tuning in survival models and provide actionable
insights for optimizing RSF in real-world predictive maintenance applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AltGDmin: Alternating GD and Minimization for Partly-Decoupled
  (Federated) Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14741v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14741v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Namrata Vaswani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article describes a novel optimization solution framework, called
alternating gradient descent (GD) and minimization (AltGDmin), that is useful
for many problems for which alternating minimization (AltMin) is a popular
solution. AltMin is a special case of the block coordinate descent algorithm
that is useful for problems in which minimization w.r.t one subset of variables
keeping the other fixed is closed form or otherwise reliably solved. Denote the
two blocks/subsets of the optimization variables Z by Za, Zb, i.e., Z = {Za,
Zb}. AltGDmin is often a faster solution than AltMin for any problem for which
(i) the minimization over one set of variables, Zb, is much quicker than that
over the other set, Za; and (ii) the cost function is differentiable w.r.t. Za.
Often, the reason for one minimization to be quicker is that the problem is
``decoupled" for Zb and each of the decoupled problems is quick to solve. This
decoupling is also what makes AltGDmin communication-efficient for federated
settings.
  Important examples where this assumption holds include (a) low rank
column-wise compressive sensing (LRCS), low rank matrix completion (LRMC), (b)
their outlier-corrupted extensions such as robust PCA, robust LRCS and robust
LRMC; (c) phase retrieval and its sparse and low-rank model based extensions;
(d) tensor extensions of many of these problems such as tensor LRCS and tensor
completion; and (e) many partly discrete problems where GD does not apply --
such as clustering, unlabeled sensing, and mixed linear regression. LRCS finds
important applications in multi-task representation learning and few shot
learning, federated sketching, and accelerated dynamic MRI. LRMC and robust PCA
find important applications in recommender systems, computer vision and video
analytics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in Foundations and Trends in Optimization (NOW publishers)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reinforcement Learning from Multi-level and Episodic Human Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14732v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14732v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Qasim Elahi, Somtochukwu Oguchienti, Maheed H. Ahmed, Mahsa Ghasemi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing an effective reward function has long been a challenge in
reinforcement learning, particularly for complex tasks in unstructured
environments. To address this, various learning paradigms have emerged that
leverage different forms of human input to specify or refine the reward
function. Reinforcement learning from human feedback is a prominent approach
that utilizes human comparative feedback, expressed as a preference for one
behavior over another, to tackle this problem. In contrast to comparative
feedback, we explore multi-level human feedback, which is provided in the form
of a score at the end of each episode. This type of feedback offers more coarse
but informative signals about the underlying reward function than binary
feedback. Additionally, it can handle non-Markovian rewards, as it is based on
the evaluation of an entire episode. We propose an algorithm to efficiently
learn both the reward function and the optimal policy from this form of
feedback. Moreover, we show that the proposed algorithm achieves sublinear
regret and demonstrate its empirical effectiveness through extensive
simulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometric Learning Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14728v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14728v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vitaly Vanchurin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a unified geometric framework for modeling learning dynamics in
physical, biological, and machine learning systems. The theory reveals three
fundamental regimes, each emerging from the power-law relationship $g \propto
\kappa^a$ between the metric tensor $g$ in the space of trainable variables and
the noise covariance matrix $\kappa$. The quantum regime corresponds to $a = 1$
and describes Schr\"odinger-like dynamics that emerges from a discrete shift
symmetry. The efficient learning regime corresponds to $a = \tfrac{1}{2}$ and
describes very fast machine learning algorithms. The equilibration regime
corresponds to $a = 0$ and describes classical models of biological evolution.
We argue that the emergence of the intermediate regime $a = \tfrac{1}{2}$ is a
key mechanism underlying the emergence of biological complexity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semi-parametric Memory Consolidation: Towards Brain-like Deep Continual
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Geng Liu, Fei Zhu, Rong Feng, Zhiqiang Yi, Shiqi Wang, Gaofeng Meng, Zhaoxiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans and most animals inherently possess a distinctive capacity to
continually acquire novel experiences and accumulate worldly knowledge over
time. This ability, termed continual learning, is also critical for deep neural
networks (DNNs) to adapt to the dynamically evolving world in open
environments. However, DNNs notoriously suffer from catastrophic forgetting of
previously learned knowledge when trained on sequential tasks. In this work,
inspired by the interactive human memory and learning system, we propose a
novel biomimetic continual learning framework that integrates semi-parametric
memory and the wake-sleep consolidation mechanism. For the first time, our
method enables deep neural networks to retain high performance on novel tasks
while maintaining prior knowledge in real-world challenging continual learning
scenarios, e.g., class-incremental learning on ImageNet. This study
demonstrates that emulating biological intelligence provides a promising path
to enable deep neural networks with continual learning capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Video QoE Metrics from Encrypted Traffic: Application-agnostic
  Methodology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14720v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14720v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tamir Berger, Jonathan Sterenson, Raz Birman, Ofer Hadar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instant Messaging-Based Video Call Applications (IMVCAs) and Video
Conferencing Applications (VCAs) have become integral to modern communication.
Ensuring a high Quality of Experience (QoE) for users in this context is
critical for network operators, as network conditions significantly impact user
QoE. However, network operators lack access to end-device QoE metrics due to
encrypted traffic. Existing solutions estimate QoE metrics from encrypted
traffic traversing the network, with the most advanced approaches leveraging
machine learning models. Subsequently, the need for ground truth QoE metrics
for training and validation poses a challenge, as not all video applications
provide these metrics. To address this challenge, we propose an
application-agnostic approach for objective QoE estimation from encrypted
traffic. Independent of the video application, we obtained key video QoE
metrics, enabling broad applicability to various proprietary IMVCAs and VCAs.
To validate our solution, we created a diverse dataset from WhatsApp video
sessions under various network conditions, comprising 25,680 seconds of traffic
data and QoE metrics. Our evaluation shows high performance across the entire
dataset, with 85.2% accuracy for FPS predictions within an error margin of two
FPS, and 90.2% accuracy for PIQE-based quality rating classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TAPIP3D: Tracking Any Point in Persistent 3D Geometry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14717v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14717v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowei Zhang, Lei Ke, Adam W. Harley, Katerina Fragkiadaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce TAPIP3D, a novel approach for long-term 3D point tracking in
monocular RGB and RGB-D videos. TAPIP3D represents videos as camera-stabilized
spatio-temporal feature clouds, leveraging depth and camera motion information
to lift 2D video features into a 3D world space where camera motion is
effectively canceled. TAPIP3D iteratively refines multi-frame 3D motion
estimates within this stabilized representation, enabling robust tracking over
extended periods. To manage the inherent irregularities of 3D point
distributions, we propose a Local Pair Attention mechanism. This 3D
contextualization strategy effectively exploits spatial relationships in 3D,
forming informative feature neighborhoods for precise 3D trajectory estimation.
Our 3D-centric approach significantly outperforms existing 3D point tracking
methods and even enhances 2D tracking accuracy compared to conventional 2D
pixel trackers when accurate depth is available. It supports inference in both
camera coordinates (i.e., unstabilized) and world coordinates, and our results
demonstrate that compensating for camera motion improves tracking performance.
Our approach replaces the conventional 2D square correlation neighborhoods used
in prior 2D and 3D trackers, leading to more robust and accurate results across
various 3D point tracking benchmarks. Project Page: https://tapip3d.github.io
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Long-term feed-forward 3D point tracking in persistent 3D point maps.
  Code:https://github.com/zbw001/TAPIP3D</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pairwise or Pointwise? Evaluating Feedback Protocols for Bias in
  LLM-Based Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14716v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14716v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuhina Tripathi, Manya Wadhwa, Greg Durrett, Scott Niekum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are widely used as proxies for human labelers in
both training (Reinforcement Learning from AI Feedback) and large-scale
response evaluation (LLM-as-a-judge). Alignment and evaluation are critical
components in the development of reliable LLMs, and the choice of feedback
protocol plays a central role in both but remains understudied. In this work,
we show that the choice of feedback protocol (absolute scores versus relative
preferences) can significantly affect evaluation reliability and induce
systematic biases. In particular, we show that pairwise evaluation protocols
are more vulnerable to distracted evaluation. Generator models can exploit
spurious attributes (or distractor features) favored by the LLM judge,
resulting in inflated scores for lower-quality outputs and misleading training
signals. We find that absolute scoring is more robust to such manipulation,
producing judgments that better reflect response quality and are less
influenced by distractor features. Our results demonstrate that generator
models can flip preferences by embedding distractor features, skewing
LLM-as-a-judge comparisons and leading to inaccurate conclusions about model
quality in benchmark evaluations. Pairwise preferences flip in about 35% of the
cases, compared to only 9% for absolute scores. We offer recommendations for
choosing feedback protocols based on dataset characteristics and evaluation
objectives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Time Frequency Analysis of EMG Signal for Gesture Recognition using Fine
  grained Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14708v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14708v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parshuram N. Aarotale, Ajita Rattani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electromyography (EMG) based hand gesture recognition converts forearm muscle
activity into control commands for prosthetics, rehabilitation, and human
computer interaction. This paper proposes a novel approach to EMG-based hand
gesture recognition that uses fine-grained classification and presents XMANet,
which unifies low-level local and high level semantic cues through cross layer
mutual attention among shallow to deep CNN experts. Using stacked spectrograms
and scalograms derived from the Short Time Fourier Transform (STFT) and Wavelet
Transform (WT), we benchmark XMANet against ResNet50, DenseNet-121,
MobileNetV3, and EfficientNetB0. Experimental results on the Grabmyo dataset
indicate that, using STFT, the proposed XMANet model outperforms the baseline
ResNet50, EfficientNetB0, MobileNetV3, and DenseNet121 models with improvement
of approximately 1.72%, 4.38%, 5.10%, and 2.53%, respectively. When employing
the WT approach, improvements of around 1.57%, 1.88%, 1.46%, and 2.05% are
observed over the same baselines. Similarly, on the FORS EMG dataset, the
XMANet(ResNet50) model using STFT shows an improvement of about 5.04% over the
baseline ResNet50. In comparison, the XMANet(DenseNet121) and
XMANet(MobileNetV3) models yield enhancements of approximately 4.11% and 2.81%,
respectively. Moreover, when using WT, the proposed XMANet achieves gains of
around 4.26%, 9.36%, 5.72%, and 6.09% over the baseline ResNet50, DenseNet121,
MobileNetV3, and EfficientNetB0 models, respectively. These results confirm
that XMANet consistently improves performance across various architectures and
signal processing techniques, demonstrating the strong potential of fine
grained features for accurate and robust EMG classification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can We Ignore Labels In Out of Distribution Detection? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Yang, Qi Yu, Travis Desel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Out-of-distribution (OOD) detection methods have recently become more
prominent, serving as a core element in safety-critical autonomous systems. One
major purpose of OOD detection is to reject invalid inputs that could lead to
unpredictable errors and compromise safety. Due to the cost of labeled data,
recent works have investigated the feasibility of self-supervised learning
(SSL) OOD detection, unlabeled OOD detection, and zero shot OOD detection. In
this work, we identify a set of conditions for a theoretical guarantee of
failure in unlabeled OOD detection algorithms from an information-theoretic
perspective. These conditions are present in all OOD tasks dealing with
real-world data: I) we provide theoretical proof of unlabeled OOD detection
failure when there exists zero mutual information between the learning
objective and the in-distribution labels, a.k.a. 'label blindness', II) we
define a new OOD task - Adjacent OOD detection - that tests for label blindness
and accounts for a previously ignored safety gap in all OOD detection
benchmarks, and III) we perform experiments demonstrating that existing
unlabeled OOD methods fail under conditions suggested by our label blindness
theory and analyze the implications for future research in unlabeled OOD
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Connecting Parameter Magnitudes and Hessian Eigenspaces at Scale using
  Sketched Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andres Fernandez, Frank Schneider, Maren Mahsereci, Philipp Hennig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, it has been observed that when training a deep neural net with SGD,
the majority of the loss landscape's curvature quickly concentrates in a tiny
*top* eigenspace of the loss Hessian, which remains largely stable thereafter.
Independently, it has been shown that successful magnitude pruning masks for
deep neural nets emerge early in training and remain stable thereafter. In this
work, we study these two phenomena jointly and show that they are connected: We
develop a methodology to measure the similarity between arbitrary parameter
masks and Hessian eigenspaces via Grassmannian metrics. We identify *overlap*
as the most useful such metric due to its interpretability and stability. To
compute *overlap*, we develop a matrix-free algorithm based on sketched SVDs
that allows us to compute over 1000 Hessian eigenpairs for nets with over 10M
parameters --an unprecedented scale by several orders of magnitude. Our
experiments reveal an *overlap* between magnitude parameter masks and top
Hessian eigenspaces consistently higher than chance-level, and that this effect
gets accentuated for larger network sizes. This result indicates that *top
Hessian eigenvectors tend to be concentrated around larger parameters*, or
equivalently, that *larger parameters tend to align with directions of larger
loss curvature*. Our work provides a methodology to approximate and analyze
deep learning Hessians at scale, as well as a novel insight on the structure of
their eigenspace.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at TMLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantitative Clustering in Mean-Field <span class="highlight-title">Transformer</span> Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shi Chen, Zhengjiang Lin, Yury Polyanskiy, Philippe Rigollet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The evolution of tokens through a deep transformer models can be modeled as
an interacting particle system that has been shown to exhibit an asymptotic
clustering behavior akin to the synchronization phenomenon in Kuramoto models.
In this work, we investigate the long-time clustering of mean-field transformer
models. More precisely, we establish exponential rates of contraction to a
Dirac point mass for any suitably regular initialization under some assumptions
on the parameters of transformer models, any suitably regular mean-field
initialization synchronizes exponentially fast with some quantitative rates.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>47 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Star Attention: Efficient LLM Inference over Long Sequences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.17116v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.17116v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shantanu Acharya, Fei Jia, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inference with Transformer-based Large Language Models (LLMs) on long
sequences is both costly and slow due to the quadratic complexity of the
self-attention mechanism. We introduce Star Attention, a two-phase block-sparse
approximation that improves computational efficiency by sharding attention
across multiple hosts while minimizing communication overhead. In the first
phase, the context is processed using blockwise-local attention across hosts,
in parallel. In the second phase, query and response tokens attend to all prior
cached tokens through sequence-global attention. Star Attention integrates
seamlessly with most Transformer-based LLMs trained with global attention,
reducing memory requirements and inference time by up to 11x while preserving
97-100% of accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/NVIDIA/Star-Attention</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Do Large Language Models Understand Graph Patterns? A Benchmark for
  Graph Pattern Comprehension <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05298v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05298v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinnan Dai, Haohao Qu, Yifen Shen, Bohang Zhang, Qihao Wen, Wenqi Fan, Dongsheng Li, Jiliang Tang, Caihua Shan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Benchmarking the capabilities and limitations of large language models (LLMs)
in graph-related tasks is becoming an increasingly popular and crucial area of
research. Recent studies have shown that LLMs exhibit a preliminary ability to
understand graph structures and node features. However, the potential of LLMs
in graph pattern mining remains largely unexplored. This is a key component in
fields such as computational chemistry, biology, and social network analysis.
To bridge this gap, this work introduces a comprehensive benchmark to assess
LLMs' capabilities in graph pattern tasks. We have developed a benchmark that
evaluates whether LLMs can understand graph patterns based on either
terminological or topological descriptions. Additionally, our benchmark tests
the LLMs' capacity to autonomously discover graph patterns from data. The
benchmark encompasses both synthetic and real datasets, and a variety of
models, with a total of 11 tasks and 7 models. Our experimental framework is
designed for easy expansion to accommodate new models and datasets. Our
findings reveal that: (1) LLMs have preliminary abilities to understand graph
patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting
input data to align with the knowledge acquired during pretraining can enhance
performance; (3) The strategies employed by LLMs may differ from those used in
conventional algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper is published in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Persistent Homology for Structural Characterization in Disordered
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.14390v8">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.14390v8.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        An Wang, Li Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a unified framework based on persistent homology (PH) to
characterize both local and global structures in disordered systems. It can
simultaneously generate local and global descriptors using the same algorithm
and data structure, and has shown to be highly effective and interpretable in
predicting particle rearrangements and classifying global phases. We also
demonstrated that using a single variable enables a linear SVM to achieve
nearly perfect three-phase classification. Inspired by this discovery, we
define a non-parametric metric, the Separation Index (SI), which not only
achieves this classification without sacrificing significant performance but
also establishes a connection between particle environments and the global
phase structure. Our methods provide an effective framework for understanding
and analyzing the properties of disordered materials, with broad potential
applications in materials science and even wider studies of complex systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 19 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09344v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09344v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenlong Deng, Yize Zhao, Vala Vakilian, Minghui Chen, Xiaoxiao Li, Christos Thrampoulidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Storing open-source fine-tuned models separately introduces redundancy and
increases response times in applications utilizing multiple models.
Delta-parameter pruning (DPP), particularly the random drop and rescale (DARE)
method proposed by Yu et al., addresses this by pruning the majority of delta
parameters--the differences between fine-tuned and pre-trained model
weights--while typically maintaining minimal performance loss. However, DARE
fails when either the pruning rate or the magnitude of the delta parameters is
large. We highlight two key reasons for this failure: (1) an excessively large
rescaling factor as pruning rates increase, and (2) high mean and variance in
the delta parameters. To push DARE's limits, we introduce DAREx (DARE the
eXtreme), which features two algorithmic improvements: (1) DAREx-q, a rescaling
factor modification that significantly boosts performance at high pruning rates
(e.g., >30 % on COLA and SST2 for encoder models, with even greater gains in
decoder models), and (2) DAREx-L2, which combines DARE with AdamR, an
in-training method that applies appropriate delta regularization before DPP. We
also demonstrate that DAREx-q can be seamlessly combined with vanilla
parameter-efficient fine-tuning techniques like LoRA and can facilitate
structural DPP. Additionally, we revisit the application of importance-based
pruning techniques within DPP, demonstrating that they outperform random-based
methods when delta parameters are large. Through this comprehensive study, we
develop a pipeline for selecting the most appropriate DPP method under various
practical scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Neural Encoding and Decoding at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.08201v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.08201v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work has demonstrated that large-scale, multi-animal models are
powerful tools for characterizing the relationship between neural activity and
behavior. Current large-scale approaches, however, focus exclusively on either
predicting neural activity from behavior (encoding) or predicting behavior from
neural activity (decoding), limiting their ability to capture the bidirectional
relationship between neural activity and behavior. To bridge this gap, we
introduce a multimodal, multi-task model that enables simultaneous Neural
Encoding and Decoding at Scale (NEDS). Central to our approach is a novel
multi-task-masking strategy, which alternates between neural, behavioral,
within-modality, and cross-modality masking. We pretrain our method on the
International Brain Laboratory (IBL) repeated site dataset, which includes
recordings from 83 animals performing the same visual decision-making task. In
comparison to other large-scale models, we demonstrate that NEDS achieves
state-of-the-art performance for both encoding and decoding when pretrained on
multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's
learned embeddings exhibit emergent properties: even without explicit training,
they are highly predictive of the brain regions in each recording. Altogether,
our approach is a step towards a foundation model of the brain that enables
seamless translation between neural activity and behavior.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revealing Treatment Non-Adherence Bias in Clinical Machine Learning
  Using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19625v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19625v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhongyuan Liang, Arvind Suresh, Irene Y. Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning systems trained on electronic health records (EHRs)
increasingly guide treatment decisions, but their reliability depends on the
critical assumption that patients follow the prescribed treatments recorded in
EHRs. Using EHR data from 3,623 hypertension patients, we investigate how
treatment non-adherence introduces implicit bias that can fundamentally distort
both causal inference and predictive modeling. By extracting patient adherence
information from clinical notes using a large language model (LLM), we identify
786 patients (21.7%) with medication non-adherence. We further uncover key
demographic and clinical factors associated with non-adherence, as well as
patient-reported reasons including side effects and difficulties obtaining
refills. Our findings demonstrate that this implicit bias can not only reverse
estimated treatment effects, but also degrade model performance by up to 5%
while disproportionately affecting vulnerable populations by exacerbating
disparities in decision outcomes and model error rates. This highlights the
importance of accounting for treatment non-adherence in developing responsible
and equitable clinical machine learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncertainty-Aware PPG-2-ECG for Enhanced Cardiovascular Diagnosis using
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11566v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11566v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omer Belhasin, Idan Kligvasser, George Leifman, Regev Cohen, Erin Rainaldi, Li-Fang Cheng, Nishant Verma, Paul Varghese, Ehud Rivlin, Michael Elad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing the cardiovascular system condition via Electrocardiography (ECG)
is a common and highly effective approach, and it has been practiced and
perfected over many decades. ECG sensing is non-invasive and relatively easy to
acquire, and yet it is still cumbersome for holter monitoring tests that may
span over hours and even days. A possible alternative in this context is
Photoplethysmography (PPG): An optically-based signal that measures blood
volume fluctuations, as typically sensed by conventional ``wearable devices''.
While PPG presents clear advantages in acquisition, convenience, and
cost-effectiveness, ECG provides more comprehensive information, allowing for a
more precise detection of heart conditions. This implies that a conversion from
PPG to ECG, as recently discussed in the literature, inherently involves an
unavoidable level of uncertainty. In this paper we introduce a novel
methodology for addressing the PPG-2-ECG conversion, and offer an enhanced
classification of cardiovascular conditions using the given PPG, all while
taking into account the uncertainties arising from the conversion process. We
provide a mathematical justification for our proposed computational approach,
and present empirical studies demonstrating its superior performance compared
to state-of-the-art baseline methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12714v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12714v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kunal Jha, Wilka Carvalho, Yancheng Liang, Simon S. Du, Max Kleiman-Weiner, Natasha Jaques
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot coordination (ZSC), the ability to adapt to a new partner in a
cooperative task, is a critical component of human-compatible AI. While prior
work has focused on training agents to cooperate on a single task, these
specialized models do not generalize to new tasks, even if they are highly
similar. Here, we study how reinforcement learning on a distribution of
environments with a single partner enables learning general cooperative skills
that support ZSC with many new partners on many new problems. We introduce two
Jax-based, procedural generators that create billions of solvable coordination
challenges. We develop a new paradigm called Cross-Environment Cooperation
(CEC), and show that it outperforms competitive baselines quantitatively and
qualitatively when collaborating with real people. Our findings suggest that
learning to collaborate across many unique scenarios encourages agents to
develop general norms, which prove effective for collaboration with different
partners. Together, our results suggest a new route toward designing generalist
cooperative agents capable of interacting with humans without requiring human
data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CogSci 2025, In-review for ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding and Optimizing Multi-Stage AI Inference Pipelines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09775v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09775v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhimanyu Rajeshkumar Bambhaniya, Hanjiang Wu, Suvinay Subramanian, Sudarshan Srinivasan, Souvik Kundu, Amir Yazdanbakhsh, Midhilesh Elavazhagan, Madhu Kumar, Tushar Krishna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid evolution of Large Language Models (LLMs) has driven the need for
increasingly sophisticated inference pipelines and hardware platforms. Modern
LLM serving extends beyond traditional prefill-decode workflows, incorporating
multi-stage processes such as Retrieval Augmented Generation (RAG), key-value
(KV) cache retrieval, dynamic model routing, and multi step reasoning. These
stages exhibit diverse computational demands, requiring distributed systems
that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However,
existing simulators lack the fidelity to model these heterogeneous,
multi-engine workflows, limiting their ability to inform architectural
decisions.
  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM
inference Execution Simulator. HERMES models diverse request stages; including
RAG, KV retrieval, reasoning, prefill, and decode across complex hardware
hierarchies. HERMES supports heterogeneous clients executing multiple models
concurrently unlike prior frameworks while incorporating advanced batching
strategies and multi-level memory hierarchies. By integrating real hardware
traces with analytical modeling, HERMES captures critical trade-offs such as
memory bandwidth contention, inter-cluster communication latency, and batching
efficiency in hybrid CPU-accelerator deployments. Through case studies, we
explore the impact of reasoning stages on end-to-end latency, optimal batching
strategies for hybrid pipelines, and the architectural implications of remote
KV cache retrieval. HERMES empowers system designers to navigate the evolving
landscape of LLM inference, providing actionable insights into optimizing
hardware-software co-design for next-generation AI workloads.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Inference System Design for Multi-Stage AI Inference Pipelines. 13
  Pages, 15 Figues, 3 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Language Anchor-Guided Method for Robust Noisy Domain Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.17211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.17211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zilin Dai, Lehong Wang, Fangzhou Lin, Yidong Wang, Zhigang Li, Kazunori D Yamada, Ziming Zhang, Wang Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-world machine learning applications often struggle with two major
challenges: distribution shift and label noise. Models tend to overfit by
focusing on redundant and uninformative features in the training data, which
makes it hard for them to generalize to the target domain. Noisy data worsens
this problem by causing further overfitting to the noise, meaning that existing
methods often fail to tell the difference between true, invariant features and
misleading, spurious ones. To tackle these issues, we introduce Anchor
Alignment and Adaptive Weighting (A3W). This new algorithm uses sample
reweighting guided by natural language processing (NLP) anchors to extract more
representative features. In simple terms, A3W leverages semantic
representations from natural language models as a source of domain-invariant
prior knowledge. Additionally, it employs a weighted loss function that adjusts
each sample's contribution based on its similarity to the corresponding NLP
anchor. This adjustment makes the model more robust to noisy labels. Extensive
experiments on standard benchmark datasets show that A3W consistently
outperforms state-of-the-art domain generalization methods, offering
significant improvements in both accuracy and robustness across different
datasets and noise levels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The last Dance : Robust backdoor attack via diffusion models and
  bayesian approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05967v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05967v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Orson Mengara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models are state-of-the-art deep learning generative models that
are trained on the principle of learning forward and backward diffusion
processes via the progressive addition of noise and denoising. In this paper,
we aim to fool audio-based DNN models, such as those from the Hugging Face
framework, primarily those that focus on audio, in particular transformer-based
artificial intelligence models, which are powerful machine learning models that
save time and achieve results faster and more efficiently. We demonstrate the
feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers
derived from Hugging Face, a popular framework in the world of artificial
intelligence research. The backdoor attack developed in this paper is based on
poisoning model training data uniquely by incorporating backdoor diffusion
sampling and a Bayesian approach to the distribution of poisoned data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint (Last update, will never be modified again( correction of a
  sketch)): audio backdoor attack on Hugging Face's Transformer pre-trained
  models. This attack incorporates state-of-the-art Bayesian techniques, a
  modified Fokker-Planck equation (via Yang-Mills), and a diffusion model
  approach</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MANGO: Learning Disentangled Image Transformation Manifolds with Grouped
  Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09542v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09542v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brighton Ancelin, Yenho Chen, Peimeng Guan, Chiraag Kaushik, Belen Martin-Urcelay, Alex Saad-Falcon, Nakul Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning semantically meaningful image transformations (i.e. rotation,
thickness, blur) directly from examples can be a challenging task. Recently,
the Manifold Autoencoder (MAE) proposed using a set of Lie group operators to
learn image transformations directly from examples. However, this approach has
limitations, as the learned operators are not guaranteed to be disentangled and
the training routine is prohibitively expensive when scaling up the model. To
address these limitations, we propose MANGO (transformation Manifolds with
Grouped Operators) for learning disentangled operators that describe image
transformations in distinct latent subspaces. Moreover, our approach allows
practitioners the ability to define which transformations they aim to model,
thus improving the semantic meaning of the learned operators. Through our
experiments, we demonstrate that MANGO enables composition of image
transformations and introduces a one-phase training routine that leads to a
100x speedup over prior works.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to SampTA 2025. This work has been submitted to the IEEE
  for possible publication</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Video QoE Metrics from Encrypted Traffic: Application-agnostic
  Methodology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14720v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14720v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tamir Berger, Jonathan Sterenson, Raz Birman, Ofer Hadar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instant Messaging-Based Video Call Applications (IMVCAs) and Video
Conferencing Applications (VCAs) have become integral to modern communication.
Ensuring a high Quality of Experience (QoE) for users in this context is
critical for network operators, as network conditions significantly impact user
QoE. However, network operators lack access to end-device QoE metrics due to
encrypted traffic. Existing solutions estimate QoE metrics from encrypted
traffic traversing the network, with the most advanced approaches leveraging
machine learning models. Subsequently, the need for ground truth QoE metrics
for training and validation poses a challenge, as not all video applications
provide these metrics. To address this challenge, we propose an
application-agnostic approach for objective QoE estimation from encrypted
traffic. Independent of the video application, we obtained key video QoE
metrics, enabling broad applicability to various proprietary IMVCAs and VCAs.
To validate our solution, we created a diverse dataset from WhatsApp video
sessions under various network conditions, comprising 25,680 seconds of traffic
data and QoE metrics. Our evaluation shows high performance across the entire
dataset, with 85.2% accuracy for FPS predictions within an error margin of two
FPS, and 90.2% accuracy for PIQE-based quality rating classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> on Music Generation from Single-Modal, Cross-Modal, and
  Multi-Modal Perspectives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.00837v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.00837v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuyu Li, Shulei Ji, Zihao Wang, Songruoyao Wu, Jiaxing Yu, Kejun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal music generation, using multiple modalities like text, images,
and video alongside musical scores and audio as guidance, is an emerging
research area with broad applications. This paper reviews this field,
categorizing music generation systems from the perspective of modalities. The
review covers modality representation, multi-modal data alignment, and their
utilization to guide music generation. Current datasets and evaluation methods
are also discussed. Key challenges in this area include effective multi-modal
integration, large-scale comprehensive datasets, and systematic evaluation
methods. Finally, an outlook on future research directions is provided,
focusing on creativity, efficiency, multi-modal alignment, and evaluation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Steganography Beyond Space-Time with Chain of Multimodal AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18547v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18547v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ching-Chun Chang, Isao Echizen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Steganography is the art and science of covert writing, with a broad range of
applications interwoven within the realm of cybersecurity. As artificial
intelligence continues to evolve, its ability to synthesise realistic content
emerges as a threat in the hands of cybercriminals who seek to manipulate and
misrepresent the truth. Such synthetic content introduces a non-trivial risk of
overwriting the subtle changes made for the purpose of steganography. When the
signals in both the spatial and temporal domains are vulnerable to unforeseen
overwriting, it calls for reflection on what, if any, remains invariant. This
study proposes a paradigm in steganography for audiovisual media, where
messages are concealed beyond both spatial and temporal domains. A chain of
multimodal artificial intelligence is developed to deconstruct audiovisual
content into a cover text, embed a message within the linguistic domain, and
then reconstruct the audiovisual content through synchronising both auditory
and visual modalities with the resultant stego text. The message is encoded by
biasing the word sampling process of a language generation model and decoded by
analysing the probability distribution of word choices. The accuracy of message
transmission is evaluated under both zero-bit and multi-bit capacity settings.
Fidelity is assessed through both biometric and semantic similarities,
capturing the identities of the recorded face and voice, as well as the core
ideas conveyed through the media. Secrecy is examined through statistical
comparisons between cover and stego texts. Robustness is tested across various
scenarios, including audiovisual resampling, face-swapping, voice-cloning and
their combinations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Steganography in Game Actions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.10442v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.10442v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ching-Chun Chang, Isao Echizen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exchange of messages has always carried with it the timeless challenge of
secrecy. From whispers in shadows to the enigmatic notes written in the margins
of history, humanity has long sought ways to convey thoughts that remain
imperceptible to all but the chosen few. The challenge of subliminal
communication has been addressed in various forms of steganography. However,
the field faces a fundamental paradox: as the art of concealment advances, so
too does the science of revelation, leading to an ongoing evolutionary
interplay. This study seeks to extend the boundaries of what is considered a
viable steganographic medium. We explore a steganographic paradigm, in which
hidden information is communicated through the episodes of multiple agents
interacting with an environment. Each agent, acting as an encoder, learns a
policy to disguise the very existence of hidden messages within actions
seemingly directed toward innocent objectives. Meanwhile, an observer, serving
as a decoder, learns to associate behavioural patterns with their respective
agents despite their dynamic nature, thereby unveiling the hidden messages. The
interactions of agents are governed by the framework of multi-agent
reinforcement learning and shaped by feedback from the observer. This framework
encapsulates a game-theoretic dilemma, wherein agents face decisions between
cooperating to create distinguishable behavioural patterns or defecting to
pursue individually optimal yet potentially overlapping episodic actions. As a
proof of concept, we exemplify action steganography through the game of
labyrinth, a navigation task where subliminal communication is concealed within
the act of steering toward a destination, and systematically validate the
stego-system in terms of distortion, capacity, secrecy and robustness when
subjected to simulated passive and active adversaries.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging <span class="chip">SemEval</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.21088v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.21088v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4:
Unlearning Sensitive Content from Large Language Models. This task aims to
selectively erase sensitive knowledge from large language models, avoiding both
over-forgetting and under-forgetting issues. We propose an unlearning system
that leverages Model Merging (specifically TIES-Merging), combining two
specialized models into a more balanced unlearned model. Our system achieves
competitive results, ranking second among 26 teams, with an online score of
0.944 for Task Aggregate and 0.487 for overall Aggregate. In this paper, we
also conduct local experiments and perform a comprehensive analysis of the
unlearning process, examining performance trajectories, loss dynamics, and
weight perspectives, along with several supplementary experiments, to
understand the effectiveness of our method. Furthermore, we analyze the
shortcomings of our method and evaluation metrics, emphasizing that MIA scores
and ROUGE-based metrics alone are insufficient to fully evaluate successful
unlearning. Finally, we emphasize the need for more comprehensive evaluation
methodologies and rethinking of unlearning objectives in future research. Code
is available at https://github.com/zjunlp/unlearn/tree/main/semeval25.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SemEval@ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-19T00:00:00Z">2025-04-19</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">26</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Density Measures for Language Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jon Kleinberg, Fan Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent successes of large language models (LLMs) have led to a surge of
theoretical research into language generation. A recent line of work proposes
an abstract view, called language generation in the limit, where generation is
seen as a game between an adversary and an algorithm: the adversary generates
strings from an unknown language $K$, chosen from a countable collection of
candidate languages, and after seeing a finite set of these strings, the
algorithm must generate new strings from $K$ that it has not seen before. This
formalism highlights a key tension: the trade-off between validity (the
algorithm should only produce strings from the language) and breadth (it should
be able to produce many strings from the language). This trade-off is central
in applied language generation as well, where it appears as a balance between
hallucination (generating invalid utterances) and mode collapse (generating
only a restricted set of outputs). Despite its importance, this trade-off has
been challenging to study quantitatively. We develop ways to quantify this
trade-off by formalizing breadth using measures of density. Existing algorithms
for language generation in the limit produce output sets that can have zero
density in the true language, and this important failure of breadth might seem
unavoidable. We show, however, that such a failure is not necessary: we provide
an algorithm for language generation in the limit whose outputs have strictly
positive density in $K$. We also study the internal representations built by
these algorithms, specifically the sequence of hypothesized candidate languages
they consider, and show that achieving the strongest form of breadth may
require oscillating indefinitely between high- and low-density representations.
Our analysis introduces a novel topology on language families, with notions of
convergence and limit points playing a key role.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diverse <span class="highlight-title">Prompt</span>s: Illuminating the <span class="highlight-title">Prompt</span> Space of Large Language Models
  with MAP-Elites <span class="chip">CEC 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Machado Santos, Rita Maria da Silva Julia, Marcelo Zanchetta do Nascimento
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt engineering is essential for optimizing large language models (LLMs),
yet the link between prompt structures and task performance remains
underexplored. This work introduces an evolutionary approach that combines
context-free grammar (CFG) with the MAP-Elites algorithm to systematically
explore the prompt space. Our method prioritizes quality and diversity,
generating high-performing and structurally varied prompts while analyzing
their alignment with diverse tasks by varying traits such as the number of
examples (shots) and reasoning depth. By systematically mapping the phenotypic
space, we reveal how structural variations influence LLM performance, offering
actionable insights for task-specific and adaptable prompt design. Evaluated on
seven BigBench Lite tasks across multiple LLMs, our results underscore the
critical interplay of quality and diversity, advancing the effectiveness and
versatility of LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages Accepted for publication in IEEE CEC 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Empirical Evaluation of Knowledge Distillation from <span class="highlight-title">Transformer</span>s to
  Subquadratic Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14366v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14366v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Haller, Jonas Golde, Alan Akbik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge distillation is a widely used technique for compressing large
language models (LLMs) by training a smaller student model to mimic a larger
teacher model. Typically, both the teacher and student are Transformer-based
architectures, leveraging softmax attention for sequence modeling. However, the
quadratic complexity of self-attention at inference time remains a significant
bottleneck, motivating the exploration of subquadratic alternatives such as
structured state-space models (SSMs), linear attention, and recurrent
architectures. In this work, we systematically evaluate the transferability of
knowledge distillation from a Transformer teacher to nine subquadratic student
architectures. Our study aims to determine which subquadratic model best aligns
with the teacher's learned representations and how different architectural
constraints influence the distillation process. We also investigate the impact
of intelligent initialization strategies, including matrix mixing and
query-key-value (QKV) copying, on the adaptation process. Our empirical results
on multiple NLP benchmarks provide insights into the trade-offs between
efficiency and performance, highlighting key factors for successful knowledge
transfer to subquadratic architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving RL Exploration for LLM Reasoning through Retrospective Replay 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14363v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14363v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shihan Dou, Muling Wu, Jingwen Xu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) has increasingly become a pivotal technique in
the post-training of large language models (LLMs). The effective exploration of
the output space is essential for the success of RL. We observe that for
complex problems, during the early stages of training, the model exhibits
strong exploratory capabilities and can identify promising solution ideas.
However, its limited capability at this stage prevents it from successfully
solving these problems. The early suppression of these potentially valuable
solution ideas by the policy gradient hinders the model's ability to revisit
and re-explore these ideas later. Consequently, although the LLM's capabilities
improve in the later stages of training, it still struggles to effectively
address these complex problems. To address this exploration issue, we propose a
novel algorithm named Retrospective Replay-based Reinforcement Learning (RRL),
which introduces a dynamic replay mechanism throughout the training process.
RRL enables the model to revisit promising states identified in the early
stages, thereby improving its efficiency and effectiveness in exploration. To
evaluate the effectiveness of RRL, we conduct extensive experiments on complex
reasoning tasks, including mathematical reasoning and code generation, and
general dialogue tasks. The results indicate that RRL maintains high
exploration efficiency throughout the training period, significantly enhancing
the effectiveness of RL in optimizing LLMs for complicated reasoning tasks.
Moreover, it also improves the performance of RLHF, making the model both safer
and more helpful.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrating Single-Cell Foundation Models with Graph Neural Networks for
  Drug Response Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14361v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14361v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Till Rossner, Ziteng Li, Jonas Balke, Nikoo Salehfard, Tom Seifert, Ming Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we propose an innovative methodology for predicting Cancer
Drug Response (CDR) through the integration of the scGPT foundation model
within the DeepCDR model. Our approach utilizes scGPT to generate embeddings
from gene expression data, which are then used as gene expression input data
for DeepCDR. The experimental findings demonstrate the efficacy of this
scGPT-based method in outperforming previous related works, including the
original DeepCDR model and the scFoundation-based model. This study highlights
the potential of scGPT embeddings to enhance the accuracy of CDR predictions
and offers a promising alternative to existing approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multimodal Recaptioning Framework to Account for Perceptual Diversity
  in Multilingual Vision-Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14359v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14359v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyle Buettner, Jacob Emmerson, Adriana Kovashka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There are many ways to describe, name, and group objects when captioning an
image. Differences are evident when speakers come from diverse cultures due to
the unique experiences that shape perception. Machine translation of captions
has pushed multilingual capabilities in vision-language models (VLMs), but data
comes mainly from English speakers, indicating a perceptual bias and lack of
model flexibility. In this work, we address this challenge and outline a
data-efficient framework to instill multilingual VLMs with greater
understanding of perceptual diversity. We specifically propose an LLM-based,
multimodal recaptioning strategy that alters the object descriptions of English
captions before translation. The greatest benefits are demonstrated in a
targeted multimodal mechanism guided by native speaker data. By adding produced
rewrites as augmentations in training, we improve on German and Japanese
text-image retrieval cases studies (up to +3.5 mean recall overall, +4.7 on
non-native error cases). We further propose a mechanism to analyze the specific
object description differences across datasets, and we offer insights into
cross-dataset and cross-language generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multimodal Coreference Resolution for Chinese Social Media Dialogues:
  <span class="highlight-title">Dataset</span> and Benchmark Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14321v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14321v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Li, Chen Gong, Guohong Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal coreference resolution (MCR) aims to identify mentions referring
to the same entity across different modalities, such as text and visuals, and
is essential for understanding multimodal content. In the era of rapidly
growing mutimodal content and social media, MCR is particularly crucial for
interpreting user interactions and bridging text-visual references to improve
communication and personalization. However, MCR research for real-world
dialogues remains unexplored due to the lack of sufficient data resources.To
address this gap, we introduce TikTalkCoref, the first Chinese multimodal
coreference dataset for social media in real-world scenarios, derived from the
popular Douyin short-video platform. This dataset pairs short videos with
corresponding textual dialogues from user comments and includes manually
annotated coreference clusters for both person mentions in the text and the
coreferential person head regions in the corresponding video frames. We also
present an effective benchmark approach for MCR, focusing on the celebrity
domain, and conduct extensive experiments on our dataset, providing reliable
benchmark results for this newly constructed dataset. We will release the
TikTalkCoref dataset to facilitate future research on MCR for real-world social
media dialogues.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Probing the Subtle Ideological Manipulation of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14287v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14287v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Demetris Paschalides, George Pallis, Marios D. Dikaiakos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have transformed natural language processing,
but concerns have emerged about their susceptibility to ideological
manipulation, particularly in politically sensitive areas. Prior work has
focused on binary Left-Right LLM biases, using explicit prompts and fine-tuning
on political QA datasets. In this work, we move beyond this binary approach to
explore the extent to which LLMs can be influenced across a spectrum of
political ideologies, from Progressive-Left to Conservative-Right. We introduce
a novel multi-task dataset designed to reflect diverse ideological positions
through tasks such as ideological QA, statement ranking, manifesto cloze
completion, and Congress bill comprehension. By fine-tuning three LLMs-Phi-2,
Mistral, and Llama-3-on this dataset, we evaluate their capacity to adopt and
express these nuanced ideologies. Our findings indicate that fine-tuning
significantly enhances nuanced ideological alignment, while explicit prompts
provide only minor refinements. This highlights the models' susceptibility to
subtle ideological manipulation, suggesting a need for more robust safeguards
to mitigate these risks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-attention for State-based model RWKV-7 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14260v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14260v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liu Xiao, Li Zhiyuan, Lin Yueyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce CrossWKV, a novel cross-attention mechanism for the state-based
RWKV-7 model, designed to enhance the expressive power of text-to-image
generation. Leveraging RWKV-7's linear-complexity Weighted Key-Value (WKV)
architecture, CrossWKV integrates text and image modalities in a single pass,
utilizing a generalized delta rule with vector-valued gating and low-rank
adaptations (LoRA) to achieve superior cross-modal alignment. Unlike
Transformer-based models, CrossWKV's non-diagonal, input-dependent transition
matrix enables it to represent complex functions beyond the $\mathrm{TC}^0$
complexity class, including all regular languages, as demonstrated by its
ability to perform state-tracking tasks like $S_5$ permutation modeling.
Evaluated within the Diffusion in RWKV-7 (DIR-7) on datasets such as LAION-5B
and ImageNet, CrossWKV achieves a Frechet Inception Distance (FID) of 2.88 and
a CLIP score of 0.33 on ImageNet 256x256, matching state-of-the-art performance
while offering robust generalization across diverse prompts. The model's
enhanced expressivity, combined with constant memory usage and linear scaling,
positions it as a powerful solution for advanced cross-modal tasks, with
potential applications in high-resolution generation and dynamic state
manipulation.Code at https://github.com/TorchRWKV/flash-linear-attention
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VibeCheck: Discover and Quantify Qualitative Differences in Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12851v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12851v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lisa Dunlap, Krishna Mandal, Trevor Darrell, Jacob Steinhardt, Joseph E Gonzalez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often exhibit subtle yet distinctive
characteristics in their outputs that users intuitively recognize, but struggle
to quantify. These "vibes" -- such as tone, formatting, or writing style --
influence user preferences, yet traditional evaluations focus primarily on the
singular axis of correctness. We introduce VibeCheck, a system for
automatically comparing a pair of LLMs by discovering identifying traits of a
model (vibes) that are well-defined, differentiating, and user-aligned.
VibeCheck iteratively discovers vibes from model outputs and then utilizes a
panel of LLM judges to quantitatively measure the utility of each vibe. We
validate that the vibes generated by VibeCheck align with those found in human
discovery and run VibeCheck on pairwise preference data from real-world user
conversations with Llama-3-70b vs GPT-4. VibeCheck reveals that Llama has a
friendly, funny, and somewhat controversial vibe. These vibes predict model
identity with 80% accuracy and human preference with 61% accuracy. Lastly, we
run VibeCheck on a variety of models and tasks including summarization, math,
and captioning to provide insight into differences in model behavior. VibeCheck
discovers vibes like Command X prefers to add concrete intros and conclusions
when summarizing in comparison to TNGL, Llama-405b often overexplains its
thought process on math problems compared to GPT-4o, and GPT-4 prefers to focus
on the mood and emotions of the scene when captioning compared to
Gemini-1.5-Flash. Code and vibe visualizer found at https://bench-mark.org/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>unironic use of the word 'vibe', added more analysis and cooler
  graphs. added website link</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Humanity's Last Exam 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.14249v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.14249v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, Michael Choi, Anish Agrawal, Arnav Chopra, Adam Khoja, Ryan Kim, Richard Ren, Jason Hausenloy, Oliver Zhang, Mantas Mazeika, Dmitry Dodonov, Tung Nguyen, Jaeho Lee, Daron Anderson, Mikhail Doroshenko, Alun Cennyth Stokes, Mobeen Mahmood, Oleksandr Pokutnyi, Oleg Iskra, Jessica P. Wang, John-Clark Levin, Mstyslav Kazakov, Fiona Feng, Steven Y. Feng, Haoran Zhao, Michael Yu, Varun Gangal, Chelsea Zou, Zihan Wang, Serguei Popov, Robert Gerbicz, Geoff Galgon, Johannes Schmitt, Will Yeadon, Yongki Lee, Scott Sauers, Alvaro Sanchez, Fabian Giska, Marc Roth, Søren Riis, Saiteja Utpala, Noah Burns, Gashaw M. Goshu, Mohinder Maheshbhai Naiya, Chidozie Agu, Zachary Giboney, Antrell Cheatom, Francesco Fournier-Facio, Sarah-Jane Crowson, Lennart Finke, Zerui Cheng, Jennifer Zampese, Ryan G. Hoerr, Mark Nandor, Hyunwoo Park, Tim Gehrunger, Jiaqi Cai, Ben McCarty, Alexis C Garretson, Edwin Taylor, Damien Sileo, Qiuyu Ren, Usman Qazi, Lianghui Li, Jungbae Nam, John B. Wydallis, Pavel Arkhipov, Jack Wei Lun Shi, Aras Bacho, Chris G. Willcocks, Hangrui Cao, Sumeet Motwani, Emily de Oliveira Santos, Johannes Veith, Edward Vendrow, Doru Cojoc, Kengo Zenitani, Joshua Robinson, Longke Tang, Yuqi Li, Joshua Vendrow, Natanael Wildner Fraga, Vladyslav Kuchkin, Andrey Pupasov Maksimov, Pierre Marion, Denis Efremov, Jayson Lynch, Kaiqu Liang, Aleksandar Mikov, Andrew Gritsevskiy, Julien Guillod, Gözdenur Demir, Dakotah Martinez, Ben Pageler, Kevin Zhou, Saeed Soori, Ori Press, Henry Tang, Paolo Rissone, Sean R. Green, Lina Brüssel, Moon Twayana, Aymeric Dieuleveut, Joseph Marvin Imperial, Ameya Prabhu, Jinzhou Yang, Nick Crispino, Arun Rao, Dimitri Zvonkine, Gabriel Loiseau, Mikhail Kalinin, Marco Lukas, Ciprian Manolescu, Nate Stambaugh, Subrata Mishra, Tad Hogg, Carlo Bosio, Brian P Coppola, Julian Salazar, Jaehyeok Jin, Rafael Sayous, Stefan Ivanov, Philippe Schwaller, Shaipranesh Senthilkuma, Andres M Bran, Andres Algaba, Kelsey Van den Houte, Lynn Van Der Sypt, Brecht Verbeken, David Noever, Alexei Kopylov, Benjamin Myklebust, Bikun Li, Lisa Schut, Evgenii Zheltonozhskii, Qiaochu Yuan, Derek Lim, Richard Stanley, Tong Yang, John Maar, Julian Wykowski, Martí Oller, Anmol Sahu, Cesare Giulio Ardito, Yuzheng Hu, Ariel Ghislain Kemogne Kamdoum, Alvin Jin, Tobias Garcia Vilchis, Yuexuan Zu, Martin Lackner, James Koppel, Gongbo Sun, Daniil S. Antonenko, Steffi Chern, Bingchen Zhao, Pierrot Arsene, Joseph M Cavanagh, Daofeng Li, Jiawei Shen, Donato Crisostomi, Wenjin Zhang, Ali Dehghan, Sergey Ivanov, David Perrella, Nurdin Kaparov, Allen Zang, Ilia Sucholutsky, Arina Kharlamova, Daniil Orel, Vladislav Poritski, Shalev Ben-David, Zachary Berger, Parker Whitfill, Michael Foster, Daniel Munro, Linh Ho, Shankar Sivarajan, Dan Bar Hava, Aleksey Kuchkin, David Holmes, Alexandra Rodriguez-Romero, Frank Sommerhage, Anji Zhang, Richard Moat, Keith Schneider, Zakayo Kazibwe, Don Clarke, Dae Hyun Kim, Felipe Meneguitti Dias, Sara Fish, Veit Elser, Tobias Kreiman, Victor Efren Guadarrama Vilchis, Immo Klose, Ujjwala Anantheswaran, Adam Zweiger, Kaivalya Rawal, Jeffery Li, Jeremy Nguyen, Nicolas Daans, Haline Heidinger, Maksim Radionov, Václav Rozhoň, Vincent Ginis, Christian Stump, Niv Cohen, Rafał Poświata, Josef Tkadlec, Alan Goldfarb, Chenguang Wang, Piotr Padlewski, Stanislaw Barzowski, Kyle Montgomery, Ryan Stendall, Jamie Tucker-Foltz, Jack Stade, T. Ryan Rogers, Tom Goertzen, Declan Grabb, Abhishek Shukla, Alan Givré, John Arnold Ambay, Archan Sen, Muhammad Fayez Aziz, Mark H Inlow, Hao He, Ling Zhang, Younesse Kaddar, Ivar Ängquist, Yanxu Chen, Harrison K Wang, Kalyan Ramakrishnan, Elliott Thornley, Antonio Terpin, Hailey Schoelkopf, Eric Zheng, Avishy Carmi, Ethan D. L. Brown, Kelin Zhu, Max Bartolo, Richard Wheeler, Martin Stehberger, Peter Bradshaw, JP Heimonen, Kaustubh Sridhar, Ido Akov, Jennifer Sandlin, Yury Makarychev, Joanna Tam, Hieu Hoang, David M. Cunningham, Vladimir Goryachev, Demosthenes Patramanis, Michael Krause, Andrew Redenti, David Aldous, Jesyin Lai, Shannon Coleman, Jiangnan Xu, Sangwon Lee, Ilias Magoulas, Sandy Zhao, Ning Tang, Michael K. Cohen, Orr Paradise, Jan Hendrik Kirchner, Maksym Ovchynnikov, Jason O. Matos, Adithya Shenoy, Michael Wang, Yuzhou Nie, Anna Sztyber-Betley, Paolo Faraboschi, Robin Riblet, Jonathan Crozier, Shiv Halasyamani, Shreyas Verma, Prashant Joshi, Eli Meril, Ziqiao Ma, Jérémy Andréoletti, Raghav Singhal, Jacob Platnick, Volodymyr Nevirkovets, Luke Basler, Alexander Ivanov, Seri Khoury, Nils Gustafsson, Marco Piccardo, Hamid Mostaghimi, Qijia Chen, Virendra Singh, Tran Quoc Khánh, Paul Rosu, Hannah Szlyk, Zachary Brown, Himanshu Narayan, Aline Menezes, Jonathan Roberts, William Alley, Kunyang Sun, Arkil Patel, Max Lamparth, Anka Reuel, Linwei Xin, Hanmeng Xu, Jacob Loader, Freddie Martin, Zixuan Wang, Andrea Achilleos, Thomas Preu, Tomek Korbak, Ida Bosio, Fereshteh Kazemi, Ziye Chen, Biró Bálint, Eve J. Y. Lo, Jiaqi Wang, Maria Inês S. Nunes, Jeremiah Milbauer, M Saiful Bari, Zihao Wang, Behzad Ansarinejad, Yewen Sun, Stephane Durand, Hossam Elgnainy, Guillaume Douville, Daniel Tordera, George Balabanian, Hew Wolff, Lynna Kvistad, Hsiaoyun Milliron, Ahmad Sakor, Murat Eron, Andrew Favre D. O., Shailesh Shah, Xiaoxiang Zhou, Firuz Kamalov, Sherwin Abdoli, Tim Santens, Shaul Barkan, Allison Tee, Robin Zhang, Alessandro Tomasiello, G. Bruno De Luca, Shi-Zhuo Looi, Vinh-Kha Le, Noam Kolt, Jiayi Pan, Emma Rodman, Jacob Drori, Carl J Fossum, Niklas Muennighoff, Milind Jagota, Ronak Pradeep, Honglu Fan, Jonathan Eicher, Michael Chen, Kushal Thaman, William Merrill, Moritz Firsching, Carter Harris, Stefan Ciobâcă, Jason Gross, Rohan Pandey, Ilya Gusev, Adam Jones, Shashank Agnihotri, Pavel Zhelnov, Mohammadreza Mofayezi, Alexander Piperski, David K. Zhang, Kostiantyn Dobarskyi, Roman Leventov, Ignat Soroko, Joshua Duersch, Vage Taamazyan, Andrew Ho, Wenjie Ma, William Held, Ruicheng Xian, Armel Randy Zebaze, Mohanad Mohamed, Julian Noah Leser, Michelle X Yuan, Laila Yacar, Johannes Lengler, Katarzyna Olszewska, Claudio Di Fratta, Edson Oliveira, Joseph W. Jackson, Andy Zou, Muthu Chidambaram, Timothy Manik, Hector Haffenden, Dashiell Stander, Ali Dasouqi, Alexander Shen, Bita Golshani, David Stap, Egor Kretov, Mikalai Uzhou, Alina Borisovna Zhidkovskaya, Nick Winter, Miguel Orbegozo Rodriguez, Robert Lauff, Dustin Wehr, Colin Tang, Zaki Hossain, Shaun Phillips, Fortuna Samuele, Fredrik Ekström, Angela Hammon, Oam Patel, Faraz Farhidi, George Medley, Forough Mohammadzadeh, Madellene Peñaflor, Haile Kassahun, Alena Friedrich, Rayner Hernandez Perez, Daniel Pyda, Taom Sakal, Omkar Dhamane, Ali Khajegili Mirabadi, Eric Hallman, Kenchi Okutsu, Mike Battaglia, Mohammad Maghsoudimehrabani, Alon Amit, Dave Hulbert, Roberto Pereira, Simon Weber,  Handoko, Anton Peristyy, Stephen Malina, Mustafa Mehkary, Rami Aly, Frank Reidegeld, Anna-Katharina Dick, Cary Friday, Mukhwinder Singh, Hassan Shapourian, Wanyoung Kim, Mariana Costa, Hubeyb Gurdogan, Harsh Kumar, Chiara Ceconello, Chao Zhuang, Haon Park, Micah Carroll, Andrew R. Tawfeek, Stefan Steinerberger, Daattavya Aggarwal, Michael Kirchhof, Linjie Dai, Evan Kim, Johan Ferret, Jainam Shah, Yuzhou Wang, Minghao Yan, Krzysztof Burdzy, Lixin Zhang, Antonio Franca, Diana T. Pham, Kang Yong Loh, Joshua Robinson, Abram Jackson, Paolo Giordano, Philipp Petersen, Adrian Cosma, Jesus Colino, Colin White, Jacob Votava, Vladimir Vinnikov, Ethan Delaney, Petr Spelda, Vit Stritecky, Syed M. Shahid, Jean-Christophe Mourrat, Lavr Vetoshkin, Koen Sponselee, Renas Bacho, Zheng-Xin Yong, Florencia de la Rosa, Nathan Cho, Xiuyu Li, Guillaume Malod, Orion Weller, Guglielmo Albani, Leon Lang, Julien Laurendeau, Dmitry Kazakov, Fatimah Adesanya, Julien Portier, Lawrence Hollom, Victor Souza, Yuchen Anna Zhou, Julien Degorre, Yiğit Yalın, Gbenga Daniel Obikoya,  Rai, Filippo Bigi, M. C. Boscá, Oleg Shumar, Kaniuar Bacho, Gabriel Recchia, Mara Popescu, Nikita Shulga, Ngefor Mildred Tanwie, Thomas C. H. Lux, Ben Rank, Colin Ni, Matthew Brooks, Alesia Yakimchyk,  Huanxu,  Liu, Stefano Cavalleri, Olle Häggström, Emil Verkama, Joshua Newbould, Hans Gundlach, Leonor Brito-Santana, Brian Amaro, Vivek Vajipey, Rynaa Grover, Ting Wang, Yosi Kratish, Wen-Ding Li, Sivakanth Gopi, Andrea Caciolai, Christian Schroeder de Witt, Pablo Hernández-Cámara, Emanuele Rodolà, Jules Robins, Dominic Williamson, Vincent Cheng, Brad Raynor, Hao Qi, Ben Segev, Jingxuan Fan, Sarah Martinson, Erik Y. Wang, Kaylie Hausknecht, Michael P. Brenner, Mao Mao, Christoph Demian, Peyman Kassani, Xinyu Zhang, David Avagian, Eshawn Jessica Scipio, Alon Ragoler, Justin Tan, Blake Sims, Rebeka Plecnik, Aaron Kirtland, Omer Faruk Bodur, D. P. Shinde, Yan Carlos Leyva Labrador, Zahra Adoul, Mohamed Zekry, Ali Karakoc, Tania C. B. Santos, Samir Shamseldeen, Loukmane Karim, Anna Liakhovitskaia, Nate Resman, Nicholas Farina, Juan Carlos Gonzalez, Gabe Maayan, Earth Anderson, Rodrigo De Oliveira Pena, Elizabeth Kelley, Hodjat Mariji, Rasoul Pouriamanesh, Wentao Wu, Ross Finocchio, Ismail Alarab, Joshua Cole, Danyelle Ferreira, Bryan Johnson, Mohammad Safdari, Liangti Dai, Siriphan Arthornthurasuk, Isaac C. McAlister, Alejandro José Moyano, Alexey Pronin, Jing Fan, Angel Ramirez-Trinidad, Yana Malysheva, Daphiny Pottmaier, Omid Taheri, Stanley Stepanic, Samuel Perry, Luke Askew, Raúl Adrián Huerta Rodríguez, Ali M. R. Minissi, Ricardo Lorena, Krishnamurthy Iyer, Arshad Anil Fasiludeen, Ronald Clark, Josh Ducey, Matheus Piza, Maja Somrak, Eric Vergo, Juehang Qin, Benjámin Borbás, Eric Chu, Jack Lindsey, Antoine Jallon, I. M. J. McInnis, Evan Chen, Avi Semler, Luk Gloor, Tej Shah, Marc Carauleanu, Pascal Lauer, Tran Đuc Huy, Hossein Shahrtash, Emilien Duc, Lukas Lewark, Assaf Brown, Samuel Albanie, Brian Weber, Warren S. Vaz, Pierre Clavier, Yiyang Fan, Gabriel Poesia Reis e Silva,  Long,  Lian, Marcus Abramovitch, Xi Jiang, Sandra Mendoza, Murat Islam, Juan Gonzalez, Vasilios Mavroudis, Justin Xu, Pawan Kumar, Laxman Prasad Goswami, Daniel Bugas, Nasser Heydari, Ferenc Jeanplong, Thorben Jansen, Antonella Pinto, Archimedes Apronti, Abdallah Galal, Ng Ze-An, Ankit Singh, Tong Jiang, Joan of Arc Xavier, Kanu Priya Agarwal, Mohammed Berkani, Gang Zhang, Zhehang Du, Benedito Alves de Oliveira Junior, Dmitry Malishev, Nicolas Remy, Taylor D. Hartman, Tim Tarver, Stephen Mensah, Gautier Abou Loume, Wiktor Morak, Farzad Habibi, Sarah Hoback, Will Cai, Javier Gimenez, Roselynn Grace Montecillo, Jakub Łucki, Russell Campbell, Asankhaya Sharma, Khalida Meer, Shreen Gul, Daniel Espinosa Gonzalez, Xavier Alapont, Alex Hoover, Gunjan Chhablani, Freddie Vargus, Arunim Agarwal, Yibo Jiang, Deepakkumar Patil, David Outevsky, Kevin Joseph Scaria, Rajat Maheshwari, Abdelkader Dendane, Priti Shukla, Ashley Cartwright, Sergei Bogdanov, Niels Mündler, Sören Möller, Luca Arnaboldi, Kunvar Thaman, Muhammad Rehan Siddiqi, Prajvi Saxena, Himanshu Gupta, Tony Fruhauff, Glen Sherman, Mátyás Vincze, Siranut Usawasutsakorn, Dylan Ler, Anil Radhakrishnan, Innocent Enyekwe, Sk Md Salauddin, Jiang Muzhen, Aleksandr Maksapetyan, Vivien Rossbach, Chris Harjadi, Mohsen Bahaloohoreh, Claire Sparrow, Jasdeep Sidhu, Sam Ali, Song Bian, John Lai, Eric Singer, Justine Leon Uro, Greg Bateman, Mohamed Sayed, Ahmed Menshawy, Darling Duclosel, Dario Bezzi, Yashaswini Jain, Ashley Aaron, Murat Tiryakioglu, Sheeshram Siddh, Keith Krenek, Imad Ali Shah, Jun Jin, Scott Creighton, Denis Peskoff, Zienab EL-Wasif, Ragavendran P V, Michael Richmond, Joseph McGowan, Tejal Patwardhan, Hao-Yu Sun, Ting Sun, Nikola Zubić, Samuele Sala, Stephen Ebert, Jean Kaddour, Manuel Schottdorf, Dianzhuo Wang, Gerol Petruzella, Alex Meiburg, Tilen Medved, Ali ElSheikh, S Ashwin Hebbar, Lorenzo Vaquero, Xianjun Yang, Jason Poulos, Vilém Zouhar, Sergey Bogdanik, Mingfang Zhang, Jorge Sanz-Ros, David Anugraha, Yinwei Dai, Anh N. Nhu, Xue Wang, Ali Anil Demircali, Zhibai Jia, Yuyin Zhou, Juncheng Wu, Mike He, Nitin Chandok, Aarush Sinha, Gaoxiang Luo, Long Le, Mickaël Noyé, Michał Perełkiewicz, Ioannis Pantidis, Tianbo Qi, Soham Sachin Purohit, Letitia Parcalabescu, Thai-Hoa Nguyen, Genta Indra Winata, Edoardo M. Ponti, Hanchen Li, Kaustubh Dhole, Jongee Park, Dario Abbondanza, Yuanli Wang, Anupam Nayak, Diogo M. Caetano, Antonio A. W. L. Wong, Maria del Rio-Chanona, Dániel Kondor, Pieter Francois, Ed Chalstrey, Jakob Zsambok, Dan Hoyer, Jenny Reddish, Jakob Hauser, Francisco-Javier Rodrigo-Ginés, Suchandra Datta, Maxwell Shepherd, Thom Kamphuis, Qizheng Zhang, Hyunjun Kim, Ruiji Sun, Jianzhu Yao, Franck Dernoncourt, Satyapriya Krishna, Sina Rismanchian, Bonan Pu, Francesco Pinto, Yingheng Wang, Kumar Shridhar, Kalon J. Overholt, Glib Briia, Hieu Nguyen,  David, Soler Bartomeu, Tony CY Pang, Adam Wecker, Yifan Xiong, Fanfei Li, Lukas S. Huber, Joshua Jaeger, Romano De Maddalena, Xing Han Lù, Yuhui Zhang, Claas Beger, Patrick Tser Jern Kon, Sean Li, Vivek Sanker, Ming Yin, Yihao Liang, Xinlu Zhang, Ankit Agrawal, Li S. Yifei, Zechen Zhang, Mu Cai, Yasin Sonmez, Costin Cozianu, Changhao Li, Alex Slen, Shoubin Yu, Hyun Kyu Park, Gabriele Sarti, Marcin Briański, Alessandro Stolfo, Truong An Nguyen, Mike Zhang, Yotam Perlitz, Jose Hernandez-Orallo, Runjia Li, Amin Shabani, Felix Juefei-Xu, Shikhar Dhingra, Orr Zohar, My Chiffon Nguyen, Alexander Pondaven, Abdurrahim Yilmaz, Xuandong Zhao, Chuanyang Jin, Muyan Jiang, Stefan Todoran, Xinyao Han, Jules Kreuer, Brian Rabern, Anna Plassart, Martino Maggetti, Luther Yap, Robert Geirhos, Jonathon Kean, Dingsu Wang, Sina Mollaei, Chenkai Sun, Yifan Yin, Shiqi Wang, Rui Li, Yaowen Chang, Anjiang Wei, Alice Bizeul, Xiaohan Wang, Alexandre Oliveira Arrais, Kushin Mukherjee, Jorge Chamorro-Padial, Jiachen Liu, Xingyu Qu, Junyi Guan, Adam Bouyamourn, Shuyu Wu, Martyna Plomecka, Junda Chen, Mengze Tang, Jiaqi Deng, Shreyas Subramanian, Haocheng Xi, Haoxuan Chen, Weizhi Zhang, Yinuo Ren, Haoqin Tu, Sejong Kim, Yushun Chen, Sara Vera Marjanović, Junwoo Ha, Grzegorz Luczyna, Jeff J. Ma, Zewen Shen, Dawn Song, Cedegao E. Zhang, Zhun Wang, Gaël Gendron, Yunze Xiao, Leo Smucker, Erica Weng, Kwok Hao Lee, Zhe Ye, Stefano Ermon, Ignacio D. Lopez-Miguel, Theo Knights, Anthony Gitter, Namkyu Park, Boyi Wei, Hongzheng Chen, Kunal Pai, Ahmed Elkhanany, Han Lin, Philipp D. Siedler, Jichao Fang, Ritwik Mishra, Károly Zsolnai-Fehér, Xilin Jiang, Shadab Khan, Jun Yuan, Rishab Kumar Jain, Xi Lin, Mike Peterson, Zhe Wang, Aditya Malusare, Maosen Tang, Isha Gupta, Ivan Fosin, Timothy Kang, Barbara Dworakowska, Kazuki Matsumoto, Guangyao Zheng, Gerben Sewuster, Jorge Pretel Villanueva, Ivan Rannev, Igor Chernyavsky, Jiale Chen, Deepayan Banik, Ben Racz, Wenchao Dong, Jianxin Wang, Laila Bashmal, Duarte V. Gonçalves, Wei Hu, Kaushik Bar, Ondrej Bohdal, Atharv Singh Patlan, Shehzaad Dhuliawala, Caroline Geirhos, Julien Wist, Yuval Kansal, Bingsen Chen, Kutay Tire, Atak Talay Yücel, Brandon Christof, Veerupaksh Singla, Zijian Song, Sanxing Chen, Jiaxin Ge, Kaustubh Ponkshe, Isaac Park, Tianneng Shi, Martin Q. Ma, Joshua Mak, Sherwin Lai, Antoine Moulin, Zhuo Cheng, Zhanda Zhu, Ziyi Zhang, Vaidehi Patil, Ketan Jha, Qiutong Men, Jiaxuan Wu, Tianchi Zhang, Bruno Hebling Vieira, Alham Fikri Aji, Jae-Won Chung, Mohammed Mahfoud, Ha Thi Hoang, Marc Sperzel, Wei Hao, Kristof Meding, Sihan Xu, Vassilis Kostakos, Davide Manini, Yueying Liu, Christopher Toukmaji, Jay Paek, Eunmi Yu, Arif Engin Demircali, Zhiyi Sun, Ivan Dewerpe, Hongsen Qin, Roman Pflugfelder, James Bailey, Johnathan Morris, Ville Heilala, Sybille Rosset, Zishun Yu, Peter E. Chen, Woongyeong Yeo, Eeshaan Jain, Ryan Yang, Sreekar Chigurupati, Julia Chernyavsky, Sai Prajwal Reddy, Subhashini Venugopalan, Hunar Batra, Core Francisco Park, Hieu Tran, Guilherme Maximiano, Genghan Zhang, Yizhuo Liang, Hu Shiyu, Rongwu Xu, Rui Pan, Siddharth Suresh, Ziqi Liu, Samaksh Gulati, Songyang Zhang, Peter Turchin, Christopher W. Bartlett, Christopher R. Scotese, Phuong M. Cao, Aakaash Nattanmai, Gordon McKellips, Anish Cheraku, Asim Suhail, Ethan Luo, Marvin Deng, Jason Luo, Ashley Zhang, Kavin Jindel, Jay Paek, Kasper Halevy, Allen Baranov, Michael Liu, Advaith Avadhanam, David Zhang, Vincent Cheng, Brad Ma, Evan Fu, Liam Do, Joshua Lass, Hubert Yang, Surya Sunkari, Vishruth Bharath, Violet Ai, James Leung, Rishit Agrawal, Alan Zhou, Kevin Chen, Tejas Kalpathi, Ziqi Xu, Gavin Wang, Tyler Xiao, Erik Maung, Sam Lee, Ryan Yang, Roy Yue, Ben Zhao, Julia Yoon, Sunny Sun, Aryan Singh, Ethan Luo, Clark Peng, Tyler Osbey, Taozhi Wang, Daryl Echeazu, Hubert Yang, Timothy Wu, Spandan Patel, Vidhi Kulkarni, Vijaykaarti Sundarapandiyan, Ashley Zhang, Andrew Le, Zafir Nasim, Srikar Yalam, Ritesh Kasamsetty, Soham Samal, Hubert Yang, David Sun, Nihar Shah, Abhijeet Saha, Alex Zhang, Leon Nguyen, Laasya Nagumalli, Kaixin Wang, Alan Zhou, Aidan Wu, Jason Luo, Anwith Telluri, Summer Yue, Alexandr Wang, Dan Hendrycks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Benchmarks are important tools for tracking the rapid advancements in large
language model (LLM) capabilities. However, benchmarks are not keeping pace in
difficulty: LLMs now achieve over 90\% accuracy on popular benchmarks like
MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In
response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at
the frontier of human knowledge, designed to be the final closed-ended academic
benchmark of its kind with broad subject coverage. HLE consists of 2,500
questions across dozens of subjects, including mathematics, humanities, and the
natural sciences. HLE is developed globally by subject-matter experts and
consists of multiple-choice and short-answer questions suitable for automated
grading. Each question has a known solution that is unambiguous and easily
verifiable, but cannot be quickly answered via internet retrieval.
State-of-the-art LLMs demonstrate low accuracy and calibration on HLE,
highlighting a significant gap between current LLM capabilities and the expert
human frontier on closed-ended academic questions. To inform research and
policymaking upon a clear understanding of model capabilities, we publicly
release HLE at https://lastexam.ai.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing Multiple Large Language Models: A <span class="highlight-title">Survey</span> on LLM Ensemble 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18036v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18036v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM Ensemble -- which involves the comprehensive use of multiple large
language models (LLMs), each aimed at handling user queries during downstream
inference, to benefit from their individual strengths -- has gained substantial
attention recently. The widespread availability of LLMs, coupled with their
varying strengths and out-of-the-box usability, has profoundly advanced the
field of LLM Ensemble. This paper presents the first systematic review of
recent developments in LLM Ensemble. First, we introduce our taxonomy of LLM
Ensemble and discuss several related research problems. Then, we provide a more
in-depth classification of the methods under the broad categories of
"ensemble-before-inference, ensemble-during-inference,
ensemble-after-inference'', and review all relevant methods. Finally, we
introduce related benchmarks and applications, summarize existing studies, and
suggest several future research directions. A curated list of papers on LLM
Ensemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 figures, codebase:
  https://github.com/junchenzhi/Awesome-LLM-Ensemble</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SparQLe: Speech Queries to Text Translation Through LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09284v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09284v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirbek Djanibekov, Hanan Aldarmaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing influence of Large Language Models (LLMs), there is
increasing interest in integrating speech representations with them to enable
more seamless multi-modal processing and speech understanding. This study
introduces a novel approach that leverages self-supervised speech
representations in combination with instruction-tuned LLMs for speech-to-text
translation. The proposed approach leverages a modality adapter to align
extracted speech features with instruction-tuned LLMs using English-language
data. Our experiments demonstrate that this method effectively preserves the
semantic content of the input speech and serves as an effective bridge between
self-supervised speech models and instruction-tuned LLMs, offering a promising
solution for various speech understanding applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental
  Health Safety 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09689v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09689v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Qiu, Yinghui He, Xinzhe Juan, Yiming Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of LLM-driven AI characters raises safety concerns, particularly for
vulnerable human users with psychological disorders. To address these risks, we
propose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate
mental health hazards in human-AI interactions. EmoAgent comprises two
components: EmoEval simulates virtual users, including those portraying
mentally vulnerable individuals, to assess mental health changes before and
after interactions with AI characters. It uses clinically proven psychological
and psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks
induced by LLM. EmoGuard serves as an intermediary, monitoring users' mental
status, predicting potential harm, and providing corrective feedback to
mitigate risks. Experiments conducted in popular character-based chatbots show
that emotionally engaging dialogues can lead to psychological deterioration in
vulnerable users, with mental state deterioration in more than 34.4% of the
simulations. EmoGuard significantly reduces these deterioration rates,
underscoring its role in ensuring safer AI-human interactions. Our code is
available at: https://github.com/1akaman/EmoAgent
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Halving transcription time: A fast, user-friendly and GDPR-compliant
  workflow to create AI-assisted transcripts for content analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.13031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.13031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakob Sponholz, Andreas Weilinghoff, Juliane Schopf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In qualitative research, data transcription is often labor-intensive and
time-consuming. To expedite this process, a workflow utilizing artificial
intelligence (AI) was developed. This workflow not only enhances transcription
speed but also addresses the issue of AI-generated transcripts often lacking
compatibility with standard content analysis software. Within this workflow,
automatic speech recognition is employed to create initial transcripts from
audio recordings, which are then formatted to be compatible with content
analysis software such as ATLAS or MAXQDA. Empirical data from a study of 12
interviews suggests that this workflow can reduce transcription time by up to
76.4%. Furthermore, by using widely used standard software, this process is
suitable for both students and researchers while also being adaptable to a
variety of learning, teaching, and research environments. It is also
particularly beneficial for non-native speakers. In addition, the workflow is
GDPR-compliant and facilitates local, offline transcript generation, which is
crucial when dealing with sensitive data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ State Space Models are Strong Text Rerankers <span class="chip">RepL4NLP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.14354v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.14354v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhichao Xu, Jinghua Yan, Ashim Gupta, Vivek Srikumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers dominate NLP and IR; but their inference inefficiencies and
challenges in extrapolating to longer contexts have sparked interest in
alternative model architectures. Among these, state space models (SSMs) like
Mamba offer promising advantages, particularly $O(1)$ time complexity in
inference. Despite their potential, SSMs' effectiveness at text reranking\, --
\,a task requiring fine-grained query-document interaction and long-context
understanding\, -- \,remains underexplored. This study benchmarks SSM-based
architectures (specifically, Mamba-1 and Mamba-2) against transformer-based
models across various scales, architectures, and pre-training objectives,
focusing on performance and efficiency in text reranking tasks. We find that
(1) Mamba architectures achieve competitive text ranking performance,
comparable to transformer-based models of similar size; (2) they are less
efficient in training and inference compared to transformers with flash
attention; and (3) Mamba-2 outperforms Mamba-1 in both performance and
efficiency. These results underscore the potential of state space models as a
transformer alternative and highlight areas for improvement in future IR
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to RepL4NLP 2025. The first two authors contributed equally,
  order decided randomly</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-Resource Allocation in Multi-Agent LLM Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.02051v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.02051v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alfonso Amayuelas, Jingbo Yang, Saaket Agashe, Ashwin Nagarajan, Antonis Antoniades, Xin Eric Wang, William Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the development of LLMs as agents, there is a growing interest in
connecting multiple agents into multi-agent systems to solve tasks
concurrently, focusing on their role in task assignment and coordination. This
paper explores how LLMs can effectively allocate computational tasks among
multiple agents, considering factors such as cost, efficiency, and performance.
In this work, we address key questions, including the effectiveness of LLMs as
orchestrators and planners, comparing their effectiveness in task assignment
and coordination. Our experiments demonstrate that LLMs can achieve high
validity and accuracy in resource allocation tasks. We find that the planner
method outperforms the orchestrator method in handling concurrent actions,
resulting in improved efficiency and better utilization of agents.
Additionally, we show that providing explicit information about worker
capabilities enhances the allocation strategies of planners, particularly when
dealing with suboptimal workers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DualKanbaFormer: An Efficient Selective Sparse Framework for Multimodal
  Aspect-based Sentiment Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15379v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15379v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adamu Lawan, Juhua Pu, Haruna Yunusa, Muhammad Lawan, Aliyu Umar, Adamu Sani Yahya, Mahmoud Basi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Aspect-based Sentiment Analysis (MABSA) enhances sentiment
detection by integrating textual data with complementary modalities, such as
images, to provide a more refined and comprehensive understanding of sentiment.
However, conventional attention mechanisms, despite notable benchmarks, are
hindered by quadratic complexity, limiting their ability to fully capture
global contextual dependencies and rich semantic information in both
modalities. To address this limitation, we introduce DualKanbaFormer, a novel
framework that leverages parallel Textual and Visual KanbaFormer modules for
robust multimodal analysis. Our approach incorporates Aspect-Driven Sparse
Attention (ADSA) to dynamically balance coarse-grained aggregation and
fine-grained selection for aspect-focused precision, ensuring the preservation
of both global context awareness and local precision in textual and visual
representations. Additionally, we utilize the Selective State Space Model
(Mamba) to capture extensive global semantic information across both
modalities. Furthermore, We replace traditional feed-forward networks and
normalization with Kolmogorov-Arnold Networks (KANs) and Dynamic Tanh (DyT) to
enhance non-linear expressivity and inference stability. To facilitate the
effective integration of textual and visual features, we design a multimodal
gated fusion layer that dynamically optimizes inter-modality interactions,
significantly enhancing the models efficacy in MABSA tasks. Comprehensive
experiments on two publicly available datasets reveal that DualKanbaFormer
consistently outperforms several state-of-the-art (SOTA) models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 2 figures, and 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Magnetic Preference Optimization: Achieving Last-iterate Convergence for
  Language Model Alignment <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.16714v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.16714v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingzhi Wang, Chengdong Ma, Qizhi Chen, Linjian Meng, Yang Han, Jiancong Xiao, Zhaowei Zhang, Jing Huo, Weijie J. Su, Yaodong Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-play methods have demonstrated remarkable success in enhancing model
capabilities across various domains. In the context of Reinforcement Learning
from Human Feedback (RLHF), self-play not only boosts Large Language Model
(LLM) performance but also overcomes the limitations of traditional
Bradley-Terry (BT) model assumptions by finding the Nash equilibrium (NE) of a
preference-based, two-player constant-sum game. However, existing methods
either guarantee only average-iterate convergence, incurring high storage and
inference costs, or converge to the NE of a regularized game, failing to
accurately reflect true human preferences. In this paper, we introduce Magnetic
Preference Optimization (MPO), a novel approach capable of achieving
last-iterate convergence to the NE of the original game, effectively overcoming
the limitations of existing methods. Building upon Magnetic Mirror Descent
(MMD), MPO attains a linear convergence rate, making it particularly suitable
for fine-tuning LLMs. To ensure our algorithm is both theoretically sound and
practically viable, we present a simple yet effective implementation that
adapts the theoretical insights to the RLHF setting. Empirical results
demonstrate that MPO can significantly enhance the performance of LLMs,
highlighting the potential of self-play methods in alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building
  Large Language Model-Based Conversational AI Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.00927v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.00927v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vardhan Dongre, Xiaocheng Yang, Emre Can Acikgoz, Suvodip Dey, Gokhan Tur, Dilek Hakkani-Tür
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model (LLM)-based agents are increasingly employed to interact
with external environments (e.g., games, APIs, world models) to solve
user-provided tasks. However, current frameworks often lack the ability to
collaborate effectively with users in fully conversational settings.
Conversations are essential for aligning on task details, achieving
user-defined goals, and satisfying preferences. While existing agents address
ambiguity through clarification questions, they underutilize the broader
potential of an LLM's conversational capabilities. In this work, we introduce
ReSpAct, an LLM-based agent designed to seamlessly integrate reasoning,
decision-making, and dynamic dialogue for task-solving. Expanding on
reasoning-first approaches like ReAct, ReSpAct employs active, free-flowing
dialogues to interpret instructions, clarify goals, provide status updates,
resolve subtask failures, and refine plans based on user inputs without any
explicit dialogue schema. By alternating between task-solving actions and
interactive conversations, ReSpAct demonstrates improved performance across
diverse environments. We evaluate ReSpAct in user-interactive settings,
including task-oriented dialogue systems (MultiWOZ) and decision-making tasks
(ALFWorld, WebShop). ReSpAct outperforms ReAct with absolute success rate
improvements of 6% and 4% in ALFWorld and WebShop, respectively, and achieves a
5.5% gain in Inform and a 3% gain in Success scores in MultiWOZ. These results
highlight the value of integrating dynamic user-agent collaboration for more
effective task resolution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 10 Figures, 25 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unraveling Arithmetic in Large Language Models: The Role of Algebraic
  Structures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16260v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16260v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fu-Chieh Chang, You-Chen Lin, Pei-Yuan Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated remarkable mathematical
capabilities, largely driven by chain-of-thought (CoT) prompting, which
decomposes complex reasoning into step-by-step solutions. This approach has
enabled significant advancements, as evidenced by performance on benchmarks
like GSM8K and MATH. However, the mechanisms underlying LLMs' ability to
perform arithmetic in a single step of CoT remain poorly understood. Existing
studies debate whether LLMs encode numerical values or rely on symbolic
reasoning, while others explore attention and multi-layered processing in
arithmetic tasks. In this work, we propose that LLMs learn arithmetic by
capturing algebraic structures, such as commutativity and identity properties.
Since these structures are observable through input-output relationships, they
can generalize to unseen data. We empirically demonstrate that LLMs can learn
algebraic structures using a custom dataset of arithmetic problems, as well as
providing theoretical evidence showing that, under specific configurations of
weights and biases, the transformer-based LLMs can generate embeddings that
remain invariant to both permutations of input tokens and the presence of
identity elements. Our findings indicate that leveraging algebraic structures
can enhance the LLMs' arithmetic capabilities, offering insights into improving
their arithmetic performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models as Quasi-crystals: Coherence Without Repetition in
  Generative Text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11986v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11986v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jose Manuel Guevara-Vela
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This essay proposes an interpretive analogy between large language models
(LLMs) and quasicrystals, systems that exhibit global coherence without
periodic repetition, generated through local constraints. While LLMs are
typically evaluated in terms of predictive accuracy, factuality, or alignment,
this structural perspective suggests that one of their most characteristic
behaviors is the production of internally resonant linguistic patterns. Drawing
on the history of quasicrystals, which forced a redefinition of structural
order in physical systems, the analogy highlights an alternative mode of
coherence in generative language: constraint-based organization without
repetition or symbolic intent. Rather than viewing LLMs as imperfect agents or
stochastic approximators, we suggest understanding them as generators of
quasi-structured outputs. This framing complements existing evaluation
paradigms by foregrounding formal coherence and pattern as interpretable
features of model behavior. While the analogy has limits, it offers a
conceptual tool for exploring how coherence might arise and be assessed in
systems where meaning is emergent, partial, or inaccessible. In support of this
perspective, we draw on philosophy of science and language, including
model-based accounts of scientific representation, structural realism, and
inferentialist views of meaning. We further propose the notion of structural
evaluation: a mode of assessment that examines how well outputs propagate
constraint, variation, and order across spans of generated text. This essay
aims to reframe the current discussion around large language models, not by
rejecting existing methods, but by suggesting an additional axis of
interpretation grounded in structure rather than semantics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The discussion was restructured to add limitations to the analogy and
  other clarifications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05216v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05216v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengran Zhang, Keping Bi, Jiafeng Guo, Xiaojie Sun, Shihao Liu, Daiting Shi, Dawei Yin, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense retrieval is a crucial task in Information Retrieval (IR) and is the
foundation for downstream tasks such as re-ranking. Recently, large language
models (LLMs) have shown compelling semantic understanding capabilities and are
appealing to researchers studying dense retrieval. LLMs, as decoder-style
generative models, are competent at language generation while falling short on
modeling global information due to the lack of attention to tokens afterward.
Inspired by the classical word-based language modeling approach for IR, i.e.,
the query likelihood (QL) model, we seek to sufficiently utilize LLMs'
generative ability by QL maximization. However, instead of ranking documents
with QL estimation, we introduce an auxiliary task of QL maximization to yield
a better backbone for contrastively learning a discriminative retriever. We
name our model as LLM-QL. To condense global document semantics to a single
vector during QL modeling, LLM-QL has two major components, Attention Stop (AS)
and Input Corruption (IC). AS stops the attention of predictive tokens to
previous tokens until the ending token of the document. IC masks a portion of
tokens in the input documents during prediction. Experiments on MSMARCO show
that LLM-QL can achieve significantly better performance than other LLM-based
retrievers and using QL estimated by LLM-QL for ranking outperforms word-based
QL by a large margin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12323v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12323v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Zhang, Ning Li, Qi Liu, Rui Li, Weibo Gao, Qingyang Mao, Zhenya Huang, Baosheng Yu, Dacheng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
retrieving relevant document from external knowledge sources. By referencing
this external knowledge, RAG effectively reduces the generation of factually
incorrect content and addresses hallucination issues within LLMs. Recently,
there has been growing attention to improving the performance and efficiency of
RAG systems from various perspectives. While these advancements have yielded
significant results, the application of RAG in domains with considerable
societal implications raises a critical question about fairness: What impact
does the introduction of the RAG paradigm have on the fairness of LLMs? To
address this question, we conduct extensive experiments by varying the LLMs,
retrievers, and retrieval sources. Our experimental analysis reveals that the
scale of the LLMs plays a significant role in influencing fairness outcomes
within the RAG framework. When the model scale is smaller than 8B, the
integration of retrieval mechanisms often exacerbates unfairness in small-scale
LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness
issues introduced by RAG for small-scale LLMs, we propose two approaches,
FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the
LLM in terms of fairness, enabling it to retrieve documents that facilitate
fairer model outputs. In FairFilter, we propose a fairness filtering mechanism
to filter out biased content after retrieval. Finally, we validate our proposed
approaches on real-world datasets, demonstrating their effectiveness in
improving fairness while maintaining performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Structural and Semantic Signals in Text-Attributed Graphs
  with BiGTex 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12474v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12474v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Azadeh Beiranvand, Seyed Mehdi Vahidipour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-attributed graphs (TAGs) present unique challenges in representation
learning by requiring models to capture both the semantic richness of
node-associated texts and the structural dependencies of the graph. While graph
neural networks (GNNs) excel at modeling topological information, they lack the
capacity to process unstructured text. Conversely, large language models (LLMs)
are proficient in text understanding but are typically unaware of graph
structure. In this work, we propose BiGTex (Bidirectional Graph Text), a novel
architecture that tightly integrates GNNs and LLMs through stacked Graph-Text
Fusion Units. Each unit allows for mutual attention between textual and
structural representations, enabling information to flow in both directions,
text influencing structure and structure guiding textual interpretation. The
proposed architecture is trained using parameter-efficient fine-tuning (LoRA),
keeping the LLM frozen while adapting to task-specific signals. Extensive
experiments on five benchmark datasets demonstrate that BiGTex achieves
state-of-the-art performance in node classification and generalizes effectively
to link prediction. An ablation study further highlights the importance of soft
prompting and bi-directional attention in the model's success.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Arabic Speech Recognition Through Large-Scale Weakly
  Supervised Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12254v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12254v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahmoud Salhab, Marwan Elghitany, Shameed Sait, Syed Sibghat Ullah, Mohammad Abusheikh, Hasan Abusheikh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic speech recognition (ASR) is crucial for human-machine interaction
in diverse applications like conversational agents, industrial robotics, call
center automation, and automated subtitling. However, developing
high-performance ASR models remains challenging, particularly for low-resource
languages like Arabic, due to the scarcity of large, labeled speech datasets,
which are costly and labor-intensive to produce. In this work, we employ weakly
supervised learning to train an Arabic ASR model using the Conformer
architecture. Our model is trained from scratch on 15,000 hours of weakly
annotated speech data covering both Modern Standard Arabic (MSA) and Dialectal
Arabic (DA), eliminating the need for costly manual transcriptions. Despite the
absence of human-verified labels, our approach achieves state-of-the-art (SOTA)
results in Arabic ASR, surpassing both open and closed-source models on
standard benchmarks. By demonstrating the effectiveness of weak supervision as
a scalable, cost-efficient alternative to traditional supervised approaches,
paving the way for improved ASR systems in low resource settings.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">16</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-Driven Usefulness Judgment for Web Search Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mouly Dewan, Jiqun Liu, Aditya Gautam, Chirag Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluation is fundamental in optimizing search experiences and supporting
diverse user intents in Information Retrieval (IR). Traditional search
evaluation methods primarily rely on relevance labels, which assess how well
retrieved documents match a user's query. However, relevance alone fails to
capture a search system's effectiveness in helping users achieve their search
goals, making usefulness a critical evaluation criterion. In this paper, we
explore an alternative approach: LLM-generated usefulness labels, which
incorporate both implicit and explicit user behavior signals to evaluate
document usefulness. We propose Task-aware Rubric-based Usefulness Evaluation
(TRUE), a rubric-driven evaluation method that employs iterative sampling and
reasoning to model complex search behavior patterns. Our findings show that (i)
LLMs can generate moderate usefulness labels by leveraging comprehensive search
session history incorporating personalization and contextual understanding, and
(ii) fine-tuned LLMs improve usefulness judgments when provided with structured
search session contexts. Additionally, we examine whether LLMs can distinguish
between relevance and usefulness, particularly in cases where this divergence
impacts search success. We also conduct an ablation study to identify key
metrics for accurate usefulness label generation, optimizing for token
efficiency and cost-effectiveness in real-world applications. This study
advances LLM-based usefulness evaluation by refining key user metrics,
exploring LLM-generated label reliability, and ensuring feasibility for
large-scale search systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unconstrained Monotonic Calibration of Predictions in Deep Ranking
  Systems <span class="chip">SIGIR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14243v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14243v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yimeng Bai, Shunyu Zhang, Yang Zhang, Hu Liu, Wentian Bao, Enyun Yu, Fuli Feng, Wenwu Ou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ranking models primarily focus on modeling the relative order of predictions
while often neglecting the significance of the accuracy of their absolute
values. However, accurate absolute values are essential for certain downstream
tasks, necessitating the calibration of the original predictions. To address
this, existing calibration approaches typically employ predefined
transformation functions with order-preserving properties to adjust the
original predictions. Unfortunately, these functions often adhere to fixed
forms, such as piece-wise linear functions, which exhibit limited
expressiveness and flexibility, thereby constraining their effectiveness in
complex calibration scenarios. To mitigate this issue, we propose implementing
a calibrator using an Unconstrained Monotonic Neural Network (UMNN), which can
learn arbitrary monotonic functions with great modeling power. This approach
significantly relaxes the constraints on the calibrator, improving its
flexibility and expressiveness while avoiding excessively distorting the
original predictions by requiring monotonicity. Furthermore, to optimize this
highly flexible network for calibration, we introduce a novel additional loss
function termed Smooth Calibration Loss (SCLoss), which aims to fulfill a
necessary condition for achieving the ideal calibration state. Extensive
offline experiments confirm the effectiveness of our method in achieving
superior calibration performance. Moreover, deployment in Kuaishou's
large-scale online video ranking system demonstrates that the method's
calibration improvements translate into enhanced business metrics. The source
code is available at https://github.com/baiyimeng/UMC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Template-Based Financial Report Generation in Agentic and Decomposed
  Information Retrieval <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14233v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14233v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong-En Tian, Yu-Chien Tang, Kuang-Da Wang, An-Zi Yen, Wen-Chih Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tailoring structured financial reports from companies' earnings releases is
crucial for understanding financial performance and has been widely adopted in
real-world analytics. However, existing summarization methods often generate
broad, high-level summaries, which may lack the precision and detail required
for financial reports that typically focus on specific, structured sections.
While Large Language Models (LLMs) hold promise, generating reports adhering to
predefined multi-section templates remains challenging. This paper investigates
two LLM-based approaches popular in industry for generating templated financial
reports: an agentic information retrieval (IR) framework and a decomposed IR
approach, namely AgenticIR and DecomposedIR. The AgenticIR utilizes
collaborative agents prompted with the full template. In contrast, the
DecomposedIR approach applies a prompt chaining workflow to break down the
template and reframe each section as a query answered by the LLM using the
earnings release. To quantitatively assess the generated reports, we evaluated
both methods in two scenarios: one using a financial dataset without direct
human references, and another with a weather-domain dataset featuring
expert-written reports. Experimental results show that while AgenticIR may
excel in orchestrating tasks and generating concise reports through agent
collaboration, DecomposedIR statistically significantly outperforms AgenticIR
approach in providing broader and more detailed coverage in both scenarios,
offering reflection on the utilization of the agentic framework in real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages; 3 figures. Accepted by SIGIR 2025 short paper track. Code
  available at
  https://github.com/bryant-nn/Template-Based-Financial-Report-Generation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Teach Me How to Denoise: A Universal Framework for Denoising Multi-modal
  Recommender Systems via Guided Calibration <span class="chip">WSDM</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongji Li, Hanwen Du, Youhua Li, Junchen Fu, Chunxiao Li, Ziyi Zhuang, Jiakang Li, Yongxin Ni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The surge in multimedia content has led to the development of Multi-Modal
Recommender Systems (MMRecs), which use diverse modalities such as text,
images, videos, and audio for more personalized recommendations. However,
MMRecs struggle with noisy data caused by misalignment among modal content and
the gap between modal semantics and recommendation semantics. Traditional
denoising methods are inadequate due to the complexity of multi-modal data. To
address this, we propose a universal guided in-sync distillation denoising
framework for multi-modal recommendation (GUIDER), designed to improve MMRecs
by denoising user feedback. Specifically, GUIDER uses a re-calibration strategy
to identify clean and noisy interactions from modal content. It incorporates a
Denoising Bayesian Personalized Ranking (DBPR) loss function to handle implicit
user feedback. Finally, it applies a denoising knowledge distillation objective
based on Optimal Transport distance to guide the alignment from modality
representations to recommendation semantics. GUIDER can be seamlessly
integrated into existing MMRecs methods as a plug-and-play solution.
Experimental results on four public datasets demonstrate its effectiveness and
generalizability. Our source code is available at
https://github.com/Neon-Jing/Guider
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACM Web Search and Data Mining (WSDM) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FedCIA: Federated Collaborative Information Aggregation for
  Privacy-Preserving Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14208v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14208v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingzhe Han, Dongsheng Li, Jiafeng Xia, Jiahao Liu, Hansu Gu, Peng Zhang, Ning Gu, Tun Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation algorithms rely on user historical interactions to deliver
personalized suggestions, which raises significant privacy concerns. Federated
recommendation algorithms tackle this issue by combining local model training
with server-side model aggregation, where most existing algorithms use a
uniform weighted summation to aggregate item embeddings from different client
models. This approach has three major limitations: 1) information loss during
aggregation, 2) failure to retain personalized local features, and 3)
incompatibility with parameter-free recommendation algorithms. To address these
limitations, we first review the development of recommendation algorithms and
recognize that their core function is to share collaborative information,
specifically the global relationship between users and items. With this
understanding, we propose a novel aggregation paradigm named collaborative
information aggregation, which focuses on sharing collaborative information
rather than item parameters. Based on this new paradigm, we introduce the
federated collaborative information aggregation (FedCIA) method for
privacy-preserving recommendation. This method requires each client to upload
item similarity matrices for aggregation, which allows clients to align their
local models without constraining embeddings to a unified vector space. As a
result, it mitigates information loss caused by direct summation, preserves the
personalized embedding distributions of individual clients, and supports the
aggregation of parameter-free models. Theoretical analysis and experimental
results on real-world datasets demonstrate the superior performance of FedCIA
compared with the state-of-the-art federated recommendation algorithms. Code is
available at https://github.com/Mingzhe-Han/FedCIA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EIoU-EMC: A Novel Loss for Domain-specific Nested Entity Recognition <span class="chip">SIGIR'2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14203v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14203v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Zhang, Tianqing Zhang, Qi Li, Hongwei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, research has mainly focused on the general NER task. There
still have some challenges with nested NER task in the specific domains.
Specifically, the scenarios of low resource and class imbalance impede the wide
application for biomedical and industrial domains. In this study, we design a
novel loss EIoU-EMC, by enhancing the implement of Intersection over Union loss
and Multiclass loss. Our proposed method specially leverages the information of
entity boundary and entity classification, thereby enhancing the model's
capacity to learn from a limited number of data samples. To validate the
performance of this innovative method in enhancing NER task, we conducted
experiments on three distinct biomedical NER datasets and one dataset
constructed by ourselves from industrial complex equipment maintenance
documents. Comparing to strong baselines, our method demonstrates the
competitive performance across all datasets. During the experimental analysis,
our proposed method exhibits significant advancements in entity boundary
recognition and entity classification. Our code are available here.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR'2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query
  Expansion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14175v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14175v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query expansion methods powered by large language models (LLMs) have
demonstrated effectiveness in zero-shot retrieval tasks. These methods assume
that LLMs can generate hypothetical documents that, when incorporated into a
query vector, enhance the retrieval of real evidence. However, we challenge
this assumption by investigating whether knowledge leakage in benchmarks
contributes to the observed performance gains. Using fact verification as a
testbed, we analyzed whether the generated documents contained information
entailed by ground truth evidence and assessed their impact on performance. Our
findings indicate that performance improvements occurred consistently only for
claims whose generated documents included sentences entailed by ground truth
evidence. This suggests that knowledge leakage may be present in these
benchmarks, inflating the perceived performance of LLM-based query expansion
methods, particularly in real-world scenarios that require retrieving niche or
novel knowledge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HF4Rec: Human-Like Feedback-Driven Optimization Framework for
  Explainable Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14147v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14147v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiakai Tang, Jingsen Zhang, Zihang Tian, Xueyang Feng, Lei Wang, Xu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in explainable recommendation have greatly bolstered user
experience by elucidating the decision-making rationale. However, the existing
methods actually fail to provide effective feedback signals for potentially
better or worse generated explanations due to their reliance on traditional
supervised learning paradigms in sparse interaction data. To address these
issues, we propose a novel human-like feedback-driven optimization framework.
This framework employs a dynamic interactive optimization mechanism for
achieving human-centered explainable requirements without incurring high labor
costs. Specifically, we propose to utilize large language models (LLMs) as
human simulators to predict human-like feedback for guiding the learning
process. To enable the LLMs to deeply understand the task essence and meet
user's diverse personalized requirements, we introduce a human-induced
customized reward scoring method, which helps stimulate the language
understanding and logical reasoning capabilities of LLMs. Furthermore,
considering the potential conflicts between different perspectives of
explanation quality, we introduce a principled Pareto optimization that
transforms the multi-perspective quality enhancement task into a
multi-objective optimization problem for improving explanation performance. At
last, to achieve efficient model training, we design an off-policy optimization
pipeline. By incorporating a replay buffer and addressing the data distribution
biases, we can effectively improve data utilization and enhance model
generality. Extensive experiments on four datasets demonstrate the superiority
of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized News Recommendation with Multi-granularity Candidate-aware
  User Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiang Li, Xinze Lin, Shenghao Lv, Faliang Huang, Xiangju Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Matching candidate news with user interests is crucial for personalized news
recommendations. Most existing methods can represent a user's reading interests
through a single profile based on clicked news, which may not fully capture the
diversity of user interests. Although some approaches incorporate candidate
news or topic information, they remain insufficient because they neglect the
multi-granularity relatedness between candidate news and user interests. To
address this, this study proposed a multi-granularity candidate-aware user
modeling framework that integrated user interest features across various levels
of granularity. It consisted of two main components: candidate news encoding
and user modeling. A news textual information extractor and a
knowledge-enhanced entity information extractor can capture candidate news
features, and word-level, entity-level, and news-level candidate-aware
mechanisms can provide a comprehensive representation of user interests.
Extensive experiments on a real-world dataset demonstrated that the proposed
model could significantly outperform baseline models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ State Space Models are Strong Text Rerankers <span class="chip">RepL4NLP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.14354v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.14354v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhichao Xu, Jinghua Yan, Ashim Gupta, Vivek Srikumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers dominate NLP and IR; but their inference inefficiencies and
challenges in extrapolating to longer contexts have sparked interest in
alternative model architectures. Among these, state space models (SSMs) like
Mamba offer promising advantages, particularly $O(1)$ time complexity in
inference. Despite their potential, SSMs' effectiveness at text reranking\, --
\,a task requiring fine-grained query-document interaction and long-context
understanding\, -- \,remains underexplored. This study benchmarks SSM-based
architectures (specifically, Mamba-1 and Mamba-2) against transformer-based
models across various scales, architectures, and pre-training objectives,
focusing on performance and efficiency in text reranking tasks. We find that
(1) Mamba architectures achieve competitive text ranking performance,
comparable to transformer-based models of similar size; (2) they are less
efficient in training and inference compared to transformers with flash
attention; and (3) Mamba-2 outperforms Mamba-1 in both performance and
efficiency. These results underscore the potential of state space models as a
transformer alternative and highlight areas for improvement in future IR
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to RepL4NLP 2025. The first two authors contributed equally,
  order decided randomly</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models Enhanced Hyperbolic Space Recommender Systems <span class="chip">SIGIR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05694v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05694v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wentao Cheng, Zhida Qin, Zexue Wu, Pengzhan Zhou, Tianyu Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have attracted significant attention in
recommender systems for their excellent world knowledge capabilities. However,
existing methods that rely on Euclidean space struggle to capture the rich
hierarchical information inherent in textual and semantic data, which is
essential for capturing user preferences. The geometric properties of
hyperbolic space offer a promising solution to address this issue.
Nevertheless, integrating LLMs-based methods with hyperbolic space to
effectively extract and incorporate diverse hierarchical information is
non-trivial. To this end, we propose a model-agnostic framework, named
HyperLLM, which extracts and integrates hierarchical information from both
structural and semantic perspectives. Structurally, HyperLLM uses LLMs to
generate multi-level classification tags with hierarchical parent-child
relationships for each item. Then, tag-item and user-item interactions are
jointly learned and aligned through contrastive learning, thereby providing the
model with clear hierarchical information. Semantically, HyperLLM introduces a
novel meta-optimized strategy to extract hierarchical information from semantic
embeddings and bridge the gap between the semantic and collaborative spaces for
seamless integration. Extensive experiments show that HyperLLM significantly
outperforms recommender systems based on hyperbolic space and LLMs, achieving
performance improvements of over 40%. Furthermore, HyperLLM not only improves
recommender performance but also enhances training stability, highlighting the
critical role of hierarchical information in recommender systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a SIGIR'25 full paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Theoretical Analysis of Recommendation Loss Functions under Negative
  Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.07770v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.07770v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giulia Di Teodoro, Federico Siciliano, Nicola Tonellotto, Fabrizio Silvestri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Loss functions like Categorical Cross Entropy (CCE), Binary Cross Entropy
(BCE), and Bayesian Personalized Ranking (BPR) are commonly used in training
Recommender Systems (RSs) to differentiate positive items - those interacted
with by users - and negative items. While prior works empirically showed that
CCE outperforms BCE and BPR when using the full set of negative items, we
provide a theoretical explanation for this by proving that CCE offers the
tightest lower bound on ranking metrics like Normalized Discounted Cumulative
Gain (NDCG) and Mean Reciprocal Rank (MRR), followed by BPR and BCE. However,
using the full set of negative items is computationally infeasible for
large-scale RSs, prompting the use of negative sampling techniques. Under
negative sampling, we reveal that BPR and CCE are equivalent when a single
negative sample is drawn, and all three losses converge to the same global
minimum. We further demonstrate that the sampled losses remain lower bounds for
NDCG (MRR), albeit in a probabilistic sense. Our worst-case analysis shows that
BCE offers the strongest bound on NDCG (MRR). Experiments on five datasets and
four models empirically support these theoretical findings. Our code and
supplementary material are available at
https://github.com/federicosiciliano/recsys_losses.git.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main paper 12 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05216v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05216v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengran Zhang, Keping Bi, Jiafeng Guo, Xiaojie Sun, Shihao Liu, Daiting Shi, Dawei Yin, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense retrieval is a crucial task in Information Retrieval (IR) and is the
foundation for downstream tasks such as re-ranking. Recently, large language
models (LLMs) have shown compelling semantic understanding capabilities and are
appealing to researchers studying dense retrieval. LLMs, as decoder-style
generative models, are competent at language generation while falling short on
modeling global information due to the lack of attention to tokens afterward.
Inspired by the classical word-based language modeling approach for IR, i.e.,
the query likelihood (QL) model, we seek to sufficiently utilize LLMs'
generative ability by QL maximization. However, instead of ranking documents
with QL estimation, we introduce an auxiliary task of QL maximization to yield
a better backbone for contrastively learning a discriminative retriever. We
name our model as LLM-QL. To condense global document semantics to a single
vector during QL modeling, LLM-QL has two major components, Attention Stop (AS)
and Input Corruption (IC). AS stops the attention of predictive tokens to
previous tokens until the ending token of the document. IC masks a portion of
tokens in the input documents during prediction. Experiments on MSMARCO show
that LLM-QL can achieve significantly better performance than other LLM-based
retrievers and using QL estimated by LLM-QL for ranking outperforms word-based
QL by a large margin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Potential Field Based Deep Metric Learning <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18560v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18560v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhang Bhatnagar, Narendra Ahuja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep metric learning (DML) involves training a network to learn a
semantically meaningful representation space. Many current approaches mine
n-tuples of examples and model interactions within each tuplets. We present a
novel, compositional DML model that instead of in tuples, represents the
influence of each example (embedding) by a continuous potential field, and
superposes the fields to obtain their combined global potential field. We use
attractive/repulsive potential fields to represent interactions among
embeddings from images of the same/different classes. Contrary to typical
learning methods, where mutual influence of samples is proportional to their
distance, we enforce reduction in such influence with distance, leading to a
decaying field. We show that such decay helps improve performance on real world
datasets with large intra-class variations and label noise. Like other
proxy-based methods, we also use proxies to succinctly represent
sub-populations of examples. We evaluate our method on three standard DML
benchmarks- Cars-196, CUB-200-2011, and SOP datasets where it outperforms
state-of-the-art baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01776v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01776v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tiansheng Wen, Yifei Wang, Zequn Zeng, Zhong Peng, Yudi Su, Xinyang Liu, Bo Chen, Hongwei Liu, Stefanie Jegelka, Chenyu You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many large-scale systems rely on high-quality deep representations
(embeddings) to facilitate tasks like retrieval, search, and generative
modeling. Matryoshka Representation Learning (MRL) recently emerged as a
solution for adaptive embedding lengths, but it requires full model retraining
and suffers from noticeable performance degradations at short lengths. In this
paper, we show that sparse coding offers a compelling alternative for achieving
adaptive representation with minimal overhead and higher fidelity. We propose
Contrastive Sparse Representation (CSR), a method that sparsifies pre-trained
embeddings into a high-dimensional but selectively activated feature space. By
leveraging lightweight autoencoding and task-aware contrastive objectives, CSR
preserves semantic quality while allowing flexible, cost-effective inference at
different sparsity levels. Extensive experiments on image, text, and multimodal
benchmarks demonstrate that CSR consistently outperforms MRL in terms of both
accuracy and retrieval speed-often by large margins-while also cutting training
time to a fraction of that required by MRL. Our results establish sparse coding
as a powerful paradigm for adaptive representation learning in real-world
applications where efficiency and fidelity are both paramount. Code is
available at https://github.com/neilwen987/CSR_Adaptive_Rep
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A novel sparse coding framework designed for learning adaptive
  representation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HeterRec: Heterogeneous Information <span class="highlight-title">Transformer</span> for Scalable Sequential
  Recommendation <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01469v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01469v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Deng, Haibo Xing, Kanefumi Matsuyama, Yulei Huang, Jinxin Hu, Hong Wen, Jia Xu, Zulong Chen, Yu Zhang, Xiaoyi Zeng, Jing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based sequential recommendation (TSR) models have shown superior
performance in recommendation systems, where the quality of item
representations plays a crucial role. Classical representation methods
integrate item features using concatenation or neural networks to generate
homogeneous representation sequences. While straightforward, these methods
overlook the heterogeneity of item features, limiting the transformer's ability
to capture fine-grained patterns and restricting scalability. Recent studies
have attempted to integrate user-side heterogeneous features into item
representation sequences, but item-side heterogeneous features, which are vital
for performance, remain excluded. To address these challenges, we propose a
Heterogeneous Information Transformer model for Sequential Recommendation
(HeterRec), which incorporates Heterogeneous Token Flatten Layer (HTFL) and
Hierarchical Causal Transformer Layer (HCT). Our HTFL is a novel item
tokenization method that converts items into a heterogeneous token set and
organizes these tokens into heterogeneous sequences, effectively enhancing
performance gains when scaling up the model. Moreover, HCT introduces
token-level and item-level causal transformers to extract fine-grained patterns
from the heterogeneous sequences. Additionally, we design a Listwise Multi-step
Prediction (LMP) Loss function to further improve performance. Extensive
experiments on both offline and online datasets show that the HeterRec model
achieves superior performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, Proceedings of the 48th International ACM SIGIR
  Conference on Research and Development in Information Retrieval (SIGIR '25),
  July 13--18, 2025, Padua, Italy</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Balancing Privacy and Action Performance: A Penalty-Driven Approach to
  Image Anonymization <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14301v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14301v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazia Aslam, Kamal Nasrollahi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of video surveillance systems for object detection,
tracking, activity recognition, and anomaly detection has revolutionized our
day-to-day lives while setting alarms for privacy concerns. It isn't easy to
strike a balance between visual privacy and action recognition performance in
most computer vision models. Is it possible to safeguard privacy without
sacrificing performance? It poses a formidable challenge, as even minor privacy
enhancements can lead to substantial performance degradation. To address this
challenge, we propose a privacy-preserving image anonymization technique that
optimizes the anonymizer using penalties from the utility branch, ensuring
improved action recognition performance while minimally affecting privacy
leakage. This approach addresses the trade-off between minimizing privacy
leakage and maintaining high action performance. The proposed approach is
primarily designed to align with the regulatory standards of the EU AI Act and
GDPR, ensuring the protection of personally identifiable information while
maintaining action performance. To the best of our knowledge, we are the first
to introduce a feature-based penalty scheme that exclusively controls the
action features, allowing freedom to anonymize private attributes. Extensive
experiments were conducted to validate the effectiveness of the proposed
method. The results demonstrate that applying a penalty to anonymizer from
utility branch enhances action performance while maintaining nearly consistent
privacy leakage across different penalty settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPRW 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ROI-Guided Point Cloud Geometry Compression Towards Human and Machine
  Vision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xie Liang, Gao Wei, Zhenghui Ming, Li Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Point cloud data is pivotal in applications like autonomous driving, virtual
reality, and robotics. However, its substantial volume poses significant
challenges in storage and transmission. In order to obtain a high compression
ratio, crucial semantic details usually confront severe damage, leading to
difficulties in guaranteeing the accuracy of downstream tasks. To tackle this
problem, we are the first to introduce a novel Region of Interest (ROI)-guided
Point Cloud Geometry Compression (RPCGC) method for human and machine vision.
Our framework employs a dual-branch parallel structure, where the base layer
encodes and decodes a simplified version of the point cloud, and the
enhancement layer refines this by focusing on geometry details. Furthermore,
the residual information of the enhancement layer undergoes refinement through
an ROI prediction network. This network generates mask information, which is
then incorporated into the residuals, serving as a strong supervision signal.
Additionally, we intricately apply these mask details in the Rate-Distortion
(RD) optimization process, with each point weighted in the distortion
calculation. Our loss function includes RD loss and detection loss to better
guide point cloud encoding for the machine. Experiment results demonstrate that
RPCGC achieves exceptional compression performance and better detection
accuracy (10% gain) than some learning-based compression methods at high
bitrates in ScanNet and SUN RGB-D datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SwinGS: Sliding Window Gaussian Splatting for Volumetric Video Streaming
  with Arbitrary Length 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07759v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07759v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bangya Liu, Suman Banerjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in 3D Gaussian Splatting (3DGS) have garnered significant
attention in computer vision and computer graphics due to its high rendering
speed and remarkable quality. While extant research has endeavored to extend
the application of 3DGS from static to dynamic scenes, such efforts have been
consistently impeded by excessive model sizes, constraints on video duration,
and content deviation. These limitations significantly compromise the
streamability of dynamic 3D Gaussian models, thereby restricting their utility
in downstream applications, including volumetric video, autonomous vehicle, and
immersive technologies such as virtual, augmented, and mixed reality.
  This paper introduces SwinGS, a novel framework for training, delivering, and
rendering volumetric video in a real-time streaming fashion. To address the
aforementioned challenges and enhance streamability, SwinGS integrates
spacetime Gaussian with Markov Chain Monte Carlo (MCMC) to adapt the model to
fit various 3D scenes across frames, in the meantime employing a sliding window
captures Gaussian snapshots for each frame in an accumulative way. We implement
a prototype of SwinGS and demonstrate its streamability across various datasets
and scenes. Additionally, we develop an interactive WebGL viewer enabling
real-time volumetric video playback on most devices with modern browsers,
including smartphones and tablets. Experimental results show that SwinGS
reduces transmission costs by 83.6% compared to previous work and could be
easily scaled to volumetric videos with arbitrary length with no increasing of
required GPU resources.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-18T00:00:00Z">2025-04-18</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Math Learning in an LMS Using AI-Driven Question
  Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14098v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14098v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Justus Råmunddal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an AI-driven approach to enhance math learning in a
modern Learning Management System (LMS) by recommending similar math questions.
Deep embeddings for math questions are generated using Meta's
Llama-3.2-11B-Vision-Instruct model, and three recommendation methods-cosine
similarity, Self-Organizing Maps (SOM), and Gaussian Mixture Models (GMM)-are
applied to identify similar questions. User interaction data, including session
durations, response times, and correctness, are used to evaluate the methods.
Our findings suggest that while cosine similarity produces nearly identical
question matches, SOM yields higher user satisfaction whereas GMM generally
underperforms, indicating that introducing variety to a certain degree may
enhance engagement and thereby potential learning outcomes until variety is no
longer balanced reasonably, which our data about the implementations of all
three methods demonstrate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 9 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CPR: Leveraging LLMs for Topic and Phrase Suggestion to Facilitate
  Comprehensive Product <span class="highlight-title">Review</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13993v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13993v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ekta Gujral, Apurva Sinha, Lishi Ji, Bijayani Sanghamitra Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Consumers often heavily rely on online product reviews, analyzing both
quantitative ratings and textual descriptions to assess product quality.
However, existing research hasn't adequately addressed how to systematically
encourage the creation of comprehensive reviews that capture both customers
sentiment and detailed product feature analysis. This paper presents CPR, a
novel methodology that leverages the power of Large Language Models (LLMs) and
Topic Modeling to guide users in crafting insightful and well-rounded reviews.
Our approach employs a three-stage process: first, we present users with
product-specific terms for rating; second, we generate targeted phrase
suggestions based on these ratings; and third, we integrate user-written text
through topic modeling, ensuring all key aspects are addressed. We evaluate CPR
using text-to-text LLMs, comparing its performance against real-world customer
reviews from Walmart. Our results demonstrate that CPR effectively identifies
relevant product terms, even for new products lacking prior reviews, and
provides sentiment-aligned phrase suggestions, saving users time and enhancing
reviews quality. Quantitative analysis reveals a 12.3% improvement in BLEU
score over baseline methods, further supported by manual evaluation of
generated phrases. We conclude by discussing potential extensions and future
research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Consensus-aware Contrastive Learning for Group Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13703v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13703v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soyoung Kim, Dongjun Lee, Jaekwang Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group recommendation aims to provide personalized item suggestions to a group
of users by reflecting their collective preferences. A fundamental challenge in
this task is deriving a consensus that adequately represents the diverse
interests of individual group members. Despite advancements made by deep
learning-based models, existing approaches still struggle in two main areas:
(1) Capturing consensus in small-group settings, which are more prevalent in
real-world applications, and (2) Balancing individual preferences with overall
group performance, particularly in hypergraph-based methods that tend to
emphasize group accuracy at the expense of personalization. To address these
challenges, we introduce a Consensus-aware Contrastive Learning for Group
Recommendation (CoCoRec) that models group consensus through contrastive
learning. CoCoRec utilizes a transformer encoder to jointly learn user and
group representations, enabling richer modeling of intra-group dynamics.
Additionally, the contrastive objective helps reduce overfitting from
high-frequency user interactions, leading to more robust and representative
group embeddings. Experiments conducted on four benchmark datasets show that
CoCoRec consistently outperforms state-of-the-art baselines in both individual
and group recommendation scenarios, highlighting the effectiveness of
consensus-aware contrastive learning in group recommendation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Type Context-Aware Conversational Recommender Systems via
  Mixture-of-Experts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Zou, Cheng Lin, Weikang Guo, Zheng Wang, Jiwei Wei, Yang Yang, Hengtao Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational recommender systems enable natural language conversations and
thus lead to a more engaging and effective recommendation scenario. As the
conversations for recommender systems usually contain limited contextual
information, many existing conversational recommender systems incorporate
external sources to enrich the contextual information. However, how to combine
different types of contextual information is still a challenge. In this paper,
we propose a multi-type context-aware conversational recommender system, called
MCCRS, effectively fusing multi-type contextual information via
mixture-of-experts to improve conversational recommender systems. MCCRS
incorporates both structured information and unstructured information,
including the structured knowledge graph, unstructured conversation history,
and unstructured item reviews. It consists of several experts, with each expert
specialized in a particular domain (i.e., one specific contextual information).
Multiple experts are then coordinated by a ChairBot to generate the final
results. Our proposed MCCRS model takes advantage of different contextual
information and the specialization of different experts followed by a ChairBot
breaks the model bottleneck on a single contextual information. Experimental
results demonstrate that our proposed MCCRS method achieves significantly
higher performance compared to existing baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Long-term Embedding with Denoising and Augmentation for
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zahra Akhlaghi, Mostafa Haghir Chehreghani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid growth of the internet has made personalized recommendation systems
indispensable. Graph-based sequential recommendation systems, powered by Graph
Neural Networks (GNNs), effectively capture complex user-item interactions but
often face challenges such as noise and static representations. In this paper,
we introduce the Adaptive Long-term Embedding with Denoising and Augmentation
for Recommendation (ALDA4Rec) method, a novel model that constructs an
item-item graph, filters noise through community detection, and enriches
user-item interactions. Graph Convolutional Networks (GCNs) are then employed
to learn short-term representations, while averaging, GRUs, and attention
mechanisms are utilized to model long-term embeddings. An MLP-based adaptive
weighting strategy is further incorporated to dynamically optimize long-term
user preferences. Experiments conducted on four real-world datasets demonstrate
that ALDA4Rec outperforms state-of-the-art baselines, delivering notable
improvements in both accuracy and robustness. The source code is available at
https://github.com/zahraakhlaghi/ALDA4Rec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contextualizing Spotify's Audiobook List Recommendations with
  Descriptive Shelves <span class="chip">ECIR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13572v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13572v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gustavo Penha, Alice Wang, Martin Achenbach, Kristen Sheets, Sahitya Mantravadi, Remi Galvez, Nico Guetta-Jeanrenaud, Divya Narayanan, Ofeliya Kalaydzhyan, Hugues Bouchard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a pipeline to generate contextualized list
recommendations with descriptive shelves in the domain of audiobooks. By
creating several shelves for topics the user has an affinity to, e.g. Uplifting
Women's Fiction, we can help them explore their recommendations according to
their interests and at the same time recommend a diverse set of items. To do
so, we use Large Language Models (LLMs) to enrich each item's metadata based on
a taxonomy created for this domain. Then we create diverse descriptive shelves
for each user. A/B tests show improvements in user engagement and audiobook
discovery metrics, demonstrating benefits for users and content creators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in the 47th European Conference on
  Information Retrieval (ECIR'25)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Sequential Recommenders through Counterfactual Augmentation of
  System Exposure <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqi Zhao, Zhaochun Ren, Jiyuan Yang, Zuming Yan, Zihan Wang, Liu Yang, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Xin Xin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In sequential recommendation (SR), system exposure refers to items that are
exposed to the user. Typically, only a few of the exposed items would be
interacted with by the user. Although SR has achieved great success in
predicting future user interests, existing SR methods still fail to fully
exploit system exposure data. Most methods only model items that have been
interacted with, while the large volume of exposed but non-interacted items is
overlooked. Even methods that consider the whole system exposure typically
train the recommender using only the logged historical system exposure, without
exploring unseen user interests.
  In this paper, we propose counterfactual augmentation over system exposure
for sequential recommendation (CaseRec). To better model historical system
exposure, CaseRec introduces reinforcement learning to account for different
exposure rewards. CaseRec uses a decision transformer-based sequential model to
take an exposure sequence as input and assigns different rewards according to
the user feedback. To further explore unseen user interests, CaseRec proposes
to perform counterfactual augmentation, where exposed original items are
replaced with counterfactual items. Then, a transformer-based user simulator is
proposed to predict the user feedback reward for the augmented items.
Augmentation, together with the user simulator, constructs counterfactual
exposure sequences to uncover new user interests. Finally, CaseRec jointly uses
the logged exposure sequences with the counterfactual exposure sequences to
train a decision transformer-based sequential model for generating
recommendation. Experiments on three real-world benchmarks show the
effectiveness of CaseRec. Our code is available at
https://github.com/ZiqiZhao1/CaseRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted at SIGIR 2025 (Proceedings of the 48th International ACM
  SIGIR Conference on Research and Development in Information Retrieval)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adversarial Hubness in Multi-Modal Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.14113v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.14113v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingwei Zhang, Fnu Suya, Rishi Jha, Collin Zhang, Vitaly Shmatikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hubness is a phenomenon in high-dimensional vector spaces where a single
point from the natural distribution is unusually close to many other points.
This is a well-known problem in information retrieval that causes some items to
accidentally (and incorrectly) appear relevant to many queries.
  In this paper, we investigate how attackers can exploit hubness to turn any
image or audio input in a multi-modal retrieval system into an adversarial hub.
Adversarial hubs can be used to inject universal adversarial content (e.g.,
spam) that will be retrieved in response to thousands of different queries, as
well as for targeted attacks on queries related to specific, attacker-chosen
concepts.
  We present a method for creating adversarial hubs and evaluate the resulting
hubs on benchmark multi-modal retrieval datasets and an image-to-image
retrieval system implemented by Pinecone, a popular vector database. For
example, in text-caption-to-image retrieval, a single adversarial hub,
generated with respect to 100 randomly selected target queries, is retrieved as
the top-1 most relevant image for more than 21,000 out of 25,000 test queries
(by contrast, the most common natural hub is the top-1 response to only 102
queries), demonstrating the strong generalization capabilities of adversarial
hubs. We also investigate whether techniques for mitigating natural hubness are
an effective defense against adversarial hubs, and show that they are not
effective against hubs that target queries related to specific concepts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Establishing a Foundation for Tetun Ad-Hoc Text Retrieval: Stemming,
  Indexing, Retrieval, and Ranking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.11758v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.11758v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel de Jesus, Sérgio Nunes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Searching for information on the internet and digital platforms to satisfy an
information need requires effective retrieval solutions. However, such
solutions are not yet available for Tetun, making it challenging to find
relevant documents for text-based search queries in this language. To address
these challenges, we investigate Tetun text retrieval with a focus on the
ad-hoc retrieval task. The study begins by developing essential language
resources -- including a list of stopwords, a stemmer, and a test collection --
which serve as foundational components for solutions tailored to Tetun text
retrieval. Various strategies are investigated using both document titles and
content to evaluate retrieval effectiveness. The results demonstrate that
retrieving document titles, after removing hyphens and apostrophes without
applying stemming, significantly improves retrieval performance compared to the
baseline. Efficiency increases by 31.37%, while effectiveness achieves an
average relative gain of +9.40% in MAP@10 and +30.35% in NDCG@10 with DFR BM25.
Beyond the top-10 cutoff point, Hiemstra LM shows strong performance across
various retrieval strategies and evaluation metrics. Contributions of this work
include the development of Labadain-Stopwords (a list of 160 Tetun stopwords),
Labadain-Stemmer (a Tetun stemmer with three variants), and
Labadain-Avaliad\'or (a Tetun test collection containing 59 topics, 33,550
documents, and 5,900 qrels). We make all resources publicly accessible to
facilitate future research in Tetun information retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Version 3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluation Report on MCP Servers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11094v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11094v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiling Luo, Xiaorong Shi, Xuanrui Lin, Jinyang Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rise of LLMs, a large number of Model Context Protocol (MCP)
services have emerged since the end of 2024. However, the effectiveness and
efficiency of MCP servers have not been well studied. To study these questions,
we propose an evaluation framework, called MCPBench. We selected several widely
used MCP server and conducted an experimental evaluation on their accuracy,
time, and token usage. Our experiments showed that the most effective MCP, Bing
Web Search, achieved an accuracy of 64%. Importantly, we found that the
accuracy of MCP servers can be substantially enhanced by involving declarative
interface. This research paves the way for further investigations into
optimized MCP implementations, ultimately leading to better AI-driven
applications and data retrieval solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Few-shot Model Extraction Attacks against Sequential Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.11677v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.11677v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Zhang, Fu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Among adversarial attacks against sequential recommender systems, model
extraction attacks represent a method to attack sequential recommendation
models without prior knowledge. Existing research has primarily concentrated on
the adversary's execution of black-box attacks through data-free model
extraction. However, a significant gap remains in the literature concerning the
development of surrogate models by adversaries with access to few-shot raw data
(10\% even less). That is, the challenge of how to construct a surrogate model
with high functional similarity within the context of few-shot data scenarios
remains an issue that requires resolution.This study addresses this gap by
introducing a novel few-shot model extraction framework against sequential
recommenders, which is designed to construct a superior surrogate model with
the utilization of few-shot data. The proposed few-shot model extraction
framework is comprised of two components: an autoregressive augmentation
generation strategy and a bidirectional repair loss-facilitated model
distillation procedure. Specifically, to generate synthetic data that closely
approximate the distribution of raw data, autoregressive augmentation
generation strategy integrates a probabilistic interaction sampler to extract
inherent dependencies and a synthesis determinant signal module to characterize
user behavioral patterns. Subsequently, bidirectional repair loss, which target
the discrepancies between the recommendation lists, is designed as auxiliary
loss to rectify erroneous predictions from surrogate models, transferring
knowledge from the victim model to the surrogate model effectively. Experiments
on three datasets show that the proposed few-shot model extraction framework
yields superior surrogate models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>It requires substantial modifications.The symbols in the mathematical
  formulas are not explained in detail</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware
  Cross-domain Recommendations <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13843v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13843v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Liu, Shengkang Gu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-based user agents, which simulate user interaction behavior, are emerging
as a promising approach to enhancing recommender systems. In real-world
scenarios, users' interactions often exhibit cross-domain characteristics and
are influenced by others. However, the memory design in current methods causes
user agents to introduce significant irrelevant information during
decision-making in cross-domain scenarios and makes them unable to recognize
the influence of other users' interactions, such as popularity factors. To
tackle this issue, we propose a dual-layer memory architecture combined with a
two-step fusion mechanism. This design avoids irrelevant information during
decision-making while ensuring effective integration of cross-domain
preferences. We also introduce the concepts of interest groups and group-shared
memory to better capture the influence of popularity factors on users with
similar interests. Comprehensive experiments validate the effectiveness of
AgentCF++. Our code is available at https://github.com/jhliu0807/AgentCF-plus.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025, 6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving LLM-powered Recommendations with Personalized Information <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13845v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13845v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Liu, Xueshuo Yan, Dongsheng Li, Guangping Zhang, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the lack of explicit reasoning modeling, existing LLM-powered
recommendations fail to leverage LLMs' reasoning capabilities effectively. In
this paper, we propose a pipeline called CoT-Rec, which integrates two key
Chain-of-Thought (CoT) processes -- user preference analysis and item
perception analysis -- into LLM-powered recommendations, thereby enhancing the
utilization of LLMs' reasoning abilities. CoT-Rec consists of two stages: (1)
personalized information extraction, where user preferences and item perception
are extracted, and (2) personalized information utilization, where this
information is incorporated into the LLM-powered recommendation process.
Experimental results demonstrate that CoT-Rec shows potential for improving
LLM-powered recommendations. The implementation is publicly available at
https://github.com/jhliu0807/CoT-Rec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025, 7 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unbiased Collaborative Filtering with Fair Sampling <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13840v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13840v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Liu, Dongsheng Li, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems leverage extensive user interaction data to model
preferences; however, directly modeling these data may introduce biases that
disproportionately favor popular items. In this paper, we demonstrate that
popularity bias arises from the influence of propensity factors during
training. Building on this insight, we propose a fair sampling (FS) method that
ensures each user and each item has an equal likelihood of being selected as
both positive and negative instances, thereby mitigating the influence of
propensity factors. The proposed FS method does not require estimating
propensity scores, thus avoiding the risk of failing to fully eliminate
popularity bias caused by estimation inaccuracies. Comprehensive experiments
demonstrate that the proposed FS method achieves state-of-the-art performance
in both point-wise and pair-wise recommendation tasks. The code implementation
is available at https://github.com/jhliu0807/Fair-Sampling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accept by SIGIR 2025, 5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model-Based Knowledge Graph System Construction for
  Sustainable Development Goals: An AI-Based Speculative Design Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12309v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12309v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi-De Lin, Guan-Ze Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  From 2000 to 2015, the UN's Millennium Development Goals guided global
priorities. The subsequent Sustainable Development Goals (SDGs) adopted a more
dynamic approach, with annual indicator updates. As 2030 nears and progress
lags, innovative acceleration strategies are critical. This study develops an
AI-powered knowledge graph system to analyze SDG interconnections, discover
potential new goals, and visualize them online. Using official SDG texts,
Elsevier's keyword dataset, and 1,127 TED Talk transcripts (2020.01-2024.04), a
pilot on 269 talks from 2023 applies AI-speculative design, large language
models, and retrieval-augmented generation. Key findings include: (1) Heatmap
analysis reveals strong associations between Goal 10 and Goal 16, and minimal
coverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time
reveals new central nodes, showing how richer data supports divergent thinking
and goal clarity. (3) Six potential new goals are proposed, centered on equity,
resilience, and technology-driven inclusion. This speculative-AI framework
offers fresh insights for policymakers and lays groundwork for future
multimodal and cross-system SDG applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a minor revision: fixed a typo in the abstract (time range)
  and corrected minor textual errors</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fashion-RAG: Multimodal Fashion Image Editing via Retrieval-Augmented
  Generation <span class="chip">IJCNN 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.14011v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.14011v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fulvio Sanguigni, Davide Morelli, Marcella Cornia, Rita Cucchiara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the fashion industry has increasingly adopted AI
technologies to enhance customer experience, driven by the proliferation of
e-commerce platforms and virtual applications. Among the various tasks, virtual
try-on and multimodal fashion image editing -- which utilizes diverse input
modalities such as text, garment sketches, and body poses -- have become a key
area of research. Diffusion models have emerged as a leading approach for such
generative tasks, offering superior image quality and diversity. However, most
existing virtual try-on methods rely on having a specific garment input, which
is often impractical in real-world scenarios where users may only provide
textual specifications. To address this limitation, in this work we introduce
Fashion Retrieval-Augmented Generation (Fashion-RAG), a novel method that
enables the customization of fashion items based on user preferences provided
in textual form. Our approach retrieves multiple garments that match the input
specifications and generates a personalized image by incorporating attributes
from the retrieved items. To achieve this, we employ textual inversion
techniques, where retrieved garment images are projected into the textual
embedding space of the Stable Diffusion text encoder, allowing seamless
integration of retrieved elements into the generative process. Experimental
results on the Dress Code dataset demonstrate that Fashion-RAG outperforms
existing methods both qualitatively and quantitatively, effectively capturing
fine-grained visual details from retrieved garments. To the best of our
knowledge, this is the first work to introduce a retrieval-augmented generation
approach specifically tailored for multimodal fashion image editing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IJCNN 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PoEmotion: Can AI Utilize Chinese Calligraphy to Express Emotion from
  Poems? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tiancheng Liu, Anqi Wang, Xinda Chen, Jing Yan, Yin Li, Pan Hui, Kang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents PoEmotion, an approach to visualizing emotions in poetry
with Chinese calligraphy strokes. Traditional textual emotion analysis often
lacks emotional resonance due to its mechanical nature. PoEmotion combines
natural language processing with deep learning generative algorithms to create
Chinese calligraphy that effectively conveys the emotions in poetry. The
created calligraphy represents four fundamental emotions: excitement, anger,
sadness, and relaxation, making the visual representation of emotions intuitive
and concise. Furthermore, the approach delves into the relationship be-tween
time, emotion, and cultural communication. Its goal is to provide a more
natural means of communicating emotions through non-verbal mediums to enhance
human emotional expression.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MusFlow: Multimodal Music Generation via Conditional Flow Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13535v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13535v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Song, Yuzhao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music generation aims to create music segments that align with human
aesthetics based on diverse conditional information. Despite advancements in
generating music from specific textual descriptions (e.g., style, genre,
instruments), the practical application is still hindered by ordinary users'
limited expertise or time to write accurate prompts. To bridge this application
gap, this paper introduces MusFlow, a novel multimodal music generation model
using Conditional Flow Matching. We employ multiple Multi-Layer Perceptrons
(MLPs) to align multimodal conditional information into the audio's CLAP
embedding space. Conditional flow matching is trained to reconstruct the
compressed Mel-spectrogram in the pretrained VAE latent space guided by aligned
feature embedding. MusFlow can generate music from images, story texts, and
music captions. To collect data for model training, inspired by multi-agent
collaboration, we construct an intelligent data annotation workflow centered
around a fine-tuned Qwen2-VL model. Using this workflow, we build a new
multimodal music dataset, MMusSet, with each sample containing a quadruple of
image, story text, music caption, and music piece. We conduct four sets of
experiments: image-to-music, story-to-music, caption-to-music, and multimodal
music generation. Experimental results demonstrate that MusFlow can generate
high-quality music pieces whether the input conditions are unimodal or
multimodal. We hope this work can advance the application of music generation
in multimedia field, making music creation more accessible. Our generated
samples, code and dataset are available at musflow.github.io.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HMPE:HeatMap Embedding for Efficient <span class="highlight-title">Transformer</span>-Based Small Object
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        YangChen Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current Transformer-based methods for small object detection continue
emerging, yet they have still exhibited significant shortcomings. This paper
introduces HeatMap Position Embedding (HMPE), a novel Transformer Optimization
technique that enhances object detection performance by dynamically integrating
positional encoding with semantic detection information through heatmap-guided
adaptive learning.We also innovatively visualize the HMPE method, offering
clear visualization of embedded information for parameter fine-tuning.We then
create Multi-Scale ObjectBox-Heatmap Fusion Encoder (MOHFE) and HeatMap Induced
High-Quality Queries for Decoder (HIDQ) modules. These are designed for the
encoder and decoder, respectively, to generate high-quality queries and reduce
background noise queries.Using both heatmap embedding and Linear-Snake
Conv(LSConv) feature engineering, we enhance the embedding of massively diverse
small object categories and reduced the decoder multihead layers, thereby
accelerating both inference and training.In the generalization experiments, our
approach outperforme the baseline mAP by 1.9% on the small object dataset (NWPU
VHR-10) and by 1.2% on the general dataset (PASCAL VOC). By employing
HMPE-enhanced embedding, we are able to reduce the number of decoder layers
from eight to a minimum of three, significantly decreasing both inference and
training costs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PathVLM-R1: A Reinforcement Learning-Driven Reasoning Model for
  Pathology Visual-Language Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09258v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09258v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianyu Wu, Hao Yang, Xinhua Zeng, Guibing He, Zhiyu Chen, Zihui Li, Xiaochuan Zhang, Yangyang Ma, Run Fang, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The diagnosis of pathological images is often limited by expert availability
and regional disparities, highlighting the importance of automated diagnosis
using Vision-Language Models (VLMs). Traditional multimodal models typically
emphasize outcomes over the reasoning process, compromising the reliability of
clinical decisions. To address the weak reasoning abilities and lack of
supervised processes in pathological VLMs, we have innovatively proposed
PathVLM-R1, a visual language model designed specifically for pathological
images. We have based our model on Qwen2.5-VL-7B-Instruct and enhanced its
performance for pathological tasks through meticulously designed post-training
strategies. Firstly, we conduct supervised fine-tuning guided by pathological
data to imbue the model with foundational pathological knowledge, forming a new
pathological base model. Subsequently, we introduce Group Relative Policy
Optimization (GRPO) and propose a dual reward-driven reinforcement learning
optimization, ensuring strict constraint on logical supervision of the
reasoning process and accuracy of results via cross-modal process reward and
outcome accuracy reward. In the pathological image question-answering tasks,
the testing results of PathVLM-R1 demonstrate a 14% improvement in accuracy
compared to baseline methods, and it demonstrated superior performance compared
to the Qwen2.5-VL-32B version despite having a significantly smaller parameter
size. Furthermore, in out-domain data evaluation involving four medical imaging
modalities: Computed Tomography (CT), dermoscopy, fundus photography, and
Optical Coherence Tomography (OCT) images: PathVLM-R1's transfer performance
improved by an average of 17.3% compared to traditional SFT methods. These
results clearly indicate that PathVLM-R1 not only enhances accuracy but also
possesses broad applicability and expansion potential.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-17T00:00:00Z">2025-04-17</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">18</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SemCORE: A Semantic-Enhanced Generative Cross-Modal Retrieval Framework
  with MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13172v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13172v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxuan Li, Yi Bin, Yunshan Ma, Guoqing Wang, Yang Yang, See-Kiong Ng, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-modal retrieval (CMR) is a fundamental task in multimedia research,
focused on retrieving semantically relevant targets across different
modalities. While traditional CMR methods match text and image via
embedding-based similarity calculations, recent advancements in pre-trained
generative models have established generative retrieval as a promising
alternative. This paradigm assigns each target a unique identifier and
leverages a generative model to directly predict identifiers corresponding to
input queries without explicit indexing. Despite its great potential, current
generative CMR approaches still face semantic information insufficiency in both
identifier construction and generation processes. To address these limitations,
we propose a novel unified Semantic-enhanced generative Cross-mOdal REtrieval
framework (SemCORE), designed to unleash the semantic understanding
capabilities in generative cross-modal retrieval task. Specifically, we first
construct a Structured natural language IDentifier (SID) that effectively
aligns target identifiers with generative models optimized for natural language
comprehension and generation. Furthermore, we introduce a Generative Semantic
Verification (GSV) strategy enabling fine-grained target discrimination.
Additionally, to the best of our knowledge, SemCORE is the first framework to
simultaneously consider both text-to-image and image-to-text retrieval tasks
within generative cross-modal retrieval. Extensive experiments demonstrate that
our framework outperforms state-of-the-art generative cross-modal retrieval
methods. Notably, SemCORE achieves substantial improvements across benchmark
datasets, with an average increase of 8.65 points in Recall@1 for text-to-image
retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on
  Technical Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nandan Thakur, Jimmy Lin, Sam Havens, Michael Carbin, Omar Khattab, Andrew Drozdov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce FreshStack, a reusable framework for automatically building
information retrieval (IR) evaluation benchmarks from community-asked questions
and answers. FreshStack conducts the following steps: (1) automatic corpus
collection from code and technical documentation, (2) nugget generation from
community-asked questions and answers, and (3) nugget-level support, retrieving
documents using a fusion of retrieval techniques and hybrid architectures. We
use FreshStack to build five datasets on fast-growing, recent, and niche topics
to ensure the tasks are sufficiently challenging. On FreshStack, existing
retrieval models, when applied out-of-the-box, significantly underperform
oracle approaches on all five topics, denoting plenty of headroom to improve IR
quality. In addition, we identify cases where rerankers do not clearly improve
first-stage retrieval accuracy (two out of five topics). We hope that
FreshStack will facilitate future work toward constructing realistic, scalable,
and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are
available at: https://fresh-stack.github.io.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Should We Tailor the Talk? Understanding the Impact of Conversational
  Styles on Preference Elicitation in Conversational Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivica Kostric, Krisztian Balog, Ujwal Gadiraju
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational recommender systems (CRSs) provide users with an interactive
means to express preferences and receive real-time personalized
recommendations. The success of these systems is heavily influenced by the
preference elicitation process. While existing research mainly focuses on what
questions to ask during preference elicitation, there is a notable gap in
understanding what role broader interaction patterns including tone, pacing,
and level of proactiveness play in supporting users in completing a given task.
This study investigates the impact of different conversational styles on
preference elicitation, task performance, and user satisfaction with CRSs. We
conducted a controlled experiment in the context of scientific literature
recommendation, contrasting two distinct conversational styles, high
involvement (fast paced, direct, and proactive with frequent prompts) and high
considerateness (polite and accommodating, prioritizing clarity and user
comfort) alongside a flexible experimental condition where users could switch
between the two. Our results indicate that adapting conversational strategies
based on user expertise and allowing flexibility between styles can enhance
both user satisfaction and the effectiveness of recommendations in CRSs.
Overall, our findings hold important implications for the design of future
CRSs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in: Proceedings of the 33rd ACM Conference on User
  Modeling, Adaptation and Personalization (UMAP '25), June 16--19, 2025, New
  York City, NY, USA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction
  Graphs for LLM-Based Task Planning <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13032v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13032v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Wang, Shu Xian Teo, Jun Jie Chew, Wei Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have enabled their use as
agents for planning complex tasks. Existing methods typically rely on a
thought-action-observation (TAO) process to enhance LLM performance, but these
approaches are often constrained by the LLMs' limited knowledge of complex
tasks. Retrieval-augmented generation (RAG) offers new opportunities by
leveraging external databases to ground generation in retrieved information. In
this paper, we identify two key challenges (enlargability and transferability)
in applying RAG to task planning. We propose InstructRAG, a novel solution
within a multi-agent meta-reinforcement learning framework, to address these
challenges. InstructRAG includes a graph to organize past instruction paths
(sequences of correct actions), an RL-Agent with Reinforcement Learning to
expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to
improve task generalization for transferability. The two agents are trained
end-to-end to optimize overall planning performance. Our experiments on four
widely used task planning datasets demonstrate that InstructRAG significantly
enhances performance and adapts efficiently to new tasks, achieving up to a
19.2% improvement over the best existing approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective
  Embedding-Based Retrieval <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12920v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12920v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Deng, Haibo Xing, Kanefumi Matsuyama, Moyu Zhang, Jinxin Hu, Hong Wen, Yu Zhang, Xiaoyi Zeng, Jing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-objective embedding-based retrieval (EBR) has become increasingly
critical due to the growing complexity of user behaviors and commercial
objectives. While traditional approaches often suffer from data sparsity and
limited information sharing between objectives, recent methods utilizing a
shared network alongside dedicated sub-networks for each objective partially
address these limitations. However, such methods significantly increase the
model parameters, leading to an increased retrieval latency and a limited
ability to model causal relationships between objectives. To address these
challenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel
method that enhances both retrieval efficiency and serving performance for
multi-objective EBR. The CSMF framework selectively masks model parameters to
free up independent learning space for each objective, leveraging the cascading
relationships between objectives during the sequential fine-tuning. Without
increasing network parameters or online retrieval overhead, CSMF computes a
linearly weighted fusion score for multiple objective probabilities while
supporting flexible adjustment of each objective's weight across various
recommendation scenarios. Experimental results on real-world datasets
demonstrate the superior performance of CSMF, and online experiments validate
its significant practical value.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 8 figures, Proceedings of the 48th International ACM SIGIR
  Conference on Research and Development in Information Retrieval (SIGIR '25),
  July 13--18, 2025, Padua, Italy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConExion: Concept Extraction with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12915v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12915v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ebrahim Norouzi, Sven Hertling, Harald Sack
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, an approach for concept extraction from documents using
pre-trained large language models (LLMs) is presented. Compared with
conventional methods that extract keyphrases summarizing the important
information discussed in a document, our approach tackles a more challenging
task of extracting all present concepts related to the specific domain, not
just the important ones. Through comprehensive evaluations of two widely used
benchmark datasets, we demonstrate that our method improves the F1 score
compared to state-of-the-art techniques. Additionally, we explore the potential
of using prompts within these models for unsupervised concept extraction. The
extracted concepts are intended to support domain coverage evaluation of
ontologies and facilitate ontology learning, highlighting the effectiveness of
LLMs in concept extraction tasks. Our source code and datasets are publicly
available at https://github.com/ISE-FIZKarlsruhe/concept_extraction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FashionDPO:Fine-tune Fashion Outfit Generation Model using Direct
  Preference Optimization <span class="chip">SIGIR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12900v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12900v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingzhe Yu, Yunshan Ma, Lei Wu, Changshuo Wang, Xue Li, Lei Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized outfit generation aims to construct a set of compatible and
personalized fashion items as an outfit. Recently, generative AI models have
received widespread attention, as they can generate fashion items for users to
complete an incomplete outfit or create a complete outfit. However, they have
limitations in terms of lacking diversity and relying on the supervised
learning paradigm. Recognizing this gap, we propose a novel framework
FashionDPO, which fine-tunes the fashion outfit generation model using direct
preference optimization. This framework aims to provide a general fine-tuning
approach to fashion generative models, refining a pre-trained fashion outfit
generation model using automatically generated feedback, without the need to
design a task-specific reward function. To make sure that the feedback is
comprehensive and objective, we design a multi-expert feedback generation
module which covers three evaluation perspectives, \ie quality, compatibility
and personalization. Experiments on two established datasets, \ie iFashion and
Polyvore-U, demonstrate the effectiveness of our framework in enhancing the
model's ability to align with users' personalized preferences while adhering to
fashion compatibility principles. Our code and model checkpoints are available
at https://github.com/Yzcreator/FashionDPO.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Building Russian Benchmark for Evaluation of Information Retrieval
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12879v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12879v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grigory Kovalev, Mikhail Tikhomirov, Evgeny Kozhevnikov, Max Kornilov, Natalia Loukachevitch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce RusBEIR, a comprehensive benchmark designed for zero-shot
evaluation of information retrieval (IR) models in the Russian language.
Comprising 17 datasets from various domains, it integrates adapted, translated,
and newly created datasets, enabling systematic comparison of lexical and
neural models. Our study highlights the importance of preprocessing for lexical
models in morphologically rich languages and confirms BM25 as a strong baseline
for full-document retrieval. Neural models, such as mE5-large and BGE-M3,
demonstrate superior performance on most datasets, but face challenges with
long-document retrieval due to input size constraints. RusBEIR offers a
unified, open-source framework that promotes research in Russian-language
information retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Lossless Token Pruning in Late-Interaction Retrieval Models <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12778v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12778v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zong, Benjamin Piwowarski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Late interaction neural IR models like ColBERT offer a competitive
effectiveness-efficiency trade-off across many benchmarks. However, they
require a huge memory space to store the contextual representation for all the
document tokens. Some works have proposed using either heuristics or
statistical-based techniques to prune tokens from each document. This however
doesn't guarantee that the removed tokens have no impact on the retrieval
score. Our work uses a principled approach to define how to prune tokens
without impacting the score between a document and a query. We introduce three
regularization losses, that induce a solution with high pruning ratios, as well
as two pruning strategies. We study them experimentally (in and out-domain),
showing that we can preserve ColBERT's performance while using only 30\% of the
tokens.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2025 Full Paper Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Validating LLM-Generated Relevance Labels for Educational Resource
  Search <span class="chip">WSDM '25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12732v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12732v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ratan J. Sebastian, Anett Hoppe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Manual relevance judgements in Information Retrieval are costly and require
expertise, driving interest in using Large Language Models (LLMs) for automatic
assessment. While LLMs have shown promise in general web search scenarios,
their effectiveness for evaluating domain-specific search results, such as
educational resources, remains unexplored. To investigate different ways of
including domain-specific criteria in LLM prompts for relevance judgement, we
collected and released a dataset of 401 human relevance judgements from a user
study involving teaching professionals performing search tasks related to
lesson planning. We compared three approaches to structuring these prompts: a
simple two-aspect evaluation baseline from prior work on using LLMs as
relevance judges, a comprehensive 12-dimensional rubric derived from
educational literature, and criteria directly informed by the study
participants. Using domain-specific frameworks, LLMs achieved strong agreement
with human judgements (Cohen's $\kappa$ up to 0.650), significantly
outperforming the baseline approach. The participant-derived framework proved
particularly robust, with GPT-3.5 achieving $\kappa$ scores of 0.639 and 0.613
for 10-dimension and 5-dimension versions respectively. System-level evaluation
showed that LLM judgements reliably identified top-performing retrieval
approaches (RBO scores 0.71-0.76) while maintaining reasonable discrimination
between systems (RBO 0.52-0.56). These findings suggest that LLMs can
effectively evaluate educational resources when prompted with domain-specific
criteria, though performance varies with framework complexity and input
structure.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented in the LLM4Eval Workshop Co-located with WSDM '25 in
  Hannover, Germany</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SimUSER: Simulating User Behavior with Large Language Models for
  Recommender System Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicolas Bougie, Narimasa Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems play a central role in numerous real-life applications,
yet evaluating their performance remains a significant challenge due to the gap
between offline metrics and online behaviors. Given the scarcity and limits
(e.g., privacy issues) of real user data, we introduce SimUSER, an agent
framework that serves as believable and cost-effective human proxies. SimUSER
first identifies self-consistent personas from historical data, enriching user
profiles with unique backgrounds and personalities. Then, central to this
evaluation are users equipped with persona, memory, perception, and brain
modules, engaging in interactions with the recommender system. SimUSER exhibits
closer alignment with genuine humans than prior work, both at micro and macro
levels. Additionally, we conduct insightful experiments to explore the effects
of thumbnails on click rates, the exposure effect, and the impact of reviews on
user engagement. Finally, we refine recommender system parameters based on
offline A/B test results, resulting in improved user engagement in the real
world.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking LLM-based Relevance Judgment Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12558v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12558v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Negar Arabzadeh, Charles L. A. Clarke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly deployed in both academic and
industry settings to automate the evaluation of information seeking systems,
particularly by generating graded relevance judgments. Previous work on
LLM-based relevance assessment has primarily focused on replicating graded
human relevance judgments through various prompting strategies. However, there
has been limited exploration of alternative assessment methods or comprehensive
comparative studies. In this paper, we systematically compare multiple
LLM-based relevance assessment methods, including binary relevance judgments,
graded relevance assessments, pairwise preference-based methods, and two
nugget-based evaluation methods~--~document-agnostic and document-dependent. In
addition to a traditional comparison based on system rankings using Kendall
correlations, we also examine how well LLM judgments align with human
preferences, as inferred from relevance grades. We conduct extensive
experiments on datasets from three TREC Deep Learning tracks 2019, 2020 and
2021 as well as the ANTIQUE dataset, which focuses on non-factoid open-domain
question answering. As part of our data release, we include relevance judgments
generated by both an open-source (Llama3.2b) and a commercial (gpt-4o) model.
Our goal is to \textit{reproduce} various LLM-based relevance judgment methods
to provide a comprehensive comparison. All code, data, and resources are
publicly available in our GitHub Repository at
https://github.com/Narabzad/llm-relevance-judgement-comparison.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Chemist-X: Large Language Model-empowered Agent for Reaction Condition
  Recommendation in Chemical Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10776v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10776v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kexin Chen, Jiamin Lu, Junyou Li, Xiaoran Yang, Yuyang Du, Kunyi Wang, Qiannuan Shi, Jiahui Yu, Lanqing Li, Jiezhong Qiu, Jianzhang Pan, Yi Huang, Qun Fang, Pheng Ann Heng, Guangyong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent AI research plots a promising future of automatic chemical reactions
within the chemistry society. This study proposes Chemist-X, a comprehensive AI
agent that automates the reaction condition optimization (RCO) task in chemical
synthesis with retrieval-augmented generation (RAG) technology and
AI-controlled wet-lab experiment executions. To begin with, as an emulation on
how chemical experts solve the RCO task, Chemist-X utilizes a novel RAG scheme
to interrogate available molecular and literature databases to narrow the
searching space for later processing. The agent then leverages a computer-aided
design (CAD) tool we have developed through a large language model (LLM)
supervised programming interface. With updated chemical knowledge obtained via
RAG, as well as the ability in using CAD tools, our agent significantly
outperforms conventional RCO AIs confined to the fixed knowledge within its
training data. Finally, Chemist-X interacts with the physical world through an
automated robotic system, which can validate the suggested chemical reaction
condition without human interventions. The control of the robotic system was
achieved with a novel algorithm we have developed for the equipment, which
relies on LLMs for reliable script generation. Results of our automatic wet-lab
experiments, achieved by fully LLM-supervised end-to-end operation with no
human in the lope, prove Chemist-X's ability in self-driving laboratories.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Argumentative Experience: Reducing Confirmation Bias on Controversial
  Issues through LLM-Generated Multi-Persona Debates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04629v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04629v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Shi, Houjiang Liu, Yian Wong, Utkarsh Mujumdar, Dan Zhang, Jacek Gwizdka, Matthew Lease
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are enabling designers to give life to exciting
new user experiences for information access. In this work, we present a system
that generates LLM personas to debate a topic of interest from different
perspectives. How might information seekers use and benefit from such a system?
Can centering information access around diverse viewpoints help to mitigate
thorny challenges like confirmation bias in which information seekers
over-trust search results matching existing beliefs? How do potential biases
and hallucinations in LLMs play out alongside human users who are also fallible
and possibly biased?
  Our study exposes participants to multiple viewpoints on controversial issues
via a mixed-methods, within-subjects study. We use eye-tracking metrics to
quantitatively assess cognitive engagement alongside qualitative feedback.
Compared to a baseline search system, we see more creative interactions and
diverse information-seeking with our multi-persona debate system, which more
effectively reduces user confirmation bias and conviction toward their initial
beliefs. Overall, our study contributes to the emerging design space of
LLM-based information access systems, specifically investigating the potential
of simulated personas to promote greater exposure to information diversity,
emulate collective intelligence, and mitigate bias in information seeking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ dsld: A Socially Relevant Tool for Teaching Statistics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04228v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04228v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taha Abdullah, Arjun Ashok, Brandon Zarate, Shubhada Martha, Billy Ouattara, Norman Matloff, Aditya Mittal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing power of data science can play a crucial role in addressing
social discrimination, necessitating nuanced understanding and effective
mitigation strategies for biases. "Data Science Looks At Discrimination" (DSLD)
is an R and Python package designed to provide users with a comprehensive
toolkit of statistical and graphical methods for assessing possible
discrimination related to protected groups such as race, gender, and age. The
package addresses critical issues by identifying and mitigating confounders and
reducing bias against protected groups in prediction algorithms.
  In educational settings, DSLD offers instructors powerful tools to teach
statistical principles through motivating real world examples of discrimination
analysis. The inclusion of an 80 page Quarto book further supports users from
statistics educators to legal professionals in effectively applying these
analytical tools to real world scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be submitted to journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Comprehending Knowledge Graphs with Large Language Models for
  Recommender Systems <span class="chip">SIGIR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12229v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12229v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes.
Second, existing methods convert textual information in KGs into IDs, resulting
in the loss of natural semantic connections between different items. Third,
existing methods struggle to capture high-order connections in the global KG.
To address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) to improve KG-based recommendations. The
extensive knowledge and remarkable reasoning capabilities of LLMs enable our
method to supplement missing facts in KGs, and their powerful text
understanding abilities allow for better utilization of semantic information.
Specifically, CoLaKG extracts useful information from KGs at both local and
global levels. By employing the item-centered subgraph extraction and prompt
engineering, it can accurately understand the local information. In addition,
through the semantic-based retrieval module, each item is enriched by related
items from the entire knowledge graph, effectively harnessing global
information. Furthermore, the local and global information are effectively
integrated into the recommendation model through a representation fusion module
and a retrieval-augmented representation learning module, respectively.
Extensive experiments on four real-world datasets demonstrate the superiority
of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a full paper by SIGIR'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PATFinger: <span class="highlight-title">Prompt</span>-Adapted Transferable Fingerprinting against
  Unauthorized Multimodal <span class="highlight-title">Dataset</span> Usage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11509v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11509v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyi Zhang, Ju Jia, Xiaojun Jia, Yihao Huang, Xinfeng Li, Cong Wu, Lina Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The multimodal datasets can be leveraged to pre-train large-scale
vision-language models by providing cross-modal semantics. Current endeavors
for determining the usage of datasets mainly focus on single-modal dataset
ownership verification through intrusive methods and non-intrusive techniques,
while cross-modal approaches remain under-explored. Intrusive methods can adapt
to multimodal datasets but degrade model accuracy, while non-intrusive methods
rely on label-driven decision boundaries that fail to guarantee stable
behaviors for verification. To address these issues, we propose a novel
prompt-adapted transferable fingerprinting scheme from a training-free
perspective, called PATFinger, which incorporates the global optimal
perturbation (GOP) and the adaptive prompts to capture dataset-specific
distribution characteristics. Our scheme utilizes inherent dataset attributes
as fingerprints instead of compelling the model to learn triggers. The GOP is
derived from the sample distribution to maximize embedding drifts between
different modalities. Subsequently, our PATFinger re-aligns the adaptive prompt
with GOP samples to capture the cross-modal interactions on the carefully
crafted surrogate model. This allows the dataset owner to check the usage of
datasets by observing specific prediction behaviors linked to the PATFinger
during retrieval queries. Extensive experiments demonstrate the effectiveness
of our scheme against unauthorized multimodal dataset usage on various
cross-modal retrieval architectures by 30% over state-of-the-art baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncertainty Calibration for Counterfactual Propensity Estimation in
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.12973v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.12973v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenbo Hu, Xin Sun, Qiang liu, Le Wu, Liang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-click conversion rate (CVR) is a reliable indicator of online customers'
preferences, making it crucial for developing recommender systems. A major
challenge in predicting CVR is severe selection bias, arising from users'
inherent self-selection behavior and the system's item selection process. To
mitigate this issue, the inverse propensity score (IPS) is employed to weight
the prediction error of each observed instance. However, current propensity
score estimations are unreliable due to the lack of a quality measure. To
address this, we evaluate the quality of propensity scores from the perspective
of uncertainty calibration, proposing the use of Expected Calibration Error
(ECE) as a measure of propensity-score quality, which quantifies the extent to
which predicted probabilities are overconfident by assessing the difference
between predicted probabilities and actual observed frequencies. Miscalibrated
propensity scores can lead to distorted IPS weights, thereby compromising the
debiasing process in CVR prediction. In this paper, we introduce a
model-agnostic calibration framework for propensity-based debiasing of CVR
predictions. Theoretical analysis on bias and generalization bounds
demonstrates the superiority of calibrated propensity estimates over
uncalibrated ones. Experiments conducted on the Coat, Yahoo and KuaiRand
datasets show improved uncertainty calibration, as evidenced by lower ECE
values, leading to enhanced CVR prediction outcomes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is the accepted manuscript version of the IEEE TKDE paper. The
  final published version will be available at:
  https://doi.ieeecomputersociety.org/10.1109/TKDE.2025.3552658</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">14</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chain-of-Modality: Learning Manipulation Programs from Multimodal Human
  Videos with Vision-Language-Models <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13351v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13351v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Wang, Fei Xia, Wenhao Yu, Tingnan Zhang, Ruohan Zhang, C. Karen Liu, Li Fei-Fei, Jie Tan, Jacky Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning to perform manipulation tasks from human videos is a promising
approach for teaching robots. However, many manipulation tasks require changing
control parameters during task execution, such as force, which visual data
alone cannot capture. In this work, we leverage sensing devices such as
armbands that measure human muscle activities and microphones that record
sound, to capture the details in the human manipulation process, and enable
robots to extract task plans and control parameters to perform the same task.
To achieve this, we introduce Chain-of-Modality (CoM), a prompting strategy
that enables Vision Language Models to reason about multimodal human
demonstration data -- videos coupled with muscle or audio signals. By
progressively integrating information from each modality, CoM refines a task
plan and generates detailed control parameters, enabling robots to perform
manipulation tasks based on a single multimodal human video prompt. Our
experiments show that CoM delivers a threefold improvement in accuracy for
extracting task plans and control parameters compared to baselines, with strong
generalization to new task setups and objects in real-world robot experiments.
Videos and code are available at https://chain-of-modality.github.io
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SemCORE: A Semantic-Enhanced Generative Cross-Modal Retrieval Framework
  with MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13172v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13172v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxuan Li, Yi Bin, Yunshan Ma, Guoqing Wang, Yang Yang, See-Kiong Ng, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-modal retrieval (CMR) is a fundamental task in multimedia research,
focused on retrieving semantically relevant targets across different
modalities. While traditional CMR methods match text and image via
embedding-based similarity calculations, recent advancements in pre-trained
generative models have established generative retrieval as a promising
alternative. This paradigm assigns each target a unique identifier and
leverages a generative model to directly predict identifiers corresponding to
input queries without explicit indexing. Despite its great potential, current
generative CMR approaches still face semantic information insufficiency in both
identifier construction and generation processes. To address these limitations,
we propose a novel unified Semantic-enhanced generative Cross-mOdal REtrieval
framework (SemCORE), designed to unleash the semantic understanding
capabilities in generative cross-modal retrieval task. Specifically, we first
construct a Structured natural language IDentifier (SID) that effectively
aligns target identifiers with generative models optimized for natural language
comprehension and generation. Furthermore, we introduce a Generative Semantic
Verification (GSV) strategy enabling fine-grained target discrimination.
Additionally, to the best of our knowledge, SemCORE is the first framework to
simultaneously consider both text-to-image and image-to-text retrieval tasks
within generative cross-modal retrieval. Extensive experiments demonstrate that
our framework outperforms state-of-the-art generative cross-modal retrieval
methods. Notably, SemCORE achieves substantial improvements across benchmark
datasets, with an average increase of 8.65 points in Recall@1 for text-to-image
retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqi Dong, Bangbang Yang, Zesong Yang, Yuan Li, Tao Hu, Hujun Bao, Yuewen Ma, Zhaopeng Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene-level 3D generation represents a critical frontier in multimedia and
computer graphics, yet existing approaches either suffer from limited object
categories or lack editing flexibility for interactive applications. In this
paper, we present HiScene, a novel hierarchical framework that bridges the gap
between 2D image generation and 3D object generation and delivers high-fidelity
scenes with compositional identities and aesthetic scene content. Our key
insight is treating scenes as hierarchical "objects" under isometric views,
where a room functions as a complex object that can be further decomposed into
manipulatable items. This hierarchical approach enables us to generate 3D
content that aligns with 2D representations while maintaining compositional
structure. To ensure completeness and spatial alignment of each decomposed
instance, we develop a video-diffusion-based amodal completion technique that
effectively handles occlusions and shadows between objects, and introduce shape
prior injection to ensure spatial coherence within the scene. Experimental
results demonstrate that our method produces more natural object arrangements
and complete object instances suitable for interactive applications, while
maintaining physical plausibility and alignment with user inputs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project webpage: https://zju3dv.github.io/hiscene/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FashionDPO:Fine-tune Fashion Outfit Generation Model using Direct
  Preference Optimization <span class="chip">SIGIR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12900v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12900v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingzhe Yu, Yunshan Ma, Lei Wu, Changshuo Wang, Xue Li, Lei Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized outfit generation aims to construct a set of compatible and
personalized fashion items as an outfit. Recently, generative AI models have
received widespread attention, as they can generate fashion items for users to
complete an incomplete outfit or create a complete outfit. However, they have
limitations in terms of lacking diversity and relying on the supervised
learning paradigm. Recognizing this gap, we propose a novel framework
FashionDPO, which fine-tunes the fashion outfit generation model using direct
preference optimization. This framework aims to provide a general fine-tuning
approach to fashion generative models, refining a pre-trained fashion outfit
generation model using automatically generated feedback, without the need to
design a task-specific reward function. To make sure that the feedback is
comprehensive and objective, we design a multi-expert feedback generation
module which covers three evaluation perspectives, \ie quality, compatibility
and personalization. Experiments on two established datasets, \ie iFashion and
Polyvore-U, demonstrate the effectiveness of our framework in enhancing the
model's ability to align with users' personalized preferences while adhering to
fashion compatibility principles. Our code and model checkpoints are available
at https://github.com/Yzcreator/FashionDPO.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Saliency-Aware Diffusion Reconstruction for Effective Invisible
  Watermark Removal 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12809v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12809v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Inzamamul Alam, Md Tanvir Islam, Simon S. Woo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As digital content becomes increasingly ubiquitous, the need for robust
watermark removal techniques has grown due to the inadequacy of existing
embedding techniques, which lack robustness. This paper introduces a novel
Saliency-Aware Diffusion Reconstruction (SADRE) framework for watermark
elimination on the web, combining adaptive noise injection, region-specific
perturbations, and advanced diffusion-based reconstruction. SADRE disrupts
embedded watermarks by injecting targeted noise into latent representations
guided by saliency masks although preserving essential image features. A
reverse diffusion process ensures high-fidelity image restoration, leveraging
adaptive noise levels determined by watermark strength. Our framework is
theoretically grounded with stability guarantees and achieves robust watermark
removal across diverse scenarios. Empirical evaluations on state-of-the-art
(SOTA) watermarking techniques demonstrate SADRE's superiority in balancing
watermark disruption and image quality. SADRE sets a new benchmark for
watermark elimination, offering a flexible and reliable solution for real-world
web content. Code is available
on~\href{https://github.com/inzamamulDU/SADRE}{\textbf{https://github.com/inzamamulDU/SADRE}}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at The Web Conference 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Cross-Modal Interaction Between Music and Multimodal Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sifei Li, Mining Tan, Feier Shen, Minyan Luo, Zijiao Yin, Fan Tang, Weiming Dong, Changsheng Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal learning has driven innovation across various industries,
particularly in the field of music. By enabling more intuitive interaction
experiences and enhancing immersion, it not only lowers the entry barriers to
the music but also increases its overall appeal. This survey aims to provide a
comprehensive review of multimodal tasks related to music, outlining how music
contributes to multimodal learning and offering insights for researchers
seeking to expand the boundaries of computational music. Unlike text and
images, which are often semantically or visually intuitive, music primarily
interacts with humans through auditory perception, making its data
representation inherently less intuitive. Therefore, this paper first
introduces the representations of music and provides an overview of music
datasets. Subsequently, we categorize cross-modal interactions between music
and multimodal data into three types: music-driven cross-modal interactions,
music-oriented cross-modal interactions, and bidirectional music cross-modal
interactions. For each category, we systematically trace the development of
relevant sub-tasks, analyze existing limitations, and discuss emerging trends.
Furthermore, we provide a comprehensive summary of datasets and evaluation
metrics used in multimodal tasks related to music, offering benchmark
references for future research. Finally, we discuss the current challenges in
cross-modal interactions involving music and propose potential directions for
future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SmartFreeEdit: Mask-Free Spatial-Aware Image Editing with Complex
  Instruction Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianqian Sun, Jixiang Luo, Dell Zhang, Xuelong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in image editing have utilized large-scale multimodal
models to enable intuitive, natural instruction-driven interactions. However,
conventional methods still face significant challenges, particularly in spatial
reasoning, precise region segmentation, and maintaining semantic consistency,
especially in complex scenes. To overcome these challenges, we introduce
SmartFreeEdit, a novel end-to-end framework that integrates a multimodal large
language model (MLLM) with a hypergraph-enhanced inpainting architecture,
enabling precise, mask-free image editing guided exclusively by natural
language instructions. The key innovations of SmartFreeEdit include:(1)the
introduction of region aware tokens and a mask embedding paradigm that enhance
the spatial understanding of complex scenes;(2) a reasoning segmentation
pipeline designed to optimize the generation of editing masks based on natural
language instructions;and (3) a hypergraph-augmented inpainting module that
ensures the preservation of both structural integrity and semantic coherence
during complex edits, overcoming the limitations of local-based image
generation. Extensive experiments on the Reason-Edit benchmark demonstrate that
SmartFreeEdit surpasses current state-of-the-art methods across multiple
evaluation metrics, including segmentation accuracy, instruction adherence, and
visual quality preservation, while addressing the issue of local information
focus and improving global consistency in the edited image. Our project will be
available at https://github.com/smileformylove/SmartFreeEdit.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Harmony: A Unified Framework for Modality Incremental Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.13218v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.13218v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaguang Song, Xiaoshan Yang, Dongmei Jiang, Yaowei Wang, Changsheng Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Incremental learning aims to enable models to continuously acquire knowledge
from evolving data streams while preserving previously learned capabilities.
While current research predominantly focuses on unimodal incremental learning
and multimodal incremental learning where the modalities are consistent,
real-world scenarios often present data from entirely new modalities, posing
additional challenges. This paper investigates the feasibility of developing a
unified model capable of incremental learning across continuously evolving
modal sequences. To this end, we introduce a novel paradigm called Modality
Incremental Learning (MIL), where each learning stage involves data from
distinct modalities. To address this task, we propose a novel framework named
Harmony, designed to achieve modal alignment and knowledge retention, enabling
the model to reduce the modal discrepancy and learn from a sequence of distinct
modalities, ultimately completing tasks across multiple modalities within a
unified framework. Our approach introduces the adaptive compatible feature
modulation and cumulative modal bridging. Through constructing historical modal
features and performing modal knowledge accumulation and alignment, the
proposed components collaboratively bridge modal differences and maintain
knowledge retention, even with solely unimodal data available at each learning
phase.These components work in concert to establish effective modality
connections and maintain knowledge retention, even when only unimodal data is
available at each learning stage. Extensive experiments on the MIL task
demonstrate that our proposed method significantly outperforms existing
incremental learning methods, validating its effectiveness in MIL scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PriorDiffusion: Leverage Language Prior in Diffusion Models for
  Monocular Depth Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16750v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16750v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyao Zeng, Jingcheng Ni, Daniel Wang, Patrick Rim, Younjoon Chung, Fengyu Yang, Byung-Woo Hong, Alex Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional monocular depth estimation suffers from inherent ambiguity and
visual nuisance. We argue that language prior can enhance monocular depth
estimation by leveraging the inductive bias learned during the text-to-image
pre-training of diffusion models. The ability of these models to generate
images that align with text indicates that they have learned the spatial
relationships, size, and shape of specified objects, which can be applied to
improve depth estimation. Thus, we propose PriorDiffusion, using a pre-trained
text-to-image diffusion model that takes both images and corresponding text
descriptions to infer affine-invariant depth through a denoising process. We
also show that language prior enhances the model's perception of specific
regions of images that users care about and describe. Simultaneously, language
prior acts as a constraint to accelerate the convergence of both training and
the inference diffusion trajectory. By training on HyperSim and Virtual KITTI,
we achieve faster training convergence, fewer inference diffusion steps, and
state-of-the-art zero-shot performance across NYUv2, KITTI, ETH3D, and ScanNet.
Code will be released upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal LLMs Can Reason about Aesthetics in Zero-Shot 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.09012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.09012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruixiang Jiang, Changwen Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid progress of generative art has democratized the creation of
visually pleasing imagery. However, achieving genuine artistic impact - the
kind that resonates with viewers on a deeper, more meaningful level - requires
a sophisticated aesthetic sensibility. This sensibility involves a
multi-faceted reasoning process extending beyond mere visual appeal, which is
often overlooked by current computational models. This paper pioneers an
approach to capture this complex process by investigating how the reasoning
capabilities of Multimodal LLMs (MLLMs) can be effectively elicited for
aesthetic judgment. Our analysis reveals a critical challenge: MLLMs exhibit a
tendency towards hallucinations during aesthetic reasoning, characterized by
subjective opinions and unsubstantiated artistic interpretations. We further
demonstrate that these limitations can be overcome by employing an
evidence-based, objective reasoning process, as substantiated by our proposed
baseline, ArtCoT. MLLMs prompted by this principle produce multi-faceted and
in-depth aesthetic reasoning that aligns significantly better with human
judgment. These findings have direct applications in areas such as AI art
tutoring and as reward models for generative art. Ultimately, our work paves
the way for AI systems that can truly understand, appreciate, and generate
artworks that align with the sensible human aesthetic standard.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WIP, Homepage https://github.com/songrise/MLLM4Art</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Fake News Video Explanation: <span class="highlight-title">Dataset</span>, Analysis and Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.08514v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.08514v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lizhi Chen, Zhong Qian, Peifeng Li, Qiaoming Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal fake news videos are difficult to interpret because they require
comprehensive consideration of the correlation and consistency between multiple
modes. Existing methods deal with fake news videos as a classification problem,
but it's not clear why news videos are identified as fake. Without proper
explanation, the end user may not understand the underlying meaning of the
falsehood. Therefore, we propose a new problem - Fake news video Explanation
(FNVE) - given a multimodal news post containing a video and title, our goal is
to generate natural language explanations to reveal the falsity of the news
video. To that end, we developed FakeVE, a new dataset of 2,672 fake news video
posts that can definitively explain four real-life fake news video aspects. In
order to understand the characteristics of fake news video explanation, we
conducted an exploratory analysis of FakeVE from different perspectives. In
addition, we propose a Multimodal Relation Graph Transformer (MRGT) based on
the architecture of multimodal Transformer to benchmark FakeVE. The empirical
results show that the results of the various benchmarks (adopted by FakeVE) are
convincing and provide a detailed analysis of the differences in explanation
generation of the benchmark models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal
  Large Language Models <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.07521v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.07521v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiang Lin, Jingdong Sun, Zhi-Qi Cheng, Jue Wang, Haomin Liang, Zebang Cheng, Yifei Dong, Jun-Yan He, Xiaojiang Peng, Xian-Sheng Hua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most existing emotion analysis emphasizes which emotion arises (e.g., happy,
sad, angry) but neglects the deeper why. We propose Emotion Interpretation
(EI), focusing on causal factors-whether explicit (e.g., observable objects,
interpersonal interactions) or implicit (e.g., cultural context, off-screen
events)-that drive emotional responses. Unlike traditional emotion recognition,
EI tasks require reasoning about triggers instead of mere labeling. To
facilitate EI research, we present EIBench, a large-scale benchmark
encompassing 1,615 basic EI samples and 50 complex EI samples featuring
multifaceted emotions. Each instance demands rationale-based explanations
rather than straightforward categorization. We further propose a Coarse-to-Fine
Self-Ask (CFSA) annotation pipeline, which guides Vision-Language Models
(VLLMs) through iterative question-answer rounds to yield high-quality labels
at scale. Extensive evaluations on open-source and proprietary large language
models under four experimental settings reveal consistent performance
gaps-especially for more intricate scenarios-underscoring EI's potential to
enrich empathetic, context-aware AI applications. Our benchmark and methods are
publicly available at: https://github.com/Lum1104/EIBench, offering a
foundation for advanced multimodal causal analysis and next-generation
affective computing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR Workshop NEXD 2025. 21 pages, Project:
  https://github.com/Lum1104/EIBench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal
  Perspective <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10291v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10291v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate interpretation and visualization of human instructions are crucial
for text-to-image (T2I) synthesis. However, current models struggle to capture
semantic variations from word order changes, and existing evaluations, relying
on indirect metrics like text-image similarity, fail to reliably assess these
challenges. This often obscures poor performance on complex or uncommon
linguistic patterns by the focus on frequent word combinations. To address
these deficiencies, we propose a novel metric called SemVarEffect and a
benchmark named SemVarBench, designed to evaluate the causality between
semantic variations in inputs and outputs in T2I synthesis. Semantic variations
are achieved through two types of linguistic permutations, while avoiding
easily predictable literal variations. Experiments reveal that the
CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.
Semantic variations in object relations are less understood than attributes,
scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in
UNet or Transformers plays a crucial role in handling semantic variations, a
factor previously overlooked by a focus on textual encoders. Our work
establishes an effective evaluation framework that advances the T2I synthesis
community's exploration of human instruction understanding. Our benchmark and
code are available at https://github.com/zhuxiangru/SemVarBench .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scene-Text Grounding for Text-Based Video Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14319v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14319v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheng Zhou, Junbin Xiao, Xun Yang, Peipei Song, Dan Guo, Angela Yao, Meng Wang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing efforts in text-based video question answering (TextVideoQA) are
criticized for their opaque decisionmaking and heavy reliance on scene-text
recognition. In this paper, we propose to study Grounded TextVideoQA by forcing
models to answer questions and spatio-temporally localize the relevant
scene-text regions, thus decoupling QA from scenetext recognition and promoting
research towards interpretable QA. The task has three-fold significance. First,
it encourages scene-text evidence versus other short-cuts for answer
predictions. Second, it directly accepts scene-text regions as visual answers,
thus circumventing the problem of ineffective answer evaluation by stringent
string matching. Third, it isolates the challenges inherited in VideoQA and
scene-text recognition. This enables the diagnosis of the root causes for
failure predictions, e.g., wrong QA or wrong scene-text recognition? To achieve
Grounded TextVideoQA, we propose the T2S-QA model that highlights a
disentangled temporal-to-spatial contrastive learning strategy for
weakly-supervised scene-text grounding and grounded TextVideoQA. To facilitate
evaluation, we construct a new dataset ViTXT-GQA which features 52K scene-text
bounding boxes within 2.2K temporal segments related to 2K questions and 729
videos. With ViTXT-GQA, we perform extensive experiments and demonstrate the
severe limitations of existing techniques in Grounded TextVideoQA. While T2S-QA
achieves superior results, the large performance gap with human leaves ample
space for improvement. Our further analysis of oracle scene-text inputs posits
that the major challenge is scene-text recognition. To advance the research of
Grounded TextVideoQA, our dataset and code are at
https://github.com/zhousheng97/ViTXT-GQA.git
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-16T00:00:00Z">2025-04-16</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Human-AI Comparative Analysis of <span class="highlight-title">Prompt</span> Sensitivity in LLM-Based
  Relevance Judgment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12408v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12408v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Negar Arabzadeh, Charles L. A . Clarke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly used to automate relevance
judgments for information retrieval (IR) tasks, often demonstrating agreement
with human labels that approaches inter-human agreement. To assess the
robustness and reliability of LLM-based relevance judgments, we systematically
investigate impact of prompt sensitivity on the task. We collected prompts for
relevance assessment from 15 human experts and 15 LLMs across three tasks~ --
~binary, graded, and pairwise~ -- ~yielding 90 prompts in total. After
filtering out unusable prompts from three humans and three LLMs, we employed
the remaining 72 prompts with three different LLMs as judges to label
document/query pairs from two TREC Deep Learning Datasets (2020 and 2021). We
compare LLM-generated labels with TREC official human labels using Cohen's
$\kappa$ and pairwise agreement measures. In addition to investigating the
impact of prompt variations on agreement with human labels, we compare human-
and LLM-generated prompts and analyze differences among different LLMs as
judges. We also compare human- and LLM-generated prompts with the standard
UMBRELA prompt used for relevance assessment by Bing and TREC 2024 Retrieval
Augmented Generation (RAG) Track. To support future research in LLM-based
evaluation, we release all data and prompts at
https://github.com/Narabzad/prompt-sensitivity-relevance-judgements/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Clarifying Ambiguities: on the Role of Ambiguity Types in <span class="highlight-title">Prompt</span>ing
  Methods for Clarification Generation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12113v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12113v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anfu Tang, Laure Soulier, Vincent Guigue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In information retrieval (IR), providing appropriate clarifications to better
understand users' information needs is crucial for building a proactive
search-oriented dialogue system. Due to the strong in-context learning ability
of large language models (LLMs), recent studies investigate prompting methods
to generate clarifications using few-shot or Chain of Thought (CoT) prompts.
However, vanilla CoT prompting does not distinguish the characteristics of
different information needs, making it difficult to understand how LLMs resolve
ambiguities in user queries. In this work, we focus on the concept of ambiguity
for clarification, seeking to model and integrate ambiguities in the
clarification process. To this end, we comprehensively study the impact of
prompting schemes based on reasoning and ambiguity for clarification. The idea
is to enhance the reasoning abilities of LLMs by limiting CoT to predict first
ambiguity types that can be interpreted as instructions to clarify, then
correspondingly generate clarifications. We name this new prompting scheme
Ambiguity Type-Chain of Thought (AT-CoT). Experiments are conducted on various
datasets containing human-annotated clarifying questions to compare AT-CoT with
multiple baselines. We also perform user simulations to implicitly measure the
quality of generated clarifications under various IR scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 3 figures. Accepted at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Compound Retrieval Systems <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12063v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12063v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harrie Oosterhuis, Rolf Jagerman, Zhen Qin, Xuanhui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern retrieval systems do not rely on a single ranking model to construct
their rankings. Instead, they generally take a cascading approach where a
sequence of ranking models are applied in multiple re-ranking stages. Thereby,
they balance the quality of the top-K ranking with computational costs by
limiting the number of documents each model re-ranks. However, the cascading
approach is not the only way models can interact to form a retrieval system.
  We propose the concept of compound retrieval systems as a broader class of
retrieval systems that apply multiple prediction models. This encapsulates
cascading models but also allows other types of interactions than top-K
re-ranking. In particular, we enable interactions with large language models
(LLMs) which can provide relative relevance comparisons. We focus on the
optimization of compound retrieval system design which uniquely involves
learning where to apply the component models and how to aggregate their
predictions into a final ranking. This work shows how our compound approach can
combine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM
relevance predictions, while optimizing a given ranking metric and efficiency
target. Our experimental results show optimized compound retrieval systems
provide better trade-offs between effectiveness and efficiency than cascading
approaches, even when applied in a self-supervised manner.
  With the introduction of compound retrieval systems, we hope to inspire the
information retrieval field to more out-of-the-box thinking on how prediction
models can interact to form rankings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Recommendation with Continuous-Token Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12007v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12007v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haohao Qu, Wenqi Fan, Shanru Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, there has been a significant trend toward using large
language model (LLM)-based recommender systems (RecSys). Current research
primarily focuses on representing complex user-item interactions within a
discrete space to align with the inherent discrete nature of language models.
However, this approach faces limitations due to its discrete nature: (i)
information is often compressed during discretization; (ii) the tokenization
and generation for the vast number of users and items in real-world scenarios
are constrained by a limited vocabulary. Embracing continuous data presents a
promising alternative to enhance expressive capabilities, though this approach
is still in its early stages. To address this gap, we propose a novel
framework, DeftRec, which incorporates \textbf{de}noising di\textbf{f}fusion
models to enable LLM-based RecSys to seamlessly support continuous
\textbf{t}oken as input and target. First, we introduce a robust tokenizer with
a masking operation and an additive K-way architecture to index users and
items, capturing their complex collaborative relationships into continuous
tokens. Crucially, we develop a denoising diffusion model to process user
preferences within continuous domains by conditioning on reasoning content from
pre-trained large language model. During the denoising process, we reformulate
the objective to include negative interactions, building a comprehensive
understanding of user preferences for effective and accurate recommendation
generation. Finally, given a continuous token as output, recommendations can be
easily generated through score-based retrieval. Extensive experiments
demonstrate the effectiveness of the proposed methods, showing that DeftRec
surpasses competitive benchmarks, including both traditional and emerging
LLM-based RecSys.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking LLM-Based Recommendations: A Query Generation-Based,
  Training-Free Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11889v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11889v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donghee Han, Hwanjun Song, Mun Yong Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing large language model LLM-based recommendation methods face several
challenges, including inefficiency in handling large candidate pools,
sensitivity to item order within prompts ("lost in the middle" phenomenon) poor
scalability, and unrealistic evaluation due to random negative sampling. To
address these issues, we propose a Query-to-Recommendation approach that
leverages LLMs to generate personalized queries for retrieving relevant items
from the entire candidate pool, eliminating the need for candidate
pre-selection. This method can be integrated into an ID-based recommendation
system without additional training, enhances recommendation performance and
diversity through LLMs' world knowledge, and performs well even for less
popular item groups. Experiments on three datasets show up to 57 percent
improvement, with an average gain of 31 percent, demonstrating strong zero-shot
performance and further gains when ensembled with existing models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Résumé abstractif à partir d'une transcription audio 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11803v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11803v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilia Derkach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Currently, large language models are gaining popularity, their achievements
are used in many areas, ranging from text translation to generating answers to
queries. However, the main problem with these new machine learning algorithms
is that training such models requires large computing resources that only large
IT companies have. To avoid this problem, a number of methods (LoRA,
quantization) have been proposed so that existing models can be effectively
fine-tuned for specific tasks. In this paper, we propose an E2E (end to end)
audio summarization model using these techniques. In addition, this paper
examines the effectiveness of these approaches to the problem under
consideration and draws conclusions about the applicability of these methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, in French language, 8 tables, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A New Paradigm of User-Centric Wireless Communication Driven by Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11696v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11696v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuiyuan Ding, Caili Guo, Yang Yang, Wuxia Hu, Yonina C. Eldar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The next generation of wireless communications seeks to deeply integrate
artificial intelligence (AI) with user-centric communication networks, with the
goal of developing AI-native networks that more accurately address user
requirements. The rapid development of large language models (LLMs) offers
significant potential in realizing these goals. However, existing efforts that
leverage LLMs for wireless communication often overlook the considerable gap
between human natural language and the intricacies of real-world communication
systems, thus failing to fully exploit the capabilities of LLMs. To address
this gap, we propose a novel LLM-driven paradigm for wireless communication
that innovatively incorporates the nature language to structured query language
(NL2SQL) tool. Specifically, in this paradigm, user personal requirements is
the primary focus. Upon receiving a user request, LLMs first analyze the user
intent in terms of relevant communication metrics and system parameters.
Subsequently, a structured query language (SQL) statement is generated to
retrieve the specific parameter values from a high-performance real-time
database. We further utilize LLMs to formulate and solve an optimization
problem based on the user request and the retrieved parameters. The solution to
this optimization problem then drives adjustments in the communication system
to fulfill the user's requirements. To validate the feasibility of the proposed
paradigm, we present a prototype system. In this prototype, we consider
user-request centric semantic communication (URC-SC) system in which a dynamic
semantic representation network at the physical layer adapts its encoding depth
to meet user requirements. Additionally, two LLMs are employed to analyze user
requests and generate SQL statements, respectively. Simulation results
demonstrate the effectiveness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PhishLang: A Real-Time, Fully Client-Side Phishing Detection Framework
  Using Mobile<span class="highlight-title">BERT</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05667v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05667v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sayak Saha Roy, Shirin Nilizadeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce PhishLang, the first fully client-side
anti-phishing framework built on a lightweight ensemble framework that utilizes
advanced language models to analyze the contextual features of a website's
source code and URL. Unlike traditional heuristic or machine learning
approaches that rely on static features and struggle to adapt to evolving
threats, or deep learning models that are computationally intensive, our
approach utilizes MobileBERT, a fast and memory-efficient variant of the BERT
architecture, to capture nuanced features indicative of phishing attacks. To
further enhance detection accuracy, PhishLang employs a multi-modal ensemble
approach, combining both the URL and Source detection models. This architecture
ensures robustness by allowing one model to compensate for scenarios where the
other may fail, or if both models provide ambiguous inferences. As a result,
PhishLang excels at detecting both regular and evasive phishing threats,
including zero-day attacks, outperforming popular anti-phishing tools, while
operating without relying on external blocklists and safeguarding user privacy
by ensuring that browser history remains entirely local and unshared. We
release PhishLang as a Chromium browser extension and also open-source the
framework to aid the research community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CSPLADE: Learned Sparse Retrieval with Causal Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10816v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10816v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhichao Xu, Aosong Feng, Yijun Tian, Haibo Ding, Lin Lee Cheong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, dense retrieval has been the focus of information retrieval
(IR) research. While effective, dense retrieval produces uninterpretable dense
vectors, and suffers from the drawback of large index size. Learned sparse
retrieval (LSR) has emerged as promising alternative, achieving competitive
retrieval performance while also being able to leverage the classical inverted
index data structure for efficient retrieval. However, limited works have
explored scaling LSR beyond BERT scale. In this work, we identify two
challenges in training large language models (LLM) for LSR: (1) training
instability during the early stage of contrastive training; (2) suboptimal
performance due to pre-trained LLM's unidirectional attention. To address these
challenges, we propose two corresponding techniques: (1) a lightweight
adaptation training phase to eliminate training instability; (2) two model
variants to enable bidirectional information. With these techniques, we are
able to train LSR models with 8B scale LLM, and achieve competitive retrieval
performance with reduced index size. Furthermore, we are among the first to
analyze the performance-efficiency tradeoff of LLM-based LSR model through the
lens of model quantization. Our findings provide insights into adapting LLMs
for efficient retrieval modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Taxonomy and Analysis of Sensitive User Queries in Generative AI Search <span class="chip">NAACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08672v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08672v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hwiyeol Jo, Taiwoo Park, Hyunwoo Lee, Nayoung Choi, Changbong Kim, Ohjoon Kwon, Donghyeon Jeon, Eui-Hyeon Lee, Kyoungho Shin, Sun Suk Lim, Kyungmi Kim, Jihye Lee, Sun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although there has been a growing interest among industries in integrating
generative LLMs into their services, limited experience and scarcity of
resources act as a barrier in launching and servicing large-scale LLM-based
services. In this paper, we share our experiences in developing and operating
generative AI models within a national-scale search engine, with a specific
focus on the sensitiveness of user queries. We propose a taxonomy for sensitive
search queries, outline our approaches, and present a comprehensive analysis
report on sensitive queries from actual users. We believe that our experiences
in launching generative AI search systems can contribute to reducing the
barrier in building generative LLM-based services.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL2025(Findings), corrected typo in co-corresponding authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Field Adaptive Retrieval <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20056v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20056v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Millicent Li, Tongfei Chen, Benjamin Van Durme, Patrick Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document retrieval for tasks such as search and retrieval-augmented
generation typically involves datasets that are unstructured: free-form text
without explicit internal structure in each document. However, documents can
have a structured form, consisting of fields such as an article title, message
body, or HTML header. To address this gap, we introduce Multi-Field Adaptive
Retrieval (MFAR), a flexible framework that accommodates any number of and any
type of document indices on structured data. Our framework consists of two main
steps: (1) the decomposition of an existing document into fields, each indexed
independently through dense and lexical methods, and (2) learning a model which
adaptively predicts the importance of a field by conditioning on the document
query, allowing on-the-fly weighting of the most likely field(s). We find that
our approach allows for the optimized use of dense versus lexical
representations across field types, significantly improves in document ranking
over a number of existing retrievers, and achieves state-of-the-art performance
for multi-field structured data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025, Spotlight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Think Before Recommend: Unleashing the Latent Reasoning Power for
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.22675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.22675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiakai Tang, Sunhao Dai, Teng Shi, Jun Xu, Xu Chen, Wen Chen, Wu Jian, Yuning Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential Recommendation (SeqRec) aims to predict the next item by capturing
sequential patterns from users' historical interactions, playing a crucial role
in many real-world recommender systems. However, existing approaches
predominantly adopt a direct forward computation paradigm, where the final
hidden state of the sequence encoder serves as the user representation. We
argue that this inference paradigm, due to its limited computational depth,
struggles to model the complex evolving nature of user preferences and lacks a
nuanced understanding of long-tail items, leading to suboptimal performance. To
address this issue, we propose \textbf{ReaRec}, the first inference-time
computing framework for recommender systems, which enhances user
representations through implicit multi-step reasoning. Specifically, ReaRec
autoregressively feeds the sequence's last hidden state into the sequential
recommender while incorporating special reasoning position embeddings to
decouple the original item encoding space from the multi-step reasoning space.
Moreover, we introduce two lightweight reasoning-based learning methods,
Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to
further effectively exploit ReaRec's reasoning potential. Extensive experiments
on five public real-world datasets and different SeqRec architectures
demonstrate the generality and effectiveness of our proposed ReaRec.
Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the
performance ceiling of multiple sequential recommendation backbones by
approximately 30\%-50\%. Thus, we believe this work can open a new and
promising avenue for future research in inference-time computing for sequential
recommendation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Personalized Conversational Sales Agents : Contextual User
  Profiling for Strategic Action 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.08754v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.08754v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tongyoung Kim, Jeongeun Lee, Soojin Yoon, Sunghwan Kim, Dongha Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Recommender Systems (CRSs) aim to engage users in dialogue to
provide tailored recommendations. While traditional CRSs focus on eliciting
preferences and retrieving items, real-world e-commerce interactions involve
more complex decision-making, where users consider multiple factors beyond
simple attributes. To bridge this gap, we introduce Conversational Sales
(CSales), a novel task that unifies preference elicitation, recommendation, and
persuasion to better support user decision-making. For a realistic evaluation
of CSales, we present CSUser, an LLM-based user simulator constructed from
real-world data, modeling diverse user profiles with needs and personalities.
Additionally, we propose CSI, a conversational sales agent that proactively
infers contextual profiles through dialogue for personalized action planning.
Extensive experiments demonstrate that CSUser effectively replicates real-world
users and emphasize the importance of contextual profiling for strategic action
selection, ultimately driving successful purchases in e-commerce.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AI-Driven Sentiment Analytics: Unlocking Business Value in the
  E-Commerce Landscape_v1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.08738v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.08738v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianye Wu, Chengxuan Xia, Sixuan Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid growth of e-commerce has led to an overwhelming volume of customer
feedback, from product reviews to service interactions. Extracting meaningful
insights from this data is crucial for businesses aiming to improve customer
satisfaction and optimize decision-making. This paper presents an AI-driven
sentiment analysis system designed specifically for e-commerce applications,
balancing accuracy with interpretability. Our approach integrates traditional
machine learning techniques with modern deep learning models, allowing for a
more nuanced understanding of customer sentiment while ensuring transparency in
decision-making. Experimental results show that our system outperforms standard
sentiment analysis methods, achieving an accuracy of 89.7% on diverse,
large-scale datasets. Beyond technical performance, real-world implementation
across multiple e-commerce platforms demonstrates tangible improvements in
customer engagement and operational efficiency. This study highlights both the
potential and the challenges of applying AI to sentiment analysis in a
commercial setting, offering insights into practical deployment strategies and
areas for future refinement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Distributed Retrieval-Augmented Generation for Enhancing
  Language Model Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11197v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11197v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shangyu Liu, Zhenzhe Zheng, Xiaoyao Huang, Fan Wu, Guihai Chen, Jie Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Small language models (SLMs) support efficient deployments on
resource-constrained edge devices, but their limited capacity compromises
inference performance. Retrieval-augmented generation (RAG) is a promising
solution to enhance model performance by integrating external databases,
without requiring intensive on-device model retraining. However, large-scale
public databases and user-specific private contextual documents are typically
located on the cloud and the device separately, while existing RAG
implementations are primarily centralized. To bridge this gap, we propose
DRAGON, a distributed RAG framework to enhance on-device SLMs through both
general and personal knowledge without the risk of leaking document privacy.
Specifically, DRAGON decomposes multi-document RAG into multiple parallel token
generation processes performed independently and locally on the cloud and the
device, and employs a newly designed Speculative Aggregation, a dual-side
speculative algorithm to avoid frequent output synchronization between the
cloud and device. A new scheduling algorithm is further introduced to identify
the optimal aggregation side based on real-time network conditions. Evaluations
on real-world hardware testbed demonstrate a significant performance
improvement of DRAGON-up to 1.9x greater gains over standalone SLM compared to
the centralized RAG, substantial reduction in per-token latency, and negligible
Time to First Token (TTFT) overhead.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Realistic Low-Light Image Enhancement via ISP Driven Data
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.12204v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.12204v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihua Wang, Yu Long, Qinghua Lin, Kai Zhang, Yazhu Zhang, Yuming Fang, Li Liu, Xiaochun Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks (DNNs) have recently become the leading method for
low-light image enhancement (LLIE). However, despite significant progress,
their outputs may still exhibit issues such as amplified noise, incorrect white
balance, or unnatural enhancements when deployed in real world applications. A
key challenge is the lack of diverse, large scale training data that captures
the complexities of low-light conditions and imaging pipelines. In this paper,
we propose a novel image signal processing (ISP) driven data synthesis pipeline
that addresses these challenges by generating unlimited paired training data.
Specifically, our pipeline begins with easily collected high-quality
normal-light images, which are first unprocessed into the RAW format using a
reverse ISP. We then synthesize low-light degradations directly in the RAW
domain. The resulting data is subsequently processed through a series of ISP
stages, including white balance adjustment, color space conversion, tone
mapping, and gamma correction, with controlled variations introduced at each
stage. This broadens the degradation space and enhances the diversity of the
training data, enabling the generated data to capture a wide range of
degradations and the complexities inherent in the ISP pipeline. To demonstrate
the effectiveness of our synthetic pipeline, we conduct extensive experiments
using a vanilla UNet model consisting solely of convolutional layers, group
normalization, GeLU activation, and convolutional block attention modules
(CBAMs). Extensive testing across multiple datasets reveals that the vanilla
UNet model trained with our data synthesis pipeline delivers high fidelity,
visually appealing enhancement results, surpassing state-of-the-art (SOTA)
methods both quantitatively and qualitatively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 11 tables, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interpreting the Linear Structure of Vision-language Model Embedding
  Spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Isabel Papadimitriou, Huangyuan Su, Thomas Fel, Naomi Saphra, Sham Kakade, Stephanie Gil
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models encode images and text in a joint space, minimizing
the distance between corresponding image and text pairs. How are language and
images organized in this joint space, and how do the models encode meaning and
modality? To investigate this, we train and release sparse autoencoders (SAEs)
on the embedding spaces of four vision-language models (CLIP, SigLIP, SigLIP2,
and AIMv2). SAEs approximate model embeddings as sparse linear combinations of
learned directions, or "concepts". We find that, compared to other methods of
linear feature learning, SAEs are better at reconstructing the real embeddings,
while also able to retain the most sparsity. Retraining SAEs with different
seeds or different data diet leads to two findings: the rare, specific concepts
captured by the SAEs are liable to change drastically, but we also show that
the key commonly-activating concepts extracted by SAEs are remarkably stable
across runs. Interestingly, while most concepts are strongly unimodal in
activation, we find they are not merely encoding modality per se. Many lie
close to - but not entirely within - the subspace defining modality, suggesting
that they encode cross-modal semantics despite their unimodal usage. To
quantify this bridging behavior, we introduce the Bridge Score, a metric that
identifies concept pairs which are both co-activated across aligned image-text
inputs and geometrically aligned in the shared space. This reveals that even
unimodal concepts can collaborate to support cross-modal integration. We
release interactive demos of the SAEs for all models, allowing researchers to
explore the organization of the concept spaces. Overall, our findings uncover a
sparse linear structure within VLM embedding spaces that is shaped by modality,
yet stitched together through latent bridges-offering new insight into how
multimodal meaning is constructed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Taming Data and <span class="highlight-title">Transformer</span>s for Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19388v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19388v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Vicente Ordonez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scalability of ambient sound generators is hindered by data scarcity,
insufficient caption quality, and limited scalability in model architecture.
This work addresses these challenges by advancing both data and model scaling.
First, we propose an efficient and scalable dataset collection pipeline
tailored for ambient audio generation, resulting in AutoReCap-XL, the largest
ambient audio-text dataset with over 47 million clips. To provide high-quality
textual annotations, we propose AutoCap, a high-quality automatic audio
captioning model. By adopting a Q-Former module and leveraging audio metadata,
AutoCap substantially enhances caption quality, reaching a CIDEr score of
$83.2$, a $3.2\%$ improvement over previous captioning models. Finally, we
propose GenAu, a scalable transformer-based audio generation architecture that
we scale up to 1.25B parameters. We demonstrate its benefits from data scaling
with synthetic captions as well as model size scaling. When compared to
baseline audio generators trained at similar size and data scale, GenAu obtains
significant improvements of $4.7\%$ in FAD score, $11.1\%$ in IS, and $13.5\%$
in CLAP score. Our code, model checkpoints, and dataset are publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Webpage: https://snap-research.github.io/GenAU/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring <span class="highlight-title">Self-supervised</span> Skeleton-based Action Recognition in Occluded
  Environments <span class="chip">IJCNN 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.12029v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.12029v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei Chen, Kunyu Peng, Alina Roitberg, David Schneider, Jiaming Zhang, Junwei Zheng, Yufan Chen, Ruiping Liu, Kailun Yang, Rainer Stiefelhagen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To integrate action recognition into autonomous robotic systems, it is
essential to address challenges such as person occlusions-a common yet often
overlooked scenario in existing self-supervised skeleton-based action
recognition methods. In this work, we propose IosPSTL, a simple and effective
self-supervised learning framework designed to handle occlusions. IosPSTL
combines a cluster-agnostic KNN imputer with an Occluded Partial
Spatio-Temporal Learning (OPSTL) strategy. First, we pre-train the model on
occluded skeleton sequences. Then, we introduce a cluster-agnostic KNN imputer
that performs semantic grouping using k-means clustering on sequence
embeddings. It imputes missing skeleton data by applying K-Nearest Neighbors in
the latent space, leveraging nearby sample representations to restore occluded
joints. This imputation generates more complete skeleton sequences, which
significantly benefits downstream self-supervised models. To further enhance
learning, the OPSTL module incorporates Adaptive Spatial Masking (ASM) to make
better use of intact, high-quality skeleton sequences during training. Our
method achieves state-of-the-art performance on the occluded versions of the
NTU-60 and NTU-120 datasets, demonstrating its robustness and effectiveness
under challenging conditions. Code is available at
https://github.com/cyfml/OPSTL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IJCNN 2025. Code is available at
  https://github.com/cyfml/OPSTL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Document Parsing Unveiled: Techniques, Challenges, and Prospects for
  Structured Information Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21169v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21169v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qintong Zhang, Bin Wang, Victor Shea-Jay Huang, Junyuan Zhang, Zhengren Wang, Hao Liang, Conghui He, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document parsing is essential for converting unstructured and semi-structured
documents such as contracts, academic papers, and invoices into structured,
machine-readable data. Document parsing reliable structured data from
unstructured inputs, providing huge convenience for numerous applications.
Especially with recent achievements in Large Language Models, document parsing
plays an indispensable role in both knowledge base construction and training
data generation. This survey presents a comprehensive review of the current
state of document parsing, covering key methodologies, from modular pipeline
systems to end-to-end models driven by large vision-language models. Core
components such as layout detection, content extraction (including text,
tables, and mathematical expressions), and multi-modal data integration are
examined in detail. Additionally, this paper discusses the challenges faced by
modular document parsing systems and vision-language models in handling complex
layouts, integrating multiple modules, and recognizing high-density text. It
outlines future research directions and emphasizes the importance of developing
larger and more diverse datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation
  from Text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.14773v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.14773v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roberto Henschel, Levon Khachatryan, Hayk Poghosyan, Daniil Hayrapetyan, Vahram Tadevosyan, Zhangyang Wang, Shant Navasardyan, Humphrey Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-video diffusion models enable the generation of high-quality videos
that follow text instructions, making it easy to create diverse and individual
content. However, existing approaches mostly focus on high-quality short video
generation (typically 16 or 24 frames), ending up with hard-cuts when naively
extended to the case of long video synthesis. To overcome these limitations, we
introduce StreamingT2V, an autoregressive approach for long video generation of
80, 240, 600, 1200 or more frames with smooth transitions. The key components
are:(i) a short-term memory block called conditional attention module (CAM),
which conditions the current generation on the features extracted from the
previous chunk via an attentional mechanism, leading to consistent chunk
transitions, (ii) a long-term memory block called appearance preservation
module, which extracts high-level scene and object features from the first
video chunk to prevent the model from forgetting the initial scene, and (iii) a
randomized blending approach that enables to apply a video enhancer
autoregressively for infinitely long videos without inconsistencies between
chunks. Experiments show that StreamingT2V generates high motion amount. In
contrast, all competing image-to-video methods are prone to video stagnation
when applied naively in an autoregressive manner. Thus, we propose with
StreamingT2V a high-quality seamless text-to-long video generator that
outperforms competitors with consistency and motion. Our code will be available
at: https://github.com/Picsart-AI-Research/StreamingT2V
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/Picsart-AI-Research/StreamingT2V</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Consensus Entropy: Harnessing Multi-VLM Agreement for Self-Verifying and
  Self-Improving OCR 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11101v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11101v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulong Zhang, Tianyi Liang, Xinyue Huang, Erfei Cui, Xu Guo, Pei Chu, Chenhui Li, Ru Zhang, Wenhai Wang, Gongshen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Optical Character Recognition (OCR) task is important for evaluating
Vision-Language Models (VLMs) and providing high-quality data sources for LLM
training data. While state-of-the-art VLMs show improved average OCR accuracy,
they still struggle with sample-level quality degradation and lack reliable
automatic detection of low-quality outputs. We introduce Consensus Entropy
(CE), a training-free post-inference method that quantifies OCR uncertainty by
aggregating outputs from multiple VLMs. Our approach exploits a key insight:
correct VLM OCR predictions converge in output space while errors diverge. We
develop a lightweight multi-model framework that effectively identifies
problematic samples, selects the best outputs and combines model strengths.
Experiments across multiple OCR benchmarks and VLMs demonstrate that CE
outperforms VLM-as-judge approaches and single-model baselines at the same cost
and achieves state-of-the-art results across multiple metrics. For instance,
our solution demonstrates: achieving 15.2% higher F1 scores than VLM-as-judge
methods in quality verification, delivering 6.0% accuracy gains on mathematical
calculation tasks, and requiring rephrasing only 7.3% of inputs while
maintaining overall performance. Notably, the entire process requires neither
training nor supervision while maintaining plug-and-play functionality
throughout.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-15T00:00:00Z">2025-04-15</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving LLM Interpretability and Performance via Guided Embedding
  Refinement for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11658v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11658v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nanshan Jia, Chenfei Yuan, Yuhang Wu, Zeyu Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fast development of Large Language Models (LLMs) offers growing
opportunities to further improve sequential recommendation systems. Yet for
some practitioners, integrating LLMs to their existing base recommendation
systems raises questions about model interpretability, transparency and related
safety. To partly alleviate challenges from these questions, we propose guided
embedding refinement, a method that carries out a guided and interpretable
usage of LLM to enhance the embeddings associated with the base recommendation
system. Instead of directly using LLMs as the backbone of sequential
recommendation systems, we utilize them as auxiliary tools to emulate the sales
logic of recommendation and generate guided embeddings that capture
domain-relevant semantic information on interpretable attributes. Benefiting
from the strong generalization capabilities of the guided embedding, we
construct refined embedding by using the guided embedding and reduced-dimension
version of the base embedding. We then integrate the refined embedding into the
recommendation module for training and inference. A range of numerical
experiments demonstrate that guided embedding is adaptable to various given
existing base embedding models, and generalizes well across different
recommendation tasks. The numerical results show that the refined embedding not
only improves recommendation performance, achieving approximately $10\%$ to
$50\%$ gains in Mean Reciprocal Rank (MRR), Recall rate, and Normalized
Discounted Cumulative Gain (NDCG), but also enhances interpretability, as
evidenced by case studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michal Lukasik, Lin Chen, Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum, Felix X. Yu, Sashank J. Reddi, Gang Fu, Mohammadhossein Bateni, Sanjiv Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bipartite ranking is a fundamental supervised learning problem, with the goal
of learning a ranking over instances with maximal area under the ROC curve
(AUC) against a single binary target label. However, one may often observe
multiple binary target labels, e.g., from distinct human annotators. How can
one synthesize such labels into a single coherent ranking? In this work, we
formally analyze two approaches to this problem -- loss aggregation and label
aggregation -- by characterizing their Bayes-optimal solutions. Based on this,
we show that while both methods can yield Pareto-optimal solutions, loss
aggregation can exhibit label dictatorship: one can inadvertently (and
undesirably) favor one label over others. This suggests that label aggregation
can be preferable to loss aggregation, which we empirically verify.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAID: An In-Training Defense against Attribute Inference Attacks in
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11510v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11510v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaohua Feng, Yuyuan Li, Fengyuan Yu, Ke Xiong, Junjie Fang, Li Zhang, Tianyu Du, Chaochao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In various networks and mobile applications, users are highly susceptible to
attribute inference attacks, with particularly prevalent occurrences in
recommender systems. Attackers exploit partially exposed user profiles in
recommendation models, such as user embeddings, to infer private attributes of
target users, such as gender and political views. The goal of defenders is to
mitigate the effectiveness of these attacks while maintaining recommendation
performance. Most existing defense methods, such as differential privacy and
attribute unlearning, focus on post-training settings, which limits their
capability of utilizing training data to preserve recommendation performance.
Although adversarial training extends defenses to in-training settings, it
often struggles with convergence due to unstable training processes. In this
paper, we propose RAID, an in-training defense method against attribute
inference attacks in recommender systems. In addition to the recommendation
objective, we define a defensive objective to ensure that the distribution of
protected attributes becomes independent of class labels, making users
indistinguishable from attribute inference attacks. Specifically, this
defensive objective aims to solve a constrained Wasserstein barycenter problem
to identify the centroid distribution that makes the attribute
indistinguishable while complying with recommendation performance constraints.
To optimize our proposed objective, we use optimal transport to align users
with the centroid distribution. We conduct extensive experiments on four
real-world datasets to evaluate RAID. The experimental results validate the
effectiveness of RAID and demonstrate its significant superiority over existing
methods in multiple aspects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Document Quality Scoring for Web Crawling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11011v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11011v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesca Pezzuti, Ariane Mueller, Sean MacAvaney, Nicola Tonellotto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The internet contains large amounts of low-quality content, yet users expect
web search engines to deliver high-quality, relevant results. The abundant
presence of low-quality pages can negatively impact retrieval and crawling
processes by wasting resources on these documents. Therefore, search engines
can greatly benefit from techniques that leverage efficient quality estimation
methods to mitigate these negative impacts. Quality scoring methods for web
pages are useful for many processes typical for web search systems, including
static index pruning, index tiering, and crawling. Building on work by Chang et
al.~\cite{chang2024neural}, who proposed using neural estimators of semantic
quality for static index pruning, we extend their approach and apply their
neural quality scorers to assess the semantic quality of web pages in crawling
prioritisation tasks. In our experimental analysis, we found that prioritising
semantically high-quality pages over low-quality ones can improve downstream
search effectiveness. Our software contribution consists of a Docker container
that computes an effective quality score for a given web page, allowing the
quality scorer to be easily included and used in other components of web search
systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at WOWS2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Why am I seeing this? Towards recognizing social media recommender
  systems with missing recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11000v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11000v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabrina Guidotti, Sabrina Patania, Giuseppe Vizzari, Dimitri Ognibene, Gregor Donabauer, Udo Kruschwitz, Davide Taibi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media plays a crucial role in shaping society, often amplifying
polarization and spreading misinformation. These effects stem from complex
dynamics involving user interactions, individual traits, and recommender
algorithms driving content selection. Recommender systems, which significantly
shape the content users see and decisions they make, offer an opportunity for
intervention and regulation. However, assessing their impact is challenging due
to algorithmic opacity and limited data availability. To effectively model user
decision-making, it is crucial to recognize the recommender system adopted by
the platform.
  This work introduces a method for Automatic Recommender Recognition using
Graph Neural Networks (GNNs), based solely on network structure and observed
behavior. To infer the hidden recommender, we first train a Recommender Neutral
User model (RNU) using a GNN and an adapted hindsight academic network
recommender, aiming to reduce reliance on the actual recommender in the data.
We then generate several Recommender Hypothesis-specific Synthetic Datasets
(RHSD) by combining the RNU with different known recommenders, producing ground
truths for testing. Finally, we train Recommender Hypothesis-specific User
models (RHU) under various hypotheses and compare each candidate with the
original used to generate the RHSD.
  Our approach enables accurate detection of hidden recommenders and their
influence on user behavior. Unlike audit-based methods, it captures system
behavior directly, without ad hoc experiments that often fail to reflect real
platforms. This study provides insights into how recommenders shape behavior,
aiding efforts to reduce polarization and misinformation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at RLDM 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MSCRS: Multi-modal Semantic Graph <span class="highlight-title">Prompt</span> Learning Framework for
  Conversational Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10921v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10921v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yibiao Wei, Jie Zou, Weikang Guo, Guoqing Wang, Xing Xu, Yang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Recommender Systems (CRSs) aim to provide personalized
recommendations by interacting with users through conversations. Most existing
studies of CRS focus on extracting user preferences from conversational
contexts. However, due to the short and sparse nature of conversational
contexts, it is difficult to fully capture user preferences by conversational
contexts only. We argue that multi-modal semantic information can enrich user
preference expressions from diverse dimensions (e.g., a user preference for a
certain movie may stem from its magnificent visual effects and compelling
storyline). In this paper, we propose a multi-modal semantic graph prompt
learning framework for CRS, named MSCRS. First, we extract textual and image
features of items mentioned in the conversational contexts. Second, we capture
higher-order semantic associations within different semantic modalities
(collaborative, textual, and image) by constructing modality-specific graph
structures. Finally, we propose an innovative integration of multi-modal
semantic graphs with prompt learning, harnessing the power of large language
models to comprehensively explore high-dimensional semantic relationships.
Experimental results demonstrate that our proposed method significantly
improves accuracy in item recommendation, as well as generates more natural and
contextually relevant content in response generation. We have released the code
and the expanded multi-modal CRS datasets to facilitate further exploration in
related research\footnote{https://github.com/BIAOBIAO12138/MSCRS-main}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bridging Stepwise Lab-Informed <span class="highlight-title">Pretrain</span>ing and Knowledge-Guided Learning
  for Diagnostic Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19955v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19955v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengfei Hu, Chang Lu, Fei Wang, Yue Ning
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing use of Electronic Health Records (EHR) for AI-assisted
diagnosis prediction, most data-driven models struggle to incorporate
clinically meaningful medical knowledge. They often rely on limited ontologies,
lacking structured reasoning capabilities and comprehensive coverage. This
raises an important research question: Will medical knowledge improve
predictive models to support stepwise clinical reasoning as performed by human
doctors? To address this problem, we propose DuaLK, a dual-expertise framework
that combines two complementary sources of information. For external knowledge,
we construct a Diagnosis Knowledge Graph (KG) that encodes both hierarchical
and semantic relations enriched by large language models (LLM). To align with
patient data, we further introduce a lab-informed proxy task that guides the
model to follow a clinically consistent, stepwise reasoning process based on
lab test signals. Experimental results on two public EHR datasets demonstrate
that DuaLK consistently outperforms existing baselines across four clinical
prediction tasks. These findings highlight the potential of combining
structured medical knowledge with individual-level clinical signals to achieve
more accurate and interpretable diagnostic predictions. The source code is
publicly available on https://github.com/humphreyhuu/DuaLK.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inferring Communities of Interest in Collaborative Learning-based
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.08929v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.08929v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yacine Belal, Sonia Ben Mokhtar, Mohamed Maouche, Anthony Simonet-Boulogne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collaborative-learning-based recommender systems, such as those employing
Federated Learning (FL) and Gossip Learning (GL), allow users to train models
while keeping their history of liked items on their devices. While these
methods were seen as promising for enhancing privacy, recent research has shown
that collaborative learning can be vulnerable to various privacy attacks. In
this paper, we propose a novel attack called Community Inference Attack (CIA),
which enables an adversary to identify community members based on a set of
target items. What sets CIA apart is its efficiency: it operates at low
computational cost by eliminating the need for training surrogate models.
Instead, it uses a comparison-based approach, inferring sensitive information
by comparing users' models rather than targeting any specific individual model.
To evaluate the effectiveness of CIA, we conduct experiments on three
real-world recommendation datasets using two recommendation models under both
Federated and Gossip-like settings. The results demonstrate that CIA can be up
to 10 times more accurate than random guessing. Additionally, we evaluate two
mitigation strategies: Differentially Private Stochastic Gradient Descent
(DP-SGD) and a Share less policy, which involves sharing fewer, less sensitive
model parameters. Our findings suggest that the Share less strategy offers a
better privacy-utility trade-off, especially in GL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Limitations of Automatic Relevance Assessments with Large Language
  Models for Fair and Reliable Retrieval Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13212v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13212v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Otero, Javier Parapar, Álvaro Barreiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Offline evaluation of search systems depends on test collections. These
benchmarks provide the researchers with a corpus of documents, topics and
relevance judgements indicating which documents are relevant for each topic.
While test collections are an integral part of Information Retrieval (IR)
research, their creation involves significant efforts in manual annotation.
Large language models (LLMs) are gaining much attention as tools for automatic
relevance assessment. Recent research has shown that LLM-based assessments
yield high systems ranking correlation with human-made judgements. These
correlations are helpful in large-scale experiments but less informative if we
want to focus on top-performing systems. Moreover, these correlations ignore
whether and how LLM-based judgements impact the statistically significant
differences among systems with respect to human assessments. In this work, we
look at how LLM-generated judgements preserve ranking differences among
top-performing systems and also how they preserve pairwise significance
evaluation as human judgements. Our results show that LLM-based judgements are
unfair at ranking top-performing systems. Moreover, we observe an exceedingly
high rate of false positives regarding statistical differences. Our work
represents a step forward in the evaluation of the reliability of using
LLMs-based judgements for IR evaluation. We hope this will serve as a basis for
other researchers to develop more reliable models for automatic relevance
assessment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Preference-based Learning with Retrieval Augmented Generation for
  Conversational Question Answering <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.22303v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.22303v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Magdalena Kaiser, Gerhard Weikum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Question Answering (ConvQA) involves multiple subtasks, i) to
understand incomplete questions in their context, ii) to retrieve relevant
information, and iii) to generate answers. This work presents PRAISE, a
pipeline-based approach for ConvQA that trains LLM adapters for each of the
three subtasks. As labeled training data for individual subtasks is unavailable
in practice, PRAISE learns from its own generations using the final answering
performance as feedback signal without human intervention and treats
intermediate information, like relevant evidence, as weakly labeled data. We
apply Direct Preference Optimization by contrasting successful and unsuccessful
samples for each subtask. In our experiments, we show the effectiveness of this
training paradigm: PRAISE shows improvements per subtask and achieves new
state-of-the-art performance on a popular ConvQA benchmark, by gaining 15.5
percentage points increase in precision over baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WWW 2025 Short Paper, 5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Relevance Emerges: Interpreting LoRA Fine-Tuning in Reranking LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.08780v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.08780v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atharva Nijasure, Tanya Chowdhury, James Allan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We conduct a behavioral exploration of LoRA fine-tuned LLMs for Passage
Reranking to understand how relevance signals are learned and deployed by Large
Language Models. By fine-tuning Mistral-7B, LLaMA3.1-8B, and Pythia-6.9B on MS
MARCO under diverse LoRA configurations, we investigate how relevance modeling
evolves across checkpoints, the impact of LoRA rank (1, 2, 8, 32), and the
relative importance of updated MHA vs. MLP components. Our ablations reveal
which layers and projections within LoRA transformations are most critical for
reranking accuracy. These findings offer fresh explanations into LoRA's
adaptation mechanisms, setting the stage for deeper mechanistic studies in
Information Retrieval. All models used in this study have been shared.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended Abstract</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lightning IR: Straightforward Fine-tuning and Inference of
  <span class="highlight-title">Transformer</span>-based Language Models for Information Retrieval <span class="chip">WSDM'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04677v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04677v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ferdinand Schlatt, Maik Fröbe, Matthias Hagen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A wide range of transformer-based language models have been proposed for
information retrieval tasks. However, including transformer-based models in
retrieval pipelines is often complex and requires substantial engineering
effort. In this paper, we introduce Lightning IR, an easy-to-use PyTorch
Lightning-based framework for applying transformer-based language models in
retrieval scenarios. Lightning IR provides a modular and extensible
architecture that supports all stages of a retrieval pipeline: from fine-tuning
and indexing to searching and re-ranking. Designed to be scalable and
reproducible, Lightning IR is available as open-source:
https://github.com/webis-de/lightning-ir.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a demo at WSDM'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are We Solving a Well-Defined Problem? A Task-Centric Perspective on
  Recommendation Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.21188v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.21188v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aixin Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems (RecSys) leverage user interaction history to predict and
suggest relevant items, shaping user experiences across various domains. While
many studies adopt a general problem definition, i.e., to recommend preferred
items to users based on past interactions, such abstraction often lacks the
domain-specific nuances necessary for practical deployment. However, models are
frequently evaluated using datasets from online recommender platforms, which
inherently reflect these specificities. In this paper, we analyze RecSys task
formulations, emphasizing key components such as input-output structures,
temporal dynamics, and candidate item selection. All these factors directly
impact offline evaluation. We further examine the complexities of user-item
interactions, including decision-making costs, multi-step engagements, and
unobservable interactions, which may influence model design and loss functions.
Additionally, we explore the balance between task specificity and model
generalizability, highlighting how well-defined task formulations serve as the
foundation for robust evaluation and effective solution development. By
clarifying task definitions and their implications, this work provides a
structured perspective on RecSys research. The goal is to help researchers
better navigate the field, particularly in understanding specificities of the
RecSys tasks and ensuring fair and meaningful evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SS4Rec: Continuous-Time Sequential Recommendation with State Space
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08132v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08132v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Xiao, Huiying Wang, Qifeng Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation is a key area in the field of recommendation
systems aiming to model user interest based on historical interaction sequences
with irregular intervals. While previous recurrent neural network-based and
attention-based approaches have achieved significant results, they have
limitations in capturing system continuity due to the discrete characteristics.
In the context of continuous-time modeling, state space model (SSM) offers a
potential solution, as it can effectively capture the dynamic evolution of user
interest over time. However, existing SSM-based approaches ignore the impact of
irregular time intervals within historical user interactions, making it
difficult to model complexed user-item transitions in sequences. To address
this issue, we propose a hybrid SSM-based model called SS4Rec for
continuous-time sequential recommendation. SS4Rec integrates a time-aware SSM
to handle irregular time intervals and a relation-aware SSM to model contextual
dependencies, enabling it to infer user interest from both temporal and
sequential perspectives. In the training process, the time-aware SSM and the
relation-aware SSM are discretized by variable stepsizes according to user
interaction time intervals and input data, respectively. This helps capture the
continuous dependency from irregular time intervals and provides time-specific
personalized recommendations. Experimental studies on five benchmark datasets
demonstrate the superiority and effectiveness of SS4Rec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are Generative AI Agents Effective Personalized Financial Advisors? <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.05862v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.05862v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takehiro Takayanagi, Kiyoshi Izumi, Javier Sanz-Cruzado, Richard McCreadie, Iadh Ounis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model-based agents are becoming increasingly popular as a
low-cost mechanism to provide personalized, conversational advice, and have
demonstrated impressive capabilities in relatively simple scenarios, such as
movie recommendations. But how do these agents perform in complex high-stakes
domains, where domain expertise is essential and mistakes carry substantial
risk? This paper investigates the effectiveness of LLM-advisors in the finance
domain, focusing on three distinct challenges: (1) eliciting user preferences
when users themselves may be unsure of their needs, (2) providing personalized
guidance for diverse investment preferences, and (3) leveraging advisor
personality to build relationships and foster trust. Via a lab-based user study
with 64 participants, we show that LLM-advisors often match human advisor
performance when eliciting preferences, although they can struggle to resolve
conflicting user needs. When providing personalized advice, the LLM was able to
positively influence user behavior, but demonstrated clear failure modes. Our
results show that accurate preference elicitation is key, otherwise, the
LLM-advisor has little impact, or can even direct the investor toward
unsuitable assets. More worryingly, users appear insensitive to the quality of
advice being given, or worse these can have an inverse relationship. Indeed,
users reported a preference for and increased satisfaction as well as emotional
trust with LLMs adopting an extroverted persona, even though those agents
provided worse advice.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at SIGIR 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dependency Structure Augmented Contextual Scoping Framework for
  Multimodal Aspect-Based Sentiment Analysis <span class="chip">ACM MM2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Liu, Lijun He, Jiaxi Liang, Zhihan Ren, Fan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Aspect-Based Sentiment Analysis (MABSA) seeks to extract
fine-grained information from image-text pairs to identify aspect terms and
determine their sentiment polarity. However, existing approaches often fall
short in simultaneously addressing three core challenges: Sentiment Cue
Perception (SCP), Multimodal Information Misalignment (MIM), and Semantic Noise
Elimination (SNE). To overcome these limitations, we propose DASCO
(\textbf{D}ependency Structure \textbf{A}ugmented \textbf{Sco}ping Framework),
a fine-grained scope-oriented framework that enhances aspect-level sentiment
reasoning by leveraging dependency parsing trees. First, we designed a
multi-task pretraining strategy for MABSA on our base model, combining
aspect-oriented enhancement, image-text matching, and aspect-level
sentiment-sensitive cognition. This improved the model's perception of aspect
terms and sentiment cues while achieving effective image-text alignment,
addressing key challenges like SCP and MIM. Furthermore, we incorporate
dependency trees as syntactic branch combining with semantic branch, guiding
the model to selectively attend to critical contextual elements within a
target-specific scope while effectively filtering out irrelevant noise for
addressing SNE problem. Extensive experiments on two benchmark datasets across
three subtasks demonstrate that DASCO achieves state-of-the-art performance in
MABSA, with notable gains in JMASA (+3.1\% F1 and +5.4\% precision on
Twitter2015).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>submitted to ACM MM2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging multimodal explanatory annotations for video interpretation
  with Modality Specific <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11232v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11232v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elisa Ancarani, Julie Tores, Lucile Sassatelli, Rémy Sun, Hui-Yin Wu, Frédéric Precioso
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We examine the impact of concept-informed supervision on multimodal video
interpretation models using MOByGaze, a dataset containing human-annotated
explanatory concepts. We introduce Concept Modality Specific Datasets (CMSDs),
which consist of data subsets categorized by the modality (visual, textual, or
audio) of annotated concepts. Models trained on CMSDs outperform those using
traditional legacy training in both early and late fusion approaches. Notably,
this approach enables late fusion models to achieve performance close to that
of early fusion models. These findings underscore the importance of
modality-specific annotations in developing robust, self-explainable video
models and contribute to advancing interpretable multimodal learning in complex
video analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 8 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph-Driven Multimodal Feature Learning Framework for Apparent
  Personality Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11515v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11515v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangsheng Wang, Chengwei Ye, Huanzhen Zhang, Linuo Xu, Shuyan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting personality traits automatically has become a challenging problem
in computer vision. This paper introduces an innovative multimodal feature
learning framework for personality analysis in short video clips. For visual
processing, we construct a facial graph and design a Geo-based two-stream
network incorporating an attention mechanism, leveraging both Graph
Convolutional Networks (GCN) and Convolutional Neural Networks (CNN) to capture
static facial expressions. Additionally, ResNet18 and VGGFace networks are
employed to extract global scene and facial appearance features at the frame
level. To capture dynamic temporal information, we integrate a BiGRU with a
temporal attention module for extracting salient frame representations. To
enhance the model's robustness, we incorporate the VGGish CNN for audio-based
features and XLM-Roberta for text-based features. Finally, a multimodal channel
attention mechanism is introduced to integrate different modalities, and a
Multi-Layer Perceptron (MLP) regression model is used to predict personality
traits. Experimental results confirm that our proposed framework surpasses
existing state-of-the-art approaches in performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMC: Iterative Refinement of VLM Reasoning via MCTS-based Multimodal
  Critique 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11009v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11009v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuhang Liu, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Jun Du, Qing Wang, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual language models (VLMs) have demonstrated strong performance across
diverse multimodal reasoning tasks but still face challenges such as
hallucinations, resulting in incorrect reasoning outcomes. Inspired by recent
research on external feedback mechanisms in large language models (LLMs), we
propose a multimodal actor-critic framework to enhance VLM reasoning
capabilities. Specifically, the actor model generates step-by-step reasoning
paths based on image and text inputs, while the critic model evaluates these
reasoning paths and provides corrective feedback. The actor model iteratively
refines its reasoning based on the feedback until the reasoning outcome is
deemed satisfactory by the critic model. To reduce reliance on costly manual
annotations, we introduce an automated method for constructing multimodal
critique datasets. By leveraging Monte Carlo Tree Search (MCTS), we
systematically guide the actor model to explore diverse reasoning paths. To
obtain critique data for correcting erroneous reasoning steps, we prompt an
annotator model to compare pairs of reasoning paths diverging from a shared
ancestor node - one leading to a correct conclusion and the other to an
incorrect one. This approach enables us to construct the MMC (MCTS-based
Multimodal Critique) dataset, upon which we further develop a comprehensive
training and inference pipeline. Extensive experiments conducted on several
public benchmark datasets and mainstream VLMs demonstrate that our approach
significantly improves the performance of VLM on complex multimodal reasoning
tasks, underscoring its effectiveness and wide applicability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dopamine Audiobook: A Training-free MLLM Agent for Emotional and
  Human-like Audiobook Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11002v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11002v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Rong, Shan Yang, Guangzhi Lei, Li Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audiobook generation, which creates vivid and emotion-rich audio works, faces
challenges in conveying complex emotions, achieving human-like qualities, and
aligning evaluations with human preferences. Existing text-to-speech (TTS)
methods are often limited to specific scenarios, struggle with emotional
transitions, and lack automatic human-aligned evaluation benchmarks, instead
relying on either misaligned automated metrics or costly human assessments. To
address these issues, we propose Dopamine Audiobook, a new unified
training-free system leveraging a multimodal large language model (MLLM) as an
AI agent for emotional and human-like audiobook generation and evaluation.
Specifically, we first design a flow-based emotion-enhanced framework that
decomposes complex emotional speech synthesis into controllable sub-tasks.
Then, we propose an adaptive model selection module that dynamically selects
the most suitable TTS methods from a set of existing state-of-the-art (SOTA)
TTS methods for diverse scenarios. We further enhance emotional expressiveness
through paralinguistic augmentation and prosody retrieval at word and utterance
levels. For evaluation, we propose a novel GPT-based evaluation framework
incorporating self-critique, perspective-taking, and psychological MagicEmo
prompts to ensure human-aligned and self-aligned assessments. Experiments show
that our method generates long speech with superior emotional expression to
SOTA TTS models in various metrics. Importantly, our evaluation framework
demonstrates better alignment with human preferences and transferability across
audio tasks. Project website with audio samples can be found at
https://dopamine-audiobook.github.io.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Word-Level Temporal Segmentation in Streaming Speech
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10849v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10849v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naoto Nishida, Hirotaka Hiraki, Jun Rekimoto, Yoshio Ishiguro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rich-text captions are essential to help communication for Deaf and
hard-of-hearing (DHH) people, second-language learners, and those with autism
spectrum disorder (ASD). They also preserve nuances when converting speech to
text, enhancing the realism of presentation scripts and conversation or speech
logs. However, current real-time captioning systems lack the capability to
alter text attributes (ex. capitalization, sizes, and fonts) at the word level,
hindering the accurate conveyance of speaker intent that is expressed in the
tones or intonations of the speech. For example, ''YOU should do this'' tends
to be considered as indicating ''You'' as the focus of the sentence, whereas
''You should do THIS'' tends to be ''This'' as the focus. This paper proposes a
solution that changes the text decorations at the word level in real time. As a
prototype, we developed an application that adjusts word size based on the
loudness of each spoken word. Feedback from users implies that this system
helped to convey the speaker's intent, offering a more engaging and accessible
captioning experience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>3 pages, 1 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ichiyo: Fragile and Transient Interaction in Neighborhood 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10848v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10848v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hirofumi Shibata, Ayako Yogo, Naoto Nishida, Yu Shimada, Toma Ishii
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the Internet develops, social networking and other communication tools
have transformed people's relationships into something fast, visible, and
geographically huge. However, these communication tools have not expanded
opportunities for acquainting oneself with neighbors outside one's social
network; rather, they have comparatively diminished occasions for interacting
with unfamiliar neighbors by prioritizing communication with existing friends.
Therefore, we invented the medium Ichiyo to increase the opportunities to think
of neighbors walking along the same street or in the same neighborhood and to
expand the imagination of those who pass by and those who used to be there.
Thus, users can engage in indirect interaction. We used commercially available
laser cutters to engrave QR codes on leaves that are naturally found in our
living space to prevent environmental invasion. The QR codes lead to a communal
space on the web where users can freely leave messages. By engraving QR codes,
information can be virtually expanded to be presented. To get the feedback of
Ichiyo, we let a total of several thousand people experience a new way of
communication as a part of the exhibition ''iii Exhibition 2022'', an art
exhibition at the University of Tokyo. A total of more than 1,000 leaves
engraved with QR codes were prepared and scattered at the exhibition site and
along the road from the nearest station to the venue.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>3 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SteerMusic: Enhanced Musical Consistency for Zero-shot Text-Guided and
  Personalized Music Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinlei Niu, Kin Wai Cheuk, Jing Zhang, Naoki Murata, Chieh-Hsin Lai, Michele Mancusi, Woosung Choi, Giorgio Fabbro, Wei-Hsiang Liao, Charles Patrick Martin, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music editing is an important step in music production, which has broad
applications, including game development and film production. Most existing
zero-shot text-guided methods rely on pretrained diffusion models by involving
forward-backward diffusion processes for editing. However, these methods often
struggle to maintain the music content consistency. Additionally, text
instructions alone usually fail to accurately describe the desired music. In
this paper, we propose two music editing methods that enhance the consistency
between the original and edited music by leveraging score distillation. The
first method, SteerMusic, is a coarse-grained zero-shot editing approach using
delta denoising score. The second method, SteerMusic+, enables fine-grained
personalized music editing by manipulating a concept token that represents a
user-defined musical style. SteerMusic+ allows for the editing of music into
any user-defined musical styles that cannot be achieved by the text
instructions alone. Experimental results show that our methods outperform
existing approaches in preserving both music content consistency and editing
fidelity. User studies further validate that our methods achieve superior music
editing quality. Audio examples are available on https://steermusic.pages.dev/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Graphical Models for Vision-Language Compositional Understanding <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.09353v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.09353v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fiorenzo Parascandolo, Nicholas Moratelli, Enver Sangineto, Lorenzo Baraldi, Rita Cucchiara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work has empirically shown that Vision-Language Models (VLMs) struggle
to fully understand the compositional properties of the human language, usually
modeling an image caption as a "bag of words". As a result, they perform poorly
on compositional tasks, which require a deeper understanding of the different
entities of a sentence (subject, verb, etc.) jointly with their mutual
relationships in order to be solved. In this paper, we model the dependency
relations among textual and visual tokens using a Causal Graphical Model (CGM),
built using a dependency parser, and we train a decoder conditioned by the VLM
visual encoder. Differently from standard autoregressive or parallel
predictions, our decoder's generative process is partially-ordered following
the CGM structure. This structure encourages the decoder to learn only the main
causal dependencies in a sentence discarding spurious correlations. Using
extensive experiments on five compositional benchmarks, we show that our method
significantly outperforms all the state-of-the-art compositional approaches by
a large margin, and it also improves over methods trained using much larger
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Muse: A Multimodal Conversational Recommendation <span class="highlight-title">Dataset</span> with
  Scenario-Grounded User Profiles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.18416v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.18416v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihan Wang, Xiaocui Yang, Yongkang Liu, Shi Feng, Daling Wang, Yifei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current conversational recommendation systems focus predominantly on text.
However, real-world recommendation settings are generally multimodal, causing a
significant gap between existing research and practical applications. To
address this issue, we propose Muse, the first multimodal conversational
recommendation dataset. Muse comprises 83,148 utterances from 7,000
conversations centered around the Clothing domain. Each conversation contains
comprehensive multimodal interactions, rich elements, and natural dialogues.
Data in Muse are automatically synthesized by a multi-agent framework powered
by multimodal large language models (MLLMs). It innovatively derives user
profiles from real-world scenarios rather than depending on manual design and
history data for better scalability, and then it fulfills conversation
simulation and optimization. Both human and LLM evaluations demonstrate the
high quality of conversations in Muse. Additionally, fine-tuning experiments on
three MLLMs demonstrate Muse's learnable patterns for recommendations and
responses, confirming its value for multimodal conversational recommendation.
Our dataset and codes are available at
https://anonymous.4open.science/r/Muse-0086.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniForm: A Unified Multi-Task Diffusion <span class="highlight-title">Transformer</span> for Audio-Video
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03897v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03897v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Zhao, Linfeng Feng, Dongxu Ge, Rujin Chen, Fangqiu Yi, Chi Zhang, Xiao-Lei Zhang, Xuelong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rise of diffusion models, audio-video generation has been
revolutionized. However, most existing methods rely on separate modules for
each modality, with limited exploration of unified generative architectures. In
addition, many are confined to a single task and small-scale datasets. To
address these limitations, we first propose UniForm, a unified multi-task
diffusion transformer that jointly generates audio and visual modalities in a
shared latent space. A single diffusion process models both audio and video,
capturing the inherent correlations between sound and vision. Second, we
introduce task-specific noise schemes and task tokens, enabling a single model
to support multiple tasks, including text-to-audio-video, audio-to-video, and
video-to-audio generation. Furthermore, by leveraging large language models and
a large-scale text-audio-video combined dataset, UniForm achieves greater
generative diversity than prior approaches. Extensive experiments show that
UniForm achieves the state-of-the-art performance across audio-video generation
tasks, producing content that is both well-aligned and close to real-world data
distributions. Our demos are available at https://uniform-t2av.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our demos are available at https://uniform-t2av.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient <span class="highlight-title">Prompt</span> Tuning for Hierarchical Ingredient Recognition <span class="chip">ICME</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10322v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10322v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yinxuan Gui, Bin Zhu, Jingjing Chen, Chong-Wah Ngo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-grained ingredient recognition presents a significant challenge due to
the diverse appearances of ingredients, resulting from different cutting and
cooking methods. While existing approaches have shown promising results, they
still require extensive training costs and focus solely on fine-grained
ingredient recognition. In this paper, we address these limitations by
introducing an efficient prompt-tuning framework that adapts pretrained
visual-language models (VLMs), such as CLIP, to the ingredient recognition task
without requiring full model finetuning. Additionally, we introduce three-level
ingredient hierarchies to enhance both training performance and evaluation
robustness. Specifically, we propose a hierarchical ingredient recognition
task, designed to evaluate model performance across different hierarchical
levels (e.g., chicken chunks, chicken, meat), capturing recognition
capabilities from coarse- to fine-grained categories. Our method leverages
hierarchical labels, training prompt-tuned models with both fine-grained and
corresponding coarse-grained labels. Experimental results on the VireoFood172
dataset demonstrate the effectiveness of prompt-tuning with hierarchical
labels, achieving superior performance. Moreover, the hierarchical ingredient
recognition task provides valuable insights into the model's ability to
generalize across different levels of ingredient granularity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE International Conference on Multimedia and Expo
  (ICME) 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-04-14T00:00:00Z">2025-04-14</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">31</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep
  Ensemble Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10753v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10753v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Radin Cheraghi, Amir Mohammad Mahfoozi, Sepehr Zolfaghari, Mohammadshayan Shabani, Maryam Ramezani, Hamid R. Rabiee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommending items to users has long been a fundamental task, and studies
have tried to improve it ever since. Most well-known models commonly employ
representation learning to map users and items into a unified embedding space
for matching assessment. These approaches have primary limitations, especially
when dealing with explicit feedback and sparse data contexts. Two primary
limitations are their proneness to overfitting and failure to incorporate
epistemic uncertainty in predictions. To address these problems, we propose a
novel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To
improve model generalization and quality, we utilize Bayesian Neural Networks,
which incorporate uncertainty within their weight parameters. In addition, we
introduce a new interpretable non-linear matching approach for the user and
item embeddings, leveraging the advantages of the attention mechanism.
Furthermore, we endorse the implementation of an ensemble-based supermodel to
generate more robust and reliable predictions, resulting in a more complete
model. Empirical evaluation through extensive experiments and ablation studies
across a range of publicly accessible real-world datasets with differing
sparsity characteristics confirms our proposed method's effectiveness and the
importance of its components.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Document Retrieval for Curating N-ary Relations in Knowledge
  Bases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xing David Wang, Ulf Leser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Curation of biomedical knowledge bases (KBs) relies on extracting accurate
multi-entity relational facts from the literature - a process that remains
largely manual and expert-driven. An essential step in this workflow is
retrieving documents that can support or complete partially observed n-ary
relations. We present a neural retrieval model designed to assist KB curation
by identifying documents that help fill in missing relation arguments and
provide relevant contextual evidence.
  To reduce dependence on scarce gold-standard training data, we exploit
existing KB records to construct weakly supervised training sets. Our approach
introduces two key technical contributions: (i) a layered contrastive loss that
enables learning from noisy and incomplete relational structures, and (ii) a
balanced sampling strategy that generates high-quality negatives from diverse
KB records. On two biomedical retrieval benchmarks, our approach achieves
state-of-the-art performance, outperforming strong baselines in NDCG@10 by 5.7
and 3.7 percentage points, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Invariance Matters: Empowering Social Recommendation via Graph Invariant
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yonghui Yang, Le Wu, Yuxin Liao, Zhuangzhuang He, Pengyang Shao, Richang Hong, Meng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-based social recommendation systems have shown significant promise in
enhancing recommendation performance, particularly in addressing the issue of
data sparsity in user behaviors. Typically, these systems leverage Graph Neural
Networks (GNNs) to capture user preferences by incorporating high-order social
influences from observed social networks. However, existing graph-based social
recommendations often overlook the fact that social networks are inherently
noisy, containing task-irrelevant relationships that can hinder accurate user
preference learning. The removal of these redundant social relations is
crucial, yet it remains challenging due to the lack of ground truth. In this
paper, we approach the social denoising problem from the perspective of graph
invariant learning and propose a novel method, Social Graph Invariant
Learning(SGIL). Specifically,SGIL aims to uncover stable user preferences
within the input social graph, thereby enhancing the robustness of graph-based
social recommendation systems. To achieve this goal, SGIL first simulates
multiple noisy social environments through graph generators. It then seeks to
learn environment-invariant user preferences by minimizing invariant risk
across these environments. To further promote diversity in the generated social
environments, we employ an adversarial training strategy to simulate more
potential social noisy distributions. Extensive experimental results
demonstrate the effectiveness of the proposed SGIL. The code is available at
https://github.com/yimutianyang/SIGIR2025-SGIL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Brain-Machine Interfaces & Information Retrieval Challenges and
  Opportunities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yashar Moshfeghi, Niall McGuire
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fundamental goal of Information Retrieval (IR) systems lies in their
capacity to effectively satisfy human information needs - a challenge that
encompasses not just the technical delivery of information, but the nuanced
understanding of human cognition during information seeking. Contemporary IR
platforms rely primarily on observable interaction signals, creating a
fundamental gap between system capabilities and users' cognitive processes.
Brain-Machine Interface (BMI) technologies now offer unprecedented potential to
bridge this gap through direct measurement of previously inaccessible aspects
of information-seeking behaviour. This perspective paper offers a broad
examination of the IR landscape, providing a comprehensive analysis of how BMI
technology could transform IR systems, drawing from advances at the
intersection of both neuroscience and IR research. We present our analysis
through three identified fundamental vertices: (1) understanding the neural
correlates of core IR concepts to advance theoretical models of search
behaviour, (2) enhancing existing IR systems through contextual integration of
neurophysiological signals, and (3) developing proactive IR capabilities
through direct neurophysiological measurement. For each vertex, we identify
specific research opportunities and propose concrete directions for developing
BMI-enhanced IR systems. We conclude by examining critical technical and
ethical challenges in implementing these advances, providing a structured
roadmap for future research at the intersection of neuroscience and IR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AlayaDB: The Data Foundation for Efficient and Effective Long-context
  LLM Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yangshen Deng, Zhengxin You, Long Xiang, Qilong Li, Peiqi Yuan, Zhaoyang Hong, Yitao Zheng, Wanting Li, Runzhong Li, Haotian Liu, Kyriakos Mouratidis, Man Lung Yiu, Huan Li, Qiaomu Shen, Rui Mao, Bo Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AlayaDB is a cutting-edge vector database system natively architected for
efficient and effective long-context inference for Large Language Models (LLMs)
at AlayaDB AI. Specifically, it decouples the KV cache and attention
computation from the LLM inference systems, and encapsulates them into a novel
vector database system. For the Model as a Service providers (MaaS), AlayaDB
consumes fewer hardware resources and offers higher generation quality for
various workloads with different kinds of Service Level Objectives (SLOs), when
comparing with the existing alternative solutions (e.g., KV cache
disaggregation, retrieval-based sparse attention). The crux of AlayaDB is that
it abstracts the attention computation and cache management for LLM inference
into a query processing procedure, and optimizes the performance via a native
query optimizer. In this work, we demonstrate the effectiveness of AlayaDB via
(i) three use cases from our industry partners, and (ii) extensive experimental
results on LLM inference benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 12 figures, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CROSSAN: Towards Efficient and Effective Adaptation of Multiple
  Multimodal Foundation Models for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junchen Fu, Yongxin Ni, Joemon M. Jose, Ioannis Arapakis, Kaiwen Zheng, Youhua Li, Xuri Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Foundation Models (MFMs) excel at representing diverse raw
modalities (e.g., text, images, audio, videos, etc.). As recommender systems
increasingly incorporate these modalities, leveraging MFMs to generate better
representations has great potential. However, their application in sequential
recommendation remains largely unexplored. This is primarily because mainstream
adaptation methods, such as Fine-Tuning and even Parameter-Efficient
Fine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high
computational costs, especially when integrating multiple modality encoders,
thus hindering research progress. As a result, it remains unclear whether we
can efficiently and effectively adapt multiple (>2) MFMs for the sequential
recommendation task.
  To address this, we propose a plug-and-play Cross-modal Side Adapter Network
(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN
achieves high efficiency while enabling cross-modal learning across diverse
modalities. To optimize the final stage of multimodal fusion across diverse
modalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.
CROSSAN achieves superior performance on the public datasets for adapting four
foundation models with raw modalities. Performance consistently improves as
more MFMs are adapted. We will release our code and datasets to facilitate
future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MURR: Model Updating with Regularized Replay for Searching a Document
  Stream <span class="chip">ECIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10250v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10250v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eugene Yang, Nicola Tonellotto, Dawn Lawrie, Sean MacAvaney, James Mayfield, Douglas W. Oard, Scott Miller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Internet produces a continuous stream of new documents and user-generated
queries. These naturally change over time based on events in the world and the
evolution of language. Neural retrieval models that were trained once on a
fixed set of query-document pairs will quickly start misrepresenting
newly-created content and queries, leading to less effective retrieval.
Traditional statistical sparse retrieval can update collection statistics to
reflect these changes in the use of language in documents and queries. In
contrast, continued fine-tuning of the language model underlying neural
retrieval approaches such as DPR and ColBERT creates incompatibility with
previously-encoded documents. Re-encoding and re-indexing all
previously-processed documents can be costly. In this work, we explore updating
a neural dual encoder retrieval model without reprocessing past documents in
the stream. We propose MURR, a model updating strategy with regularized replay,
to ensure the model can still faithfully search existing documents without
reprocessing, while continuing to update the model for the latest topics. In
our simulated streaming environments, we show that fine-tuning models using
MURR leads to more effective and more consistent retrieval results than other
strategies as the stream of documents and queries progresses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ECIR 2025. 16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From <span class="highlight-title">Prompt</span>ing to Alignment: A Generative Framework for Query
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10208v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10208v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erxue Min, Hsiu-Yuan Huang, Min Yang, Xihong Yang, Xin Jia, Yunfang Wu, Hengyi Cai, Shuaiqiang Wang, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In modern search systems, search engines often suggest relevant queries to
users through various panels or components, helping refine their information
needs. Traditionally, these recommendations heavily rely on historical search
logs to build models, which suffer from cold-start or long-tail issues.
Furthermore, tasks such as query suggestion, completion or clarification are
studied separately by specific design, which lacks generalizability and hinders
adaptation to novel applications. Despite recent attempts to explore the use of
LLMs for query recommendation, these methods mainly rely on the inherent
knowledge of LLMs or external sources like few-shot examples, retrieved
documents, or knowledge bases, neglecting the importance of the calibration and
alignment with user feedback, thus limiting their practical utility. To address
these challenges, we first propose a general Generative Query Recommendation
(GQR) framework that aligns LLM-based query generation with user preference.
Specifically, we unify diverse query recommendation tasks by a universal prompt
framework, leveraging the instruct-following capability of LLMs for effective
generation. Secondly, we align LLMs with user feedback via presenting a
CTR-alignment framework, which involves training a query-wise CTR predictor as
a process reward model and employing list-wise preference alignment to maximize
the click probability of the generated query list. Furthermore, recognizing the
inconsistency between LLM knowledge and proactive search intents arising from
the separation of user-initiated queries from models, we align LLMs with user
initiative via retrieving co-occurrence queries as side information when
historical logs are available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation
  with User History Encoding and Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Zhang, Bo Hu, Weidong Chen, Zhendong Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) have proven effective in leveraging
textual data for recommendations, their application to multimodal
recommendation tasks remains relatively underexplored. Although LLMs can
process multimodal information through projection functions that map visual
features into their semantic space, recommendation tasks often require
representing users' history interactions through lengthy prompts combining text
and visual elements, which not only hampers training and inference efficiency
but also makes it difficult for the model to accurately capture user
preferences from complex and extended prompts, leading to reduced
recommendation performance. To address this challenge, we introduce HistLLM, an
innovative multimodal recommendation framework that integrates textual and
visual features through a User History Encoding Module (UHEM), compressing
multimodal user history interactions into a single token representation,
effectively facilitating LLMs in processing user preferences. Extensive
experiments demonstrate the effectiveness and efficiency of our proposed
mechanism.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of Personalization: From RAG to Agent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10147v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10147v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopeng Li, Pengyue Jia, Derong Xu, Yi Wen, Yingyi Zhang, Wenlin Zhang, Wanyu Wang, Yichao Wang, Zhaocheng Du, Xiangyang Li, Yong Liu, Huifeng Guo, Ruiming Tang, Xiangyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalization has become an essential capability in modern AI systems,
enabling customized interactions that align with individual user preferences,
contexts, and goals. Recent research has increasingly concentrated on
Retrieval-Augmented Generation (RAG) frameworks and their evolution into more
advanced agent-based architectures within personalized settings to enhance user
satisfaction. Building on this foundation, this survey systematically examines
personalization across the three core stages of RAG: pre-retrieval, retrieval,
and generation. Beyond RAG, we further extend its capabilities into the realm
of Personalized LLM-based Agents, which enhance traditional RAG systems with
agentic functionalities, including user understanding, personalized planning
and execution, and dynamic generation. For both personalization in RAG and
agent-based personalization, we provide formal definitions, conduct a
comprehensive review of recent literature, and summarize key datasets and
evaluation metrics. Additionally, we discuss fundamental challenges,
limitations, and promising research directions in this evolving field. Relevant
papers and resources are continuously updated at
https://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Contrastive Learning's Capability of Neighborhood Aggregation
  for Collaborative Filtering <span class="chip">SIGIR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10113v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10113v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Zhang, Yiwen Zhang, Yi Zhang, Lei Sang, Yun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized recommendation is widely used in the web applications, and graph
contrastive learning (GCL) has gradually become a dominant approach in
recommender systems, primarily due to its ability to extract self-supervised
signals from raw interaction data, effectively alleviating the problem of data
sparsity. A classic GCL-based method typically uses data augmentation during
graph convolution to generates more contrastive views, and performs contrast on
these new views to obtain rich self-supervised signals. Despite this paradigm
is effective, the reasons behind the performance gains remain a mystery. In
this paper, we first reveal via theoretical derivation that the gradient
descent process of the CL objective is formally equivalent to graph
convolution, which implies that CL objective inherently supports neighborhood
aggregation on interaction graphs. We further substantiate this capability
through experimental validation and identify common misconceptions in the
selection of positive samples in previous methods, which limit the potential of
CL objective. Based on this discovery, we propose the Light Contrastive
Collaborative Filtering (LightCCF) method, which introduces a novel
neighborhood aggregation objective to bring users closer to all interacted
items while pushing them away from other positive pairs, thus achieving
high-quality neighborhood aggregation with very low time complexity. On three
highly sparse public datasets, the proposed method effectively aggregate
neighborhood information while preventing graph over-smoothing, demonstrating
significant improvements over existing GCL-based counterparts in both training
efficiency and recommendation accuracy. Our implementations are publicly
accessible.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing LLM-based Recommendation through Semantic-Aligned
  Collaborative Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10107v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10107v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihan Wang, Jinghao Lin, Xiaocui Yang, Yongkang Liu, Shi Feng, Daling Wang, Yifei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) demonstrate remarkable capabilities in
leveraging comprehensive world knowledge and sophisticated reasoning mechanisms
for recommendation tasks. However, a notable limitation lies in their inability
to effectively model sparse identifiers (e.g., user and item IDs), unlike
conventional collaborative filtering models (Collabs.), thus hindering LLM to
learn distinctive user-item representations and creating a performance
bottleneck. Prior studies indicate that integrating collaborative knowledge
from Collabs. into LLMs can mitigate the above limitations and enhance their
recommendation performance. Nevertheless, the significant discrepancy in
knowledge distribution and semantic space between LLMs and Collab. presents
substantial challenges for effective knowledge transfer. To tackle these
challenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving
alignment between the semantic spaces of Collabs. and LLMs. This alignment
fosters effective knowledge fusion, mitigating the influence of discriminative
noise and facilitating the deep integration of knowledge from diverse models.
Specifically, three special tokens with collaborative knowledge are embedded
into the LLM's semantic space through a hybrid projection layer and integrated
into task-specific prompts to guide the recommendation process. Experiments
conducted on two public benchmark datasets (MovieLens-1M and Amazon Book)
demonstrate that SeLLa-Rec achieves state-of-the-art performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Session-based Recommender Systems: User Interest as a Stochastic Process
  in the Latent Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10005v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10005v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Klaudia Balcer, Piotr Lipinski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper jointly addresses the problem of data uncertainty, popularity
bias, and exposure bias in session-based recommender systems. We study the
symptoms of this bias both in item embeddings and in recommendations. We
propose treating user interest as a stochastic process in the latent space and
providing a model-agnostic implementation of this mathematical concept. The
proposed stochastic component consists of elements: debiasing item embeddings
with regularization for embedding uniformity, modeling dense user interest from
session prefixes, and introducing fake targets in the data to simulate extended
exposure. We conducted computational experiments on two popular benchmark
datasets, Diginetica and YooChoose 1/64, as well as several modifications of
the YooChoose dataset with different ratios of popular items. The results show
that the proposed approach allows us to mitigate the challenges mentioned.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Precomputation and Caching in Information Retrieval Experiments with
  Pipeline Architectures <span class="chip">ECIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09984v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09984v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sean MacAvaney, Craig Macdonald
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern information retrieval systems often rely on multiple components
executed in a pipeline. In a research setting, this can lead to substantial
redundant computations (e.g., retrieving the same query multiple times for
evaluating different downstream rerankers). To overcome this, researchers take
cached "result" files as inputs, which represent the output of another
pipeline. However, these result files can be brittle and can cause a disconnect
between the conceptual design of the pipeline and its logical implementation.
To overcome both the redundancy problem (when executing complete pipelines) and
the disconnect problem (when relying on intermediate result files), we describe
our recent efforts to improve the caching capabilities in the open-source
PyTerrier IR platform. We focus on two main directions: (1) automatic implicit
caching of common pipeline prefixes when comparing systems and (2) explicit
caching of operations through a new extension package, pyterrier-caching. These
approaches allow for the best of both worlds: pipelines can be fully expressed
end-to-end, while also avoiding redundant computations between pipelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WOWS @ ECIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Constrained Auto-Regressive Decoding Constrains Generative Retrieval <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09935v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09935v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiguang Wu, Zhaochun Ren, Xin Xin, Jiyuan Yang, Mengqi Zhang, Zhumin Chen, Maarten de Rijke, Pengjie Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative retrieval seeks to replace traditional search index data
structures with a single large-scale neural network, offering the potential for
improved efficiency and seamless integration with generative large language
models. As an end-to-end paradigm, generative retrieval adopts a learned
differentiable search index to conduct retrieval by directly generating
document identifiers through corpus-specific constrained decoding. The
generalization capabilities of generative retrieval on out-of-distribution
corpora have gathered significant attention.
  In this paper, we examine the inherent limitations of constrained
auto-regressive generation from two essential perspectives: constraints and
beam search. We begin with the Bayes-optimal setting where the generative
retrieval model exactly captures the underlying relevance distribution of all
possible documents. Then we apply the model to specific corpora by simply
adding corpus-specific constraints. Our main findings are two-fold: (i) For the
effect of constraints, we derive a lower bound of the error, in terms of the KL
divergence between the ground-truth and the model-predicted step-wise marginal
distributions. (ii) For the beam search algorithm used during generation, we
reveal that the usage of marginal distributions may not be an ideal approach.
This paper aims to improve our theoretical understanding of the generalization
capabilities of the auto-regressive decoding retrieval paradigm, laying a
foundation for its limitations and inspiring future advancements toward more
robust and generalizable generative retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures, 2 tables, accepted by SIGIR 2025 (Proceedings of
  the 48th International ACM SIGIR Conference on Research and Development in
  Information Retrieval)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StePO-Rec: Towards Personalized Outfit Styling Assistant via
  Knowledge-Guided Multi-Step Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09915v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09915v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxi Bi, Yunfan Gao, Haofen Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in Generative AI offers new opportunities for FashionAI,
surpassing traditional recommendation systems that often lack transparency and
struggle to integrate expert knowledge, leaving the potential for personalized
fashion styling remain untapped. To address these challenges, we present PAFA
(Principle-Aware Fashion), a multi-granular knowledge base that organizes
professional styling expertise into three levels of metadata, domain
principles, and semantic relationships. Using PAFA, we develop StePO-Rec, a
knowledge-guided method for multi-step outfit recommendation. StePO-Rec
provides structured suggestions using a scenario-dimension-attribute framework,
employing recursive tree construction to align recommendations with both
professional principles and individual preferences. A preference-trend
re-ranking system further adapts to fashion trends while maintaining the
consistency of the user's original style. Experiments on the widely used
personalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in
MAP. Furthermore, case studies highlight improved explainability, traceability,
result reliability, and the seamless integration of expertise and
personalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Constructing Micro Knowledge Graphs from Technical Support Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09877v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09877v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atul Kumar, Nisha Gupta, Saswati Dana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Short technical support pages such as IBM Technotes are quite common in
technical support domain. These pages can be very useful as the knowledge
sources for technical support applications such as chatbots, search engines and
question-answering (QA) systems. Information extracted from documents to drive
technical support applications is often stored in the form of Knowledge Graph
(KG). Building KGs from a large corpus of documents poses a challenge of
granularity because a large number of entities and actions are present in each
page. The KG becomes virtually unusable if all entities and actions from these
pages are stored in the KG. Therefore, only key entities and actions from each
page are extracted and stored in the KG. This approach however leads to loss of
knowledge represented by entities and actions left out of the KG as they are no
longer available to graph search and reasoning functions. We propose a set of
techniques to create micro knowledge graph (micrograph) for each of such web
pages. The micrograph stores all the entities and actions in a page and also
takes advantage of the structure of the page to represent exactly in which part
of that page these entities and actions appeared, and also how they relate to
each other. These micrographs can be used as additional knowledge sources by
technical support applications. We define schemas for representing
semi-structured and plain text knowledge present in the technical support web
pages. Solutions in technical support domain include procedures made of steps.
We also propose a technique to extract procedures from these webpages and the
schemas to represent them in the micrographs. We also discuss how technical
support applications can take advantage of the micrographs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAKG:Document-level Retrieval Augmented Knowledge Graph Construction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09823v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09823v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hairong Zhang, Jiaheng Si, Guohang Yan, Boyuan Qi, Pinlong Cai, Song Mao, Ding Wang, Botian Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rise of knowledge graph based retrieval-augmented generation (RAG)
techniques such as GraphRAG and Pike-RAG, the role of knowledge graphs in
enhancing the reasoning capabilities of large language models (LLMs) has become
increasingly prominent. However, traditional Knowledge Graph Construction (KGC)
methods face challenges like complex entity disambiguation, rigid schema
definition, and insufficient cross-document knowledge integration. This paper
focuses on the task of automatic document-level knowledge graph construction.
It proposes the Document-level Retrieval Augmented Knowledge Graph Construction
(RAKG) framework. RAKG extracts pre-entities from text chunks and utilizes
these pre-entities as queries for RAG, effectively addressing the issue of
long-context forgetting in LLMs and reducing the complexity of Coreference
Resolution. In contrast to conventional KGC methods, RAKG more effectively
captures global information and the interconnections among disparate nodes,
thereby enhancing the overall performance of the model. Additionally, we
transfer the RAG evaluation framework to the KGC field and filter and evaluate
the generated knowledge graphs, thereby avoiding incorrectly generated entities
and relationships caused by hallucinations in LLMs. We further developed the
MINE dataset by constructing standard knowledge graphs for each article and
experimentally validated the performance of RAKG. The results show that RAKG
achieves an accuracy of 95.91 % on the MINE dataset, a 6.2 % point improvement
over the current best baseline, GraphRAG (89.71 %). The code is available at
https://github.com/LMMApplication/RAKG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Augmented Relevance <span class="highlight-title">Dataset</span>s with Fine-Tuned Small LLMs <span class="chip">WSDM '25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09816v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09816v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quentin Fitte-Rey, Matyas Amrouche, Romain Deveaud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building high-quality datasets and labeling query-document relevance are
essential yet resource-intensive tasks, requiring detailed guidelines and
substantial effort from human annotators. This paper explores the use of small,
fine-tuned large language models (LLMs) to automate relevance assessment, with
a focus on improving ranking models' performance by augmenting their training
dataset. We fine-tuned small LLMs to enhance relevance assessments, thereby
improving dataset creation quality for downstream ranking model training. Our
experiments demonstrate that these fine-tuned small LLMs not only outperform
certain closed source models on our dataset but also lead to substantial
improvements in ranking model performance. These results highlight the
potential of leveraging small LLMs for efficient and scalable dataset
augmentation, providing a practical solution for search engine optimization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, and 6 tables. Accepted and presented to LLM4EVAL
  at WSDM '25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryota Tanaka, Taichi Iki, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Jun Suzuki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We aim to develop a retrieval-augmented generation (RAG) framework that
answers questions over a corpus of visually-rich documents presented in mixed
modalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In
this paper, we introduce a new RAG framework, VDocRAG, which can directly
understand varied documents and modalities in a unified image format to prevent
missing information that occurs by parsing documents to obtain text. To improve
the performance, we propose novel self-supervised pre-training tasks that adapt
large vision-language models for retrieval by compressing visual information
into dense token representations while aligning them with textual content in
documents. Furthermore, we introduce OpenDocVQA, the first unified collection
of open-domain document visual question answering datasets, encompassing
diverse document types and formats. OpenDocVQA provides a comprehensive
resource for training and evaluating retrieval and question answering models on
visually-rich documents in an open-domain setting. Experiments show that
VDocRAG substantially outperforms conventional text-based RAG and has strong
generalization capability, highlighting the potential of an effective RAG
paradigm for real-world documents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025; project page: https://vdocrag.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Trustworthy Answers, Messier Data: Bridging the Gap in Low-Resource
  Retrieval-Augmented Generation for Domain Expert Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19596v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19596v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nayoung Choi, Grace Byun, Andrew Chung, Ellie S. Paek, Shinsun Lee, Jinho D. Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  RAG has become a key technique for enhancing LLMs by reducing hallucinations,
especially in domain expert systems where LLMs may lack sufficient inherent
knowledge. However, developing these systems in low-resource settings
introduces several challenges: (1) handling heterogeneous data sources, (2)
optimizing retrieval phase for trustworthy answers, and (3) evaluating
generated answers across diverse aspects. To address these, we introduce a data
generation pipeline that transforms raw multi-modal data into structured corpus
and Q&A pairs, an advanced re-ranking phase improving retrieval precision, and
a reference matching algorithm enhancing answer traceability. Applied to the
automotive engineering domain, our system improves factual correctness (+1.94),
informativeness (+1.16), and helpfulness (+1.67) over a non-RAG baseline, based
on a 1-5 scale by an LLM judge. These results highlight the effectiveness of
our approach across distinct aspects, with strong answer grounding and
transparency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Snippet-based Conversational Recommender System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06064v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06064v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haibo Sun, Naoki Otani, Hannah Kim, Dan Zhang, Nikita Bhutani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Recommender Systems (CRS) engage users in interactive
dialogues to gather preferences and provide personalized recommendations. While
existing studies have advanced conversational strategies, they often rely on
predefined attributes or expensive, domain-specific annotated datasets, which
limits their flexibility in handling diverse user preferences and adaptability
across domains. We propose SnipRec, a novel resource-efficient approach that
leverages user-generated content, such as customer reviews, to capture a
broader range of user expressions. By employing large language models to map
reviews and user responses into concise snippets, SnipRec represents user
preferences and retrieves relevant items without the need for intensive manual
data collection or fine-tuning. Experiments across the restaurant, book, and
clothing domains show that snippet-based representations outperform document-
and sentence-based representations, achieving Hits@10 of 0.25-0.55 with 3,000
to 10,000 candidate items while successfully handling free-form user responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Do Recommendation Models Amplify Popularity Bias? An Analysis from
  the Spectral Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12008v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12008v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyi Lin, Chongming Gao, Jiawei Chen, Sheng Zhou, Binbin Hu, Yan Feng, Chun Chen, Can Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation Systems (RS) are often plagued by popularity bias. When
training a recommendation model on a typically long-tailed dataset, the model
tends to not only inherit this bias but often exacerbate it, resulting in
over-representation of popular items in the recommendation lists. This study
conducts comprehensive empirical and theoretical analyses to expose the root
causes of this phenomenon, yielding two core insights: 1) Item popularity is
memorized in the principal spectrum of the score matrix predicted by the
recommendation model; 2) The dimension collapse phenomenon amplifies the
relative prominence of the principal spectrum, thereby intensifying the
popularity bias. Building on these insights, we propose a novel debiasing
strategy that leverages a spectral norm regularizer to penalize the magnitude
of the principal singular value. We have developed an efficient algorithm to
expedite the calculation of the spectral norm by exploiting the spectral
property of the score matrix. Extensive experiments across seven real-world
datasets and three testing paradigms have been conducted to validate the
superiority of the proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Weighted Tensor Decompositions for Context-aware Collaborative Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08393v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08393v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joey De Pauw, Bart Goethals
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over recent years it has become well accepted that user interest is not
static or immutable. There are a variety of contextual factors, such as time of
day, the weather or the user's mood, that influence the current interests of
the user. Modelling approaches need to take these factors into account if they
want to succeed at finding the most relevant content to recommend given the
situation.
  A popular method for context-aware recommendation is to encode context
attributes as extra dimensions of the classic user-item interaction matrix,
effectively turning it into a tensor, followed by applying the appropriate
tensor decomposition methods to learn missing values. However, unlike with
matrix factorization, where all decompositions are essentially a product of
matrices, there exist many more options for decomposing tensors by combining
vector, matrix and tensor products. We study the most successful decomposition
methods that use weighted square loss and categorize them based on their tensor
structure and regularization strategy. Additionally, we further extend the pool
of methods by filling in the missing combinations.
  In this paper we provide an overview of the properties of the different
decomposition methods, such as their complexity, scalability, and modelling
capacity. These benefits are then contrasted with the performances achieved in
offline experiments to gain more insight into which method to choose depending
on a specific situation and constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Workshop on Context-Aware Recommender Systems, September 18, 2023,
  Singapore</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Offline Metrics Measure Explanation Goals? A Comparative <span class="highlight-title">Survey</span>
  Analysis of Offline Explanation Metrics in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.14379v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.14379v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        André Levi Zanon, Marcelo Garcia Manzato, Leonardo Rocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explanations in a Recommender System (RS) provide reasons for recommendations
to users and can enhance transparency, persuasiveness, engagement, and
trust-known as explanation goals. Evaluating the effectiveness of explanation
algorithms offline remains challenging due to subjectivity. Initially, we
conducted a literature review on current offline metrics, revealing that
algorithms are often assessed with anecdotal evidence, offering convincing
examples, or with metrics that don't align with human perception. We
investigated whether, in explanations connecting interacted and recommended
items based on shared content, the selection of item attributes and interacted
items affects explanation goals. Metrics measuring the diversity and popularity
of attributes and the recency of item interactions were used to evaluate
explanations from three state-of-the-art agnostic algorithms across six
recommendation systems. These offline metrics were compared with results from
an online user study. Our findings reveal a trade-off: transparency and trust
relate to popular properties, while engagement and persuasiveness are linked to
diversified properties. This study contributes to the development of more
robust evaluation methods for explanation algorithms in recommender systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ External Large Foundation Model: How to Efficiently Serve Trillions of
  Parameters for Online Ads Recommendation <span class="chip">WWW</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17494v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17494v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingfu Liang, Xi Liu, Rong Jin, Boyang Liu, Qiuling Suo, Qinghai Zhou, Song Zhou, Laming Chen, Hua Zheng, Zhiyuan Li, Shali Jiang, Jiyan Yang, Xiaozhen Xia, Fan Yang, Yasmine Badr, Ellie Wen, Shuyu Xu, Hansey Chen, Zhengyu Zhang, Jade Nie, Chunzhi Yang, Zhichen Zeng, Weilin Zhang, Xingliang Huang, Qianru Li, Shiquan Wang, Evelyn Lyu, Wenjing Lu, Rui Zhang, Wenjun Wang, Jason Rudy, Mengyue Hang, Kai Wang, Yinbin Ma, Shuaiwen Wang, Sihan Zeng, Tongyi Tang, Xiaohan Wei, Longhao Jin, Jamey Zhang, Marcus Chen, Jiayi Zhang, Angie Huang, Chi Zhang, Zhengli Zhao, Jared Yang, Qiang Jin, Xian Chen, Amit Anand Amlesahwaram, Lexi Song, Liang Luo, Yuchen Hao, Nan Xiao, Yavuz Yetim, Luoshang Pan, Gaoxiang Liu, Yuxi Hu, Yuzhen Huang, Jackie Xu, Rich Zhu, Xin Zhang, Yiqun Liu, Hang Yin, Yuxin Chen, Buyun Zhang, Xiaoyi Liu, Xingyuan Wang, Wenguang Mao, Zhijing Li, Zhehui Zhou, Feifan Gu, Qin Huang, Chonglin Sun, Nancy Yu, Shuo Gu, Shupin Mao, Benjamin Au, Jingzheng Qin, Peggy Yao, Jae-Woo Choi, Bin Gao, Ernest Wang, Lei Zhang, Wen-Yen Chen, Ted Lee, Jay Zha, Yi Meng, Alex Gong, Edison Gao, Alireza Vahdatpour, Yiping Han, Yantao Yao, Toshinari Kureha, Shuo Chang, Musharaf Sultan, John Bocharov, Sagar Chordia, Xiaorui Gan, Peng Sun, Rocky Liu, Bo Long, Wenlin Chen, Santanu Kolay, Huayu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ads recommendation is a prominent service of online advertising systems and
has been actively studied. Recent studies indicate that scaling-up and advanced
design of the recommendation model can bring significant performance
improvement. However, with a larger model scale, such prior studies have a
significantly increasing gap from industry as they often neglect two
fundamental challenges in industrial-scale applications. First, training and
inference budgets are restricted for the model to be served, exceeding which
may incur latency and impair user experience. Second, large-volume data arrive
in a streaming mode with data distributions dynamically shifting, as new
users/ads join and existing users/ads leave the system. We propose the External
Large Foundation Model (ExFM) framework to address the overlooked challenges.
Specifically, we develop external distillation and a data augmentation system
(DAS) to control the computational cost of training/inference while maintaining
high performance. We design the teacher in a way like a foundation model (FM)
that can serve multiple students as vertical models (VMs) to amortize its
building cost. We propose Auxiliary Head and Student Adapter to mitigate the
data distribution gap between FM and VMs caused by the streaming data issue.
Comprehensive experiments on internal industrial-scale applications and public
datasets demonstrate significant performance gain by ExFM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the ACM Web Conference (WWW) 2025 Industrial Track as
  Oral Presentation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Augmentation as Free Lunch: Exploring the Test-Time Augmentation
  for Sequential Recommendation <span class="chip">SIGIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04843v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04843v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhou Dang, Yuting Liu, Enneng Yang, Minhan Huang, Guibing Guo, Jianzhe Zhao, Xingwei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data augmentation has become a promising method of mitigating data sparsity
in sequential recommendation. Existing methods generate new yet effective data
during model training to improve performance. However, deploying them requires
retraining, architecture modification, or introducing additional learnable
parameters. The above steps are time-consuming and costly for well-trained
models, especially when the model scale becomes large. In this work, we explore
the test-time augmentation (TTA) for sequential recommendation, which augments
the inputs during the model inference and then aggregates the model's
predictions for augmented data to improve final accuracy. It avoids significant
time and cost overhead from loss calculation and backward propagation. We first
experimentally disclose the potential of existing augmentation operators for
TTA and find that the Mask and Substitute consistently achieve better
performance. Further analysis reveals that these two operators are effective
because they retain the original sequential pattern while adding appropriate
perturbations. Meanwhile, we argue that these two operators still face
time-consuming item selection or interference information from mask tokens.
Based on the analysis and limitations, we present TNoise and TMask. The former
injects uniform noise into the original representation, avoiding the
computational overhead of item selection. The latter blocks mask token from
participating in model calculations or directly removes interactions that
should have been replaced with mask tokens. Comprehensive experiments
demonstrate the effectiveness, efficiency, and generalizability of our method.
We provide an anonymous implementation at https://github.com/KingGugu/TTA4SR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SIGIR 2025 Full Paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Pre-train</span>ing Generative Recommender with Multi-Identifier Item
  Tokenization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04400v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04400v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Zheng, Enze Liu, Zhongfu Chen, Zhongrui Ma, Yue Wang, Wayne Xin Zhao, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative recommendation autoregressively generates item identifiers to
recommend potential items. Existing methods typically adopt a one-to-one
mapping strategy, where each item is represented by a single identifier.
However, this scheme poses issues, such as suboptimal semantic modeling for
low-frequency items and limited diversity in token sequence data. To overcome
these limitations, we propose MTGRec, which leverages Multi-identifier item
Tokenization to augment token sequence data for Generative Recommender
pre-training. Our approach involves two key innovations: multi-identifier item
tokenization and curriculum recommender pre-training. For multi-identifier item
tokenization, we leverage the RQ-VAE as the tokenizer backbone and treat model
checkpoints from adjacent training epochs as semantically relevant tokenizers.
This allows each item to be associated with multiple identifiers, enabling a
single user interaction sequence to be converted into several token sequences
as different data groups. For curriculum recommender pre-training, we introduce
a curriculum learning scheme guided by data influence estimation, dynamically
adjusting the sampling probability of each data group during recommender
pre-training. After pre-training, we fine-tune the model using a single
tokenizer to ensure accurate item identification for recommendation. Extensive
experiments on three public benchmark datasets demonstrate that MTGRec
significantly outperforms both traditional and generative recommendation
baselines in terms of effectiveness and scalability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Universal Item Tokenization for Transferable Generative Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.04405v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.04405v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Zheng, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, generative recommendation has emerged as a promising paradigm,
attracting significant research attention. The basic framework involves an item
tokenizer, which represents each item as a sequence of codes serving as its
identifier, and a generative recommender that predicts the next item by
autoregressively generating the target item identifier. However, in existing
methods, both the tokenizer and the recommender are typically domain-specific,
limiting their ability for effective transfer or adaptation to new domains. To
this end, we propose UTGRec, a Universal item Tokenization approach for
transferable Generative Recommendation. Specifically, we design a universal
item tokenizer for encoding rich item semantics by adapting a multimodal large
language model (MLLM). By devising tree-structured codebooks, we discretize
content representations into corresponding codes for item tokenization. To
effectively learn the universal item tokenizer on multiple domains, we
introduce two key techniques in our approach. For raw content reconstruction,
we employ dual lightweight decoders to reconstruct item text and images from
discrete representations to capture general knowledge embedded in the content.
For collaborative knowledge integration, we assume that co-occurring items are
similar and integrate collaborative signals through co-occurrence alignment and
reconstruction. Finally, we present a joint learning framework to pre-train and
adapt the transferable generative recommender across multiple domains.
Extensive experiments on four public datasets demonstrate the superiority of
UTGRec compared to both traditional and generative recommendation baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-view Intent Learning and Alignment with Large Language Models for
  Session-based Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13840v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13840v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shutong Qiao, Wei Zhou, Junhao Wen, Chen Gao, Qun Luo, Peixuan Chen, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based recommendation (SBR) methods often rely on user behavior data,
which can struggle with the sparsity of session data, limiting performance.
Researchers have identified that beyond behavioral signals, rich semantic
information in item descriptions is crucial for capturing hidden user intent.
While large language models (LLMs) offer new ways to leverage this semantic
data, the challenges of session anonymity, short-sequence nature, and high LLM
training costs have hindered the development of a lightweight, efficient LLM
framework for SBR.
  To address the above challenges, we propose an LLM-enhanced SBR framework
that integrates semantic and behavioral signals from multiple views. This
two-stage framework leverages the strengths of both LLMs and traditional SBR
models while minimizing training costs. In the first stage, we use multi-view
prompts to infer latent user intentions at the session semantic level,
supported by an intent localization module to alleviate LLM hallucinations. In
the second stage, we align and unify these semantic inferences with behavioral
representations, effectively merging insights from both large and small models.
Extensive experiments on two real datasets demonstrate that the LLM4SBR
framework can effectively improve model performance. We release our codes along
with the baselines at https://github.com/tsinghua-fib-lab/LLM4SBR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RAG-VR: Leveraging Retrieval-Augmented Generation for 3D Question
  Answering in VR Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.08256v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.08256v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiyi Ding, Ying Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models (LLMs) provide new opportunities for
context understanding in virtual reality (VR). However, VR contexts are often
highly localized and personalized, limiting the effectiveness of
general-purpose LLMs. To address this challenge, we present RAG-VR, the first
3D question-answering system for VR that incorporates retrieval-augmented
generation (RAG), which augments an LLM with external knowledge retrieved from
a localized knowledge database to improve the answer quality. RAG-VR includes a
pipeline for extracting comprehensive knowledge about virtual environments and
user conditions for accurate answer generation. To ensure efficient retrieval,
RAG-VR offloads the retrieval process to a nearby edge server and uses only
essential information during retrieval. Moreover, we train the retriever to
effectively distinguish among relevant, irrelevant, and hard-to-differentiate
information in relation to questions. RAG-VR improves answer accuracy by
17.9%-41.8% and reduces end-to-end latency by 34.5%-47.3% compared with two
baseline systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>GenAI-XR 2025 Workshop, co-located with 2025 IEEE Conference on
  Virtual Reality and 3D User Interfaces (VR)</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HippoMM: Hippocampal-inspired Multimodal Memory for Long Audiovisual
  Event Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10739v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10739v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yueqian Lin, Qinsi Wang, Hancheng Ye, Yuzhe Fu, Hai "Helen" Li, Yiran Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Comprehending extended audiovisual experiences remains a fundamental
challenge for computational systems. Current approaches struggle with temporal
integration and cross-modal associations that humans accomplish effortlessly
through hippocampal-cortical networks. We introduce HippoMM, a
biologically-inspired architecture that transforms hippocampal mechanisms into
computational advantages for multimodal understanding. HippoMM implements three
key innovations: (i) hippocampus-inspired pattern separation and completion
specifically designed for continuous audiovisual streams, (ii) short-to-long
term memory consolidation that transforms perceptual details into semantic
abstractions, and (iii) cross-modal associative retrieval pathways enabling
modality-crossing queries. Unlike existing retrieval systems with static
indexing schemes, HippoMM dynamically forms integrated episodic representations
through adaptive temporal segmentation and dual-process memory encoding.
Evaluations on our challenging HippoVlog benchmark demonstrate that HippoMM
significantly outperforms state-of-the-art approaches (78.2% vs. 64.2%
accuracy) while providing substantially faster response times (20.4s vs.
112.5s). Our results demonstrate that translating neuroscientific memory
principles into computational architectures provides a promising foundation for
next-generation multimodal understanding systems. The code and benchmark
dataset are publicly available at https://github.com/linyueqian/HippoMM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention GhostUNet++: Enhanced Segmentation of Adipose Tissue and Liver
  in CT Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.11491v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.11491v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mansoor Hayat, Supavadee Aramvith, Subrata Bhattacharjee, Nouman Ahmad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate segmentation of abdominal adipose tissue, including subcutaneous
(SAT) and visceral adipose tissue (VAT), along with liver segmentation, is
essential for understanding body composition and associated health risks such
as type 2 diabetes and cardiovascular disease. This study proposes Attention
GhostUNet++, a novel deep learning model incorporating Channel, Spatial, and
Depth Attention mechanisms into the Ghost UNet++ bottleneck for automated,
precise segmentation. Evaluated on the AATTCT-IDS and LiTS datasets, the model
achieved Dice coefficients of 0.9430 for VAT, 0.9639 for SAT, and 0.9652 for
liver segmentation, surpassing baseline models. Despite minor limitations in
boundary detail segmentation, the proposed model significantly enhances feature
refinement, contextual understanding, and computational efficiency, offering a
robust solution for body composition analysis. The implementation of the
proposed Attention GhostUNet++ model is available
at:https://github.com/MansoorHayat777/Attention-GhostUNetPlusPlus.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation in the 47th Annual International Conference
  of the IEEE Engineering in Medicine and Biology Society (EMBC 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multimodal Long Video Modeling Based on Temporal Dynamic Context 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10443v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10443v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Hao, Jiaming Han, Yiyuan Zhang, Xiangyu Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Large Language Models (LLMs) have led to significant
breakthroughs in video understanding. However, existing models still struggle
with long video processing due to the context length constraint of LLMs and the
vast amount of information within the video. Although some recent methods are
designed for long video understanding, they often lose crucial information
during token compression and struggle with additional modality like audio. In
this work, we propose a dynamic long video encoding method utilizing the
temporal relationship between frames, named Temporal Dynamic Context (TDC).
Firstly, we segment the video into semantically consistent scenes based on
inter-frame similarities, then encode each frame into tokens using visual-audio
encoders. Secondly, we propose a novel temporal context compressor to reduce
the number of tokens within each segment. Specifically, we employ a query-based
Transformer to aggregate video, audio, and instruction text tokens into a
limited set of temporal context tokens. Finally, we feed the static frame
tokens and the temporal context tokens into the LLM for video understanding.
Furthermore, to handle extremely long videos, we propose a training-free
chain-of-thought strategy that progressively extracts answers from multiple
video segments. These intermediate answers serve as part of the reasoning
process and contribute to the final answer. We conduct extensive experiments on
general video understanding and audio-video understanding benchmarks, where our
method demonstrates strong performance. The code and models are available at
https://github.com/Hoar012/TDC-Video.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a
  Novel Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10258v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10258v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Liu, Youmeng Li, Jizeng Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document Reading Order Recovery is a fundamental task in document image
understanding, playing a pivotal role in enhancing Retrieval-Augmented
Generation (RAG) and serving as a critical preprocessing step for large
language models (LLMs). Existing methods often struggle with complex
layouts(e.g., multi-column newspapers), high-overhead interactions between
cross-modal elements (visual regions and textual semantics), and a lack of
robust evaluation benchmarks. We introduce XY-Cut++, an advanced layout
ordering method that integrates pre-mask processing, multi-granularity
segmentation, and cross-modal matching to address these challenges. Our method
significantly enhances layout ordering accuracy compared to traditional XY-Cut
techniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8
BLEU overall) while maintaining simplicity and efficiency. It outperforms
existing baselines by up to 24\% and demonstrates consistent accuracy across
simple and complex layouts on the newly introduced DocBench-100 dataset. This
advancement establishes a reliable foundation for document structure recovery,
setting a new standard for layout ordering tasks and facilitating more
effective RAG and LLM preprocessing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam
  Annealing Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengfei Hu, Zhenrong Zhang, Qikai Chang, Shuhang Liu, Jiefeng Ma, Jun Du, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma, Qingfeng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work increasingly focuses on improving the reasoning capabilities of
Multimodal Large Language Models (MLLMs). Among existing methods, Process
Reward Models (PRMs) stand out for offering dense, step-wise supervision to
guide intermediate reasoning. However, how to effectively integrate PRMs into
search strategies remains an open question. In this paper, we introduce PRM-BAS
(PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided
reasoning that dynamically adjusts beam size -- starting with a broader search
space and gradually narrowing it as contextual information accumulates, thereby
balancing performance and efficiency. We further propose a unified framework
for data construction and PRM training. Specifically, we construct the
PRM-BAS-300k dataset by selecting 300k questions from existing datasets and
performing rollouts at each step to estimate the probability of reaching a
correct final answer. The PRM is then trained using a combination of value loss
for absolute action quality and rank loss for relative action quality.
Extensive experiments on challenging multimodal reasoning benchmarks
demonstrate that PRM-BAS significantly improves reasoning performance while
maintaining low computational cost. Moreover, it generalizes well across
different model scales and architectures, showcasing strong robustness and
plug-and-play capability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented
  LLMs for Social Media Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10166v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10166v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arka Ujjal Dey, Muhammad Junaid Awan, Georgia Channing, Christian Schroeder de Witt, John Collomosse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose CRAVE (Cluster-based Retrieval Augmented Verification with
Explanation); a novel framework that integrates retrieval-augmented Large
Language Models (LLMs) with clustering techniques to address fact-checking
challenges on social media. CRAVE automatically retrieves multimodal evidence
from diverse, often contradictory, sources. Evidence is clustered into coherent
narratives, and evaluated via an LLM-based judge to deliver fact-checking
verdicts explained by evidence summaries. By synthesizing evidence from both
text and image modalities and incorporating agent-based refinement, CRAVE
ensures consistency and diversity in evidence representation. Comprehensive
experiments demonstrate CRAVE's efficacy in retrieval precision, clustering
quality, and judgment accuracy, showcasing its potential as a robust
decision-support tool for fact-checkers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation
  with User History Encoding and Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.10150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.10150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Zhang, Bo Hu, Weidong Chen, Zhendong Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) have proven effective in leveraging
textual data for recommendations, their application to multimodal
recommendation tasks remains relatively underexplored. Although LLMs can
process multimodal information through projection functions that map visual
features into their semantic space, recommendation tasks often require
representing users' history interactions through lengthy prompts combining text
and visual elements, which not only hampers training and inference efficiency
but also makes it difficult for the model to accurately capture user
preferences from complex and extended prompts, leading to reduced
recommendation performance. To address this challenge, we introduce HistLLM, an
innovative multimodal recommendation framework that integrates textual and
visual features through a User History Encoding Module (UHEM), compressing
multimodal user history interactions into a single token representation,
effectively facilitating LLMs in processing user preferences. Extensive
experiments demonstrate the effectiveness and efficiency of our proposed
mechanism.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Omni-Dish: Photorealistic and Faithful Image Generation and Editing for
  Arbitrary Chinese Dishes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09948v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09948v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huijie Liu, Bingcan Wang, Jie Hu, Xiaoming Wei, Guoliang Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dish images play a crucial role in the digital era, with the demand for
culturally distinctive dish images continuously increasing due to the
digitization of the food industry and e-commerce. In general cases, existing
text-to-image generation models excel in producing high-quality images;
however, they struggle to capture diverse characteristics and faithful details
of specific domains, particularly Chinese dishes. To address this limitation,
we propose Omni-Dish, the first text-to-image generation model specifically
tailored for Chinese dishes. We develop a comprehensive dish curation pipeline,
building the largest dish dataset to date. Additionally, we introduce a
recaption strategy and employ a coarse-to-fine training scheme to help the
model better learn fine-grained culinary nuances. During inference, we enhance
the user's textual input using a pre-constructed high-quality caption library
and a large language model, enabling more photorealistic and faithful image
generation. Furthermore, to extend our model's capability for dish editing
tasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish
editing dataset and train a specialized editing model. Extensive experiments
demonstrate the superiority of our methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 10 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StePO-Rec: Towards Personalized Outfit Styling Assistant via
  Knowledge-Guided Multi-Step Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09915v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09915v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxi Bi, Yunfan Gao, Haofen Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in Generative AI offers new opportunities for FashionAI,
surpassing traditional recommendation systems that often lack transparency and
struggle to integrate expert knowledge, leaving the potential for personalized
fashion styling remain untapped. To address these challenges, we present PAFA
(Principle-Aware Fashion), a multi-granular knowledge base that organizes
professional styling expertise into three levels of metadata, domain
principles, and semantic relationships. Using PAFA, we develop StePO-Rec, a
knowledge-guided method for multi-step outfit recommendation. StePO-Rec
provides structured suggestions using a scenario-dimension-attribute framework,
employing recursive tree construction to align recommendations with both
professional principles and individual preferences. A preference-trend
re-ranking system further adapts to fashion trends while maintaining the
consistency of the user's original style. Experiments on the widely used
personalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in
MAP. Furthermore, case studies highlight improved explainability, traceability,
result reliability, and the seamless integration of expertise and
personalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in
  Adaptive Video Streaming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09906v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09906v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiqiang He, Zhi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adaptive video streaming systems are designed to optimize Quality of
Experience (QoE) and, in turn, enhance user satisfaction. However, differences
in user profiles and video content lead to different weights for QoE factors,
resulting in user-specific QoE functions and, thus, varying optimization
objectives. This variability poses significant challenges for neural networks,
as they often struggle to generalize under evolving targets - a phenomenon
known as plasticity loss that prevents conventional models from adapting
effectively to changing optimization objectives. To address this limitation, we
propose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning
framework that dynamically modulates network plasticity by balancing memory
retention with selective forgetting. In particular, PA-MoE leverages noise
injection to promote the selective forgetting of outdated knowledge, thereby
endowing neural networks with enhanced adaptive capabilities. In addition, we
present a rigorous theoretical analysis of PA-MoE by deriving a regret bound
that quantifies its learning performance. Experimental evaluations demonstrate
that PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in
dynamic streaming environments. Further analysis reveals that the model
effectively mitigates plasticity loss by optimizing neuron utilization.
Finally, a parameter sensitivity study is performed by injecting varying levels
of noise, and the results align closely with our theoretical predictions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Laugh at Your Own Pace: Basic Performance Evaluation of Language
  Learning Assistance by Adjustment of Video Playback Speeds Based on Laughter
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.09835v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.09835v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naoto Nishida, Hinako Nozaki, Buntarou Shizuki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Among various methods to learn a second language (L2), such as listening and
shadowing, Extensive Viewing involves learning L2 by watching many videos.
However, it is difficult for many L2 learners to smoothly and effortlessly
comprehend video contents made for native speakers at the original speed.
Therefore, we developed a language learning assistance system that
automatically adjusts the playback speed according to the learner's
comprehension. Our system judges that learners understand the contents if they
laugh at the punchlines of comedy dramas, and vice versa. Experimental results
show that this system supports learners with relatively low L2 ability (under
700 in TOEIC Score in the experimental condition) to understand video contents.
Our system can widen learners' possible options of native speakers' videos as
Extensive Viewing material.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive
  Learning: Adapting Alignment Calibration to MERU 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.15166v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.15166v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Àlex Pujol Vidal, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine unlearning methods have become increasingly important for selective
concept removal in large pre-trained models. While recent work has explored
unlearning in Euclidean contrastive vision-language models, the effectiveness
of concept removal in hyperbolic spaces remains unexplored. This paper
investigates machine unlearning in hyperbolic contrastive learning by adapting
Alignment Calibration to MERU, a model that embeds images and text in
hyperbolic space to better capture semantic hierarchies. Through systematic
experiments and ablation studies, we demonstrate that hyperbolic geometry
offers distinct advantages for concept removal, achieving near perfect
forgetting with reasonable performance on retained concepts, particularly when
scaling to multiple concept removal. Our approach introduces
hyperbolic-specific components including entailment calibration and norm
regularization that leverage the unique properties of hyperbolic space.
Comparative analysis with Euclidean models reveals fundamental differences in
unlearning dynamics, with hyperbolic unlearning reorganizing the semantic
hierarchy while Euclidean approaches merely disconnect cross-modal
associations. These findings not only advance machine unlearning techniques but
also provide insights into the geometric properties that influence concept
representation and removal in multimodal models. Source code available at
https://github.com/alex-pv01/HAC
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2025-04-22T05:29:13.620184959Z">
            2025-04-22 05:29:13 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
